[
  {
    "file_path": "./devposts/accompany.html",
    "project_id": "accompany",
    "title": "Accompany",
    "tagline": "Make new friends, make new memories",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "google-geocoding",
      "google-maps",
      "java",
      "sqlite",
      "xml"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration - Our inspiration for Accompany comes from Hackathon itself. Until two weeks before the event we had no idea it even existed until a friend introduced us to it. What we came to realize is that this is a common trend with activities in the DFW Area. We wanted a way to explore the different communities and events in your local area while facilitating making new friends. What it does - Our app is a repository of events in your local area but more than that its centered around meeting new people. We realized that there may be events people want to go to but they may be unable to find others to go with  them....so we developed Accompany. It connects new people into groups based around their interests and events they're planning on attending. How we built it - Our app is built using the Android Studio IDE with java, SQlite, and the Google API Challenges we ran into - Our main challenge in developing Accompany was learning how to develop an Android app. this was a first time experience for all the members of our team. Accomplishments that we're proud of - If learning to develop the Android app was our biggest challenge then it was also our greatest accomplishment. In the short amount of time at Hackathon we learned how to do a variety of different functions in an entirely new system of coding for our team. What we learned - We learned a lot about the design of a product as multiple times we had to go back to pen and paper and chart out how to connect the classes we designed. Overall this was a great experience in real world development of an idea outside of the classroom. What's next for Accompany - While we are happy with our progress, we are looking forward to developing this even further in the next couple of months and hope to publish it on the Android marketplace by the end of the summer. Built With android-studio google-geocoding google-maps java sqlite xml Submitted to HackDFW 2016 Created by Nikhil Pandeti Karthik Lel Kazuki Shin Alexander Tekle Andrew "
      }
    ]
  },
  {
    "file_path": "./devposts/allo-mia782.html",
    "project_id": "allo-mia782",
    "title": "Allo",
    "tagline": "Allo is a banking app that allows parents to manage their children's allowance spending. It's designed to replace cash allowance and allow children to have financial freedom while adults manage.",
    "hackathon": "",
    "built_with": [
      "miro",
      "preact",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/369/918/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our inspiration comes from Apple Pay, but we wanted to create a more kid-friendly version. What it does Allo allows parents to track how their children spend their allowance money. It also makes sure that children are spending responsibly. How we built it We used Miro to design the mobile app version of Allo, and Preact to create the website. Challenges we ran into Challenges we ran into include lack of experience and time management. Accomplishments that we're proud of We're proud of using new technologies and creating a working website. What we learned We learned how much detail matters in UX/UI design when creating a website. What's next for Allo We want to implement more of the features in our design that we were unable to incorporate into the website. Built With miro preact typescript Try it out allo.deno.dev docs.google.com miro.com Submitted to CruzHacks 2023 Created by Created the UI/UX for the Allo website using miro Edmund Xu Aditi Bhat Elvis Bui Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/ai3d-primitives-for-adobe-express.html",
    "project_id": "ai3d-primitives-for-adobe-express",
    "title": "AI3D Primitives for Adobe Express",
    "tagline": "create your vision expressively with precision control of AI - seamlessly integrated with Adobe Express",
    "hackathon": "",
    "built_with": [
      "adobe",
      "adobe-express",
      "copilot",
      "javascript",
      "three.js",
      "typescript",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "WebGL inside Adobe Express wasn’t happy at first—took some clever sandboxing"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/631/509/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Most AI tools feel like playing roulette with your ideas. You write a prompt, cross your fingers, and hope the output matches your vision. We wanted something better—something tactile, visual, and grounded. So we built a way to sketch in 3D, direct AI with structure, and bring your scenes to life in motion. What it does AI3D Primitives turns Adobe Express into a spatial AI sketchpad.\nStart with 3D primitives—cubes, spheres, cones—and shape your scene as if you're blocking out a stage. Describe your concept in natural language, and AI helps fill in the details. When you’re ready, scan a QR code to step inside your composition in Augmented Reality and tweak it in real space. Then comes AI3D Render Mode: select what you want to animate, frame it up, and generate a video—frame-by-frame, with precision and intention. Less \"generate and hope.\" More \"direct and create.\" How we built it Adobe Express Add-on SDK to embed our UI natively Unity WebGL + iOS/Android AR Foundation for intuitive 3D layout  and integration with reality Also AI3D Render with Keyframe control of AI video (we showed this at CVPR 2025 Demo and also brief 30s demo / mention during Orals!) AI3D Co-Create wiht AI3D Render will be at SIGGRAPH! Scene metadata packed into a QR code for quick AR access A custom backend pipeline (built on AI3D RenderFlow) that interprets scene structure for AI video generation Built a communication layer between the web frontend and Unity using Jint and C# Challenges WebGL inside Adobe Express wasn’t happy at first—took some clever sandboxing Getting AI to respect our 3D layout instead of overriding it required training and a lot of fails QR handoff between web and mobile AR had to feel instant, not clunky Composing for AI is different from composing for humans—it needed a new language of control Proud of A real pipeline from static 3D sketch to dynamic AI motion, all from inside a design tool Seeing people walk around their AI-generated scenes in AR and actu"
      }
    ]
  },
  {
    "file_path": "./devposts/automatic-tolling.html",
    "project_id": "automatic-tolling",
    "title": "Automatic Tolling",
    "tagline": "Have you had your time wasted waiting in line at a toll booth? Well, Automatic Tolling is a program that saves you time and lessens traffic, by automatically charging license owner's on toll roads.",
    "hackathon": "",
    "built_with": [
      "google-cloud",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/657/223/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Real-time object detection. Real-time object detection. Real-time object detection. 1 2 Inspiration Toll booths are inefficient. They create congestion in traffic and waste people's time. This inspired us to create an automatic tolling system where cars can use toll roads without the need to stop at a toll booth. What it does Automatic tolling takes a video as input and uses object detection to identify cars and grab their license plates. From there it uses optical character recognition to read the license plate and lookup information about the vehicle owner in a database and charge him the toll fee. How we built it We used the opencv library in python to detect the moving cars in the video, Google's Vision API to perform the optical character recognition, and reading and writing to CSV file was done with the pandas library in python. Challenges we ran into Our group does not possess a camera that can take high quality pictures of the license plates on moving cars. We were forced to find videos of cars driving on the highway, but the issue with this is there were no videos were the license plates were visible. Our solution was for every passing vehicle we would send a random picture of a license plate to the optical character recognition function. What we learned Learned how to interact with Google's vision API as it was our first time using it. Also, tracking moving objects using computer vision is more difficult than we initially thought. What's next for Automatic Tolling -Implement Google's object detection API alongside a camera hung above the highway to gather more accurate results. \n-And use a larger database and host it in the cloud. Built With google-cloud opencv python Try it out GitHub Repo Submitted to Hack the North 2021 Created by I worked on the object-detection and passing the license plate images to the OCR function. Private user Worked on the Computer Vision AI w/ OpenCV Sean Wang kiefer rau"
      }
    ]
  },
  {
    "file_path": "./devposts/7degree.html",
    "project_id": "7degree",
    "title": "7 Degrees",
    "tagline": "Never forget a connection again",
    "hackathon": "",
    "built_with": [
      "figma",
      "flask",
      "gemini",
      "javascript",
      "openai",
      "postman",
      "python",
      "react",
      "sql",
      "supabase",
      "typescript",
      "vapi",
      "whatsapp",
      "windsurf",
      "zep"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/742/102/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Tools We Used Logo Landing Page Home Page Connections Page QR Authentication Page Tools We Used Logo Landing Page Home Page Connections Page QR Authentication Page Tools We Used 1 2 3 4 5 6 7 The Problem 💭 Conversations are how relationships start, but they’re fragile. After a hackathon or networking event, you might have talked to 20 people, but a week later, you can’t remember who mentioned what. Was it Sarah who said she was struggling to break into machine learning? Or Toby who’s in the entrepreneurship club? Those are the details that make follow-ups meaningful, but they’re also the first to fade. The friction comes in two forms:\nThe Human Problem: We connect best when we find common ground shared struggles, shared passions, or ambitions. But without a system to surface those overlaps, most of it gets lost. Follow-ups become shallow (if they ever happen), and opportunities for real connection never happen. To add to all of that, managing and enhancing your relationship with people takes a lot of effort, so can technology solve that problem? The Technical Gap: Current tools still require human effort and they don't leverage the best technologies for the purpose of relationships. We thought of it from the ground up and realized that storing relationships in a knowledge graph that is powered by AI (chat with it, go on a phone call with it) alligns perfectly with how human beings think. So in some way it's a 2nd brain, a memory vault for who you care about or want to grow your relationship with Inspiration 🌎 Recently, there has been a boom in virtual meeting bots that can summarize and take actions on meeting notes. One popular e.g. is granola.ai , but there are MANY more, but what about face-to-face interaction? The name 7 Degrees comes from the “seven degrees of separation” idea, which suggests that any two people in the world are connected through just a handful of relationships. Our project extends this concept by focusing on professional and personal networkin"
      }
    ]
  },
  {
    "file_path": "./devposts/2sum-dance.html",
    "project_id": "2sum-dance",
    "title": "LeetDance",
    "tagline": "Learn TikTok dances using a LeetCode-style problem format where you can step through moves, track progress, and master viral routines in a fun and structured way.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "fastapi",
      "gemini",
      "mediapipe",
      "next.js",
      "numpy",
      "python",
      "react",
      "shadcn",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Google Gemini 2.0 Flash + MediaPipe Pose track moves and give timestamped feedback",
      "Balancing performance and responsiveness for video and pose tracking on the web.",
      "Implementing real-time pose tracking so users can compare themselves to reference videos.",
      "Building a platform that makes learning dances fun, repeatable, and trackable.",
      "Enhance pose tracking accuracy and provide personalized feedback for improvement."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/740/761/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "dance selected dances home page dance selected dances home page dance selected 1 2 3 4 Inspiration We love watching TikTok dances and learning viral routines for fun. As computer science students, we also spend a lot of time grinding LeetCode challenges. That got us thinking about why not combine the structured, step-by-step challenge format of coding with the joy of learning dances? Alas, LeetDance was born. What it does LeetDance breaks down TikTok routines into step-by-step challenges. Users can practice each move in sequence, see real-time feedback on their performance, and track their progress over time. The app gamifies dance learning, turning popular routines into repeatable, trackable challenges that feel rewarding to complete. How we built it Next.js 15 + React 19 with Tailwind for a responsive, LeetCode-style dance interface FastAPI handles video uploads and async processing for real-time analysis Google Gemini 2.0 Flash + MediaPipe Pose track moves and give timestamped feedback OpenCV synchronizes user and reference videos with annotated overlays Challenges we ran into Breaking down dance routines into clear, repeatable steps. Detecting user poses accurately and giving meaningful visual feedback in real-time. Designing a challenge-based UI that felt motivating without being too “coding-like.” Balancing performance and responsiveness for video and pose tracking on the web. Accomplishments that we're proud of Successfully gamifying TikTok dance learning with a structured challenge system. Implementing real-time pose tracking so users can compare themselves to reference videos. Creating a clean, user-friendly interface that combines the feel of coding platforms with dance practice. Building a platform that makes learning dances fun, repeatable, and trackable. What we learned How to merge computer vision with interactive web interfaces. How to create a gamified learning experience outside of traditional coding. The value of real-time feedback in teaching and "
      }
    ]
  },
  {
    "file_path": "./devposts/algorithmic-method-for-puzzle.html",
    "project_id": "algorithmic-method-for-puzzle",
    "title": "Algorithmic Method for Puzzle",
    "tagline": "Solves the puzzle using and algorithmic approach by comparing average pixel values.  92.25% acc on the entire training dataset :).",
    "hackathon": "",
    "built_with": [
      "pil",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMU Datathon 2022WinnerTAMU Datathon Challenge: Puzzle Solver",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/247/991/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Solve the puzzle What it does Solves the puzzle using an algorithm that compares pixel values. Some added porbability. Challenges we ran into A lot of complex logic, from comparing adjacencies to finding a way to rate how good two pices matched up. Accomplishments that we're proud of I did it, and when run on the entire dataset my model has a whoping accuracy of 92.63%! Built With pil python Try it out GitHub Repo Submitted to TAMU Datathon 2022 Winner TAMU Datathon Challenge: Puzzle Solver Created by Lucian Chauvin"
      }
    ]
  },
  {
    "file_path": "./devposts/agentictraders.html",
    "project_id": "agentictraders",
    "title": "Tradegentix",
    "tagline": "High-Frequency Trading with Agentic Workflows and GPU parallelization.",
    "hackathon": "",
    "built_with": [
      "agents",
      "c++",
      "cuda",
      "flutterflow",
      "llm",
      "perplexity",
      "python",
      "vlm"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Case, Best Path, Last Price, Original Values, and Worst Case—which consists of over 4"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/274/287/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Tesla Challenge Video Analysis Diagram Tradegentix Logo Trading Interface Analysis Agent System Diagram Monte Carlo Simulation Stock Data Tesla Challenge Video Analysis Diagram Tradegentix Logo Trading Interface Analysis Agent System Diagram Monte Carlo Simulation Stock Data Tesla Challenge Video Analysis Diagram 1 2 3 4 5 6 (scroll for FlutterFlow, Perplexity, Rox, Tesla, and Agentic Workflows!) Project Summary Let's say Stock A goes up at t=0 (where time is t). The idea is that there is a latency between a related/correlated Stock B that may be positively or negatively correlated at t = 3. We would use this tool to predict this correlation and buy at t=2 before Stock B response to some market force affecting Stock A. More specifically, our team developed a semi-high frequency trading system leveraging CUDA C++ accelerated computing that allowed for an agent network based chain of reasoning in order to use qualitative factors to explain the quantitative phenomena. Our agentic workflow allows us to benefit from market research and news analysis for a robust report. NVIDIA Technology: Our semi-high frequency trading system, powered by CUDA and chain of reasoning, comprises the following components: CUDA-Accelerated ICA: We implemented a custom CUDA-based Independent Component Analysis (ICA) module to extract statistical market forces from mixed signals. This approach is based on the concept that while independent source signals are non-Gaussian, their mixtures tend to exhibit a more normal distribution. For further reading, refer to this quick guide . Accelerated Monte Carlo Simulation: Using CUDA acceleration, our system runs an implementation of a Monte Carlo simulation that models variant BM and JP inclusive sequence. The simulations are weighted based on a feedback cycle derived from the ICA process. High-Performance Processing: By focusing on parallelization, the entire system completes computations in just a few milliseconds. Predictive Filtering with HMM: A Hi"
      }
    ]
  },
  {
    "file_path": "./devposts/allinone-yvah7t.html",
    "project_id": "allinone-yvah7t",
    "title": "PicPick",
    "tagline": "Tired of endless tabs to find the best deal? PicPick’s a fast, smart platform that compares listings instantly, saves you cash, and redefines shopping with a sleek, intuitive design!",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "mongodb",
      "next.js",
      "react",
      "serpapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/346/979/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "displaying gmail login homepage product search page filtering on product signup page getting actual gmail authentication displaying gmail login homepage product search page filtering on product signup page getting actual gmail authentication displaying gmail login 1 2 3 4 5 6 7 Inspiration Based on this year's theme for BearHacks, we instantly knew the use case for Automation and noticed a real issue with online shopping. People are spending way too much time searching for all kinds of products, like a new pair of trendy shoes to make a fashion statement or that specific glue they need for a DIY project, like fixing a leaky sink their mom keeps bringing up. It’s not just about one thing; it’s the constant back-and-forth, opening tabs, comparing prices, and sorting through endless options that eats up their day. We saw a clear need for a simpler, faster way to handle this, something that could automate the process and cut out the hassle. That’s why we built PicPick; this is a tool that pulls together thousands of listings from across the web, organizes them cleanly, and helps users find exactly what they want without the headache. What it does PicPick is an all-in-one platform that gathers data from thousands of products across major online retailers like Amazon, Walmart, or specialty stores to compare options and deliver a solution tailored to the user’s needs. Whether someone’s hunting for a sleek new jacket to stand out or a niche tool like heavy-duty glue for a sink repair, PicPick pulls listings from multiple websites into one place. It’s built to save time, letting users find what they want faster and often at exclusive prices they wouldn’t spot digging through sites one by one. Instead of juggling tabs or missing out on deals, users get a clear, organized view of their options. On top of that, PicPick comes with a robust filtering system to take the guesswork out of searching. Users can sort through products with precision, narrowing down by categories like pr"
      }
    ]
  },
  {
    "file_path": "./devposts/audio-player.html",
    "project_id": "audio-player",
    "title": "Web MusicPlayer",
    "tagline": "Let the Music Speak!",
    "hackathon": "",
    "built_with": [
      "css3",
      "django",
      "heroku",
      "html5",
      "javascript",
      "jinja",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/673/807/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration Something which drives me is the way we collaborate we people. Metabob got those . What it does Well not something rocket science . It just plays songs.We needed to work on the frontend didn't got time and thought to stay authenticated(if you know what i mean !  ;). How we built it we used django framework which is based on the famous python lang...  .also used simple web dev tools like chrome dev tolls and html5,css3,javascript. Challenges we ran into the time limit of course !!. We tried our best to work on frontend but at the same time to make it responsive and deployable. We tried to use heruko cloud services but something went wrong. Accomplishments that we're proud of To be able to complete in time whatever the excuses we wrote above, and proud to didn't  turn our back and tried to finish it. What we learned leadership, technical stuffs like the backend dev meets the front and viceversa. What's next for Web MusicPlayer we thinkin' to make it more responsive ; work on the frontend and try another time if we not get  into it . Built With css3 django heroku html5 javascript jinja python Try it out GitHub Repo Submitted to BobHacks Hackathon:  A Space Odyssey Created by I worked on the backend  using Django which wasn't my first time.  Tried to make it quite robust and deploy using Heroku but failed. Though it was a great expirence to work with the coder community and being a part of hackathon was great. donald laishram pruthviraj jadhav Anuj Kundar Asswin C R Abhishek Shinde"
      }
    ]
  },
  {
    "file_path": "./devposts/assit-bot.html",
    "project_id": "assit-bot",
    "title": "Assist Bot",
    "tagline": "Go Anywhere !",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "arduino",
      "general-motors-remote",
      "intel-edison",
      "intel-xdk",
      "node.js",
      "project-tango",
      "python",
      "raspberry-pi",
      "raspian"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/459/941/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Implementation on a cycle (turning) Final Design (Guidance and assistance) Final Design (for transportation) Final Design (Deactivated) First Prototype (With Project Tango) First Prototype (Without Project Tango) Second prototype (Rpi Zero & project tango) front Second prototype (Rpi Zero & project tango) side Second prototype (Rpi Zero & project tango) back Implementation with a bicycle (Side) Implementation with a bicycle (Back) Implementation on a cycle (handle) Implementation on a cycle (Rpi) Implementation on a cycle (front) Implementation on a cycle (turning) Final Design (Guidance and assistance) Final Design (for transportation) Final Design (Deactivated) First Prototype (With Project Tango) First Prototype (Without Project Tango) Second prototype (Rpi Zero & project tango) front Second prototype (Rpi Zero & project tango) side Second prototype (Rpi Zero & project tango) back Implementation with a bicycle (Side) Implementation with a bicycle (Back) Implementation on a cycle (handle) Implementation on a cycle (Rpi) Implementation on a cycle (front) Implementation on a cycle (turning) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Inspiration While travelling to Hong Kong for the demo of a project called Air-Ink, I missed my flight because of the different procedures that were there in the airport which made me late for the flight. After somehow rescheduling the flight for the next day, I had to stay one whole day at the airport, thinking about how this delay could be solved, I thought about making a robot but not the one which runs on artificial intelligence or something. A simple machine that \"Assists\" you through all of the different procedures at the airport and all the places where you are in a rush, assist you not only with a building but places and not only first timers but also to people with disability. I worked on making the description about the project and how it can be used in different perspectives and all of the components that would be required in it. \nTh"
      }
    ]
  },
  {
    "file_path": "./devposts/allingpt.html",
    "project_id": "allingpt",
    "title": "All in GPT",
    "tagline": "Chat with the minds behind the world number one VC show 'The All In Podcast': A cutting-edge AI chatbot that brings the world's top VC show hosts to your fingertips.",
    "hackathon": "",
    "built_with": [
      "api",
      "featureform",
      "llm",
      "openai",
      "pinecone",
      "react",
      "vector"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/511/983/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration We all love all in podcast. Join our enthusiastic hosts as they share valuable insights and expert advice on finance, entrepreneurship, and personal growth. Unlock your potential, increase wealth, and attain financial freedom. Join us today to transform your financial outlook. Go All-In! What it does The Allin podcast was born out of a deep passion for the chosen subject matter, a desire to share knowledge and expertise, and a longing to connect with like-minded individuals. Inspired by successful podcasts and the potential to create a platform for meaningful conversations, the hosts embarked on a journey to educate, empower, and entertain their audience. How we built it We utilized the Cockatoo API to transfer audio data into CSV (Comma-Separated Values) format. The Cockatoo API offers powerful functionality for converting audio files into machine-readable data, enabling efficient processing and analysis. Once the audio data was transformed into CSV format, we proceeded to save the resulting scripts into the Pinecore vector database. The Pinecore vector database serves as a storage system for various types of data, including text. By saving the scripts, we ensured easy access and retrieval of the information at a later stage. To enhance the prompts we sent to the ChatAPI, we integrated the Featureform API into our workflow. The Featureform API facilitated the retrieval of relevant information from the stored CSV data. By extracting key features such as speaker identification, sentiment analysis, or speech patterns, we obtained valuable insights from the audio scripts. Next, we embedded the extracted information into the prompts we sent to the ChatAPI. This embedding process involved incorporating the relevant details retrieved through the Featureform API into the prompt text itself. By doing so, we provided contextual information to the ChatAPI, enabling it to generate more informed and accurate responses. Finally, the enhanced prompts, contai"
      }
    ]
  },
  {
    "file_path": "./devposts/asl-hand-to-text.html",
    "project_id": "asl-hand-to-text",
    "title": "ASL-hand-to-text",
    "tagline": "Very fun project with VGG+RNN",
    "hackathon": "",
    "built_with": [
      "python",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration A lot of fun What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for ASL-hand-to-text Built With python react tensorflow Try it out GitHub Repo Submitted to PolyHacks 2023 Created by SarinaMashreghi Mashreghi Xin Lei Lin Aly Shariff"
      }
    ]
  },
  {
    "file_path": "./devposts/911-resq.html",
    "project_id": "911-resq",
    "title": "911 rEsQ",
    "tagline": "Harnessing AI to revolutionize emergency response with AI-driven audio analysis to swiftly respond to emergencies and saving lives.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "humeai",
      "pytorch",
      "streamlit",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/931/016/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "audio classification emotion result Home Page About Page Features Demo Page (Audio Classification, Audio Save, Text Summarize) audio classification emotion result Home Page About Page Features Demo Page (Audio Classification, Audio Save, Text Summarize) audio classification emotion result 1 2 3 4 Inspiration In 2022 alone, the United States experienced 150 school shootings, following a staggering 240 incidents in 2021 and over 300 from 2010 to 2020. These tragedies have claimed countless innocent lives among students, teachers, and staff. During these horrific events, hiding students and teachers often struggle to discreetly alert authorities, compounded by the challenge 911 operators face in distinguishing genuine emergencies from false or accidental calls, thereby delaying critical response times. Background research into 911 dispatch operations reveals a critical issue: vital audio cues like distant gunshots or cries for help often go unnoticed amidst the chaos of emergency responses. This lack of clear communication can spell the difference between life and death for those trapped in these harrowing situations. Having experienced frequent active shooter drills and lockdowns firsthand during school, we intimately understand the pervasive fear that grips schools nationwide. Motivated to make a tangible difference, we took a novel approach with our project. Thus, our team developed 911-rEsQ, an AI-driven application tailored specifically for 911 operators. This innovation aims to enhance 911 operators' ability to swiftly and accurately respond to emergencies, particularly during school shootings. By leveraging advanced audio processing capabilities, 911-rEsQ promises to clean and enhance caller audio, enabling dispatchers to better assess the urgency and severity of each situation. This technological advancement is poised to revolutionize emergency response protocols, ensuring that every distress call receives the attention it urgently requires. As students ourselv"
      }
    ]
  },
  {
    "file_path": "./devposts/asl-bridgify.html",
    "project_id": "asl-bridgify",
    "title": "ASL Bridgify",
    "tagline": "Our innovative platform for learning American Sign Language (ASL) aims to redefine education through real-time feedback, personalized learning paths, and comprehensive AI-driven modules.",
    "hackathon": "",
    "built_with": [
      "faiss",
      "flask",
      "intel",
      "intelai",
      "ipex",
      "langchain",
      "lstms",
      "mongodb",
      "nextjs",
      "openai",
      "poseestimation",
      "python",
      "rag",
      "randomforests"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "UC Berkeley AI Hackathon 2024WinnerAI For Good by Academic Innovation Catalyst (AIC)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/931/170/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "AI sign-to-letter Seaching Feature AI Chatbot Quiz AI word-to-text AI sign-to-letter Seaching Feature AI Chatbot Quiz AI word-to-text AI sign-to-letter 1 2 3 4 5 Inspiration We created ASL Bridgify to address the need for an interactive real time pose-estimation based learning model for ASL. In a post-pandemic world, we foresee that working from home and more remote experiences signals the need to communicate with individuals with hearing disabilities. It is a feature that is missing from various video conferencing, learning, and entertainment - based platforms. Shockingly, Duolingo the number 1 language learning platform does not teach ASL. What it does ASLBridgify is an educational platform that specifically focuses on the learning of ASL. We provide comprehensive modules that help you learn languages in scientifically proven ways. We provide easy to follow UI and personalized AI assistance in your learning journey. We realize that the future of AI comes in more than chatbot form, so our AI models are integrated within video to track hand-movement using Media pipe and TensorFlow. How we built it We created an educational platform by leveraging many technologies. Our frontend uses Next.js, Tailwind and Supabase. Our backend used Python libraries such as PyTorch, TensorFlow, and Keras to train our LLMs with the use of Intel Developer Cloud GPU and CPU to expedite the training. We connected the Frontend with the Backend with Flask. Moreover, we combined our trained models with Google Search API OpenAI API for Retrival-Augemented-Generation (RAG) Challenges we ran into The biggest challenge was time. The time it took to train one Large Language Model, even when using Intel Developer Cloud GPU capabilities was immense. It was a roadblock because we couldn't test any other code on one computer until the LLM was done training. Initially we tried to preprocess both words and sentences using hand pose to map ASL and using encoder decoder architecture, but we were not able "
      }
    ]
  },
  {
    "file_path": "./devposts/asianparent.html",
    "project_id": "asianparent",
    "title": "StudySnitch",
    "tagline": "Keeping you accountable when studying, no matter the cost",
    "hackathon": "",
    "built_with": [
      "google-cloud",
      "javascript",
      "next.js",
      "opencv",
      "python",
      "redis",
      "streamlit",
      "taipy",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Google Cloud Winner Best Use of Kintone Created by Jerry Zhu CS @UWaterloo | Retired | Fanat",
      "Best Use of Google Cloud Winner Best Use of Kintone Created by Jerry Zhu CS @UWaterloo | Retired |",
      "The GoldenHackWinnerBest Use of Google CloudWinnerBest Use of Kintone",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In our digital age, time has become the ultimate luxury. With countless distractions in our lives, we strive to become the best versions of ourselves, but are bogged down by the sheer amount of distractions and issues in our lives. We wanted to create an application that would help us concentrate on our daily tasks so that we can enjoy the time we have in life to not procrastinate and stress. What it does Introducing StudySnitch, the ultimate tool for optimizing your daily activities. StudySnitch uses extreme methods to keep you accountable when performing your tasks, and makes sure you are staying on track with everything that you should be doing. If you are not paying attention to the screen or wandering off to the depths of TikTok, StudySnitch will remind you kindly, and then not so kindly using text-to-speech, to get back to work and finish off your tasks. You have a roadmap and analytics page that will break down the tasks you are doing, and how well you are doing them. How we built it To build StudySnitch, we used Next.JS and Vite for our frontend components, using Three.JS and CSS animations to improve the latency and responsiveness of our user interface. In the backend, we used OpenCV and FastAPI to create REST API endpoints, calling them from the frontend using requests. We also used ElevenLabs for TTS, Streamlit and Taipy for dashboards, Kintone for creating a dynamic backend for recording tasks, and Redis Cloud and Google Cloud for our database and Cloud OCR provider, respectively. We built a chrome extension, a full stack web application, and a machine learning pipeline, in order to build a full set of tools for productivity success! Challenges we ran into We ran into issues integrating the full stack pipeline together, which ended up being solved using Redis Cloud and syncing the database at each tick. We also learned a lot about CSS animations and how we can trigger TTS and keyframes within the code, leading to remote triggers of backend fu"
      }
    ]
  },
  {
    "file_path": "./devposts/a-pok3h8.html",
    "project_id": "a-pok3h8",
    "title": "Pollution is a MisTech!",
    "tagline": "Pollution is a MisTech! is a website that takes in a start and end location of a drive, and visualizes the number of trees required to offset the negative environmental impact of that car ride.",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "google-maps",
      "html",
      "javascript",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/256/364/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration As our world continues to combat the impacts of industrial activities, we designed Pollution is a MisTech! to allow our users to visualise the contribution they can provide in terms of number of trees required to plant to offset the negative environmental impacts of their car ride. What it does Pollution is a MisTech! takes in a driver's start and end location. Granted Google deems there is a drivable path between start and end, we use the Google Maps API to calculate the distance between the two locations. Using historical data of the amount of emissions a car produces per kilometer, and the amount of emissions a tree absorbs in a day, the website outputs the amount of trees needed to offset the exhaust emissions of the car ride along with a visualisation of the car killing trees as it moves. How we built it We began our post-brainstorming Development Workflow by working on a rough mock-up of how we wanted our end result to be on Microsoft Paint. Then we proceeded to create a standardized UI on Figma. After this, we divided the tasks into research, front-end development (for which we used HTML, Javascript and CSS) and API incorporation. We also had regular team check-ins to address shortcomings, challenges faced during development, group debugging sessions, etc. After each of us completed our individual assignments, we had a team reunification of code where we addressed merge conflicts, and merged branches on GitHub to create a functional web application using a Domain.com domain. To finish up, we had a team review of code and quality assurance. Challenges we ran into This was our team’s first time implementing an API and while learning to read the Google Map API documentation, we had trouble figuring out how to allow user inputs and ensuring our program works accordingly. We wanted to create a .tech domain and ran into troubles with Domain.com regarding that. Krishna was on call with a Domain.com representative about setting it up and received an e"
      }
    ]
  },
  {
    "file_path": "./devposts/asciifi.html",
    "project_id": "asciifi",
    "title": "asciifi",
    "tagline": "A fast P2P video-calling platform. No sign up required.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "opencv",
      "peerjs",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMUhack 2021 Grand Prize Winner Dell Technologies Challenge Created by I worked on frontend with R",
      "Winner Dell Technologies Challenge Created by I worked on frontend with React, and also focused on",
      "TAMUhack 2021WinnerTAMUhack 2021 Grand PrizeWinnerDell Technologies Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/377/333/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "asciifi Welcome to asciifi Faster than competing video calling services Stay connected even without high-speed internet How it works asciifi Welcome to asciifi Faster than competing video calling services Stay connected even without high-speed internet How it works asciifi 1 2 3 4 5 6 Tired of the laggy connections? Are you part of the four billion people who do not have access to high-speed internet connections? Do you wish there was a low latency alternative to Zoom and Microsoft Teams that does not require a high quality internet access? Introducing asciifi A fast low latency P2P video-calling platform that everyone with internet access can use. Connecting people in all the corners of the world, we hope that asciifi is able to remove the barrier to staying connected even if the infrastructure may not be in place. Whether you live in Silicon Valley or a remote rural area, your voice should not be limited by internet speed. Asciifi provides an avenue for the voices not heard and the faces not seen to finally be projected around the world. Why asciffi? With over 51% of the world's population lacking reliable high speed internet, most of the common video conferencing platforms demand too much data and are not suitable for the underprivileged users. In order to mitigate the needs for high speed internet and still provide access to video conferencing software,  we created asciifi. Asciifi enables people from less privileged backgrounds to finally connect with other people all around the world. While other competitors have a latency anywhere form 30ms to 40ms, Asciifi is more than 3x faster with an average latency of 10 ms . It removes the bottleneck of sending video by sending text instead. Why send gigabytes of data when you can send 1000 times less data and send megabytes of data? Asciifi has lower barrier to entry and makes sure that more people have access to reliable video conferencing. How it works [ ] Start a Call [ ] Automatically Greyscaled [ ] Asciifi Other n"
      }
    ]
  },
  {
    "file_path": "./devposts/adobe-brainrot.html",
    "project_id": "adobe-brainrot",
    "title": "Adobe Brainrot",
    "tagline": "Sassiest Design Feedback Tool",
    "hackathon": "",
    "built_with": [
      "adobe-express",
      "ffmpeg",
      "javascript",
      "node.js",
      "openai",
      "react",
      "yt-dlp"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the 6ix 2024WinnerMLH: Most Creative Adobe Express Add-On",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/974/452/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Adobe Express Output Video Adobe Express Output Video 1 2 3 4 5 6 7 8 Example brainrot output Demo Inspiration Graphic design is a skill like any other, that if honed, allows us to communicate and express ourselves in marvellous ways. To do so, it's massively helpful to receive specific feedback on your designs. Thanks to recent advances in multi-modal models, such as GPT-4o, even computers can provide meaningful design feedback. What if we put a sassy spin on it? What it does Adobe Brainrot is an unofficial add-on for Adobe Express that analyzes your design, creates a meme making fun of it, and generates a TikTok-subway-surfers-brainrot-style video with a Gordon Ramsey-esque personality roasting your design. (Watch the attached video for an example!) How we built it The core of this app is an add-on for Adobe Express. It talks to a server (which we operate locally) that handles AI, meme-generation, and video-generation. Here's a deeper breakdown: The add-on screenshots the Adobe Express design and passes it to a custom-prompted session of GPT-4o using the ChatGPT API. It then receives the top design issue & location of it (if applicable). It picks a random meme format, and asks ChatGPT for the top & bottom text of said meme in relation to the design flaw (e.g. \"Too many colours\"). Using the memegen.link API, it then generates the meme on-the-fly and insert it into the add-on UI. Using yt-dlp, it downloads a \"brainrot\" background clip (e.g. Subway Surfers gameplay). It then generates a ~30-second roast using ChatGPT based on the design flaw & creates a voiceover using it, using OpenAI Text-to-Speech. Finally, it uses FFmpeg to overlay the user's design on top of the \"brainrot\" clip, add the voiceover in the background, and output a video file to the user's computer. Challenges we ran into We were fairly unfamiliar with the Adobe Express SDK, so it was a learning curve getting the hang of it! It was especially hard due to having two SDKs (UI & Sandbox). Thankfully, i"
      }
    ]
  },
  {
    "file_path": "./devposts/a-machine-learning-mobile-app-for-the-hearing-impaired.html",
    "project_id": "a-machine-learning-mobile-app-for-the-hearing-impaired",
    "title": "A Machine Learning Mobile App for the Hearing Impaired",
    "tagline": "In a world where 430 million people are hearing impaired and where cars and guns can pose serious danger to people, there is a need for a more accessible solution to help detect dangerous sounds.",
    "hackathon": "",
    "built_with": [
      "colab",
      "python",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/893/006/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "proposed mobile app prototype that can detect outdoor sounds built with Swift and XCode proposed mobile app prototype that can detect outdoor sounds built with Swift and XCode proposed mobile app prototype that can detect outdoor sounds built with Swift and XCode 1 2 Inspiration Five years ago, my grandma became hearing impaired and thus needed a hearing aid. However, even with the best ones she could find, she still had trouble hearing sounds around her. This can be dangerous as she may not know whether a car is behind her or not as she is walking outside. I wonder if there is a better solution to help her and other hearing impaired individuals navigate places safely and knowingly outside. What it does My idea is to train a machine learning model to detect potentially dangerous outdoor sounds like gun shots, car horns, and car engines and then integrate the model into a mobile app to detect sounds in real time for hearing impaired users so they can be notified and move to a safer place, for example, if a car is behind them. How we built it Using Python and Google Colab for the machine learning model and using Swift and XCode for the mobile app. Challenges we ran into Trying to find a problem and solution by combining several fields together, such as audio classification, machine learning, and mobile app development. Accomplishments that we're proud of I successfully found an important problem in the world and came up with a solution/idea. What we learned That sometimes inspirations, ideas, and problems can come from your own community, family, etc., and see if a solution can be found to that problem or idea. What's next for A Machine Learning Mobile App for the Hearing Impaired To fully develop the mobile app for audio classification, test it on real sounds, and potentially put it on the App Store for free download and usage. Built With colab python swift xcode Submitted to The Innovation Challenge Created by I worked on the front and back end of the project. I uti"
      }
    ]
  },
  {
    "file_path": "./devposts/a-salter.html",
    "project_id": "a-salter",
    "title": "A salter",
    "tagline": "An automated robot that uses numerous sensors to prepare for winter storms by salting, breaking ice, and plowing snow",
    "hackathon": "",
    "built_with": [
      "c++",
      "flask",
      "solidworks"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/763/167/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 Inspiration After walking to the engineering building yesterday morning for this makeathon, there was lots of ice still on the pathways around campus. We took this as inspiration to solve a problem we just faced. What it does A Salter is an automated robot that uses Telus LTE-M along with soft boundries GPS driven to go around pathways and break any ice, disperse salt, and prepare to plow snow in an incoming snowfall How we built it The first thing we did was cad the tank treads so we could get 3d printing right away. Once we printed 3 of them to ensure good tolerance and fit around the sprocket, we began printing several dozens of them. We then got certified in the machine shop so we could cut wood for the base of our bot. We then made the plow and holes for the hammer. While this was happening on of our teammates was working on the Telus kit so we could have the robot automatically know when to go out and do its duties. Challenges we ran into At about 15 hours in we realized our drive motors were not strong enough to move the robot. This was abit of a crisis but eventually a fellow hacker came by and told us to checkout the hardware booth as they had just recieved strong gearbox motors. We adapted those new motors to our old wheel hubs and the robot was able to drive great. We had lots of trouble with the azure side of IoT as it is just so complicated it is hard to learn exactly what you need in 24 hours. Accomplishments that we're proud of We created a fully working, driving robot in less than 24 hours from salvaged parts and things we cadded from scratch. None of us have ever even created a tank tread robot before. We also were proud of the amount of work we got done in 24 hours, we made use of every minute we could to create the best product possible. What we learned We learned alot about how powerful azure is. We have been afraid to use it because of the sheer complexity, but this hackathon forced us to use it and we have learn"
      }
    ]
  },
  {
    "file_path": "./devposts/ai-llm-powered-learning-assistant.html",
    "project_id": "ai-llm-powered-learning-assistant",
    "title": "Classroom Companion",
    "tagline": "With ClassCompanion, students can chat with teacher-curated lessons to understand curriculum concepts. Learn at your own pace! Let's empower minds, embrace AI, and move forward together.",
    "hackathon": "",
    "built_with": [
      "langchain",
      "mongodb",
      "openai",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/541/714/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Admin Page, viewing Minglun's Conversation History User Chat Page Home Page Admin Page, viewing Minglun's Conversation History User Chat Page Home Page Admin Page, viewing Minglun's Conversation History 1 2 3 4 Classroom Companion - Redefining Learning with AI Inspiration As avid learners and AI enthusiasts, we were inspired to create an innovative solution that addresses the challenges posed by Large Language Models (LLMs) in the education landscape. We noticed that while LLMs offered tremendous potential for personalized learning and data-driven insights, they also presented unintended consequences, such as facilitating cheating among students. Our vision was to empower teachers to harness the power of AI in a way that fosters academic integrity and creates a positive learning environment for every student. We aimed to provide educators with a tool that allows them to curate personalized learning journeys alongside lessons, ensuring that the AI enhances the teaching process rather than detracting from it. What We Learned We realized that embracing AI with a focus on ethics and integrity was essential for cultivating a generation of responsible and informed learners. We also gained insights into the diverse needs of teachers and students, shaping our approach to create a tool that would be user-friendly and adaptable across different educational settings. Building the Project The project was built using langchain's ChatOpenAI and OpenAIEmbeddings to manage pdf Q&A. For the UI we used Streamlit, which was a major help when designing web apps in python. For backend, we used MongoDB Atlas, and for repository hosting we used GitHub Challenges Faced The development of Classroom Companion came with its share of challenges. One of the major hurdles was striking the right balance between AI assistance and preserving the essence of traditional teaching methods. We needed to ensure that teachers felt in control of the learning experience while leveraging the power of AI to e"
      }
    ]
  },
  {
    "file_path": "./devposts/bankcoop.html",
    "project_id": "bankcoop",
    "title": "bankcoop",
    "tagline": "This a fintech solution",
    "hackathon": "",
    "built_with": [
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How we built it Challenges we ran into Time Accomplishments that we're proud of What we learned What's next for bankcoop Built With react Submitted to Global Hack Week: AI/ML Created by Stephen Maina"
      }
    ]
  },
  {
    "file_path": "./devposts/alpha-ek9j1u.html",
    "project_id": "alpha-ek9j1u",
    "title": "Alpha",
    "tagline": "Revolutionize learning by integrating AI-generated videos, Desmos graphing, and other visual tools like Mermaid to transform complex concepts into clear, engaging insights that help empower learning.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "cloudflare",
      "css",
      "docker",
      "html",
      "javascript",
      "json",
      "manim",
      "python",
      "react-native",
      "shell",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best AI Application Built with Cloudflare Created by Shlok Bhakta Sugam Mishra Ziyang Chen Ha",
      "Tidal Hackathon Spring 2025Winner[MLH] Best AI Application Built with Cloudflare",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/333/343/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Notes Feature Landing Page Math Studio Page Add Source Feature Notes Feature Landing Page Math Studio Page Add Source Feature Notes Feature 1 2 3 4 5 Inspiration We were inspired to create a better alternative to the traditional study mashsup of 10 different websites - a unified sandbox, Alpha,  that brings together all the diverse tools STEM majors rely on. Instead of hunting for obscure videos or resources, Alpha directs you in real time to the tool that perfectly matches your needs while crafting personalized, short-form learning videos to simplify and clarify complex concepts. It knows what you want from your chat and helps you get it with simple tools in the shortest time possible. What It Does Alpha is an AI-powered assistant that seamlessly integrates dynamic Python video scripting, interactive Desmos graphing, and smart visual tools like Mermaid charts. It understands your queries and intelligently directs you to the right tool for each task, whether you're visualizing math equations, generating explanatory videos, or translating natural language content into engaging, educational formats. There are also additional UI comfort features like notetaking and uploading files so that the AI can help you more specifically and also so that you can remember what you need to for your studying. How We Built It The project is built with a clear separation between frontend and backend systems. Our frontend, developed with React and Vite, provides a modern, responsive interface, while Auth0 secures user authentication and Cloudflare tunneling ensures smooth deployment. Videos and audio files are stored in AWS S3 buckets, and our backend integrates with APIs such as GPT, Gemini, Desmos, Mermaid to deliver dynamic content. The codebase is organized into modular components like ChatInterface , MathStudio , and DesmosStudio , each designed to handle specific tasks — by parsing the input language from the user into LaTeX-controlled Desmos expressions and to render markdown and"
      }
    ]
  },
  {
    "file_path": "./devposts/beats.html",
    "project_id": "beats",
    "title": "Beats",
    "tagline": "\"Feel the beat of emotions with Beats.\"",
    "hackathon": "",
    "built_with": [
      "firebase",
      "pandas",
      "python",
      "seaborn",
      "swift",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ConUHacks VIIWinnerNventive - 4 x $125 Amazon Gift Cards",
      "This is everyone's first time developing an app related to smartwatches. We learned new things and applied them well.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/351/779/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration The inspiration for the project Beats came from the desire to create a more authentic and accurate way for people to communicate their emotions online. Traditional text-based messaging can be misinterpreted, leading to misunderstandings and conflicts. With the increasing use of data analysis and quantification in various industries, it seemed like a natural next step to apply this to the realm of emotions. What it does Beats is a real-time messaging app. The unique thing is that it can show each person's emotions in conversation. It achieves this by utilizing large amounts of data captured by Apple Watches, including heartbeat and blood oxygen levels. It also uses sentiment analysis models to determine the mood of individual messages. If demanded, it can generate detailed reports for a given conversation to visualize data in various ways and provide further insights. By incorporating emotional analysis into the conversation experience, Beats has the potential to create clearer, deeper and more authentic connections between users.\nIn particular, we believe this app can disrupt the dating app industry. How we built it We used Swift to provide a smooth user experience and to better integrate with Apple Watches. We chose Firebase as the backend to simplify the development process and utilize its powerful SDKs and scalability potential. Firebase's DataSnapshot made real-time conversation easier to achieve. Because of Python's effective data-related libraries like pandas, seaborn and TensorFlow, we mainly used it to implement emotional analysis algorithms and on-demand data visualization. Challenges we ran into We have never done any project like this before, so the learning curve was quite big. We took an overnight bus from Ontario, and any rest was luxurious because of the short timeframe and the big project scale. We ran into Swift package dependency issues, third-party data access prohibition problems and countless build failures. We almost lost al"
      }
    ]
  },
  {
    "file_path": "./devposts/0k-health.html",
    "project_id": "0k-health",
    "title": "0K Health",
    "tagline": "By taking advantage of Fitbit's technology, our website compares a user's health statistics against publicly available scientific data, allowing them to contextualize their health stats easily.",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "flask",
      "html",
      "javascript",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/804/317/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "0K_Health_Logo Inspiration Our project began as we sat down to think about problems that affect people's health in our modern world. The biggest issue that came to mind was stress, particularly medical stress. We wanted people to be confident in their health even if they couldn't see a doctor at any particular time which is often a problem in America. What it does What our project aims to do is take data that could be collected from a Fitbit and combine the information to create a holistic image of the user's health. Our website would connect to a user's Fitbit, run their data against scientifically proven statistics for health, and show the user how they could improve or maintain their health through stats-based advice, ie. Increase # of calories burnt. How we built it We used Flask for our back end, React for our front end, and Firebase for our database. Challenges we ran into Integrating both Flask and React to form our website proved to be a challenge for us as everyone in our team was not used to web development and had very little experience actually utilizing either in a comprehensive product. Firebase was also a challenge to link up as it has a lot of dependencies that are not maintained and require running an older version of Python. Accomplishments that we're proud of What we learned We learned how to use React, Flask, Firebase What's next for 0K Health Built With css firebase flask html javascript python react Try it out GitHub Repo Submitted to HackMerced IX Created by I was responsible for my teams artistic ventures, for this project I was responsible for the creation of our logo. Afaan Tiwana I built the frontend using React and set up the firebase for our data. Raybo Ghosh I worked on the Backend with flask and linking flask to the react frontend Elvis Bui Eeshan Khullar"
      }
    ]
  },
  {
    "file_path": "./devposts/a-i-utism-plkrxs.html",
    "project_id": "a-i-utism-plkrxs",
    "title": "A.I.utism",
    "tagline": "Transforming lives for individuals with autism",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "ibm",
      "javascript",
      "python",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "s) Winner 3RD PLACE TEAM Created by Abhik Sharma Private user",
      "Pebble Change the World Hackathon ($70K in prizes)Winner3RD PLACE TEAM",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/661/872/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ML model to teach facial expressions for those on spectrum who struggle with it A.I.utism OpenCV Expression Practice #1 OpenCV Expression Practice #2 OpenCV Expression Practice #3 OpenCV Expression Practice #4 OpenCV Expression Practice #5 OpenCV Expression Practice #6 Training the Model ML model to teach facial expressions for those on spectrum who struggle with it A.I.utism OpenCV Expression Practice #1 OpenCV Expression Practice #2 OpenCV Expression Practice #3 OpenCV Expression Practice #4 OpenCV Expression Practice #5 OpenCV Expression Practice #6 Training the Model ML model to teach facial expressions for those on spectrum who struggle with it 1 2 3 4 5 6 7 8 9 A.I.utism: Transforming Lives 💡 Inspiration As developers, our goal has always been to leverage technology to address real-world challenges. Our journey began with the realization that many individuals with autism face difficulty recognizing and practicing facial expressions due to challenges in reading social cues. This gap in resources sparked our inspiration to develop a tool specifically designed to assist individuals with autism in learning and practicing facial expressions. A.I.utism was born from our desire to create a supportive platform that helps individuals understand and practice social interactions in an intuitive and empowering way. 🌐 What it does A.I.utism is a platform tailored for individuals with autism to practice facial expressions using cutting-edge machine learning (ML) and OpenCV. By analyzing the user’s facial expressions in real-time, the tool provides feedback, helping users understand which expressions to practice and improve. Through interactive modules, users can gain confidence in recognizing and mimicking expressions, which can improve their ability to navigate social interactions more effectively. 🛠 How we built it The platform was built using React for the front-end, ensuring a responsive and intuitive user interface. OpenCV and ML algorithms were integrated to detect an"
      }
    ]
  },
  {
    "file_path": "./devposts/algoherence.html",
    "project_id": "algoherence",
    "title": "Algoherence",
    "tagline": "Algoherence democratizes trading with AI, offering easy access and financial literacy for all, breaking down barriers to financial inclusion.",
    "hackathon": "",
    "built_with": [
      "alpaca",
      "cohere",
      "langchain",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/785/908/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Complex Prompt Logo Buy Stock Thinking Buy Stock Answer Mean Reversion Thinking Mean Reversion Final Answer RAG Complex Prompt Logo Buy Stock Thinking Buy Stock Answer Mean Reversion Thinking Mean Reversion Final Answer RAG Complex Prompt 1 2 3 4 5 6 7 8 Algoherence: A Leap Towards Accessible Financial Literacy Use of Cohere API We used Cohere's Chat API to create agents through Langchain. When users send a message, Cohere's LLM helps us decide which tool to use. One of our tools used Cohere's RAG which searched the internet to get information. Using agents and Cohere, we were able to make a multi-function chatbot. In creating Algoherence, we harnessed the power of Cohere's API alongside Langchain in a way that's truly groundbreaking for our financial chatbot. This innovative pairing allowed us to craft an Agent with a deep understanding of finance, capable of engaging users in meaningful conversations about the stock market, investments, and much more. The agent has access to tools including buy stock, sell a stock, mean reversion emulation, as well as RAG, which ensures that users' queries can be reasoned with evidence-backed responses to prevent hallucination but also fetch relevant information for mean reversion algorithm to be used when evaluating stocks. The high level of intelligence that Cohere Chat API presents allows the users to interact with the model in very natural languages while fetching the desired information that doesn't have to be hard coded. The process of making Cohere Chat API an Agent was a very fruitful exploration where we tuned temperature and tried different command models, including nightly and lightly. After learning about ReAct and Structured Prompt, we were finally able to make the Cohere Chat API act as an agent, which is an approach that is not present in the current langchain or cohere community. We are confident that this is an innovative and technologically sophisticated project that is both useful to underprivileged people and p"
      }
    ]
  },
  {
    "file_path": "./devposts/a-cropping-drought.html",
    "project_id": "a-cropping-drought",
    "title": "A Cropping Drought",
    "tagline": "Save money and the world with this website! Give us your info, see the prices, and reimagine your lawn to be drought-safe.",
    "hackathon": "",
    "built_with": [
      "chakraui",
      "cv",
      "django",
      "firebase",
      "javascript",
      "python",
      "react-native",
      "tailwind",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This was two of our team member's first time using AI to solve a problem and they had a lot of fun."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Lots of water is used on front lawns annually. We wanted to try and help consumer make any easier choice by seeing their options that will save them money What it does This website converts thirsty lawns into fake ones. How we built it We built it by creating our own AI. Challenges we ran into The biggest challenge we ran into was not having any data or api for determining lawns so we had to create our own data. Accomplishments that we're proud of This was two of our team member's first time using AI to solve a problem and they had a lot of fun. What we learned We learned a lot. We had to understand how to clean our data before training our model. What's next for A Cropping Drought Built With chakraui cv django firebase javascript python react-native tailwind tensorflow Try it out GitHub Repo GitHub Repo GitHub Repo Submitted to CruzHacks 2024 Created by rickNrip Bailey Andrew Solbjor Cody Kneale Andrew Bustos"
      }
    ]
  },
  {
    "file_path": "./devposts/ai4genetx.html",
    "project_id": "ai4genetx",
    "title": "AI4GenetX",
    "tagline": "My idea is using TensorFlow 2.0 and a convolutional neural network to improve the detection of rare craniofacial genetic disorders using only facial images.",
    "hackathon": "",
    "built_with": [
      "gpu",
      "nvidia",
      "objective-c",
      "python",
      "swift",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/905/966/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Screenshot of the home page of the AI4GenetX App Screenshot of some of the code output as ipynb file on Jupyter Notebook. (output of the rest of the code is in the GitHub link) App Icon Screenshot Screenshot of the home page of the AI4GenetX App Screenshot of some of the code output as ipynb file on Jupyter Notebook. (output of the rest of the code is in the GitHub link) App Icon Screenshot Screenshot of the home page of the AI4GenetX App 1 2 3 4 Inspiration I was inspired to build AI4GenetX recently. I have just started to get deeper into machine learning and TensorFlow recently. I have seen the amazing applications of machine learning and wanted to focus a project on improving the quality of life of different people with different diseases. Through my research, I found rare craniofacial genetic disorders as harder to identify by doctors and wanted to try using machine learning to improve detection. This is when AI4GenetX was born! What it does AI4GenetX is an iOS mobile application which uses a trained TensorFlow 2.0 CNN model. The app takes a facial image (either from the user's camera roll or a live photo from their camera) and runs it through the trained CNN model. For this project, the two rare craniofacial genetic disorders I focused on were Down Syndrome and Williams Syndrome (these were my two classes plus a normal class, for a total of three classifications). My CNN model outputs a predicted class and a confidence level (probability). How I built it To build it, I first had to create my own image dataset (as a preexisting image dataset of facial images of rare craniofacial genetic disorders is not available). To make the dataset, I wrote a Python script which took a list of inputed Youtube video files (which I complied from Youtube under Youtube's Fair Use Policy) and searched each video frame for a face and saved them each as a photo. I then went through the images and created the three classes of images (Down Syndrome, Williams Syndrome, and Normal) in t"
      }
    ]
  },
  {
    "file_path": "./devposts/alphad-technologies.html",
    "project_id": "alphad-technologies",
    "title": "AlphaD Technologies",
    "tagline": "Rapid Disease-Protein Targeting with AI - We enable researchers to rapidly identify proteins critical to diseases.",
    "hackathon": "",
    "built_with": [
      "alphafold",
      "css3",
      "django",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/582/805/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Working Description! Working Description! Working Description! 1 2 Inspiration The inspiration of this project was based upon the AlphaFold API which one of our team members discovered a few months back. While in anatomy class learning about proteins, to maximize efficiency and have correct protein structures, one of our members found AlphaFold to make protein structure models. Coming into the project, with the knowledge of the AlphaFold API, they figured it would be perfect to incorporate into a project for this health based hackathon. What it does Our web application is a tool that combines medical research with AI technology. It interacts with users easily and prompts them to enter disease names. AlphaD provides an array of protein data through its seamless connection with the AlphaFold API. This information is a vital tool for observant researchers, acting as an indicator in the huge ocean of biological knowledge. Our application enables researchers to speed up the essential task of identifying crucial proteins, therefore expanding the boundaries of medical knowledge and research. It does this by providing quick and informative access to protein information for multiple disorders. How we built it In the development of AlphaD Technologies, we effectively used the powerful Django framework in addition to HTML, CSS, and JavaScript. Additionally, with the inclusion of AlphaFold API, a AI System that predicts a protein's 3D structure, and ChatGPT API, we were able to facilitate the main feature of the website, which was displaying information of given proteins. Challenges we ran into In the course of development, our team struggled with the handling of the AlphaFold API. Analyzing their return data, we were clueless when it came to getting the model of the protein through the API. After a bit of research about different file types and urls and how to incorporate them into HTML, our teammates successfully faced our biggest challenge. Accomplishments that we're proud o"
      }
    ]
  },
  {
    "file_path": "./devposts/ascii-chess.html",
    "project_id": "ascii-chess",
    "title": "ASCII Chess",
    "tagline": "play chess using ascii character pieces!",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/583/126/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 ASCII Chess Master 🏆 Inspiration Chess is the ultimate strategy game, but finding an accessible, beautiful, and fully-featured chess application that works seamlessly across all devices can be challenging. We wanted to create a chess experience that combines the elegance of ASCII art with modern web technologies, making the timeless game accessible to everyone while maintaining the sophisticated gameplay chess masters demand. What it does ASCII Chess Master is a fully-featured, interactive chess game that brings the classic board game to life using beautiful Unicode chess pieces (♔♕♖♗♘♙ vs ♚♛♜♝♞♟). Players can: Play Complete Chess Games : Full implementation of chess rules including piece movement, capturing, check, checkmate, and stalemate detection Interactive Gameplay : Click-to-select pieces with visual feedback showing valid moves (green highlights) and capture opportunities (red highlights) Smart Move Validation : The engine prevents illegal moves and ensures players can't put their own king in check Game State Tracking : Real-time display of current player, captured pieces, and game status Move History : Complete game notation in standard algebraic format for review and analysis Responsive Design : Seamlessly adapts from desktop to mobile devices while maintaining perfect ASCII alignment How we built it The application leverages modern web technologies for optimal performance and user experience: Frontend Framework : React 18 with TypeScript for type-safe, component-based architecture Styling : Tailwind CSS with custom color schemes and responsive design patterns Chess Logic : Custom-built game engine with comprehensive move validation, check detection, and game state management User Interface : Lucide React icons for intuitive controls and visual feedback Build Tool : Vite for lightning-fast development and optimized production builds Deployment : Netlify for reliable, global content delivery Technical Challenges We Overcame Chess Engine Implementation"
      }
    ]
  },
  {
    "file_path": "./devposts/algonauts-38tuyg.html",
    "project_id": "algonauts-38tuyg",
    "title": "COSMiQ",
    "tagline": "The ISS just got a sidekick",
    "hackathon": "",
    "built_with": [
      "cad",
      "celetrak",
      "physics",
      "python",
      "space-track.org",
      "spg4",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DevHacksWinner3rd Place",
      "space-track.org",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/349/748/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Simulating Satellite Launch Simulating Satellite Launch 1 2 3 Cosmic is an autonomous, AI-powered debris collector system that launches from the International Space Station (ISS) to identify and capture critical space debris interfering with satellite launches and orbital operations. After each mission, the system autonomously returns to the ISS for refueling and maintenance. This ensures a sustainable, reusable debris removal strategy without the need for dedicated launch vehicles. The system focuses on removing debris that directly threatens optimal launch trajectories and operational satellites, effectively minimizing collision risks and enabling safer, more efficient space missions. Inspiration The increasing density of space debris presents a serious risk to active satellites, future launch missions, and the ISS. Even a single piece of debris can cause millions in damage and delays. While agencies like NASA and ESA have explored debris removal, many solutions require separate costly launches and are not reusable. The idea behind Cosmic was to create an ISS-based, always-available collector that can be refueled and reused. This dramatically lowers mission costs and maximizes response efficiency, offering a smart, sustainable approach to active debris removal. How We Built It The system is built around a modular multi-agent AI architecture that operates in real time: Trajectory Optimization AI\nIdentifies the most critical debris based on orbital paths and planned launch trajectories using reinforcement learning and classical orbital mechanics (Hohmann transfers, Lambert solvers). Navigation and Dispatch AI\nPlans and adjusts real-time launch and return paths from the ISS to target debris using A* and D* algorithms. This ensures collision avoidance and adaptive mission routing. Execution and Control Agent\nOperates the robotic arm and propulsion system for physical debris collection and return operations. Technologies Used: Python (Poliastro, sgp4, NumPy, TensorFlow"
      }
    ]
  },
  {
    "file_path": "./devposts/artifact-explore.html",
    "project_id": "artifact-explore",
    "title": "Artifact Explore",
    "tagline": "A web app to explore and create a journey to view various artifacts",
    "hackathon": "",
    "built_with": [
      "css",
      "django",
      "html5",
      "javascript",
      "node.js",
      "python",
      "scss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by the \"swiping\" design from Tinder and decided to build a web app that is similar to Tinder where you can \"swipe\" through artifacts. We integrated a \"create a course\" for people (like teachers) who want to create a predetermined sequence of artifacts to show others. We also added a discussion forum where users can ask/talk about the artifact What it does It displays various museum artifacts with a small description one at a time. Users can log in to save the artifact in their \"collection\", join the discussion page for the artifact, or view other artifacts. Users can also create a predetermined sequence of artifacts that they want to show to others (which we call a \"course\"). The web app will generate a code that represents the course and anyone with the code will be able to visit/follow the sequence of artifacts. How we built it We used Django and python for the backend and HTML/CSS/JS for the frontend with a bit of node/SCSS for styling Challenges we ran into Getting everyone to understand the same idea/design for the UI/UX Figuring out how to get a specific sequence when the user inputs a code Designing the databases Making the web app dynamic without using a frontend framework Accomplishments that we're proud of Getting the project working Building a fully-fledged web app Designing the database What we learned How to sleep for only 4h Got better at using git Passing data from frontend to backend on the same page Using JS to make webapp dynamic What's next for Artifact Explore We can probably use AI to create recommendations for what artifact the user sees next. We can also improve on the UX/UI for the discussion and artifact pages Built With css django html5 javascript node.js python scss Try it out GitHub Repo Submitted to hackathon x - vol.2 Created by Ryan Lam UWaterloo Physics Michael Ng Jax Wang uwo 24' intermediate FE"
      }
    ]
  },
  {
    "file_path": "./devposts/altruistic-agent.html",
    "project_id": "altruistic-agent",
    "title": "Altruistic Agent",
    "tagline": "Operation: Neighborhood",
    "hackathon": "",
    "built_with": [
      "godaddy-registry",
      "google-cloud",
      "html",
      "linode",
      "tailwindcss",
      "unsplashapi",
      "vanillajs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Agent:HackerWinnerBest use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/728/197/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 ✨Inspiration✨ BATMAN. Besides being the world’s greatest detective, he does everything he can to make the world a better place. Batman runs multiple charitable organizations as Bruce Wayne and becomes a hero saving countless lives in Gotham City. We created a web-app that helps YOU be like batman. ⚙️What it does⚙️ The web-app is essentially a mission directory for special agents like you, who want to become just like Batman. These missions are carefully selected to benefit society. An agent receives a message on the homepage after logging in. The agent can choose to view the mission directory, which takes him to a new page in our application. Over there, clicking a button generates a mission, which the agent has to complete. Some of our missions are — Donate Blood, Volunteer at a Soup Kitchen, Plant a Tree etc. The resources tab includes a list of organizations that would help the agent on their way along with a map. 🏗How we built it🏗 We used TailwindCSS, VanillaJS and HTML to build the application. The Unsplash API lets us show images of our missions. We also did full justice to tools like Google Cloud, Linode and GoDaddy provided by Major League Hacking this weekend. Here’s how we used them: 🟡Use of Google Cloud - https://high-acre-325503.web.app/ 🟡 We built Altruistic Agent's authentication system with Google Cloud's Firebase. We chose this because we wanted to make an application that was VERY VERY SECURE — something Batman himself would use. We learned how robust & fast Google Cloud services are and seeing that Firebase had a free plan that was great for us student hackers, using Google Cloud was kind of a no-brainer. Additionally, Firebase Authentication provided a backend service, easy-to-use SDKs, and ready-made UI libraries, and the ability to authenticate using passwords, phone numbers, Google, Facebook and Twitter, and the like. Thus, implementation was easy and we are pretty sure we made it incredibly convenient for our users while keeping it secur"
      }
    ]
  },
  {
    "file_path": "./devposts/altsight.html",
    "project_id": "altsight",
    "title": "AltSight",
    "tagline": "A customized wearable assistant for the visually impaired",
    "hackathon": "",
    "built_with": [
      "espeak",
      "google-cloud",
      "google-cloud-vision",
      "python",
      "raspberry-pi",
      "ssh"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best use of Google Cloud Created by Neel Adwani yeet",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/607/816/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration ✨ From the perspective of someone who is visually impaired, the world seems to be a bit different but with the power of technology, we can change that. Using state-of-the-art (Google cloud vision in this case) object detection algorithms, their worldview can be improvised. What it does? 👨‍🚀 It is a custom, and portable object recognition device that can be worn as a cap, and can be connected to most audio devices. This wearable will play out the names of objects that are encountered by the user, who is supposedly visually impaired in this case. How I built it? 🏗 This setup is equipped with a raspberry pi, camera, and a power source which is a USB adapter as of now, but can be replaced with a 18650 lithium ion battery. With the help of Google's Cloud Vision API, I got most probable name of the object in front of the camera and used espeak on it, which is an open-source text-to-speech library in python. Challenges I ran into 😨 I'm traveling most of the time this weekend, and had less than 18 hours to build it, so I built a quick project. Accomplishments that I'm proud of 🚀 I'm proud of myself for finishing up the whole project in a short span of time. What I learned? 🏫 It is calm and cozy to write up devpost submissions in a train. What's next for AltSight? 🥠🔮 I'll make it fully portable once I have an Li-Ion battery and its adapter. Built With espeak google-cloud google-cloud-vision python raspberry-pi ssh Try it out GitHub Repo Submitted to FrostHack Hacky Birthday MLH! Winner Best use of Google Cloud Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/articuaite.html",
    "project_id": "articuaite",
    "title": "ArticuAIte",
    "tagline": "ArticulAIte automates first-round interviews with AI-powered VR, generating structured questions, evaluating candidates transparently, and providing real-time hiring insights.",
    "hackathon": "",
    "built_with": [
      "chatgpt",
      "langchain",
      "metaquest",
      "nvidia",
      "omniverse",
      "openai",
      "unity",
      "verecel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We deployed a VR-based solution on Meta Quest 3, aligning with Meta’s Most Technically Complex Hack track.",
      "Candidate performance tracking over multiple interview rounds.",
      "Seamless ATS (Applicant Tracking System) integration for streamlined hiring workflows."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/273/277/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration Interviewing is one of the biggest bottlenecks in hiring. Companies spend countless hours conducting first-round interviews, often struggling with standardizing evaluations and reducing bias. Candidates—especially neurodivergent ones—face challenges navigating interviews due to inconsistencies in assessment criteria. Our team, many of whom have experienced these issues firsthand, wanted to build a solution that streamlines early-stage hiring while ensuring a structured, transparent, and adaptable experience for candidates. That’s why we created ArticulAIte, a VR-enabled AI interview automation platform that allows companies to generate, deploy, and assess structured interviews using AI-powered avatars. Recruiters input a prompt, and our system automatically generates interview questions, evaluation criteria, and assessment metrics to ensure consistent and efficient hiring decisions. What it does ArticulAIte automates first-round interviews by enabling companies to create AI-powered interviewers that dynamically assess candidates based on customizable prompts. The platform provides: Automated Interview Generation – Recruiters input a prompt (e.g., “Assess technical skills for a backend developer. Ask about algorithms and data structures.”), and ArticulAIte generates a structured interview with relevant questions. Customizable Evaluation Criteria – The AI generates a list of assessment metrics based on the prompt and questions, ensuring standardized evaluations across candidates. AI-Driven Interview Deployment – Interviews can be conducted in VR or on a web-based interface, where candidates interact with an AI avatar interviewer. Post-Interview Analysis & Justification – ArticulAIte analyzes responses, extracts key metrics, and cites specific reasoning for each score, providing transparent, data-driven feedback. This allows companies to efficiently scale hiring, reduce recruiter workload, and ensure objective candidate assessm"
      }
    ]
  },
  {
    "file_path": "./devposts/altru.html",
    "project_id": "altru",
    "title": "Altru",
    "tagline": "A healthier model, for a wealthier you",
    "hackathon": "",
    "built_with": [
      "figma",
      "flutter",
      "metamask",
      "react",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/815/624/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Unmet needs in Health: 1. Data is a valuable resource : especially, Healthcare data: locked by EPIC and hospitals. Patients need to request it in a cumbersome process for access to their own data. The ever growing wearable data: sleep, exercise, device habits, diet, home medical devices 2. People: Are kept out of the loop (both in transparency and in profit): Big companies, big pharma/research institutions are already using your data without your awareness (and sometimes without your consent) 3. Small entities (researchers, clinicians, small NFPs): Health-related data requires privacy treatment: and small entities cannot afford/do this treatment, which raises cost of access 4. Insurance companies: generally operate in a passive outdated model: use the small payments of many people to cover the large health costs of a few, and take a cut Some have started active measures, like incentivising weight and cholesterol loss. However, more are scared to do it, as there is not enough data on the impact to risk and profitability What it does A platform on the blockchain to improve health data access and fairer monetisation.\nEmpowers users/patients with control, oversight, and earning options to monetise their data to companies and groups they support. Built With figma flutter metamask react visual-studio Created by Product Management mainly, and some Design. Clarified features, engaged stakeholders, guided wireframing, did the UX typing, made logo, made slides/advised slides, pitched demo, created/edited the video, and organised the team. Joey Koh Product Engineer, Electrical Eng., ML pipelines, Consultant, Idea Thrower, Team Facilitator Ehtesham Siddiqui Meliora Ho A student, researcher, and avid programmer Abdulhadi Hashim"
      }
    ]
  },
  {
    "file_path": "./devposts/alzheimear.html",
    "project_id": "alzheimear",
    "title": "ActivEar",
    "tagline": "ActivEar is a product to aid people with Alzheimer's, or any other memory-stunting disease, helping them jog their memory using their personal data.",
    "hackathon": "",
    "built_with": [
      "elevenlabs",
      "fastapi",
      "ffmpeg",
      "gpt",
      "pinecone",
      "python",
      "react",
      "shadcnui",
      "tailwind-css",
      "typescript",
      "uvicorn",
      "vectorization",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/587/857/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "As a team, we collectively understand the struggles of being forgetful. With needing to remake an Apple ID password on every login, it gets frustrating, and that’s only a fraction of what patients with Alzheimer's experience. With this in mind, we built ActivEar. ActivEar is an application that continuously records, transfers, and transcribes data from the user. Utilizing the microphone, it transforms audio into text that is then stored in a vector database. When the user asks a question, ActivEar retrieves and searches the relevant data, using an API to provide helpful answers. Originally, we had planned for a major hardware component that consisted of an ESP32-based microcontroller, a microphone, a speaker, and a battery. The goal was to have an inexpensive, portable method of access to ActivEar's services. Unfortunately, we ran across multiple unrecoverable issues. After we had tested each component and subsequently soldered the circuit together, we discovered a short that proved fatal to the microcontroller. Despite this, we carried on and loaned an alternative microcontroller. After a minor redesign and reassembly, we later discovered that some of the crucial libraries we had been using were no longer compatible and there were no functional equivalents. Defeated, sleep-deprived, and with 9 hours remaining, we went back to the drawing board to see how we could salvage what we had. Most of the software backend had been completed at this point, so we made the difficult decision of dropping the hardware component completely in favour of a multi-platform application. With only 8 hours remaining, we successfully put together a working browser demo as shown. Despite facing so many challenges, we never gave up and continued to work past them. We learned the importance of working together to push through challenges and what could be achieved when we do so. Every project has its challenges, it is just a matter of working through them. As young students, it is common for "
      }
    ]
  },
  {
    "file_path": "./devposts/80-minute-assistant.html",
    "project_id": "80-minute-assistant",
    "title": "too long; didn't listen",
    "tagline": "Convert audio files to detailed notes!",
    "hackathon": "",
    "built_with": [
      "gemini",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/899/343/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "front page Inspiration It can be difficult to focus on and retain information from verbal presentations. Luckily, tl;dl has your back, so you can continue pretending you remember everything from Monday's standup. What it does This Gemini AI-powered tool transcribes audio recordings to text, then provides either a brief summary or detailed, formatted notes of the audio's contents. How we built it Python, Google Cloud Speech and Text AI, Gemini AI API and Streamlit Challenges we ran into Iman: everything except Colab refused to work on my end, so it was a tough decision between trying to troubleshoot everything, or write everything up and have Lavanya test it on her end. Accomplishments that we're proud of Iman: I got to use an AI API for the first time! It was very cool and I've learned a lot more about prompt engineering.\nLavanya: got to work with in-app audio with streamlit What we learned What's next for tl;dl Built With gemini python streamlit Try it out GitHub Repo Submitted to Hack with AI Created by Iman Umair-Qaiser UWaterloo CE '26 Lavanya Yadav Trying to learn how to do things"
      }
    ]
  },
  {
    "file_path": "./devposts/accxbot.html",
    "project_id": "accxbot",
    "title": "Accsbot",
    "tagline": "A helpful and more personalised companion",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "api.ai",
      "heroku",
      "html",
      "unity",
      "webvr",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/543/875/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "TRY IT OUT https://bot.api.ai/accxbot (What can it do: flight info (Emirates, Jet Airways, Vistara), complaints, entertainment linking and links specific to location of person in flight) Inspiration Usually there is a series of problems that come up when someone is taking a flight. Though there have been ways in which the experience has been tried to be maximized by the use of android applications and information desks available in every airport. However, there is still a lot of scenarios these days in which problems for people trying to take up the flight takes place. In most of the cases, there is a requirement of a personal assistant for people in helping them travel with ease. What it does As discussed, ease of access of information as well as delivering the information to anyone at any point of time is really important. In order to ensure that the whole process is more sublime, we have come up with a simple chatbot that can be used by any passenger anytime to get all information about the flight, whether it is flight details or giving complaints related to anyone or maybe getting some information about how to kill time during the flight. The bot can be asked anything.\nIt helps in making the whole experience better and more peaceful giving more satisfied customers. How we built it We used api.ai based chatbot for which we trained several labels for natural language processing. We then used wix for hosting a webpage in which we added details related to in-flight entertainment. Apart from that we have also used webVR and unity for making a VR and AR application and webpages that can be used in keep the passengers busy. Challenges we ran into Integration of the whole system\nwebVR based virtual environments\nchatbot training Accomplishments that we're proud of Completing this project and making it working! Built With android-studio api.ai heroku html unity webvr wix Try it out GitHub Repo Submitted to Vistara Hackathon Bangalore Created by Chatbot & Webpages Shreyasv"
      }
    ]
  },
  {
    "file_path": "./devposts/ars.html",
    "project_id": "ars",
    "title": "WACH",
    "tagline": "We save lives by coordinating helpers in catastrophes caused by extreme weather occurrences.",
    "hackathon": "",
    "built_with": [
      "css",
      "draw-io",
      "express.js",
      "html",
      "javascript",
      "react",
      "rest-api",
      "tailwindcss",
      "web-socket"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/672/962/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "No catastrophes happened, though no need to help Two open events in the open event view Event details of an example event One open event just popped up An event in the my event tab No catastrophes happened, though no need to help Two events, the user participating in the upper one No catastrophes happened, though no need to help Two open events in the open event view Event details of an example event One open event just popped up An event in the my event tab No catastrophes happened, though no need to help Two events, the user participating in the upper one No catastrophes happened, though no need to help 1 2 3 4 5 6 7 8 Inspiration \"Es hakt beim Krisenmanagement im Ahrtal: Helfer und Betroffene fordern stärkere Koordination\" - \"\"It's faltering in crisis management in the Ahr valley: Helpers and those affected demand stronger coordination.\"\" Rhein-Zeitung (30. Juli 2021) The flooding in the region of Ahr valley in 2021 was disastrous. And part of the problem was a severely flawed crisis management system: Hundreds of citizens of close-by regions were offering to help the affected people, couldn't, however, since there was no reliable and effective coordination system for the voluntary workers. We want to make such a scenario for Munich impossible! That's why we strive to build a fast and resilient volunteer coordination tool for the City of Munich! What it does Our tool provides one single centralized platform to coordinate voluntary helpers. Our first prototype is specialized on the needs of the helpers. It therefore provides features like a notification service, which informs you about open tasks in your area. To enable customization, the user can freely decide, what sort of tasks he wants to be informed about. When the user accepts a task he is provided with a detailed overview including the planned time slot for the task, the route to the location, and an explanation of the task. Information about the accident can be provided in a separate application by the res"
      }
    ]
  },
  {
    "file_path": "./devposts/armigo-0usdxe.html",
    "project_id": "armigo-0usdxe",
    "title": "ARmigo",
    "tagline": "ARmigo offers emotional support and anxiety alleviation through AR – chat with a virtual therapist or play with a Corgi companion in the time you need the most, right from the comfort of your home.",
    "hackathon": "",
    "built_with": [
      "blender",
      "fetchai",
      "flask",
      "javascript",
      "lens",
      "ngrok",
      "python",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/396/148/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "ARmigo with Alice ARmigo with Alice ARmigo with Alice 1 2 Inspiration Have you ever felt alone, stressed, or wished you could easily talk to a close friend, a professional therapist, or even just a comforting, playful puppy? We feel you, and that's exactly what inspired us.\nWe believe augmented reality (AR) has the power to create real emotional connections with others through our senses. Our goal was to build an immersive experience that offers users emotional support anytime, anywhere right in front of their eyes. What it does ARmigo is an augmented reality experience built for Snapchat Spectacles that alleviates anxiety through multiple channels. We want to highlight 3 key features of our AR application: One-on-One Chats: Engage in a virtual conversation with a virtual companion, your reliable friend and listener, Professional Mental Health Advice: some characters also equip rich domain knowledge in psychology and mental health, empowered by the comprehensive agentic system. Corgi Companion: Interact with an adorable animated Corgi that can handshake, play dead, roll over and offer delightful companionship. How we built it Development Environment: Lens Studio was our main platform for building and animating the AR experience, a powerful studio tool that provides a gamified development experience for AR developers. Virtual Human Interaction: We leveraged many built-in and external toolkits to establish one-on-one communication with our custom virtual human agents. Our pipeline begins by capturing the user’s audio and video inputs through the snap spectacles hardware, where the audio inputs are further converted to natural language using Lens Studio’s native speech recognition library support. Together text and image inputs are distributed to LLM-based AI agents for thorough research and reasoning. The agent has access to a diverse database where it can thoughtfully “produce” an informative and relevant answer, and return its responses as synthesized audio output b"
      }
    ]
  },
  {
    "file_path": "./devposts/ambuplus.html",
    "project_id": "ambuplus",
    "title": "Ambuplus+",
    "tagline": "Expect fast ⚡ & worry less with Ambuplus+ 🚑",
    "hackathon": "",
    "built_with": [
      "android",
      "firebase",
      "gcp",
      "glide",
      "google-maps-sdk",
      "love",
      "mqtt",
      "solace"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place Overall Winner Solace - Best use of PubSub+ Created by I was in charge of the video ;) Pr",
      "uOttaHack 4Winner1st Place OverallWinnerSolace - Best use of PubSub+",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/385/724/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "System-Architecture GIF System-Architecture GIF System-Architecture 1 2 3 Inspiration These days, Emergency Response times for Ambulances have hiked to a whopping 150% with Covid19 positive patients asked to stay home for more than 2-3 days. Patients dealing with real emergencies often are receiving their ambulances late. Every second matters, and we can’t afford to lose a life because of delayed emergency response times. What it does Introducing AmbuPlus+ — a smart Ambulance service, which brings the nearest rescue squad to your home. You can also request blood from other users and blood banks. We have used Solace extensively in order to track Ambulances realtime. Ambulances push their live locations to specific topics which the backend subscribes to. The backend calculates the nearest Ambulance and matches the same when an user is in need. After this, the user’s application subscribes to the topic this ambulance is publishing its real time location to. We also confirm if beds are available at the hospital we might be going to & last but not the least it's supported by all devices above Android Lollipop! Expect fast, Worry less with Ambuplus+ 🚑 How we built it Ambuplus+ is crafted with ❤️. It's built on Android Native. We are using Solace's Pub-Sub for live-tracking of the ambulances and for initiating the blood request from the user end. We're also using Google Maps API to populate the info's of the same on the map viewport. The authentication of our app is being served via Firebase Authentication. And last but not the least, the chat server was deployed on a free dyno of Heroku. Our app is available in most local languages like Hindi, Bengali, Chinese, Korean, etc. Challenges we ran into We took a lot of time configuring and refactoring the example code of the Solace. Moreover, we were also looking at the security side of the location which is a very important thing to be kept in mind for these types of projects. Also, it was a bit difficult for us to collaborate"
      }
    ]
  },
  {
    "file_path": "./devposts/armi.html",
    "project_id": "armi",
    "title": "ArmI",
    "tagline": "Smarter workouts, better results! Our AI-powered fitness coach personalizes your workouts using real-time biometrics, optimizing performance and recovery.",
    "hackathon": "",
    "built_with": [
      "artificial-intelligence",
      "cloudflare",
      "dart",
      "flutterflow",
      "machine-learning",
      "python",
      "reinforcement-learning",
      "terraapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/274/230/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration The inspiration came from the need for personalized health advice to help maximize the potential of those in the army. Throughout my own experience with workout recommendation apps, I have had a lot of experiences with apps that take the \"one-size-fits-all\" approach. Without being able to receive that individual advice from top to bottom, there is the risk of injuries and negative impacts on health. What it does ArmI is an application that through data extracted from wearable devices provides workout advice based on individual biometrics through the use of a powerful reinforcement learning model. This allows for an adaptive and self-improving model that does not generalize for a population but tailors for the needs of every soldier. How I built it The UI was built on FlutterFlow, which required the use of API calls to interact with the backend to fetch data. The data was processed through Terra API to extract user fitness metrics, both the historical data to get the model going and real-time updates. The backend was developed in Flask, and this helped serve as an API layer to handle data processing. The main model is a reinforcement learning model using Stable-Baselines3 (PPO Algorithm) to optimize workout recommendations based on current fatigue levels and other biometrics. A custom Gymnasium environment was built to simulate and effectively go through that trial and error process to find the best workout routines. Cloudflare tunnel was also used for secure access to our local API without the need to deploy on the cloud. Challenges I ran into The deployment of the ML model so that Flutterflow could receive the predictions and display them was a difficult process to get organized. Additionally, ensuring the combination of the different metrics (bpm, stress, sleep respiration) was something I had to be extra careful with to ensure I was feeding the model with clean data. Accomplishments that I am proud of It was very rewarding seeing the model imp"
      }
    ]
  },
  {
    "file_path": "./devposts/agroit.html",
    "project_id": "agroit",
    "title": "Agroit",
    "tagline": "Farm Profitability Calculator",
    "hackathon": "",
    "built_with": [
      "flask",
      "johndeereapi",
      "matplotlib",
      "numpy",
      "pyplot",
      "python",
      "streamlit",
      "usda-ers"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "John Deere's Hack Challenge Created by I did everything :) Kanha Korgaonkar MLH Top 50 | Frontend &",
      "PickHacks 2022WinnerJohn Deere's Hack Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/900/023/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 💡 Inspiration My inspiration for Agroit was the John Deere Hack Challenge. I realized that the potential for improving farming practices and profits by using technology to collect and analyse data, that would lead to an increase in production in the farming system is massive and unexploited, and could lead to innovation and implementation of a variety of new ideas. That is why we built a user-friendly and accessible application that helps farmers understand their field profitability and find ways to maximize it. With this tool, we hope to help farmers focus on being both profitable and sustainable. ⚙️ What it does Agroit is a clever, simple and accessible tool that helps farmers assess their farm's profitability and find ways to improve and maximize it. Agroit accepts field data and details of expenses per acre from the farmer and compares them to USDA's estimated costs of production. In order to simplify and visualize all of this data, Agroit plots it in the form of pie charts with plotly, which helps you understand where you can potentially reduce expenses. Finally, you have to enter the your commodity price, and if you don't know it, Agroit provides links to view live commodity prices and futures for the crop you select. Then, it calculates and displays metrics of your field's profitability. Depending on your expenses for a particular area, it also generates ways to reduce them. 🏗 How we built it We built Agroit Auth with Flask and John Deere OAuth2 API. The main app is built with Python and Streamlit. It uses data from USDA's ERS page, more specifically the commodity costs and returns, to provide farmers with an estimated cost of production, which enables them to decide where their expenditure could be minimized. For visualizing this data, Agroit has graphs and charts that it generates through Plotly, Matplotlib and Numpy. A quirk/feature you might notice with Agroit, is the color scheme of the app and the logo. Agroit uses the exact shades of Green, Y"
      }
    ]
  },
  {
    "file_path": "./devposts/actv.html",
    "project_id": "actv",
    "title": "ACTV",
    "tagline": "ACTV—the personalized, dynamic AI coach for all your fitness and nutritional needs. Get tailored workout plans and custom meal recommendations to achieve your goals efficiently based on your workouts.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "gemini",
      "jitter",
      "mongodb",
      "mongoose",
      "node.js",
      "openai",
      "pexel",
      "pixabay",
      "postman",
      "react",
      "strava",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/053/377/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Saved meals page for all the suggested meals that turned out to be favourites. Landing page with minimal but thought after UX for Easy and Efficient Access. Landing page for the AI Coach. Personalised workout suggestions made by the AI Coach. Personal AI coach suggesting meals according to the workout and recovery loads. Once you like the Suggested Workout Week Block, you can add it and save to your agenda. Saved meals page for all the suggested meals that turned out to be favourites. Landing page with minimal but thought after UX for Easy and Efficient Access. Landing page for the AI Coach. Personalised workout suggestions made by the AI Coach. Personal AI coach suggesting meals according to the workout and recovery loads. Once you like the Suggested Workout Week Block, you can add it and save to your agenda. Saved meals page for all the suggested meals that turned out to be favourites. 1 2 3 4 5 6 Inspiration ACTV was born out of a personal need—while training for my Ironman, I realized how much professional coaching could help but was well beyond my budget as a student. I wanted to be at my peak but couldn’t justify paying so much for the tailored advice that would take my training to the next level. That frustration drove me to find a solution. Instead of giving up, I saw it as an opportunity. What if I could build something for myself, something that others in a similar position could use as well? When I learned about the potential of using large language models (LLMs) like GPT and integrating fitness data from apps like Garmin and Strava, I knew I had to bring this idea to life. The hackathon was the perfect stage to take this dream beyond a basic concept and turn it into a working reality. What it does ACTV is a personalized fitness coaching platform built from the ground up to provide smart, actionable training plans and nutritional recommendations tailored to individual athletes. By pulling real-time data from Garmin and Strava, the app analyzes user perfor"
      }
    ]
  },
  {
    "file_path": "./devposts/2ndchance.html",
    "project_id": "2ndchance",
    "title": "2ndChance",
    "tagline": "We provide individuals with criminal backgrounds a 2nd chance in life by providing exclusive CS-related opportunities",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Google Nest Hub (2) Winner Swag Created by Ryan Lam UWaterloo Physics Jax Wang uwo 24' intermediate",
      "Hack Brooklyn 2021WinnerGoogle Nest Hub (2)WinnerSwag",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/495/196/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Prisoners and individuals with a criminal background are very isolated from society. Our project aims to help provide a 2nd chance to these individuals by providing them an exclusive CS-related opportunity so they can enter society (after their prison time) and contribute to society. Our project also improves the diversity of workplaces since the individuals would have a non-conventional path. What it does 2ndChance connects prisoners to job posts to look for jobs. Their accounts can be monitored by prison administrators where they have full control over prisoner's information and whether they can have an account or not. An administrator first registers an account for a specific prisoner by entering the prisoner's personal information such as name, age, criminal ID and etc. then provides username and password for that prisoner. Later, the prisoner can use that username and password to login to his/her account to view profile and browse job posting. However, personal information set by the admin will not be changeable which prevents frauds and misinformation. How we built it We built this program by using Flask framework for backend and Bootstrap, HTML, and CSS for frontend. The login, user and job information are all stored on a database in Flask while the design and client functionalities of the site are programmed using Bootstrap, HTML, and CSS. Challenges we ran into We ran into many challenges along the way such as adding prisoner information from the admin's dashboard and updating the information on the prisoner's profile. This all stemmed from the challenge of passing data from Flask to HTML and vice versa. Accomplishments that we're proud of Having a working database where you can add/remove things Getting the project done What we learned Passing info between the frontend and backend Using the passed info to make changes in the database/backend What's next for 2ndChance Allow companies to add job posting (but they will first need to be approve"
      }
    ]
  },
  {
    "file_path": "./devposts/autonoprint.html",
    "project_id": "autonoprint",
    "title": "AutonoPrint",
    "tagline": "Fully autonomous 3D printing system",
    "hackathon": "",
    "built_with": [
      "3dprinting",
      "ai",
      "arduino",
      "octoprint",
      "pcb",
      "raspberry-pi",
      "solidworks"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/941/491/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration At the time of development, at home 3D printers require constant surveillance and hands on intervention to clear and clean the print board. We saw this as an opportunity to allow users to be able to print multiple objects consecutively with proper cleaning between prints, as well as video surveillance and the use of AI to detect failures. What it does Our system detects when an object has finished printing, moves the print head away, adjusts the bed, and lowers a mechanical scraping arm. Then, the arm with a sharp edge clears the board as the print bed passes underneath it. Following the completion of this task, isopropyl alcohol dispensed from the arm is used to clean the bed sufficiently and prepare it for the following print. When a print is running, Octoprint hosts a webcam livestream, keeping the user updated on the status on their print. In addition, we've implemented the AI plug-in \"Spaghetti Detective\" that uses image detection to detect anomalies in the print. If an irregularity is detected, it notifies the user and stops the print, preventing dangerous accidents such as printer fires. How I built it Our mechanical arm is moved by a Servo. It features a tubing system running down the length of the scraper, which dispenses the isopropyl alcohol used to clear the board of all prints. The tubing system dispenses isopropyl alcohol using a diaphragm pump. We designed the parts of the mechanical arm in Solidworks and 3D printed them ourselves. We used a Raspberry Pi to run an Octoprint server, which interfaced with the printer. The raspberry pi includes a custom pcb for voltage regulation. The Octoprint server hosted the plugin Spaghetti Detector, which connected to a proxy server running an AI pipeline monitoring the print for failures through a webcam. Challenges I ran into Some challenges included managing our time to ensure all our mechanical parts were 3D printed on time, having adequate power deliver circuits, and ensuring we had ensuring all ou"
      }
    ]
  },
  {
    "file_path": "./devposts/american-airlines-gate-finder.html",
    "project_id": "american-airlines-gate-finder",
    "title": "American Airlines Gate Finder",
    "tagline": "Have you ever been late to a flight? Do you wish you got real time updates for how long it would take to get to your gate? Want to know if you can squeeze in a coffee break? AAGF is here for you!",
    "hackathon": "",
    "built_with": [
      "flight-engine-api",
      "google-directions",
      "google-maps",
      "google-maps-react",
      "material-ui",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/379/138/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Yellow Bar when you have to start going to the gate and there are 15 mins left. The leaderboard where you can get a rank for your steps and calories. Blue Bar when there is ample time to walk around. Red Bar when you have to start running. Yellow Bar when you have to start going to the gate and there are 15 mins left. The leaderboard where you can get a rank for your steps and calories. Blue Bar when there is ample time to walk around. Red Bar when you have to start running. Yellow Bar when you have to start going to the gate and there are 15 mins left. 1 2 3 4 5 Inspiration Every time we have flown, we have been kind of scared to leave the gate to go get some food or look at a store in another terminal. We also missed some flights due to being late to our gates. As soon as we saw the AA challenge, we had some ideas on how to improve customer satisfaction, and this was at the top of our list. We wanted to find a way to ease the stress and occurrence of missing a flight. A major way for us to relieve the stress was to gamify the app so people would have some fun while still going on time to their flights. What it does Currently, our app gives you the time it would take to travel between 2 places in the airport by walking, and it is calculated by actual google maps directions, so it is accurate if we assume normal walking speed. The path is then displayed on the screen with a time to boarding, and it will be updated in real time with gate updates, and any boarding time changes. The app then changes colors based on how long you have to get back to your gate so you can take a quick glance and know what to do. There is also a leaderboard of steps taken so people can have some fun with walking around and it will keep people active. Another main feature is that you can select options to do things that will add to the time and so the bar at the top changes colors. For example, if you add that you want to go to the bathroom, 30 minutes gets added to the time needed, and so t"
      }
    ]
  },
  {
    "file_path": "./devposts/arlingo-wsre0k.html",
    "project_id": "arlingo-wsre0k",
    "title": "ARLingo",
    "tagline": "An AR app that helps you master your Lingo",
    "hackathon": "",
    "built_with": [
      "arkit",
      "openai",
      "swiftui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "of all, it takes less than 3 seconds to do everything"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/667/932/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Welcome Page Language Selection Step2 Step4 Step3 Step1 Welcome Page Language Selection Step2 Step4 Step3 Step1 1 2 3 4 5 6 7 8 9 Required Information Ayush - A student who's pursuing Computer Science currently doing research in Human Computer Interaction and loves to play badminton!\nLeia - A Computer Science student @ UC Berkeley very passionate about XR. I aspire to create multiple tech companies that get us closer to a great future and empower diverse people from all around the globe.\nManchen- An Electrical Engineering PhD student @ Stanford working on Optics and Photonics. Passionate about implementing XR\nTrack - XREAL and XR Trailblazer\nTeam Location - 016 Basement Huang\nHardware - iPhone (LIDAR Sensor)\nDevelopment Tools - xCode, OpenAI APIs, Swift, RealityKit, ARKit, and Sketch Fab (3d Models) Inspiration When growing up I learned English on my own by singing Justin Bieber’s baby. From then on, I really enjoy learning new languages. However, when I visit a foreign place I cannot always remember the meaning of some objects. So, I need to pull out my phone and go to the Translate app, and it’s actually not that fast to use. I need to find the app, get into the selection tab, and it doesn’t recognize the language I wanna translate to. It’s just a mess. So what if instead of that I would just open my camera and touch the screen to the object I wanna translate and voilà . I can even select a button to translate all items of a similar size around me, and best of all, it takes less than 3 seconds to do everything. Do you know that feeling when you see an object (in the real world or your mind) but don’t remember the word in the language you’re trying to learn What it does Arlingo helps millions of people around the world to translate anything they want around them.\nWe can help everyone who is in a new country, every tourist, every immigrant, even help the insert number of people with hands and hearing disabilities. Arlingo allows you to save time in three simple step"
      }
    ]
  },
  {
    "file_path": "./devposts/alexa-eye-doctor.html",
    "project_id": "alexa-eye-doctor",
    "title": "Alexa Eye Doctor",
    "tagline": "Our innovative technology allows effortless and instantaneous contact with your doctor, and all of that from home!",
    "hackathon": "",
    "built_with": [
      "amazon-alexa",
      "amazon-web-services",
      "clustering",
      "css3",
      "flask",
      "html5",
      "javascript",
      "machine-learning",
      "python",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hackatum18WinnerZeiss",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/723/622/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Summary Inspiration The worst thing about getting light illnesses, are the lengthy queue times at your doctors place and potential diseases you could catch from others visiting the doctor's place. This however, can be avoided!\nInspired by the already broad functionality of Amazon's Alexa , we set our minds on simplifying the doctor visit experience. We could only dream about replacing doctor visits with technology that would allow the same procedure from home, but towards the end of the project, our dream became a reality. What it does Our Diagnose application on your home Amazon device like Amazon Echo or Amazon Fire is all you need to contact your home doctor with consultation requests or any other questions that you might have. For the doctors, the life has never been easier - a special application designed just for doctors who are connected to our Diagnose network allows fast and easy review of all patient requests, questions or images. Our application supports: Full hand-free control of the application using Amazon's Alexa Medical history of patients and their previous diagnoses Two-way communication between the patient and the doctor Easily usable scheduling tool Live consultation requests for urgent problems Accessible diagnosis for the potential problems of the patients But most importantly - the eye health analysis. Using convolutional neural networks and other machine learning algorithms, we have managed to achieve close to perfect eye feature detection that was tested on massive facial image datasets provided to us by the University of Montreal . Using this technology we can provide insights about eyes to the doctor, extracted directly from the image thus speeding up the process of eye problem review and increasing the accuracy of your diagnosis. How we built it The program was built using multiple modern toolkits to ensure speed and stability. Since the focus of the program was eye analysis, the first part consisted of multiple machine learning algorithm"
      }
    ]
  },
  {
    "file_path": "./devposts/ai-boyfriend-of1kue.html",
    "project_id": "ai-boyfriend-of1kue",
    "title": "Damon, Your AI Boyfriend (aibf.rsvp)",
    "tagline": "Building a boyfriend that buys you flowers and treats your right.",
    "hackathon": "",
    "built_with": [
      "merklebot",
      "openai",
      "pinecone",
      "telegram",
      "wehead"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/772/042/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "A happy beta-tester of the wehead interface on the Apple Vision Pro Real telegram conversation that resulted in an order A happy beta-tester of the wehead interface on the Apple Vision Pro Real telegram conversation that resulted in an order A happy beta-tester of the wehead interface on the Apple Vision Pro 1 2 Inspiration 💡 In the face of a growing loneliness epidemic, notably among millennial women, 42% of whom fear loneliness more than cancer, and young adults with 61% feeling \"serious loneliness,” we built a solution that extends beyond mere digital interaction. For women, the consequences of loneliness raises the risks of heart disease and stroke by nearly a third and is intricately connected with heightened rates of depression, anxiety, and the potential for cognitive decline. Feelings of isolation are also a factor that drive many women to enter toxic relationships. Our AI boyfriend concept – called DamonAI – is born from the urgent need to combat these alarming trends by providing emotional support and companionship, aiming to mitigate the adverse effects of loneliness. Designed to provide companionship via adaptive conversation and physical gift sending, DamonAI enhances self-worth and fulfillment. It provides users with connection and emotional support in a safe, controlled, and engaging environment. What it does 💪 The primary platform for DamonAI's interaction is through Telegram, where it engages in text-based conversations. However, our AI boyfriend is engineered to serve as more than a chatbot. ​​DamonAI, designed to mimic the evolving nature of human relationships, leverages advanced natural language processing to remember and build upon every conversation. This ensures dynamic and evolving interactions. Central to its design is an integration with Instacart that responds to keywords in conversations to dispatch physical gifts, adding a layer of tangible interaction. This feature mimics the attentiveness found in relationships, making the AI's suppor"
      }
    ]
  },
  {
    "file_path": "./devposts/aristotle-1a73mt.html",
    "project_id": "aristotle-1a73mt",
    "title": "Project Aristotle",
    "tagline": "Project Aristotle harnesses the addictive nature of games like Cookie Clicker to make you more productive and innovates the future of learning.",
    "hackathon": "",
    "built_with": [
      "c#",
      "javascript",
      "react",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/355/940/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Plan Here is the link for our business plan: https://docs.google.com/document/d/1oBgPyO9pyNoALsNB94jSBAhFN_wjZfVblgC-SwBKu4E/edit?usp=sharing We are going for the most real-world applicable and entrepreneurial awards. Although this is just a proof of concept, the potential later on as we expand on this idea is limitless. If successful and implemented, the future of learning would change forever. Inspiration We have a vision for this project: to change the way we study. After many drafts and ideas planned out, we created a small proof of concept project to begin prototyping the different game models that we can design to see which form works best for learning and productivity. We wish that someday, we can turn this into a multiplayer game where other people can create content and study sets, similar to the Quizlet business model, but with a focus on making it rewarding. Then, we hope that educators and teachers will have the ability to surround their curriculum around this application, where elementary, middle, and high school classes can now learn in a fun and addictive manner where studying becomes a video game. With this, we have the potential to change the landscape of how our future generation learns. More than 60% of high school dropouts say they dropped because of boredom. By changing the mindset of school and study, we can make a significant difference in millions of lives. For now, the task is to find the best game model, and here is one of our prototypes. As we expand, we will add features and grow a userbase. What it does Project Aristotle harnesses the addictive nature of games like Cookie Clicker and Adventure Capitalist to make you more productive. Here, you have the ability to draft out tasks, schedule them, and track how long it takes you to complete them. Then, once you complete a task, you can cash it in for a cash gain on a unity game. This game takes the concept of Cookie Clicker with your own business tycoon, where you can buy up companies,"
      }
    ]
  },
  {
    "file_path": "./devposts/airplane-r5t2he.html",
    "project_id": "airplane-r5t2he",
    "title": "AirPlane",
    "tagline": "Discover AirPlane: Transform your old iOS device into extra storage! Enjoy seamless file management, transfers, and more across devices and double your storage overnight!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "swift",
      "swiftui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/542/798/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration We're no stranger to running out of storage on our phones from all the photos, videos, and apps that we download, and we've always wanted an easy way to increase our storage without having to upgrade our phones or pay to use subscription-based services like iCloud. Instead of trading in old phones for a small fraction of their original value or throwing them away, we wanted to come up with a way to utilize them as storage devices. What it does AirPlane is an innovative app that allows you to turn your old phones into cloud storage devices. AirPlane does that by creating its own file management system. Via Airplane, users transfer files from their current device to another device that has AirPlane installed on it. When they want to use those files, they can transfer the files from the other device back to their current device also using AirPlane. To be clear, AirPlane is different from iCloud because it uses an older phone's \"physical\" storage whereas iCloud is hosted on Apple's servers. Whereas iCloud comes with a monthly subscription, users face no cost when using AirPlane. In addition, AirPlane can potentially be used to backup a device's information without having to plug that device into a computer. Similarly, AirPlane is completely digital, meaning that users don't have to go through the pain of transferring data manually through an intermediate physical device. How we built it We built this app using Swift and SwiftUI for the interface. In order to initiate a successful data transfer between phones, we used Firebase as an intermediate, temporary storage source. Challenges we ran into Kevin, being from a web development background, has never worked with SwiftUI before, so he had to learn from Apple's 4-hour SwiftUI tutorial. Many aspects of mobile development are different from web development, and Apple in particular constrains customization of the UI, so Kevin also had to figure out how to work with that. \nSoham, never having used SwiftUI "
      }
    ]
  },
  {
    "file_path": "./devposts/a-purrfectly-pawesome-place-j9fw7k.html",
    "project_id": "a-purrfectly-pawesome-place-j9fw7k",
    "title": "A Purrfectly Pawesome Place",
    "tagline": "Prepare for cuteness overload! An avenue for people to study while relieving themselves of stress by taking a look at cat pictures.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "flask",
      "javascript",
      "nextjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by Mimi Zhang Helen Law Welcome to my minecraft server EMEKA ⚡️ Creative Soft",
      "WhiskerHacksWinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/400/639/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Domain.com Logo Pomodoro timer Home page of cute cats Design of some webpages Domain.com Logo Pomodoro timer Home page of cute cats Design of some webpages Domain.com 1 2 3 4 5 6 Inspiration ❤️ If you're ever feeling sad and depressed without any cats to cheer you up, don't worry! A Purrfectly Pawesome Place is a webapp that let you stare at insanely cute cat pictures and increase your productivity. You won't ever be sad again and get all your work done! Our main goal is to improve productivity with a pomodoro timer to keep track of studying and time spent in this purrfectly pawesome website. Under the forum page, users can discuss with other cat lovers about their interests to increase socialization. Cat owners can recommend cat toys for others to enjoy, and anyone can share their favourite music. The forum page is used for getting tips on better mental health and increasing productivity. A Purrfectly Pawesome Place is a website that boosts your happiness and productivity! Please feast your eyes on cats and enjoy the cuteness! This website is intended for everyone who is feeling sad or needs a bit of cuteness in their life, not just for cat owners! There's a purrfect place for everyone :) What it does 🦅 On the home page, there are pictures of super cute cats for you to stare at. By looking at cats, you will no longer feel sad and forget any negativity in your life. As you scroll to the bottom, there is a next button for you to click on to go to the next page and prevent any doom-scrolling because cats have all our attention! Users can also create a profile by signing up and logging in. On their profile page, users can see the cat pictures they posted and make new friends by sharing a bit about themselves. By having an account, users can upload cat pictures and comment on them. Here we’re scrolling through cat memes that’ll make you laugh and smile. Next, there’s also an art page where users can post artwork of adorable cats they made. How we built it 🇺🇸 We built it"
      }
    ]
  },
  {
    "file_path": "./devposts/argon.html",
    "project_id": "argon",
    "title": "Argon",
    "tagline": "Hate reading the Terms and Conditions? Let argon help!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "bulma",
      "css3",
      "firebase",
      "flask",
      "html5",
      "javascript",
      "machine-learning",
      "nltk",
      "python",
      "react",
      "sqlite",
      "tailwind",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/662/301/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "footer landing_page team tech_stack argon main_form footer landing_page team tech_stack argon main_form footer 1 2 3 4 5 6 7 Business Write-up: 💡 Inspiration A genuine problem faced by millions of people every day. There was not enough awareness and useful tools for navigating the confusing terrain of online agreements. Big tech companies often collect and store large amounts of user data, which users consent to unknowingly. 📃 What it does Condenses thousands of lines in agreement forms into the few concise lines containing key points. Customizes the points according to the user's preferences and suggests alternative services that may provide more user-friendly policies. We have included additional tools to aid with accessibility factors such as text-speech, translation and pre-loaded terms and conditions. 🛠 How we built it Frontend: The frontend of our website was built with HTML, CSS, JavaScript, ReactJS, and Vue. We also used Bootstrap, Tailwind CSS, and Bulma for styling. Backend: The backend of our website was built with Python Flask, Firebase for authentication and SQLite databases. Machine Learning: We used NLTK and HuggingFace to train our Natural Language Processing models. Branding, UI, design, and Video: We designed our website using Figma and edited our demo video using Adobe After Effects. 🛑 Challenges we ran into The short time frame was a challenge since all of our team members had other commitments over the weekend. As a result, we were unable to spend as much time on the project as we had hoped to. We also were not able to model the “perfect” summarizer, nevertheless, we had tested about a dozen different varieties. So, we had to create a custom solution in this short time frame. Additionally, we had to spend countless hours debugging the front-end framework to get our website up and running. 🏆 Accomplishments that we're proud of Creating a custom summarization model in a short time span. Designing and prototyping websites in various frameworks whil"
      }
    ]
  },
  {
    "file_path": "./devposts/american-airlines-attraction-finder-in-cities.html",
    "project_id": "american-airlines-attraction-finder-in-cities",
    "title": "American Airlines - Attraction Finder in Cities",
    "tagline": "Used MongoDB, Python, JavaScript, and React to create web app to show attractions/events in a city, intended for users to use when thinking about what to do for their next trip!",
    "hackathon": "",
    "built_with": [
      "git",
      "github",
      "javascript",
      "mongodb",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Description We believe that to persuade a customer, three things need to be fulfilled: the product's What, How, and Why. On the current American Airlines website, attempts to redeem miles are met with locations that you can use your points on. The customer knows what the location is (What is the location we're going to?) and understands that they will get their via air travel (How are we getting there?). But, the customer has to search up themselves what the city they're traveling to has to offer. To make it more convenient, we have designed a web app that shows a list of cities which, after clicking on, shows events that the city has to offer (Why are we going?). How we built it Created web app frontend using data surfing backend, using inputs from app users to determine what the backend gives to the frontend. Challenges we ran into Many data formatting issues Accomplishments that we're proud of Completed our first hackathon (3/4 of us have never competed), learned to use MongoDB, experience with React, JavaScript, Python, Frontend/Backend Built With git github javascript mongodb python react Try it out GitHub Repo Submitted to TAMUhack X Created by ahbalbaid BPerez17 Sarah Alramahi John Paul"
      }
    ]
  },
  {
    "file_path": "./devposts/ai-assisted-stories.html",
    "project_id": "ai-assisted-stories",
    "title": "AI Assisted Stories",
    "tagline": "\"Using our story AI, it can write anything from love letters to short stories. But it doesn’t mean we should let machines rule over us.\" <-- This was written by the AI.",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Let's ask the AI a few questions! Since our prompts aren't all that descriptive, the AI's responses aren't very coherent What inspires the story AI? How does it work? Is there a limit to what stories it can write? You’ll find out in this book. The best part is that you can try this technology for yourself right now! All you need is a computer and an internet connection. If you want to see what kind of stories your AI can write, just go to the website in the back of the book! I am also writing a novel using this AI. It has already written more than 50 chapters and counting. It writes faster than I can type. If you want to read this novel when it’s done, check out my author page on Amazon. Interesting... Well, this project was inspired by a game called AI dungeons. What does the story AI do? You don't need any special knowledge or skills. Just copy and paste a few lines of text into your browser's address bar. And press enter. It will then start writing its own story right in front of your eyes. This book will show you how you can do that too. You don't need any special knowledge or skills. Just copy and paste a few lines of text into your browser's address bar. And press enter. It will then start writing its own story right in front of your eyes. Something along those lines... The AI enhances prompts that you feel it with a whole story that you can add to on the go! The story AI's creators were met with challenges such as ... the character development of an artificial intelligence, and also creating a unique world where robots and humans co-existed. They decided to use modern technology as a base for the future technology that they would create for their story. The first episode was released on October 25, 2006. It was well received by critics and fans alike. Well, we faced issues mainly with Github merging. The story AI's creators learned many important lessons of code, including ... Python and Javascript. The two main characters are Asuma Shinohara and Aoi Miyamori"
      }
    ]
  },
  {
    "file_path": "./devposts/a-self-building-website.html",
    "project_id": "a-self-building-website",
    "title": "a self-building website",
    "tagline": "ideally it will just keep building, perpetual building machine",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Dynamic building block system that tracks construction progress"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/596/201/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Self-Building Website with Interactive Construction Inspiration What if websites could construct themselves? Inspired by the concept of self-assembling systems and the magic of watching code come to life, we created a website that literally builds itself before your eyes—a digital organism that grows, evolves, and demonstrates the beauty of real-time web development. What it does Our Self-Building Website is an interactive demonstration that showcases: Real-time Construction : Watch as website components materialize one by one with smooth animations Live Code Generation : See actual code being typed in real-time as features are built Interactive Builder Panel : Generate new features and components on demand Progress Visualization : Track construction progress with beautiful visual indicators Self-Evolution : The site continuously grows and adapts, adding new capabilities The experience feels like watching a digital construction site where code becomes architecture, and every element has a purpose in the grand design. How we built it Tech Stack: React 18 with TypeScript for robust component architecture Tailwind CSS for responsive, modern styling with custom animations Lucide React for crisp, scalable icons Vite for lightning-fast development and building Key Features: Custom animation system with staggered component reveals Real-time code typing effect with syntax highlighting Dynamic building block system that tracks construction progress Responsive grid layout with animated background elements Interactive controls for starting/stopping the building process Challenges we ran into Timing Coordination : Synchronizing multiple animations and state changes to create a cohesive building experience Performance Optimization : Ensuring smooth animations while managing multiple timers and state updates Visual Hierarchy : Balancing information density with aesthetic appeal in the construction interface State Management : Coordinating complex state between building prog"
      }
    ]
  },
  {
    "file_path": "./devposts/airplane-optimizer.html",
    "project_id": "airplane-optimizer",
    "title": "Airplane Optimizer",
    "tagline": "Traveling Salesman Problem Applied to Airplanes Using Quantum Computing",
    "hackathon": "",
    "built_with": [
      "python",
      "qiskit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Environmental Hack Created by KellieChong Mihir Kakkar Nanotechnology Engineering @ UWaterloo Ryan",
      "Best Environmental Hack Created by KellieChong Mihir Kakkar Nanotechnology Engineering @ UWaterloo",
      "MacHacksWinnerBest Environmental Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/384/429/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Wanted to do something with quantum computing and was interested in quantum hybrid algorithms What it does Applies the traveling salesman problem to the airplane industry and uses a quantum computer to compute the optimal solution How we built it I took a list of airports, found their latitude/longitude to create a distance matrix Created a graph and mapped the distance matrix to the graph Mapped it to the Ising model then sent it to the quantum algorithm to optimize Take the answer and determined which path to take Challenges we ran into Figuring out what the functions do and what the variables do in the Qiskit tutorial Trying to read and understand the Qiskit documentation Constant trial and error Accomplishments that we're proud of Getting the distance matrix from the airports mapped onto the real graph for the quantum algorithm Getting the code to work What we learned How the math/theory works for the algorithm How to create a distance matrix from scratch What's next for Airplane Optimizer Create parameters and airspace limits (ie. can't fly over White House, etc.) Have it work for more airports (more nodes) Built With python qiskit Try it out GitHub Repo Submitted to MacHacks Winner Best Environmental Hack Created by KellieChong Mihir Kakkar Nanotechnology Engineering @ UWaterloo Ryan Lam UWaterloo Physics Ryan Lam Raj Zala 3rd year nanotechnology engineering @UW, nanoelectronics researcher, R&D engineer"
      }
    ]
  },
  {
    "file_path": "./devposts/baker-hughes-challenge-zdslx2.html",
    "project_id": "baker-hughes-challenge-zdslx2",
    "title": "Baker Hughes Challenge",
    "tagline": "Optimizing Electric Motor Health Monitoring with Smart Data Selection for Efficient, Resource-Conscious Machine Learning",
    "hackathon": "",
    "built_with": [
      "pandas",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/129/654/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Evaluation Metrics on X2 Our writeup! Algorithm code Histogram of Original Dataset Evaluation Metrics on X1 Evaluation Metrics on X2 Our writeup! Algorithm code Histogram of Original Dataset Evaluation Metrics on X1 Evaluation Metrics on X2 1 2 3 4 5 6 Inspiration The challenge of efficiently monitoring the health of electric motors, while minimizing computational resources, inspired us to develop a smart data-selection approach. The goal is to improve predictive maintenance systems, enabling industries to track motor health and prevent downtime in a cost-effective manner. By optimizing the data used for machine learning, we aim to make these systems more practical, even in resource-constrained environments. What it does Our solution is a condition-monitoring algorithm that predicts electric motor vibration levels based on frequency (X1) and power (X2) measurements. By training a machine learning model with a carefully selected subset of the data, the system predicts vibration levels and detects early signs of motor health degradation. The predictions are compared with actual data, allowing operators to identify maintenance needs before a failure occurs. How we built it We designed a data-selection algorithm that efficiently reduces 500,000 data points to just 2,500, ensuring we maintain the balance between data coverage and density. The first step was normalizing the frequency and power data to make them comparable. Then, we developed a grid-based sampling algorithm that divides the input space into cells. Each cell's density is calculated by counting how many data points fall into it. Data points are then selected based on both uniform and density-based sampling, with a tuning parameter (α) that adjusts the balance between the two approaches. This reduces training time and computational resources while maintaining high prediction accuracy. Challenges we ran into The main challenge was selecting a representative subset of data from a much larger dataset. We had to "
      }
    ]
  },
  {
    "file_path": "./devposts/ar-shopping.html",
    "project_id": "ar-shopping",
    "title": "AR Shopping",
    "tagline": "What to decide which Jewellery or shoes suit you, while doing online shopping, This project will help you try out the product in AR.",
    "hackathon": "",
    "built_with": [
      "ar",
      "canvas",
      "face-tracking",
      "headmask",
      "sketchfad",
      "world-tracking",
      "zapps"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "face-tracking",
      "world-tracking"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/337/485/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration While doing online shopping we face issues, like not being able to try it online or see if it will suit us. Ar shopping will solve the problem, we can try furniture, jewelry, and shoes in Ar virtually. What it does We can select the dress, shoes, and jewelry and try them. To see if it will suit us or not. Then we can go to the website and purchase it. How we built it We built using the zap works app. Challenges we ran into While using zap works studio, we face some issues which publishing our ar app Accomplishments that we're proud of What we learned What's next for AR Shopping We are adding AI to the website for recommendation systems and adding more products in the Ar app to try out. Built With ar canvas face-tracking headmask sketchfad world-tracking zapps Try it out webxr.run kirankhanna.pythonanywhere.com GitHub Repo Created by Private user Sri Harshitha Anantatmula Learn ."
      }
    ]
  },
  {
    "file_path": "./devposts/airlyft.html",
    "project_id": "airlyft",
    "title": "AirLyft",
    "tagline": "Uber within Airports",
    "hackathon": "",
    "built_with": [
      "aviation-stack",
      "dart",
      "figma",
      "firebase",
      "flutter",
      "stripe"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/824/375/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration 💡 Picture this: you book your flights to Europe, create a fancy itinerary, pack three suitcases and reach the airport only to realize that you’ve overpacked, your back hurts, and you just can’t make it to the departure gate. Well, you’ve just viewed the world from the eyes of an adventurous 70-year old Grandpa. Traveling is a problem for seniors. Surveys of international travelers show that only 25 percent of seniors (aged 65+) take international trips, compared to 45 percent of the general population. A contributing factor to is a lack of services at tourist-heavy places like airports. Expecting our seniors, 24% of whom experience some sort of disability, to carry 50lbs around in an airport is absolutely inhumane. What it does 🤔 To make travel easier for our future wrinkly selves, we made AirLyft , a luggage carrying service at airports. On Airlyft, young individuals, who we call carriers, get hired by prospective travelers to drop their luggage at the airport gate. We also imagine Airlyft being used by younger travelers that prefer the luxury of not carrying their things around the airport. As a proof of concept, our team has observed that such a service is present and widely used in developing countries like India, Brazil, and Bangladesh. How we built it ⚙️ For the front-end, we’ve used Flutter & Material Design . The backend is implemented using Firebase. We use several Firebase services like Firebase Functions , Firebase Functions, & Firebase Database. We also use external APIs like Aviation Stack and Google Maps. For the backend we have used Stripe for the payment gateway:- Tech Stack :- Design 🎨 We were heavily inspired by the revised version of Iterative design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling your solution & then finally deploy it. Discover : a deep dive into the problem we are trying to solve. Define : synthesizing the i"
      }
    ]
  },
  {
    "file_path": "./devposts/ai-commentator.html",
    "project_id": "ai-commentator",
    "title": "AI Commentator",
    "tagline": "Our AI platform automates commentary, creates digital twins, and generates highlights. Users can easily search for actions like knockouts and instantly share clips, helping teams scale and save costs.",
    "hackathon": "",
    "built_with": [
      "captions",
      "chatgpt",
      "ffmpeg",
      "gpt4",
      "labs",
      "nextjs",
      "python",
      "twelve"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "CHAMPION Winner LA TECH WEEK GRAND CHAMPION Created by Andrew Montanez Kartik Pandey AI innovator d",
      "TOP 8 AT LA TECH WEEK Winner ENTERTAINMENT TRACK CHAMPION Winner LA TECH WEEK GRAND CHAMPION Create",
      "+ Grand Champion for LA Tech Week Hackathon 2024 Entertainment Track Champion + Grand Champion for",
      "+ Grand Champion for LA Tech Week Hackathon 2024 1 2 Our AI-powered platform revolutionizes sports",
      "Winner LA TECH WEEK GRAND CHAMPION Created by Andrew Montanez Kartik Pandey AI innovator driven to",
      "LA Tech Week Hackathon 2024WinnerTOP 8 AT LA TECH WEEKWinnerENTERTAINMENT TRACK CHAMPIONWinnerLA TECH WEEK GRAND CHAMPION",
      "Winner",
      "Our project is the Grand Champion & Entertainment Track Champion for LA Tech Week Hackathon 2024!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/082/009/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Entertainment Track Champion + Grand Champion for LA Tech Week Hackathon 2024 Entertainment Track Champion + Grand Champion for LA Tech Week Hackathon 2024 Entertainment Track Champion + Grand Champion for LA Tech Week Hackathon 2024 1 2 Our AI-powered platform revolutionizes sports media production by automating real-time commentary, highlight generation, and social media sharing for live events. Designed to streamline the production process, our platform allows small teams to scale their operations with minimal resources, saving time and money while delivering high-quality, engaging content. This solution is perfect for sports organizations looking to enhance fan engagement without the overhead of a large production crew. Bridging the Digital Divide in Sports Media: In line with addressing the digital divide, our platform also tackles inequities in digital access, design, and use. The digital divide, as defined by the U.S. Department of Education, refers to the gap in access to digital tools and resources. Our platform addresses this by offering affordable, scalable solutions for sports organizations that may lack the resources to implement advanced media production technologies. By leveraging AI, we make it easier for underfunded teams to access and utilize cutting-edge production tools, thus leveling the playing field. Key factors that contribute to the digital divide, such as lack of wealth, underdeveloped infrastructure, and limited digital content, are addressed through our solutions like affordable internet connectivity, AI-driven highlight generation, and offline content options. This way, even smaller sports organizations can harness the power of advanced technology without significant investments. Challenge & Objective: The traditional process of live sports production is resource-heavy, requiring large teams and significant investment in manual editing, commentary, and highlight creation. Our goal was to create a solution that could automate these tasks "
      }
    ]
  },
  {
    "file_path": "./devposts/aquastreet.html",
    "project_id": "aquastreet",
    "title": "Aquastreet",
    "tagline": "Aquatic Lanes to Sail & Save Aquatic Biodiversity ⛵",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "firebase",
      "gcp",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Top 10 sunhacks Created by Arsalaan Alam Fullstack Dev Pratyay Banerjee Trying to learn how to lear",
      "HyperHacksWinnerTop 10",
      "Making our team's first-ever Ambiware (Software - Hardware) hack.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/677/255/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Architecture GIF Architecture 1 2 3 4 5 6 Inspiration 💡 I believe everyone of us knows that around 76% i.e more than ¾th of our mother Earth consists of water bodies & rest is Land of which we are a part of. That also means that there are around 8-10x times more wild marine animals which reside in those water bodies. Times have changed, so have we. The increase in pollution is leading to an extensive increase in water volume which is resulting in huge chaos across the globe. But, unfortunately, it's very disappointing to see few people disagreeing with the same. This is not only harming us, but also causing intensive harm to the marine world. Besides, because of the same, thousands if not millions of species have become extinct and the death toll is still on the rise. The species which used to be common are now being counted under the list of endangered ones. The death of those living objects is amplifying the garbage in the sea/ocean and stacking the same with ours. Keeping all in limelight, it's disturbing the ecosystem \nas well as the entire biodiversity chain. There's a famous quote that says — \"We are unanimously entangled with Mother Nature & her Children.\" We catch fish for food, but also there are a few anonymous group of people who hunt/poach them for their purpose irrespective of the fact that it's disturbing the entire ecological lifecycle as well as the food chain of those animals. This is not good, but there's nothing that can help us evade the same in a correct manner. Coming back to the main idea, have you ever tried fishing? If yes, you must know how hard and time tedious it is. Or while at a beach holiday you unknowingly interacted with something you weren't supposed to, which resulted in unexpected & unwanted circumstances just like this - Box jellyfish: Australian teenager fatally stung on Queensland beach while messing with a jellyfish . The unwanted circumstances are not just for you, it's for the fishes too. Most of the fishes don't want to"
      }
    ]
  },
  {
    "file_path": "./devposts/ananke.html",
    "project_id": "ananke",
    "title": "Ananke",
    "tagline": "Ananke is a novel fitness app that rewards you based on your individual efforts instead of raw performance.",
    "hackathon": "",
    "built_with": [
      "odinai",
      "python",
      "react",
      "terraapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/633/115/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Overview of Hand-drawn vectors Home screen of Ananke Suggested workouts Ranking with your friends Comment section Overview of Hand-drawn vectors Home screen of Ananke Suggested workouts Ranking with your friends Comment section Overview of Hand-drawn vectors 1 2 3 4 5 6 Inspiration Exercising is very important to living a healthy and happy life. Motivation and consistency are key factors that prevent people from reaching their fitness goals. There are many apps to try to help motivate aspiring athletes, but they often just pit people against each other and focus on raw performance. People, however, are not equally athletic and therefore the progress should not be based on absolute performances. Ananke uses a new approach to encourage people to improve their fitness. What it does Ananke does not determine your progress based on absolute miles ran or the time spent on a road bike, but more on invested efforts instead. If a 2 mile run is exhausting for you, that is fine! And if you managed to run 3 miles the next day, we reward your progress. That's how Ananke will continuously empower you to achieve more - every single day. The strongest competitor is always yourself!\nTo suggest the optimal workouts for you that suit your performance level, Ananke takes your fitness history into account. Ananke will provide you with a suggestion for a light, medium and challenging workout, and it is up to you to choose the preferable workout depending on your mood and well-being. Whatever workout you choose, it is going to be an advancement and propel you forward on your journey to a blossomed life. \nOur app-architecture has a functional, minimalistic design. By completing suggested workouts and pushing yourself to your limits, you will grow plants. The more you exercise, the greener your profile becomes. Ananke will analyse the fitness data corresponding to the accomplished workout and determine an intensity-score based on factors other than pure data - we use an algorithm to determi"
      }
    ]
  },
  {
    "file_path": "./devposts/airhacker.html",
    "project_id": "airhacker",
    "title": "AirHacker",
    "tagline": "Using a multitude of APIs, machine learning, data science and online market campaigns, AirHacker delivers personalized flights & experiences for users according to their interests and locations.",
    "hackathon": "",
    "built_with": [
      "amadeusapi",
      "api",
      "chatgpt",
      "folium",
      "html",
      "openai",
      "opentripmapapi",
      "python",
      "selenium",
      "serpapi",
      "ticketmasterapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/362/745/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The flowchart used to plan our project and divide tasks between the four members. The flowchart used to plan our project and divide tasks between the four members. The flowchart used to plan our project and divide tasks between the four members. 1 2 Inspiration We really enjoy concerts and exhibits, but we often struggle to decide on a destination. As college students we normally can't afford big trips, making it even harder to decide. Thus, we created AirHacker, an AI powered comprehensive ad service that designs and delivers personalized trips and make the flight worth the money. What it does The systems takes in keywords of customers' interests, which can be collected over media platforms, as well as their locations, and desired traveling dates. Then it correlates keywords and dates with point of interests and events across the US, generating the best destinations and sight-seeing recommendations. Finally it integrates the all the data such as airline tickets, descriptions, maps, and potential places to visit into a mail system that broadcasts to each group of niche audiences. How we built it First we use a geolocation database to export all the coordinates of the airports and attractions. Then we use Python stats library to compute distances between sites and the \"interest density index\" of each airports. We then use web scrapers and APIs to find events that are time, location, and subject sensitive, as well as the availability and prices of airline tickets. Lastly, we use HTML email integration to provide visual and emotional appeals for the trip, along with AI generated text descriptions. Challenges we ran into We were all experiencing a hackathon for the first time, and we had little experience. This meant we had a lot of struggles learning and implementing new APIs. Basically, we did not sleep. Accomplishments that we're proud of We wrote 25 python modules and integrated 10+ APIs to accommodate the heavy data processing. What we learned APIs can be extremely"
      }
    ]
  },
  {
    "file_path": "./devposts/bahen-s-crossy-road.html",
    "project_id": "bahen-s-crossy-road",
    "title": "Bahen's Crossy Road",
    "tagline": "Dangerous jaywalking between the Bahen Centre and Galbraith building is all too common for UofT students. With inspiration from “Squid Game,” Bahen’s Crossy Road catches jaywalkers red-handed.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c++",
      "cloudflare",
      "dnn",
      "esp32",
      "esp32-cam",
      "numpy",
      "opencv",
      "python",
      "streamlit",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/272/524/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Streamlit dean yip Streamlit dean yip Streamlit 1 2 3 Inspiration Whether we’re late to class or meeting up with a friend, dangerous jaywalking the crosswalk between the Bahen Centre and Galbraith building is all too common for us UofT engineering students. With inspiration from the show “Squid Game,” we made Bahen’s Crossy Road, an interactive game that catches jaywalkers red-handed (and hypothetically automatically deducts meal plan money. What it does Bahen’s Crossy Road is a gamified version of the infamous crosswalk between the Bahen Centre of Information Technology and the Galbraith Building. Inspired by the show “Squid Game” on Netflix, Bahen’s Crossy Road lets players compete against each other when crossing the road. The goal for every player is to cross the road first without being eliminated. Players are eliminated whenever they are moving during a red light and are free to move during a green light. When the traffic light, in this case, a figurine of Dean Yip says green light, players are free to move until he turns around and says red light.\nScores and current neural network processes are streamed in an interactive web app. When someone crosses the road, the game ends, and their score is increased on the leaderboard. How we built it We built Bahen’s Crossy Road using an ESP32 with a camera, Python and streamlit which displays the leaderboard and handles all the game, detection, and streaming logic. We also used redis for storing to increment player wins and handle race conditions with fetching data from the esp web server. We leveraged cloudflare-based gemini to create dynamic responses to different player codes winning. Challenges we ran into One of the biggest challenges we faced was an issue with our 3D printing request. When we went to collect our 3D-printed part, we were informed that our submission had been rejected some time ago, but we had never received any notification about it. This unexpected setback forced us to rethink our design at the la"
      }
    ]
  },
  {
    "file_path": "./devposts/470-million-sigma.html",
    "project_id": "470-million-sigma",
    "title": "-470 Million Sigma",
    "tagline": "We make money on the stock market. We also lose money on the stock market. Sometimes we even lose 470 Million.",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/478/613/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The market takes and the market gives... Inspiration and what it does Our strategy is simple: Let’s imagine there are snickers bars that have a value of 10€. We buy them for 5€ and sell them for 6€. This is because we want to buy as many snickers as possible but only have limited storage space. People will be able to buy cheap snickers and we will make a lot of profit! How we built it We are using a boosted version of an arbitrage technique. While most basic arbitrage techniques will eventually hit the max instrument limit, we strategically added a market-making element which lists our arbitrage position for a little profit and therefore increases liquidity (analogous to the analogy above). A strength of the algorithm is the resilience towards unprofitable trades. We did not design the program to maximimize the profit, but to avert any losses in the first place. Moreover we focused on latency and computational efficiency so that the product benefits from short response times and immediate requests to the server. \nWithin the testing and developing phase we aimed at covering any occurring bugs and thereby making the code more stable. These actions momentarily led to extreme PnL’s and made us set records ;) Challenges we ran into We faced many bugs that we did not expect. They got nastier with increasing code complexity and therefore we had to readjust our strategy multiple times We were trading as team-008 Built With python Submitted to HackUPC 2023 Created by Max Hecker Rojus Lapinskas Mantas Kandratavičius Justus Beck"
      }
    ]
  },
  {
    "file_path": "./devposts/apparel.html",
    "project_id": "apparel",
    "title": "AppArel",
    "tagline": "A tool to redefine fashion design.",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "api",
      "cockroachdb",
      "flask",
      "gan",
      "github",
      "repel.it"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by I worked on the frontend of the application",
      "Hack The RunwayWinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/034/818/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Thumbnail Artboard LookBook Landing Page Thumbnail Artboard LookBook Landing Page 1 2 3 4 5 Inspiration There are new and exciting fashion designs being introduced into the market, and we wish to bolster this phenomenon by harnessing the power of Deep Learning. Also, there hasn't been an easy way to store designs for future reference. Until now. What it does AppArel has some main functionalities: An API-driven solution that lets you generate lists of designs you like A GAN-driven solution that suggests new items of clothing for design inspiration (Shirts, pants, dresses) An artboard feature that lets you import the generated images and work your sketches onto them. It is a one stop tool to find inspiration for new designs, set up your own collection and sketch new ideas for your next look. How we built it The frontend was built using Figma and Angular The backend was built using Flask and has been deployed to Replit. The network was generated by training NIVIDIA's StyleGAN2ADA network on custom data Challenges we ran into We faced many problems configuring the development environment to train the model. Also, the models took a long time to train Integrating the front-end with the backend was also quite tricky. Accomplishments that we're proud of All three of us learnt something new through this hackathon and we are proud to be able to develop and host an end-to-end product like this in such a short time. Integrating all three modules was a task and so was time management. We learnt more about Angular - how we can structure our project better, how GAN essentially works and how we could leverage different technologies to make something new. Integrating the backend with frontend was interesting too. What's next for AppArel Generating designs on the fly, more intensive training of the model Richer API support Integration of User login Built With angular.js api cockroachdb flask gan github repel.it Try it out replit.com GitHub Repo GitHub Repo Submitted to H"
      }
    ]
  },
  {
    "file_path": "./devposts/autismed-monitor.html",
    "project_id": "autismed-monitor",
    "title": "AutisMed Monitor",
    "tagline": "A Social Platform for Neurodiversity Empowerment",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "python",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Diversity Hack Created by Private user Abhik Sharma",
      "Best Diversity Hack Created by Private user Abhik Sharma",
      "AliceHacksWinnerBest Diversity Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/677/417/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "AutisMed AutisMed: A Social Platform for Neurodiversity Empowerment ✨ Our Journey The inception of AutisMed was deeply personal, born out of the desire to create a supportive community for individuals with autism. Our experiences highlighted the need for a dedicated social platform where individuals on the autism spectrum could connect, share, and celebrate their unique perspectives. AutisMed reflects our commitment to inclusivity and the power of technology to build meaningful connections. 🌟 Vision and Purpose AutisMed is a social media platform exclusively designed for individuals with autism. It offers a safe and inclusive environment where users can express themselves, share stories, join interest-based communities, and find support. AutisMed celebrates neurodiversity, fostering connections that empower users to thrive socially and emotionally. 🛠 Tech Stack and Development The technical development of AutisMed revolved around building an intuitive and accessible platform. Here’s an overview of the technologies and approaches that powered its creation: Tech Stack Utilization Bootstrap : Ensuring responsive and accessible design across devices. CSS : Custom styles for an inviting and user-friendly interface. JavaScript : Dynamic functionality for seamless interaction. Python : Backend logic to manage community interactions and features. Figma : For prototyping and user-centric design iterations. HTML5 : Structuring the platform with semantic clarity. Development Features Community Groups : Interest-based groups where users can connect and collaborate. Story Sharing : A space for users to share personal experiences and milestones. Moderation Tools : Ensuring a safe and respectful environment through active monitoring. Custom Profiles : Personalizing user experiences to foster a sense of belonging. Support Resources : Access to helpful materials and peer support. 🚧 Overcoming Obstacles Balancing user safety with openness and inclusivity was a key challenge during de"
      }
    ]
  },
  {
    "file_path": "./devposts/ai3d-nanodimensions.html",
    "project_id": "ai3d-nanodimensions",
    "title": "AI3D NanoDimensions",
    "tagline": "What if you can step into the world of a picture via pointclouds and Nano Banana to get the perfect shot?",
    "hackathon": "",
    "built_with": [
      "ios",
      "polyspatial",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/808/164/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 What if you can step into the world of a picture via pointclouds and Nano Banana to re-create and thus visit the scene from a new angle? We can also enter the world of the proverbially iconic. Let's begin by using NanoBanana as the endpoint on Napkinmatic to transform the iconic Banksy silhouette of the girl without a balloon - into a real girl who just lost her heart shaped balloon. And now: Live demo from the Vision Pro version of my AI3D Nano Dimensions app - and then, we use MoGe to instantly convert this single image into a 3D model right in front of us… so that we change the angle of this new image. We pinch to take a new photo to send to fal.ai NanoBanana to turn our rough 3D model into a real picture. What if you can time travel through a photograph to get the perfect shot? Nearly Life Size Live Demo from my AI3D Nano Dimensions app. Here we take a postcard depicting Penn Station in the early 1900s, use MoGe to convert it into a sparse hallucination-free point cloud that we can now walk through. And we do our pinch to take our desired snapshot of this rough 3D model from a new angle, and NanoBanana turns it into a real picture. And repeat. AI3D NanoDimensions uses 3D and novel HCI to apply perspective to see new dimensions and beyond --\nWhat if you can step into the shoes of someone living through a historic moment in time? Shift perspectives via AI3D NanoDimensions, as if you were a Time Lord, and then teleport your consciousness into theirs? Built With ios polyspatial unity Try it out GitHub Repo Submitted to RevenueCat Shipaton 2025 Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur) Caramel Corgi"
      }
    ]
  },
  {
    "file_path": "./devposts/answerme-ce2ip0.html",
    "project_id": "answerme-ce2ip0",
    "title": "AnswerMe",
    "tagline": "Easy access to ChatGPT anywhere, anytime. Just a text or call away!",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "openai",
      "python",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Created by huzafahyde Hyde Nabil Johny Kevin Nguyen Jackson Lippert",
      "Third Place Overall Created by huzafahyde Hyde Nabil Johny Kevin Nguyen Jackson Lippert",
      "Hack the MISTWinnerThird Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/421/845/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Introducing AnswerMe! Have you ever used ChatGPT but were discouraged by the lack of mobile support and long login process? Well, look no further than AnswerMe! An easy way to access ChatGPT from your phone with no internet needed. What it does We built a full-stack application that allows users to text and call a phone number that answers questions using OpenAI's ChatGPT. Text the bot's number to get an SMS response from ChatGPT, or call the number and ask it a question for the bot to use voice recognition to get a vocal response from ChatGPT. All the user has to do is give their phone number to our web application and then they are free to text and call ChatGPT anytime! Our solution will save you data when you're out since our call and SMS options don't require an internet connection. How we built it We built the back end of this application using Python, Flask, OpenAi API, and Twilio's call/SMS API. The front-end sign-up is built with HTML and CSS and connects to the back end using Flask endpoints. Challenges we ran into This technology is very new and there aren't many existing applications similar to ours. This meant that we were on our own when creating everything, with no existing things to base our app on. Accomplishments that we're proud of A fully functioning app, that may even be good enough to ship to real customers. What's next for AnswerMe Stay tuned for a possible release of our application into the real-world market! Built With css3 flask html5 openai python twilio Try it out 078d-74-15-83-239.ngrok.io GitHub Repo Submitted to Hack the MIST Winner Third Place Overall Created by huzafahyde Hyde Nabil Johny Kevin Nguyen Jackson Lippert"
      }
    ]
  },
  {
    "file_path": "./devposts/aifluence.html",
    "project_id": "aifluence",
    "title": "AIFluence",
    "tagline": "Turn market insight into influencer revenue",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "node.js",
      "python",
      "typescript",
      "veo3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Highest Startup Userbase Potential - Startup Track Created by sber Emma Shi cs @uwaterloo sb",
      "1st Place Overall - Startup Track Winner Highest Startup Userbase Potential - Startup Track Created",
      "SpurHacksWinner1st Place Overall - Startup TrackWinnerHighest Startup Userbase Potential - Startup Track",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/496/230/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 AIFluence is a platform that lets users create autonomous AI influencer personas capable of growing their own presence and publishing content—entirely on autopilot. Whether you're a business seeking a full-time brand ambassador or a creator hoping to monetize a niche, AIFluence offers a new way to scale influence through generative video, smart scheduling, and AI-driven storytelling. Inspiration Influencer marketing is booming, but it’s inefficient and expensive. Human influencers come with inconsistent availability, high costs, and limited scalability. We imagined a world where you could \"design\" an influencer that doesn't sleep, doesn't charge thousands per post, and aligns perfectly with your product or personal vision. AIFluence was born from this thought—giving creators and companies alike the tools to scale influence on demand. What AIFluence Does At its core, AIFluence is a marketing automation engine powered by AI-generated personas. Users can initialize a virtual influencer by giving it a name, backstory, tone, goals, and preferred audience. From there, the system handles the entire content lifecycle: It generates reels and stories using multimodal models like Veo 3 and Gemini 2.5 Pro . It schedules posts at your desired time. It directly publishes to Instagram via the official Publishing API . It builds a real-time digital identity and adapts based on user-defined objectives and \"changes\" to the persona's life AIFluence supports two key use cases: B2B : Businesses can build persistent, custom brand ambassadors tailored to their market segment. B2C : Individual users or niche entrepreneurs can create lifestyle personas to explore passive-income opportunities—similar to dropshipping, but with content instead of products. How We Built It Frontend: We used Next.js with React and Tailwind CSS to build an immersive and highly interactive onboarding and dashboard experience. The frontend lets users walk through persona creation, view posting history, and "
      }
    ]
  },
  {
    "file_path": "./devposts/baby-turtle.html",
    "project_id": "baby-turtle",
    "title": "Trash-Snap",
    "tagline": "With a simple picture, Trash-Snap instantly categorizes waste and provides accurate disposal instructions, making waste disposal effortless",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "django",
      "figma",
      "folium",
      "opencv",
      "postman",
      "python",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TurtleHacksWinnerRunner up",
      "Currently errors present in taking a picture button and clicking the upload button without first selecting an image",
      "Add a feature where AI generated recommendations will show up for the user, model must be trained first",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/479/074/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Every year, a staggering amount of waste is improperly disposed of, leading to environmental and economic consequences.\nDid you know that globally, E-waste comprises a staggering 70% of our overall toxic waste? Shockingly, only 12.5% of E-waste is recycled, while a staggering 85% ends up in landfills or is burned, releasing harmful toxins into the air. The consequences are dire, as electronics contain lead, a hazardous substance that can damage our central nervous system and kidneys. For instance, a study by CBC News revealed that in Canada alone, up to 30% of recycling placed in blue bins is contaminated with non-recyclable materials .\nFurthermore, people often dispose plastic waste incorrectly. According to a report by Our World in Data, of the 359 million metric tons of plastic produced in 2018, an estimated 91% was not recycled and ended up in landfills or the environment. These alarming statistics motivated us to take action and develop a solution that would help individuals identify the specific type of waste they have and help them dispose of it. Our solution, Trash-Snap, is an application aimed at revolutionizing waste disposal practices and reducing environmental contamination caused by hazardous materials. Trash-Snap is more than just a convenient accessibility pro application; it's a powerful tool for change. Our mission is to provide a platform that enables individuals, regardless of their technological proficiency or geographic location, to easily and correctly dispose of their waste, including e-waste. By doing so, we can collectively minimize the harm caused by toxic materials and promote a more sustainable future. But our vision doesn't stop there. Trash-Snap is just the beginning. We have a plethora of exciting features planned for future iterations of the application, ensuring that we level the playing field for everyone. We want to ensure that every individual has the opportunity to participate actively in creating a better, more"
      }
    ]
  },
  {
    "file_path": "./devposts/aeris-ej7d9k.html",
    "project_id": "aeris-ej7d9k",
    "title": "AERIS: Autonomous Emergency Response & Intelligence System",
    "tagline": "Autonomous drones scan disaster zones, detecting humans and hazards (fire, flood, debris), triaging victims by urgency & routing responders along safe paths that avoid obstacles.",
    "hackathon": "",
    "built_with": [
      "butterfly",
      "dain",
      "docker",
      "fastapi",
      "ffmpeg",
      "groq",
      "leaflet.js",
      "llama",
      "next.js",
      "nginx",
      "shadcn",
      "supabase",
      "tailwind",
      "twilio",
      "yolov8"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best of Groq Created by Frontend + CV Pipeline Jeff Zhang Rian Corcino i code stuff for fun Tannvi",
      "LA Hacks 2025WinnerBest of Groq",
      "🚑 Dispatches first responders directly to the victims' coordinates.",
      "🚑 Getting first responders moving toward critical victims faster than traditional search teams.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/394/896/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 AERIS: Autonomous Emergency Response & Intelligence System 🚁🆘 Inspiration 🌪️📉 During disasters, over 60% of victims lose phone service , cutting them off from emergency help. Rescue teams are forced to search blindly, wasting precious hours while lives hang in the balance. We realized search and rescue needs to be faster, smarter, and autonomous . That’s why we built AERIS — AI drones that find victims and guide rescuers automatically. What it does 🎯 🚁 Locates victims needing urgent care using autonomous drone navigation. 🚑 Dispatches first responders directly to the victims' coordinates. How we built it 🛠️ 🎨 Front end: Next.js, Tailwind CSS, Shadcn/ui, Leaflet, Butterfly for a smooth, responsive command dashboard. 🎥 Live Video Streaming: Dockerized NGINX RTMP server + FFmpeg ingests the DJI drone feed 🧠 AI agents: Dain for intelligent mission control orchestration, including hazard detection and hospital coordination. 🚀 CV Pipeline Pipeline: FastAPI server exposing REST endpoints to ingest frames, run YOLOv8 object detection, invoke Groq LLaMA for victim triage, and persist results to Supabase 🗄️ Database: Supabase for real-time detection/event logging 👁️ Object detection: Ultralytics YOLOv8 custom model trained on composed disaster datasets (humans, fire, smoke, flood, debris, collapse) for live inference 📞 Emergency Response Automation: Dain agents locate the nearest hospitals based on pinned coordinates, list phone numbers and distances, and automate emergency calls via Twilio API Challenges we ran into 🧩 🔄 Getting hospitals and dispatchers synced with Supabase without massive lag. 🧠 Designing complex systems combining computer vision, AI agents, and real-time routing without everything breaking. Accomplishments that we're proud of 🏆 🖥️ Displaying urgent victim and hazard data in a clean, intuitive way. 🚑 Getting first responders moving toward critical victims faster than traditional search teams. What we learned 📚 🤯 AI agents are wildly hard to coordina"
      }
    ]
  },
  {
    "file_path": "./devposts/aoeu.html",
    "project_id": "aoeu",
    "title": "Stack Up",
    "tagline": "Stack up your standardized testing scores to those in your region as you improve with continuously evolving problems.",
    "hackathon": "",
    "built_with": [
      "flask",
      "pinata",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/143/687/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "User score and generation based off of previous answers Data analytics page User Score input User score and generation based off of previous answers Data analytics page User Score input User score and generation based off of previous answers 1 2 3 4 Inspiration The idea for this program came from our realization that students in underserved communities could be benefitted by AI feedback systems to=hat reinforce their learning. In an effort to have a standardized measure for potential weaknesses and knowledge gaps we wanted to use the ACT. What it does StackUp begins by prompting users to input an estimate of their region’s ACT test scores, typically accessible on the ACT test-feedback website, along with their own ACT scores. Based on this input, StackUp identifies subject areas that offers the greatest potential for score improvement and generates a tailored set of four questions. After completing the initial quiz, users can regenerate additional problems that build on the concepts covered, adapting dynamically to their performance. If a user struggles with a particular subject, StackUp adjusts to provide more questions at an appropriate difficulty level in that area. When users finish their session, they can explore the Analytics Tab to track their progress and see how their performance compares to their previously inputted regional benchmarks. How we built it The entire architecture of StackUp was implemented in Python, leveraging Flask to manage the API layer, Pinata for decentralized data storage, and Streamlit for rapid front-end development and prototyping. Flask was strategically chosen for its lightweight nature and flexibility, enabling seamless scalability and integration with more robust frameworks in the future as the product evolves. This modular design ensures that each component is optimized for its role, providing a solid foundation for future enhancements and growth. The stack prioritizes simplicity without compromising on the potential for scaling"
      }
    ]
  },
  {
    "file_path": "./devposts/autinjoy.html",
    "project_id": "autinjoy",
    "title": "Autinjoy",
    "tagline": "“Autism is part of my child, it’s not everything he is. My child is so much more than a diagnosis.” So our moto is to provide Autistic kids with Enjoyment they feel they are deprived of!",
    "hackathon": "",
    "built_with": [
      "auth0",
      "figma",
      "github",
      "google-cloud",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Authentication Hack by Auth0 Created by Anita Yip Product owner, project manager, retired hackathon",
      "MLH - Best Authentication Hack by Auth0 Created by Anita Yip Product owner, project manager, retire",
      "YHack 2022WinnerMLH - Best Authentication Hack by Auth0",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/898/872/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Social Community & Forum for Kids with Autism to Interact Multilayer Authentication with Twilio Phone Number & Auth0 Login to Setup Device with Auth0 Journal Entry by Twilio SMS Login Page for Mobile Application Audio Story Books for Autistic Children Event & Tour Planning Calendar Feature Enjoyful Activities the Autistic Child Would like to Attend Upcoming events and Social Community for Autistic Kids Parents refer Event details and timings & Decide tour Socially Planned Activities so that Autistic kids are in Safe Environment Dashboard for all Journal Entries and Decisions taken by Parents Communication Page for Autistic Child to Use Social Community & Forum for Kids with Autism to Interact Multilayer Authentication with Twilio Phone Number & Auth0 Login to Setup Device with Auth0 Journal Entry by Twilio SMS Login Page for Mobile Application Audio Story Books for Autistic Children Event & Tour Planning Calendar Feature Enjoyful Activities the Autistic Child Would like to Attend Upcoming events and Social Community for Autistic Kids Parents refer Event details and timings & Decide tour Socially Planned Activities so that Autistic kids are in Safe Environment Dashboard for all Journal Entries and Decisions taken by Parents Communication Page for Autistic Child to Use Social Community & Forum for Kids with Autism to Interact 1 2 3 4 5 6 7 8 9 10 11 12 13 14 📚🙋‍♂️Domain Name📚🙋‍♂️ DOMAIN.COM: AUTINJOY-WITH.TECH 💡Inspiration💡 Parents know that travelling can be an eye-opening experience for kids, but they also know that travelling even with one kid can be overwhelming, involving lots of bathroom stops and needing to manage boredom, motion sickness, and more. When parents have an autistic kid, it means they have to consider additional factors when travelling. Because when places with sensory overload, closed spaces, or constant movement stress out an autistic child, the child can have what's called an \"autistic meltdown\", which is very difficult to manage temper tantrums"
      }
    ]
  },
  {
    "file_path": "./devposts/ai-story-journey.html",
    "project_id": "ai-story-journey",
    "title": "AI story journey",
    "tagline": "Choose your own adventure with your AI buddy",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "t3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AI HackfestWinnerBest Use of MongoDB Atlas",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/479/642/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The inspiration for \"AI Story Journey\" came from our love for interactive stories and the advancements in AI technology. We wanted to create an engaging, fun, and immersive experience for users, where they can explore different storylines and make choices that affect the outcome of their adventure. With AI becoming more and more sophisticated, we saw an opportunity to integrate it into our project to enhance the storytelling and user interaction. What it does \"AI Story Journey\" is an interactive storytelling platform where users can choose their own adventure, guided by an AI buddy. The platform presents users with different storylines and choices that lead to various outcomes, creating a personalized and dynamic story experience. The AI buddy helps in generating story content and responding to user choices, ensuring that the story remains engaging and immersive. How we built it We built \"AI Story Journey\" using a combination of languages, frameworks, platforms, cloud services, databases, APIs, and other technologies. Some of the main tools and technologies we used include: JavaScript, HTML, and CSS for frontend development Real-time database and user authentication GPT-3 API for AI-based text generation Challenges we ran into During the development of \"AI Story Journey,\" we faced several challenges, such as: Integrating AI-generated content with user choices to create a seamless story experience Ensuring that the AI-generated content remains coherent, engaging, and appropriate for users of all ages Optimizing the performance of our platform, as generating AI-based text can be resource-intensive Designing an intuitive user interface that showcases the interactive nature of the story Accomplishments that we're proud of We are proud of successfully integrating AI technology into interactive storytelling, creating a unique and engaging experience for users. We have managed to overcome the challenges of generating coherent and captivating AI-generated co"
      }
    ]
  },
  {
    "file_path": "./devposts/aidventure.html",
    "project_id": "aidventure",
    "title": "AIdventure",
    "tagline": "Your very own AI-generated RPG",
    "hackathon": "",
    "built_with": [
      "css3",
      "gemini",
      "go",
      "javascript",
      "json",
      "llm",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/772/144/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Website Inspiration This was inspired by RPG games like Deltarune and LLM based projects like AI Dungeon. What it does Our project uses the Gemini LLM to creatively guide the player through different scenarios, facing AI-designed enemies with their own twists and quirks.  Problem solving and creative solutions to this game are also encouraged by the ML dungeon master. How we built it We used a Go backend, React frontend, and the Gemini API as the skeleton of our project.  We carefully engineered and curated many prompts working in tandem to create a smooth and robust playing experience.  We cleverly manipulated the output formats of the LLM to integrate the AI's decisions into our own representations of the game, such as health bars, stat counters, and inventories. Challenges we ran into The documentation for the Gemini model was rather terse, so we spent much time figuring out the idiosyncrasies of the API and model.  Additionally, as a small team without frontend specialization, we toiled for hours over the CSS to get it just right.  The prompt engineering was another one of our obstacles, since the LLM often refused to output in an accurate JSON, sometimes hallucinating or omitting important tidbits. Accomplishments that we're proud of We are especially proud of the final product, providing many entertaining scenarios to work through.  The experience is controlled, with few hallucinations and a stronger sense of memory than other LLM-powered adventures. What we learned We learned a lot about CSS, React, and prompt engineering, in addition to how Google's generative AI library for Go works. What's next for AIdventure Some cool features that we didn't have time to add were minigames that would affect combat and stable diffusion avatars for all the characters. Built With css3 gemini go javascript json llm react Try it out GitHub Repo aidventure.stvnrdg.me Submitted to Hack(H)er413 2024 Created by I worked on the Go code to interface with the LLM and some of the "
      }
    ]
  },
  {
    "file_path": "./devposts/academic-weapon-jvp0ty.html",
    "project_id": "academic-weapon-jvp0ty",
    "title": "Academic Weapon",
    "tagline": "Turn your notes into customized flashcards and quizzes with ease, making learning both enjoyable and effective.",
    "hackathon": "",
    "built_with": [
      "azure",
      "css3",
      "flask",
      "html5",
      "javascript",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/657/107/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Within the heart of every student, there's a shared challenge: turning class notes into powerful study tools. We've been there, navigating the maze of traditional note-taking 📝, wrestling with digital tools like Evernote or OneNote that lack automation 🤖. We've felt the pain of inputting data manually into popular flashcard apps like Anki or Quizlet 🧠💡, and the frustration of crafting quizzes on platforms like Google Forms 📊. Even those pre-made study materials on SparkNotes and CliffsNotes don't always hit the mark for our specific coursework 📖❌. In response, we harnessed the magic of GPT-3.5 to create Academic Weapon, a revolutionary tool. We've redefined the way you interact with your notes. What it does Your notes, whether they're digital or handwritten in PDFs, or even scanned from physical pages, are your canvas 🎨. Academic Weapon is the artist, effortlessly transforming your notes into a masterpiece of learning 📚. You'll have the choice to review your materials through captivating quizzes or dynamic flashcards. Get ready to experience a new dimension in studying! 🤯📝📊🔥 How we built it We developed our app using a combination of technologies: Microsoft Azure OCR: 🌐 To transform the way users interact with their notes, we leveraged the cutting-edge technology of Microsoft Azure's OCR (Optical Character Recognition). This powerful tool enabled us to extract text seamlessly from both digital and handwritten notes, paving the way for a more interactive study experience. 📜🖋 React and HTML/CSS: 🌐 Crafting a captivating and user-friendly interface was pivotal to our project. We used React, a dynamic and versatile JavaScript library, in tandem with HTML and CSS to design an engaging user interface. This combination allowed us to create interactive flashcards and quizzes that resonate with our users. 🎨💻 ChatGPT-3.5: ✨ We harnessed the power of this AI model to create dynamic content for our quizzes and flashcards. With ChatGPT-3.5, we could deliver tailored "
      }
    ]
  },
  {
    "file_path": "./devposts/aurana.html",
    "project_id": "aurana",
    "title": "Aurana",
    "tagline": "the world’s first financial AI agent for creators, with full creator context",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "love",
      "nextjs",
      "python",
      "twelvelabs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackAI TorontoWinnerMost Creative Project",
      "the world’s first financial AI agent for creators, with full creator context",
      "Built a hyper-responsive API that processes complex channel analysis requests in seconds",
      "Designed a scalable architecture that handles multiple creators simultaneously with sub-second response times",
      "Implement real-time revenue tracking and optimization",
      "Build analytics dashboard for tracking monetization progress",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/499/102/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Aurana — from “post-and-pray” to **profit-on-repeat for every creator** 🔥🔥🔥 Inspiration Creators pour hours into videos and carefully curated content; they record, edit and share it with the world. Yet, a large question often remains: how do we allow creatives and creators alike to turn their craft into a living? Ads that fluctuate, one-off sponsorships, and fan tips. With all the best CRM tools and creator stores like Stan, the gap isn’t the tools that yet to exist, but the knowledge gap of creators on how to monetize their content. Our team aimed to tackle this: reducing friction with the world’s first financial AI agent for creators, with full creator context. In conducting extensive research on current creator workflows, we’ve identified and validated this gap: there is an extremely relevant need for tools that allow creators to focus on the creation portion, and thus, Aurana came to life: an AI layer that knows your craft, your content and identifies every monetizable avenue and opportunity. What it does Aurana provides a streamlined, AI-powered path to creator monetization by automating the tedious aspects of revenue generation: Intelligent Channel Analysis - Deep analytics on subscriber growth, engagement, and content performance using YouTube Data API AI-Powered Video Intelligence - Automated analysis of top-performing content to identify monetization patterns ML-Driven Affiliate Discovery - Automatically identifies and generates affiliate codes for products mentioned in videos Contextual AI Coach - Personalized chatbot assistant that understands your specific channel data and provides tailored monetization advice 30-Day Revenue Playbooks - AI-generated, actionable monetization strategies based on your content niche How we built it Backend Architecture: FastAPI for high-performance API endpoints GROQ AI for intelligent content analysis and coaching TwelveLabs for advanced video content understanding YouTube Data API for comprehensive channel insights S"
      }
    ]
  },
  {
    "file_path": "./devposts/audiority-a-mobile-app-for-the-hearing-impaired.html",
    "project_id": "audiority-a-mobile-app-for-the-hearing-impaired",
    "title": "Audiority: A Mobile App for the Hearing Impaired",
    "tagline": "Utilizing the latest machine learning and app development software to promote focus on developing innovative methods and provide a convenient and free tech hearing aid for the hearing impaired.",
    "hackathon": "",
    "built_with": [
      "createml",
      "kaggle",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/015/555/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "coding languages used for mobile app diagram audiority logo app interface and design (includes audio output) app interface and design (includes audio history) coding languages used for mobile app diagram audiority logo app interface and design (includes audio output) app interface and design (includes audio history) coding languages used for mobile app diagram 1 2 3 4 Inspiration Five years ago, my grandma had lost her hearing in one ear: however, she still has trouble hearing sounds around her even when wearing the latest conventional hearing aid available in her country. When outside, a family member would need to walk with her to make sure she avoids incoming people, different vehicles, etc. But the trouble comes when no family member is available. And in addition, 430 million people around the world are hearing impaired. After I looked into the function of hearing aids, I discovered that the conventional hearing aid is only meant to help amplify human words, not background noises such as a car horn. While researching alternative tools to help aid the hearing impaired navigate outdoor environments, I’ve also been furthering my knowledge in machine learning and app development. Whenever I see a new technological solution come out to solve a problem, it always blows me away to see how creative and mesmerizing they are. Therefore, as outdoor sounds can pose a lot more danger to people than indoor ones, such as when people are walking close to fast-paced vehicles or when there is an armed gunman nearby, I decided to create from scratch a mobile app with an embedded machine learning model with a focus on detecting and classifying outdoor sounds in order to aid the safety of the hearing impaired people. This app would be a free, accessible, and convenient solution for hearing impaired members around the world. What Audiority does Audiority is a mobile app that ensures its hearing impaired users will always have up-to-date information on different sounds surrounding the"
      }
    ]
  },
  {
    "file_path": "./devposts/binarky.html",
    "project_id": "binarky",
    "title": "Binarky",
    "tagline": "Marky enables brands to efficiently create social media posts, but how can we predict whether a post will be approved? In comes Binarky, a binary classification using machine learning for approval!",
    "hackathon": "",
    "built_with": [
      "cnn",
      "nn",
      "python",
      "pytorch",
      "tensorflow",
      "xgboost"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Speaking with Josiah about the goal of Marky inspired us to join in on the cause to help smaller brands break into the social media industry to grow their company. However, we mutually recognized the existing weaknesses of modern AI, so it only seems natural to discover how variations in posts can lead to an approved post! What it does Our algorithm analyzes trends in both tabular data and graphic styling to uncover the key features that impact the probability of getting approved. How we built it In order to do tabular classification, we used XGBoost, an extreme gradient boosting algorithm, to analyze the tabular data. Then, we used convolutional neural networks to uncover key features in the image. What makes a good post -> A combination of both graphics and text content. All of it should meld together in order to serve a purpose whether it is to inform, convince, inspire...etc. Built With cnn nn python pytorch tensorflow xgboost Submitted to TAMU Datathon 2023 Created by Rishabh Prasad Neha Rajganesh Harsh Gangaramani Anish Karthik"
      }
    ]
  },
  {
    "file_path": "./devposts/behaviorly.html",
    "project_id": "behaviorly",
    "title": "Behaviorly",
    "tagline": "A portal for teachers to input comments and grades for behavior.",
    "hackathon": "",
    "built_with": [
      "api/v1/students",
      "api/v1/teachers",
      "bootstrap",
      "css3",
      "flask",
      "html5",
      "javascript",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/327/385/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Edit Teacher Log In Page Teacher Dashboard Student Dashboard Create Teacher Edit Teacher Log In Page Teacher Dashboard Student Dashboard Create Teacher Edit Teacher 1 2 3 4 5 Inspiration What it does In the covid-19 lockdown, many students have lost the valuable learning time that is crucial for the brain. We have made a portal where teachers can give personal instructions to students about grades and homework. They can assign assignments and based on that input we have given assignments and quizzes. Managing work is a real difficulty so our website ensures direct interaction with the student. You can log behavior reports that will send an email to the parents in order for everyone’s education to elevate and become better. How we built it We built it using flask and python. We built the front end using Bootstrap CSS and basic HTML. Finally, we stored the student and teacher data in SQLite. Challenges we ran into We ran into many problems regarding choosing the correct database and inputting that database to our project. Also we had problems starting off where we couldn't think and come up with any good ideas Accomplishments that we're proud of We are proud of being able to participate in this hackathon and contributing to it. It is one of our first hackathons so it was also very exciting. What we learned We learned a faster way to use flask in our project and how to use bootstrap better. We also learned how to use flask properly. What's next for Behaviorly We were not able to completely finish and input all our ideas for this project so I plan on doing that. Also there are a few bugs that still need to be fixed. Built With api/v1/students api/v1/teachers bootstrap css3 flask html5 javascript python sqlite Try it out GitHub Repo Submitted to HackJA 2021 Created by Jayadev Ghanta Prashant  Kon Just a High schooler trying to bring a little light into the world. Trying to make a really good website with my team."
      }
    ]
  },
  {
    "file_path": "./devposts/autocc.html",
    "project_id": "autocc",
    "title": "AutoCC",
    "tagline": "Automatic closed captioning for any sources of audio, for the hard of hearing",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/807/089/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "AutoCC on a movie trailer Inspiration We were inspired to make this to make automatic closed captioning more accessible to the hard of hearing. Although closed captioning exists on sites like YouTube, other popular tools like Discord or Skype don't offer closed captioning for the hearing impaired, so we wanted to create something that could help address that gap. There are many websites with video content What it does It takes in all audio that is being output by the system, such as from conference calls, Google Hangouts, YouTube videos, Netflix, etc., and produces automatic closed captioning for the audio recorded. It then displays a black box with the text overlayed at the bottom of the screen. How we built it We used PyAudio and some sort of programming chicanery to record audio directly from the system (rather than from the microphone) and our textbox was made using PyGame. We managed to record and transcribe audio and minimize losses by recording audio in short segments via one thread, and in another thread running simultaneously, pushing the recorded audio onto a queue, where the oldest item on it would be transcribed to text using Google Cloud Speech-to-Text, and then pushed off the queue, into an input for the textbox. This method produces some lag between what the listener is reading and what's actually being said, but the immense upside of this as opposed to other methods is that very little of the audio is lost, so the user can get as much as possible. Challenges we ran into The two main challenges we ran into were getting audio data from the system, and minimizing the lag between all the processes of retrieving the audio, converting it to text, and then displaying it for the user. Getting audio data was actually a lot harder than it seemed, because unlike microphone input, there were no good libraries or APIs for recognizing data coming from the system itself, and trying to find a way to record that audio ate up most of our time. To properly get audio in"
      }
    ]
  },
  {
    "file_path": "./devposts/beach-please.html",
    "project_id": "beach-please",
    "title": "Beach, please",
    "tagline": "A rover to cleanse beaches and decrease impact of plastic on the environment",
    "hackathon": "",
    "built_with": [
      "computer-vision",
      "google-cloud-vision",
      "iot",
      "python",
      "raspberry-pi",
      "servo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by Neel Adwani yeet Deblina Chattopadhyay Avijit Das Tiffany Trinh Recent gra",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/564/051/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration When we picture ourselves at the seaside on vacation, we imagine a clean seashore with clear water. But, in reality, this is never the case, as marine pollution has become one of humanity's biggest concerns. Thanks to human negligence, most of the beaches on our planet are littered with plastic and non-biodegradable trash, which eventually reach the sea and damage the marine ecosystem. As fellow stewards of this Earth, we were inspired to build something that can help restore beaches and protect sea life. What it does The automated smart rover built by us moves around the beach to identify and pick up trash. The wheels of the rover are potent enough to move across dry as well as wet sand. The camera of the Raspberry pi 4 used in this rover takes an image of the material, and then it sends that image to Google Cloud. With the help of Google's CloudVision API, it identifies what is there in the image and returns it to my client. Depending upon the type of that object, the program classifies it as either trash or not. If the object gets identified as trash, then the rover picks it up, moves, and gathers them to a specific corner away from the seashore, making it easy for the garbage collector to collect the whole trash of the site at once. And the rover keeps repeating the process of picking up trash and moving it near a trashcan until the entire area (in this case, the beach shore) is clean and free of plastic. How we built it The heart of the rover is the Raspberry pi 4, and along with it, we are using the RPI cam. We have used two motors for the movement, and for the picking mechanism, we used a micro servo motor. We used an l293d as the Motor Driver, which drives the motors. With the help of Google Cloud Vision Object Detection API and some python code for driving the motor driver, we merged both the API code for the object detection and the robot's movement. Next, we calibrated the rover with threshold values, such as for the movement or tuning t"
      }
    ]
  },
  {
    "file_path": "./devposts/bamaps-better-aggie-maps.html",
    "project_id": "bamaps-better-aggie-maps",
    "title": "BAMaps - Better Aggie Maps",
    "tagline": "Howdy! BAMaps or Better Aggie Maps is our submission to the 2023 TAMU Hackathon. BAMaps allows users to find the closest bus stop to their current location and makes navigating Texas A&M easier.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "leaflet.js",
      "python",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/582/499/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our inspiration for BAMaps came from the official Aggie bus map on the A&M mobile app. Although the A&M app does its job, we believe that we could improve upon its design and add more features to the app. We envisioned a more convenient version of the current Aggie Bus app. What it does Our website provides an interactive map that calculates the nearest bus from your current location. You no longer need to manually check every bus route to determine which bus is closest to you. Let BAMaps do the work for you! Just input your location below and where you wish to go on campus and let BAMaps determine which bus stop is closest to you! How we built it We used Leaflet, a javascript library to map the bus stop and the user's current location. We also use its pop-up feature to add additional information about the stop. We also use HTML for the layout of the website, CSS to improve responsiveness among different devices, and JavaScript to implement the core logic of BAMaps. We needed all the locations of the bus stops, We accomplished this by scraping it from OpenStreetMap with Python, converting the data to a .csv file, and reading from this .csv file with JavaScript. Challenges we ran into We had to obtain all the latitudes and longitudes of each bus stop manually and make our own database in order to determine the closest bus stop. We also ran into issues where responsiveness would vary on different devices. Additionally, we had difficulties reaching our fourth team member and had to navigate around this issue, completing the project with 3 members. Accomplishments that we're proud of Developing a creative and coherent way method to implement javascript functions to map specific points on a map based on user location and distance from the nearest stop. We also used web scraping to obtain all the information on bus stops with custom Python code. What's next for BAMaps - Better Aggie Maps In the future, we hope to continue to expand BAMaps and add useful featur"
      }
    ]
  },
  {
    "file_path": "./devposts/best-cm-detector.html",
    "project_id": "best-cm-detector",
    "title": "best CM-detector",
    "tagline": "Through 5 machine learning models, we have determined that the best way of solving any problem is to brute force every classification model that we know! (fun stuff :)",
    "hackathon": "",
    "built_with": [
      "sklearn",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/430/775/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Our selection method consisted of selecting features based on their correlation to the final CM content, and based on the class that was provided (*sufficient/insufficient). The output data, CM content, given in the dataset was continuous (ranging between 50-100), but we set a threshold of 90 to distinguish between sufficient and insufficient classes. The correlation was determined using a correlation matrix, which helped us choose the most relevant features. In another approach, we also used Principal Component Analysis (PCA) to reduce the dimensionality of our input data from 102 to 10, therefore removing bias and improving the training time, and we test the models on both datasets (PCA and feature selection). Our approach consisted of passing the data through dense neural networks, random forest regressor, and logistic regression models. To evaluate performance, we considered precision, recall, accuracy, F1 score (classification), and R2 score (for regression) We found that logistic regression has the best metrics, with an accuracy of 72.2%. Additionally, since the data was unbalanced (there were more entries labeled \"insufficient\" than \"sufficient\"), we performed SMOTE (Synthetic Minority Over-sampling Technique). We also experimented with variational autoencoders and generals GANs to generate synthetic data (not fully functional yet). Built With sklearn tensorflow Try it out GitHub Repo Submitted to PharmaHacks 2023 Created by Aly Shariff Xin Lei Lin SarinaMashreghi Mashreghi"
      }
    ]
  },
  {
    "file_path": "./devposts/benice-rating-system-login.html",
    "project_id": "benice-rating-system-login",
    "title": "BeNice Rating system/ Login",
    "tagline": "In BeNice, the user can spend his or her free time to engage in activities that help his or her community.",
    "hackathon": "",
    "built_with": [
      "html5",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/758/542/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Whenever I feel bored, I feel guilty for not doing anything productive, so we designed a software where a user can spend his or her free time to engage in helpful activities to gain points and gain a position on the leaderboard What it does The user is given random prompts to help the community. the user can submit photographic evidence of having completed those prompts, and users can rate and comment on others' posts How we built it We built the app version in python using a graphics module called graphics.py and the website version using html5 Challenges we ran into Since graphics.py is very limited and unpredictable, we ran into several problems. For developing the rating system specifically, I ran into problems with reading and writing to a text file in order to store a user's rating to certain images. Accomplishments that we're proud of We are proud of developing this app with a limited python graphics module: graphics.py What we learned We learned to determine the feasibility of projects before attempting to do them for a hackathon What's next for BeNice Rating system/ Login We are going to work on increasing user friendliness and allowing for network functionality Built With html5 python Try it out GitHub Repo Submitted to LancerHacks 2019 Created by Surya Jasper oleks Gorpynich Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/basket-buddy-1rf7wu.html",
    "project_id": "basket-buddy-1rf7wu",
    "title": "Basket Buddy",
    "tagline": "Basket Buddy: Experience immersive solo game simulation with real-time shot prompts, score tracking, and AI-assisted detection for the ultimate training challenge.",
    "hackathon": "",
    "built_with": [
      "css",
      "gemini",
      "json",
      "mongodb",
      "nextauth",
      "opencv",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "UI/UX Hack Created by Isaac Chacko Allen Thomas Jevin Joy",
      "Best UI/UX Hack Created by Isaac Chacko Allen Thomas Jevin Joy",
      "HackWesTX VIWinnerBest UI/UX Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/743/621/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "openCV interpretation of Jevin title screen just logged in VS game screen openCV interpretation of Jevin title screen just logged in VS game screen openCV interpretation of Jevin 1 2 3 4 5 6 Inspiration Our inspiration sprang from our collective passion for basketball and a relentless drive to elevate our skills through innovative technology. We wanted to create a system that captures the immersive experience of playing basketball — simulating not just the physical activity, but also the mental and strategic aspects of the game. Inspired by Athletiq’s vision to bridge athletic performance and technology, we sought to build an engaging, high-tech platform that empowers players to train smarter and compete against a dynamic virtual opponent. What it does Basket Buddy is a cutting-edge web application that simulates a complete, real-time basketball game experience. It features seamless integration of text-to-speech and speech-to-text for dynamic voice prompts and commands, enabling users to interact naturally while playing. Utilizing OpenCV -based computer vision, the app tracks player movements and basketball shot attempts, laying a foundation for sophisticated motion analysis. The system includes user authentication and profile management via a backend database, ensuring personalized gameplay and persistent stat tracking. The app provides real-time scorekeeping, shot clock management, and simulates an AI opponent with difficulty-adjusted behaviors—delivering an immersive gamified basketball training environment accessible through any modern web browser. How we built it We developed Basket Buddy using React and TypeScript , crafting a responsive SPA with precise type safety and modular component architecture. The integration of computer vision was implemented through WebSocket communication with a FastAPI backend using OpenCV , enabling real-time basketball and hoop detection. We leveraged modern web APIs for audio synthesis and speech recognition to create intelligen"
      }
    ]
  },
  {
    "file_path": "./devposts/bionote.html",
    "project_id": "bionote",
    "title": "BioNote",
    "tagline": "Master biology with precision through intelligent, interactive learning.",
    "hackathon": "",
    "built_with": [
      "fetchai",
      "gemini",
      "groq",
      "meshy",
      "nextjs",
      "openai",
      "python",
      "sketchfab"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/501/042/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 🧠 Inspiration Textbooks are dense, outdated, and hard to engage with — especially for something as visual as human anatomy. We wanted to make studying biology actually make sense for med students. 💡 What it does BioNote lets you explore 3D anatomical models, draw directly on them, chat with an AI tutor, and turn your notes into Anki flashcards — all in one workspace. It’s like if your iPad and med school had a baby. 🔧 How we built it We used Sketchfab for the 3D models (embedded via iframe), added a canvas overlay for pen tools and screenshots, and layered in a chat interface with spaced repetition and auto flashcard generation. 🚧 Challenges Selecting specific regions under multiple model layers was tough (iframe + canvas coordination = pain 😅) Fetch.ai’s Agentverse didn’t play well with multi-turn conversations Screenshotting while preserving annotations + context was surprisingly complex ✅ Accomplishments Built a clean, immersive 3D note-taking setup — basically replicated an iPad experience Made complex AI prompts dead simple for users (click, snapshot, done) Streamlined the flow from visual > notes > memory 📚 What we learned How to use iframes way beyond just embeds — think multi-purpose tools Managing canvas layering and state across multiple UI elements Designing for both clarity and utility in a tight UI 🔮 What’s next Full-body anatomical models Depth-aware visualization (not just surface level) Smarter AI feedback based on what part you’re studying Built With fetchai gemini groq meshy nextjs openai python sketchfab Try it out GitHub Repo Submitted to UC Berkeley AI Hackathon 2025 Created by Rian Corcino i code stuff for fun Priyansh Shah CS @ UCI Kieran Llarena CS @ UM-Dearborn. Graduating 2027 Jhonathan Herrera SWE @ Snap Inc."
      }
    ]
  },
  {
    "file_path": "./devposts/aurora-aeu6v8.html",
    "project_id": "aurora-aeu6v8",
    "title": "Aurora",
    "tagline": "A platform for women by women devoted to providing resources that will not only inform but empower and connect women across the globe.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "figma",
      "flask",
      "html",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/378/284/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sneak peek of our hotline page! Our lovely logo! Sneak peek of our home page! Sneak peek of our scopes! Sneak peek of our server page! Sneak peek of our hotline page! Our lovely logo! Sneak peek of our home page! Sneak peek of our scopes! Sneak peek of our server page! Sneak peek of our hotline page! 1 2 3 4 5 6 Inspiration A great number of women tend to not have the support and resources necessary to reach their full potential. We saw that nobody had yet approached this issue, so we decided to get rolling and create something for our feminist community. What it does On Aurora , you can find the latest scopes, join a discord server and chat up with fellow sisters, and have a great number of hotlines handy for emergencies. Aside from that, our distinctive UI/UX will make you want to just explore the website further. While you explore, we also added some lofi to release those queen hormones. How we built it We built our website using HTML, CSS, bootstrap, python, and flask. HTML/CSS in addition to bootstrap was used to create and operated our frontend while python and flask operated our backend. Challenges we ran into Our first challenge was figuring out how to work together on the project through Live Share and Visual Studio Code. When we began our coding it took us a good 60 minutes to add everyone and get adjusted, but with perseverance, we were all about to work on the same files at the same time! Though we continued to experience the unfortunate crashing of Visual Studio Code which ended up holding back our development team for 2 hours because we were unable to make changes to our code. But luckily again, after several restarts and advice from mentors and web searching, we were able to make changes to our code again. Secondly, when making our website, we noticed the CSS file did not appear to be working when we referenced the file in our HTML code. To fix and overcome this irritating problem, we decided to just place the style elements within our code. Third, it"
      }
    ]
  },
  {
    "file_path": "./devposts/begreen-goe5rj.html",
    "project_id": "begreen-goe5rj",
    "title": "BeGreen",
    "tagline": "Sustainable BeReal: Post daily photos of eco-actions, grow a tree from sapling to forest, & plant a real tree each time it grows. Miss a day, lose streak & your plant. Join now!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "mongodb",
      "node.js",
      "python",
      "react.js",
      "swiftui",
      "turtle"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/435/642/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "all done using Swift on Xcode :) all done using Swift on Xcode :) 1 2 3 4 5 6 7 8 Inspiration The app came from our desire to help the environment. What it does This is essentially a merger between BeReal and Forest. Users are notified once a day to post themselves engaging in environmentally-friendly activities daily, and given select prompt. If they are successful and post on time, their sprout will grow. A streak of five days grows a tree, and users are enticed to build a luscious forest with rewards! How we built it We built it using Swift, React.js, NodeJS, MongoDB, and Python (+ turtle). Challenges we ran into Two of our team members are new to Swift, so there was a lot of debugging involved. We also faced lots of pressure due to the time constraint. Additionally, one of our team members who was specialized in frontend failed to show up, so we had to improvised. Accomplishments that we're proud of The BeGreen team is proud of creating a product that not only helps individuals make sustainable choices but also has the potential to make a significant impact on the environment. The team is also proud of creating a product that is engaging and user-friendly, with a strong focus on social connection and community building. What we learned During the hackathon, we learned a lot about web and phone app development. We learned to value teamwork through discussions about the projects and working on separate components of the app. The BeGreen team learned a lot during the development process, including the challenges of building a sustainable product, and the power of gamification and social connection in driving behavior change . What's next for BeGreen The BeGreen team is committed to continually improving the app and expanding its impact. Plans include adding new challenges and features, expanding the social component, and partnering with organizations to promote sustainable practices on a larger scale. We are planning to expand this into a web application and tune o"
      }
    ]
  },
  {
    "file_path": "./devposts/blochsphere-space.html",
    "project_id": "blochsphere-space",
    "title": "BlochSphere.space",
    "tagline": "a one shot prompt generated interactive 3D bloch sphere visualizer for a qubit in quantum computing",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/584/433/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Bloch Sphere Quantum State Visualizer Inspiration Quantum mechanics is notoriously difficult to visualize and understand, especially for students and researchers new to the field. The Bloch sphere is a fundamental tool for representing quantum states, but traditional 2D diagrams in textbooks fail to capture its three-dimensional nature and dynamic properties. We wanted to create an interactive, beautiful visualization that makes quantum concepts more accessible and intuitive. What it does Our Bloch Sphere Visualizer is an interactive 3D educational tool that allows users to: Visualize quantum states in real-time with a fully interactive 3D Bloch sphere Manipulate state parameters using intuitive sliders for polar (θ) and azimuthal (φ) angles Explore common quantum states like |0⟩, |1⟩, |+⟩, |-⟩, and complex superposition states View mathematical representations including state vectors, measurement probabilities, and Bloch vector components Animate quantum evolution to see how states change over time Learn interactively with real-time updates of all quantum mechanical properties The visualization includes proper axis labeling, wireframe rendering for depth perception, and a golden state vector that clearly shows the current quantum state position on the sphere. How we built it Frontend Framework: React with TypeScript for type safety and component architecture 3D Graphics: React Three Fiber (@react-three/fiber) and Drei (@react-three/drei) for performant WebGL rendering Styling: Tailwind CSS with custom gradients and glassmorphism effects for a modern, scientific aesthetic Mathematical Engine: Pure JavaScript calculations for quantum state transformations, probability calculations, and Bloch vector projections Architecture: Modular component design with: BlochSphere component handling all 3D rendering and interactions QuantumControls for parameter manipulation and common state presets QuantumStateDisplay for real-time mathematical output Custom hooks for state "
      }
    ]
  },
  {
    "file_path": "./devposts/bettercommits.html",
    "project_id": "bettercommits",
    "title": "BetterCommits",
    "tagline": "Because your PR's deserve a LGTM!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "python",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/023/046/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Inspiration As developers, we often find ourselves building a habit of creating poor commit message descriptions when building personal projects. As this habit carries over when doing internships, co-ops or jobs, we wanted to build a solution to the habit. What it does BetterCommits is a VSCode extension which gives real-time feedback to user’s commit messages based on a chosen commit message template convention. It highlights parts of the user’s commit message which lack detail or are “weak”. BetterCommits then creates a tooltip on the highlighted section which the user can hover over with their cursor to see the suggestions. How we built it We built BetterCommits using TypeScript, Python, and Cohere. We used TypeScript for the extension part (communicating with VS-code) and Python and Cohere’s SDK to handle the real-time feedback logic. Challenges we ran into Initially, we wanted to have our project be purely TypeScript based. This turned out to be a mistake as we ran into difficulties setting up the Cohere SDK for TypeScript. Compared to its counterpart written in Python, the TypeScript version was much more complex and difficult to work with despite having the same results. Because of this and the Cohere representatives suggesting we migrate, we had to move a large portion of our TypeScript codebase to Python. This migration took a long time because of how our logic was set up initially. Setting up the Python libraries was also a mini struggle as everyone’s machine was on different versions of Python which made it harder to work on it together due to library version mismatch. Accomplishments that we're proud of We’re proud to have built a product we find helpful in our day to day lives. Although our project doesn’t solve world hunger, cure cancer or something unimaginable, we’re still proud to have built something that helps people by just a little, even if it's just saving a couple minutes of their time. What we learned During the development of BetterComm"
      }
    ]
  },
  {
    "file_path": "./devposts/benice-4a87vp.html",
    "project_id": "benice-4a87vp",
    "title": "BeNice",
    "tagline": "When people are bored, they could help the community instead of doing nothing!",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/758/454/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo What it does It gives a random good deed for the day and after completing it you get points as rewards. After you get enough points, you can use it to customize your character, and the best part is that it saves across computer restarts and page reloads. How I built it I used Atom to write the code for the javascript,html, and css and piskel for the pixelart. Challenges I ran into Lots of bugs in the code, mostly on my part Accomplishments that I'm proud of Getting it to work as a webserver for a while before discontinuing that feature. Built With javascript Try it out lino-levan.github.io Submitted to LancerHacks 2019 Created by Lino Le Van oleks Gorpynich Surya Jasper"
      }
    ]
  },
  {
    "file_path": "./devposts/bingo-winners.html",
    "project_id": "bingo-winners",
    "title": "Televate",
    "tagline": "Legacy codebase resurrection platform",
    "hackathon": "",
    "built_with": [
      "auth0",
      "canva",
      "crewai",
      "fastapi",
      "figma",
      "heroku",
      "langchain",
      "nextjs",
      "openai",
      "python",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[Hack Kosice] 1st Place Overall Winner [MLH] Best Use of AI in Education Created by I worked on mos",
      "Hack Kosice 2024Winner[Hack Kosice] 1st Place OverallWinner[MLH] Best Use of AI in Education",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/836/786/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "A helpful tool for all situations Televate your code to the next level! Landing page of Televate WebApp Code rework review page Pipeline A helpful tool for all situations Televate your code to the next level! Landing page of Televate WebApp Code rework review page Pipeline A helpful tool for all situations 1 2 3 4 5 In a digital world where yesterday's code quickly becomes obsolete, our new platform offers a lifeline. We rejuvenate outdated codebases, transforming them into sleek, maintainable masterpieces. Join us in giving unmaintainable code a second life, paving the way for tomorrow's innovations. At Hack Kosice 2024, drawing inspiration from Deutsche Telekom —one of the event's sponsors—we ventured into the complex realm of legacy code maintenance. We recognized that while individual developers might find their own code challenging to maintain after just a year, the giants of the IT world are wrestling with codebases that are several decades old, created by professionals who have long since retired. Fuelled by this realization, we swiftly aligned on our project's objectives and were able to implement our key features with remarkable speed: While we were pleased with these accomplishments, the real triumph was how we built upon this solid foundation to achieve something truly groundbreaking: How we built it Our project unfolds through four distinct but interconnected modules, each serving a critical function in our vision of code revitalization. The journey begins with the process of tokenization and vectorization, an operation where entire code repositories are deconstructed layer by layer. This dissection progresses from files to functions, from functions to individual lines, and finally, from lines to discrete tokens. These tokens are then vectorized, capturing the essence of the code in a form amenable to advanced analysis. This transformed data is then cataloged in a specialized ChromaDB database, ensuring that each fragment, each vectorized token, is readi"
      }
    ]
  },
  {
    "file_path": "./devposts/boardmate.html",
    "project_id": "boardmate",
    "title": "ExpressMate",
    "tagline": "Quickly learn any concept with AI in Adobe Express.",
    "hackathon": "",
    "built_with": [
      "claude",
      "nextjs",
      "python",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/841/056/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "What a User Sees in our Adobe Plugin Our Adobe Plugin What a User Sees in our Adobe Plugin Our Adobe Plugin What a User Sees in our Adobe Plugin 1 2 Inspiration Our inspiration for this project was the millions of Americans who don't have access to proper tutoring. We wanted to solve this problem by providing easy, personalized, and highly visual tutoring using a very accurate model (Claude 3). What it does Our app has a few simple steps to provide powerful results. First, a user inputs a prompt like \"I would like to know more about Reimann Sums\" or \"Can you teach me more about linear functions?\". Then, our model uses this user input to generate a quality response. The user can then ask further questions about what they have read, so our app acts as a personalized math tutor for the student. Challenges we ran into We encountered a variety of challenges throughout our development process. Firstly, we had trouble getting our AI-generated video to be accurate to the concept it was describing. For instance, when given the prompt \"Explain Riemann Sums using visuals,\" it generated inaccurate visuals and made little sense. Another major challenge was integrating ExpressMate with Adobe Express, as it was our first time working with the Adobe Express suite of tools. However, the development experience was excellent, and the thorough documentation helped a lot, especially when we were facing errors related to Cross-Origin errors. Accomplishments that we're proud of One accomplishment that we're proud of is our ability to make an excellent user interface using Next.js and Radix UI Themes. We ensured that our beautiful yet simple user interface made the ExpressMate experience smooth and helpful for various people. Built With claude nextjs python tailwind Submitted to Los Altos Hacks 8 Created by Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Kosei Tsukamoto Vedant Garg"
      }
    ]
  },
  {
    "file_path": "./devposts/bassets.html",
    "project_id": "bassets",
    "title": "Bassets",
    "tagline": "Our goal is to help users understand the power of contrasts when building UI/UX. Our model opens accessibility options and advances a brand's ability to be read and distinguished at a glance.",
    "hackathon": "",
    "built_with": [
      "excel",
      "google-form",
      "photoshop",
      "python",
      "txt",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/357/874/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Same Grayscale different color (Gray) Graph Sample Question The value (lightness) of colors have the a significant impact on perception even if the contrast value is the same Figure A (Brand Use Case) Figure B Figure C (Grayscale B) Figure D (Adjusted Saturation) Unknown Source (Gray) Unknown Sourse Same Grayscale different color Same Grayscale different color (Gray) Graph Sample Question The value (lightness) of colors have the a significant impact on perception even if the contrast value is the same Figure A (Brand Use Case) Figure B Figure C (Grayscale B) Figure D (Adjusted Saturation) Unknown Source (Gray) Unknown Sourse Same Grayscale different color Same Grayscale different color (Gray) 1 2 3 4 5 6 7 8 9 10 11 12 🐶Inspiration The namesake of our project was our four-legged family friends' canines because no one understands the power of grayscale like a species that evolved to live without our luxury of RGB-colored sight*. While interviewing people with visual color disabilities, all of our applicants owned a dog, and one held a Basset that interrupted our meeting. We thought it was a fun reference to remember this fun project. 📈What it does We created a model for understanding the response time to a corresponding grayscale ratio. On the x-axis, we graphed the contrast, while the y-axis estimated the time it took the user to answer correctly. As we collected data, we saw an exponential decay form in quadrant one. The horizontal asymptote approached a number within the margin of error for average human reaction time: we will refer to this line going further as ‘Ht.’ The vertical asymptote approached within the margin of error for the average most negligible contrast humans can perceive we will refer to this line going further as ‘Hc.’ We then looked at famous International, National, Regional, and Local brand logos contrast to predict their recognizability.\nThe findings were surprising; International/National were all clustered comparatively high compared to loc"
      }
    ]
  },
  {
    "file_path": "./devposts/benice-g13wx6.html",
    "project_id": "benice-g13wx6",
    "title": "BeNice",
    "tagline": "BeNice is an app that helps people decide what to do for a day that helps their community.",
    "hackathon": "",
    "built_with": [
      "html",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/758/453/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "BeNice logo Inspiration Sometimes I wake up very bored with nothing in mind. I usually end up doing nothing for the day and go to sleep feeling like I accomplished nothing. This app should help people in that situation and the community at the same time. What it does BeNice gives you a random prompt to do for that day, the prompt ranges from picking up trash to donating food. After you are done, you can take a picture of yourself and what you did an post it. For this, you can get points and with these points you customize your character on the website. You can also review and leave comments on other people's pictures. How we built it The build was split into 3 parts. The python app that lets you \"upload\" pictures, the python app that lets you \"review\" pictures, and a website with a character that can be customized for points. Challenges we ran into We were using the graphics python library which is limited in its use and sometimes can be unpredictable. It was also my first time using that library Accomplishments that I am proud of I created the uploading image python app and considering it was my first time using python graphics library, I am pretty proud of it. I think there is A LOT of improvement to be done, but it is definitely a good start. Future plan Creating a database with all the user login info and images. Also overall making the app work online. Built With html python Try it out GitHub Repo Submitted to LancerHacks 2019 Created by I worked on the part of the app that lets you \"upload\" images and creates a leader board. It was my first time using python graphics but I think I learned a lot about this library. oleks Gorpynich Surya Jasper Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/bitnote.html",
    "project_id": "bitnote",
    "title": "Bitnote",
    "tagline": "Lightning-fast Bitcoin learning, powered by Lightning, Nostr, and AI. Authenticate, zap courses, and switch to creator mode. Revolutionizing education, without Database ⚡",
    "hackathon": "",
    "built_with": [
      "alby",
      "javascript",
      "next",
      "nostr",
      "voltage"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "User can zap first when viewing the course and later zap on each section if they like"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/854/490/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GiF Home Page Creator Page Course Upload and Section Create Voltage's MutinyNet node ( Connected with Alby ) Testing Nostr: npub1wkn3zgdwr4n6d7aagqfswls94elgl0hlnejym9ezpmtm6p6vhd5shntxcg GIF GiF Home Page Creator Page Course Upload and Section Create Voltage's MutinyNet node ( Connected with Alby ) Testing Nostr: npub1wkn3zgdwr4n6d7aagqfswls94elgl0hlnejym9ezpmtm6p6vhd5shntxcg GIF GiF 1 2 3 4 5 6 7 What it does It's a nostr based platform similar to Udemy but for Bitcoin Education Plebs can view, watch and read courses. Plebs can create and upload media and markdown for each section in course. Functioning Each course is a Note and the sections are reposts by the creator There's a standard format for Note of course details and sections Reviews and comments are retweet on the same note by other users with appropriate tags User can zap first when viewing the course and later zap on each section if they like On each section in course user can add note ( not nostr note ) for later reference which is actually just a note How we built it The core of this project is Nostr and notes as the building block Voltage is used to run nodes, here we are using MutinyNet node and channels. Lightning is used to authenticate ( Using Alby Wallet ) Upcoming Features Optimizing the sorting and searches as there's no backend apart form nostr Support for NIP-05 Editing courses & commenting on each section Making Zap work for each section Making Note taking process collaborative for both users and creator so the courses can be optmized NOTE: Currently there are some issues with nostr integrations we are trying to fix it asap. Stay tuned for updates. Built With alby javascript next nostr voltage Try it out mitbitcoin-frontend.vercel.app GitHub Repo Submitted to MIT Bitcoin Hackathon: Scaling Up Created by I worked on the Frontend UI creation using Nextjs, TailwindCss and Shadcn UI library, integration of nostr for course creation Ankit Yadav Shevxer Zk A student at IIT Roorkee and Member o"
      }
    ]
  },
  {
    "file_path": "./devposts/binoculearn.html",
    "project_id": "binoculearn",
    "title": "Binoculearn.ai",
    "tagline": "Redefining Learning in low-bandwidth Internet⚡",
    "hackathon": "",
    "built_with": [
      "ai",
      "co:here",
      "express.js",
      "figma",
      "natural-language-processing",
      "react",
      "redux",
      "summarization",
      "tensorflow",
      "twilio",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Most Creative Use of Twilio Created by Sometimes, I video call myself",
      "1st Place - Education Track Winner Most Creative Use of Twilio Created by Sometimes, I video call m",
      "MetroHacks 2022Winner1st Place - Education TrackWinnerMost Creative Use of Twilio",
      "First and foremost, it is Crafted with 💙. The whole process can be broken into the following points :-",
      "Best Use of NLP with Cohere 🗣️",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/304/599/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF GIF GIF 1 2 3 4 5 6 Submission Category Age group — 18+ Inspiration 💡 As ubiquitous and fast as the internet seems in developed countries, developing countries still struggle with reliable internet connections. The impact of poor internet connectivity exasperate the education inequality between children from prosperous countries and children from developing countries, because the latter cannot benefit from remote learning via video conferencing. Last year, it was found that millions of students in the state of Odisha in India are stuck at home with no access to either internet or online education. Our teammate Subham Sahu, an Odisha native, has had first-hand experience of interruptions during his undergraduate studies. For even those who have access to the internet, the price is premium and the bandwidth is limited. For instance, while talking to his parents in India, Subham found that they frequently run out of their allocated 1 GB far before the allowance period, after which the bandwidth gets throttled: stalled frames, choppy audio, painful delays, and eventual disconnections, and subsequent retries are a normal occurrence, but still arguably much better than normal telephone conversations because he gets to “see” them. At the heart of the problem may lack tele-infrastructure for the implementation of education on virtual platforms. To address this problem, we propose a new approach based on the insight that if we are willing to give up some realism or realistic rendering of faces and screens, then there is a whole new world of face and screen representations that can be derived for ultra-low bandwidth, with an acceptable quality of experience. The proposed solution can be primarily implemented as software needing no change in the underlying infrastructure. This would in turn be cheaper, and allow internet access to people that are currently being marginalized based on their affordability. Our architectural goal is to prioritize a reliable frame rate"
      }
    ]
  },
  {
    "file_path": "./devposts/bestudious-zwg835.html",
    "project_id": "bestudious-zwg835",
    "title": "BeStudious",
    "tagline": "Where studying meets community and competition.",
    "hackathon": "",
    "built_with": [
      "clerk",
      "moment.js",
      "next.js",
      "openai",
      "supabase",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "bestudious.vercel.app"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/540/966/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Feed (Main Feature) Studious Spaces (Feature) Trivia Questions (Feature) Profile Page Homepage Feed (Main Feature) Studious Spaces (Feature) Trivia Questions (Feature) Profile Page Homepage 1 2 3 4 5 6 7 Inspiration In today's generation, many students face the immense pressures to perform academically and get good grade. But always being one touch away from getting sucked into distraction, it's extremely difficult to stay motivated and passionate toward our goals. Yet when we eventually overcome those temptations, it's easy to feel lonely or feel like we're missing out on the outside world. Solution Luckily we have a solution: BeStudious is not just another study app; it is a dynamic and innovative platform that maximizes daily productivity through competition and community engagement. Our primary goal is to transform studying into an exciting and competitive experience that motivates and empowers students to excel in their academic pursuits. The heart of BeStudious lies in its daily productivity prompt, expertly generated by our AI. Each prompt serves as a source of motivation, challenging users to perform specific tasks that promote productivity, such as \"Go to the library to study today.\" The user's objective is to capture a picture of themselves while accomplishing the task. These images can then be shared within the BeStudious community, fostering positive accountability and creating a supportive environment that fuels productivity. Tying together competition and learning, BeStudious hosts a built-in leaderboard based on a comprehensive point system. Users can earn points in two ways: 1: by uploading their daily picture or 2: by answering trivia questions correctly. Everyday, our AI generates four engaging trivia questions spanning diverse subjects, including Math, Science, English, and History. Correct answers contribute to a user's points, therefore increasing their chances of ascending the leaderboard. Overall, the point system adds an element of fun and he"
      }
    ]
  },
  {
    "file_path": "./devposts/baker-hugh-s.html",
    "project_id": "baker-hugh-s",
    "title": "Baker Hugh's",
    "tagline": "Data classification model for a uniform and density-based data set",
    "hackathon": "",
    "built_with": [
      "numpy",
      "pandas",
      "python",
      "sklearn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/127/878/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 Bakers Hughes Selections Kmeans, centroid based BIRCH, works better on large sets vs kmeans Evaluation plots orginal data set finds the max and minimum distances and the standerad variation of the diffrences between eveypoint in the orginal data set and its clustered paired. Process V1 Started with multiple models several clustering models such as kmeans, spectural, BIRCH, OPTICS, DBSCAN, FeatureAgglomeration, kmeans_plusplus, and affinity_propagation. As well as clustering using KDE's. V2 due to long load times and trouble evaluting centers point and cluster indices the pool of vibal methods was reduced too. kmeans, spectural, OPTICS, BIRCH, DBSCAN, and KDE + kmeans. V3 Due too lack of time the pool was reduced kmeans and BIRCH as well as a layered clustering method mixing the two models. Finals Notes Birch accurracy improves with lowered threshhold hovever it also raise compute time. Nothing to found on kmeans random seeds. Layered model clustering ratio could see improvements. 3d Hist's ugly idk _(-v-)_/ Built With numpy pandas python sklearn Try it out GitHub Repo Submitted to TAMU Datathon 2024 Created by I modeled the data and created the viz's, as well as Taking the time to simulate and run each model. Aleksey Payne Shameem Monjazeb"
      }
    ]
  },
  {
    "file_path": "./devposts/away.html",
    "project_id": "away",
    "title": "Away",
    "tagline": "Waste management: reimagined",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "firebase",
      "flask",
      "flutter",
      "python",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Once you submit it, you can track your goals on the list in the goals block."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/354/465/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration With each day that goes by, humans generate a disturbingly large amount of waste that inevitably gets thrown into landfills. Even worse, a lot of the waste gets burnt releasing tons of toxic chemicals into the atmosphere. According to the EPA, the total generation of municipal solid waste (MSW) in 2018 was 292.4 million tons or 4.9 pounds per person per day . In the same year, we only recycled or composted a disappointing 32.1% of that amount, leaving the remaining 200 million tons to be sent to landfills . When looking forward, the World Bank predicts that the yearly global waste will rise to 3.4 billion tons by only the year 2050 , as new regions of the Earth begin to develop. Obviously, this is an issue that needs to be slowed down, if not stopped entirely. Unfortunately, there is no real way any average person can make a notable difference... False! Everyday purchases, most frequently food, are things that often lead to large amounts of waste, and are all things we can improve on. Whether it is buying less of something, or buying more sustainable alternatives, there is always something that you can do to help. Again, the ways you can help out are not only through the food industry: Around 4900 Metric tons—60% of all plastics ever produced—were discarded and are accumulating in landfills or in the natural environment. Because of this, my team decided to make Away , a mobile app that will help you become a more green citizen. What it does Away puts users in greater control and awareness of their waste.\nIn just seconds, users can scan the barcodes of any packaged item, with a network of web scrapers, APIs, and databases retrieving/storing valuable information on each item. We'll provide you with the: The amount of waste it’ll eventually generate The types of packaging materials. In case users want to simplify or edit any parameters for some kind of unique product, they can quickly change them and submit an individual scan, only a small extra step that w"
      }
    ]
  },
  {
    "file_path": "./devposts/bitbots.html",
    "project_id": "bitbots",
    "title": "Speak Out!",
    "tagline": "Speak Out! aims to provide access and combat inequality as a Language-as-a-Service (LaaS) by enabling people of disabilities to talk to each other with the world like the others!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "opencv",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/796/438/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Basic Functionality The Speak Out! landing page Record a video of you signing in ASL to convert it to English! Basic Functionality The Speak Out! landing page Record a video of you signing in ASL to convert it to English! Basic Functionality 1 2 3 Inspiration We were inspired to create a program that would convert ASL (American Sign Language) to text or voice commands, in order to simplify communication. In a world full of constantly-evolving technology, we are always being shown examples of smart devices that are voice-activated, but devices like these may not be accessible and inclusive for everyone & we don't want this disability to stop people from achieving their goals! That's why we created Speak Out!. What it does Speak Out! is a program that uses computer vision and artificial intelligence to convert ASL signs into English text or audio, and vice versa. It takes input from a user who finger-spells letters, and the phrase is then interpreted into text or audio. How we built it We built Speak Out! using Google Teachable Machine and the interactive dashboard using HTML,CSS,Javascript & Netlify. As we used Teachable it allowed us to concentrate a lot more on the data to train to give out more accurate results! Challenges we ran into Initially we decided to finish the project with TensorFlow and integrate with Google Cloud! But we ran into a lot of problems with TensorFlow so there was no time to debug & it was too late to shift to OpenCV to train the models. Hence we shifted to no-code platforms - Google Teachable Machine! and our results speaks now! ;) Accomplishments that we're proud of As stated earlier we ran into unexpected and major problems and we are really proud that we didn't give up and made some very important  We are proud that we didn't panic but instead took quick on-the-spot decisions! We were able to produce a finished product despite all of the technical difficulties we experienced. However, we also learned a lot. We learned more about using co"
      }
    ]
  },
  {
    "file_path": "./devposts/blossom-8r5e1n.html",
    "project_id": "blossom-8r5e1n",
    "title": "Blossom",
    "tagline": "Blossom is an effort to relieve stress and manage mental health. Our platform allows users to journal, track, and analyze a user's mental health.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for Social Good Created by Nafi Islam Whoop! Quenton Hua Alejandro Valenzuela",
      "JP Morgan Challenge: Best Hack for Social Good Created by Nafi Islam Whoop! Quenton Hua Alejandro V",
      "TAMUhack 2022WinnerJP Morgan Challenge: Best Hack for Social Good",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/817/566/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Suggested Resources Page Home Page Rating Page Analytics Page Activities Page Suggested Activities Page Resources Page Suggested Resources Page Home Page Rating Page Analytics Page Activities Page Suggested Activities Page Resources Page Suggested Resources Page 1 2 3 4 5 6 7 8 Inspiration Since the start of the pandemic depression rates have skyrocketed, and many people have had pre-existing mental health issues. This app influences users to take an active role in managing their mental health. What it does Our app allows users to log how they are feeling based on an option of emoticons (happy, mediocre, neutral, sad, awful), and further elaborate by logging their day. This data is then used to create visual diagrams of user's mood. Furthermore, the intended purpose is that based off machine learning and a user's data, our platform will provide recommendations, on the topic of activities, to uplift a user's mental health. Another similar feature is recommendations for resources! This way users can take actions to improve mental health in numerous ways. How we built it We used a combination of three web development languages, HTML, CSS, and JavaScript. Challenges we ran into We had issues in both areas of full stack development, front end and back end. We had no prior experience in web development, so picking up HTML on such a short amount of time was definitely challenging. This affected us from formatting, syntax, and even code architecture. As for our backend problems, we intended to create a database that stored information. Accomplishments that we're proud of We are proud that our website is functional! We also were to develop all the features that we originally thought of. Furthermore, we are proud that, with no prior experience, we are able to present our product as a prototype. What we learned We learned that programming in a safe space was extremely beneficial to our development. With no experience but many mentors, they were able to support us and teach us "
      }
    ]
  },
  {
    "file_path": "./devposts/bloomberg.html",
    "project_id": "bloomberg",
    "title": "Embedding Crackers",
    "tagline": "Categorizing unlabelled articles.",
    "hackathon": "",
    "built_with": [
      "deepnote",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked on categorizing the data and finding the best k value for the k means algorithm."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/248/570/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Guesses for Part 1 Guess for article 1: To understand what this article is about, we found the top 3 articles that have the highest cosine similarity to the mystery article. The three articles that had the highest cosine similarity were: A. R. Rahman, an Indian musical composer, and his music Online shopping on Cyber Monday, which is the monday just after Black Friday Richard Gariott’s experience with private space travel The cosine similarities were respectively: 0.8070927869054605 0.8047635531994215 0.803327863916594 Using K-means clustering, we divided the articles into 11 categories: Technology, Money, Law, Environment, Health, Employment, World News, Politics, Entertainment, Violence, and Other. This mystery article was classified in the Entertainment category. Our guess for article 1 is that it has something to do with entertainment. It may be about music, tourism, or shopping. Guess for article 2: To understand what this article is about, we found the top 3 articles that have the highest cosine similarity to the mystery article. The three articles that had the highest cosine similarity were about: The impact of the credit crisis on world governments and banks Patrick Dempsey with others bought the struggling coffee company Tully’s Coffee Matthew McConaughey got married with Camila Alves The cosine similarities were respectively: 0.9665118691237833 0.7595008813120413 0.7163007338621993 This mystery article was classified in the Entertainment category. Note that the cosine similarity for the first article is much higher than that for the other two articles. The first article is also an outlier in the entertainment category. This leads us to believe that the mystery article is also an outlier in the entertainment category. Our guess for article 2 is that it has something to do with a financial crisis or recession. It also may have a lot of high profile names involved. Guess for article 3: To understand what this article is about, we found the top 3 articles that"
      }
    ]
  },
  {
    "file_path": "./devposts/bias-ai.html",
    "project_id": "bias-ai",
    "title": "bias.ai",
    "tagline": "bias.ai helps developers, and hobbyists create AI models that are free of any racial, gender, or other forms of bias. Together, let's shape a future where AI serves as a force for positive change.",
    "hackathon": "",
    "built_with": [
      "deno",
      "gpt-3.5",
      "preact",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Track - Paw Patrol"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/478/212/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Track - Paw Patrol Inspiration We were inspired to create bias.ai when we realized the increasing need to tackle biases in AI models, given the growing popularity of AI technology. As students, we recognized the importance of building a platform that empowers developers and hobbyists to create fair and unbiased AI models. What it does bias.ai is a platform that helps you identify and address biases in your AI models. Using technologies like Deno, Preact, and Tailwind, we built a user-friendly interface where you are currently able to do 2 things Remove biased records from your training data Evaluate your model on a \"bias rating\". With the power of GPT-3.5, bias.ai ensures that your AI models make unbiased and ethical decisions. How we built it The backend is written with Deno, while the frontend uses Preact, and Tailwind. These technologies made development a breeze and allowed us to craft a sleek and intuitive user interface. For the backend, we harnessed the power of GPT-3.5, a mind-blowing language model, to enhance the capabilities of our platform. We used TypeScript to ensure type safety and smooth development throughout the process. Challenges we ran into Throughout the development journey, we encountered our fair share of challenges. Integrating different technologies like Deno, Preact, and GPT-3.5 had its complexities. We had to troubleshoot and find workarounds to ensure smooth interactions between the frontend and backend. Additionally, fine-tuning the GPT-3.5 prompt took some trial and error. Accomplishments that we're proud of As students, we are extremely proud of what we have accomplished with bias.ai. It's our first time working with GPT-3.5, and integrating it seamlessly into our platform was a major achievement. We're also proud of the user experience we crafted using Preact, Tailwind, and TypeScript. What we learned Throughout the development process, we learned so much! We gained hands-on experience with Deno, Preact, Tailwind, GPT-3.5, and TypeSc"
      }
    ]
  },
  {
    "file_path": "./devposts/better-clock.html",
    "project_id": "better-clock",
    "title": "Better Clock",
    "tagline": "A base 10 time system made by the organizers in 3 hours",
    "hackathon": "",
    "built_with": [
      "css",
      "javascript",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/283/397/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Most things in our lives from temperature to measurement are base-10. Why not time? We wanted to make a simple and standardized time system, set in base-10. What it does https://better-clock.netlify.app/ displays the current time in base-10 in both analog and digital. It makes it easy to convert the current time to this better timing system. In addition, Better-clock helps you visualize what percentage of your day has passed. How it works Just like real life, each year is composed of 365 days.\nOne day: 10 hours\n1 hours: 100 minutes\n1 minute: 100 seconds\n100 seconds: 1000 milliseconds How we built it For the frontend, we used JavaScript, React, and Tailwind. We used the built-in javascript time module to calcuate the time. With some clever CSS, we animated the moving of the hands. What's next for Better Clock We hope that this better timing system gets implemented around the world someday.\nAlso, we'll eventually add blockchain technology and machine learning. Built With css javascript react tailwind Try it out better-clock.netlify.app GitHub Repo twitch.tv Submitted to ClockHacks Created by I helped with this part Jeffrey Zang hackathon boy I helped set up the project, debug random issues that Nathan made, and also helped with this part Jay Ren Helo I was in charge of among us specifically the idea and oversight of the creation of the clock. You can see my contribution here . Nathan Wong University of Waterloo CS/BBA Sean Wang Cera Wang"
      }
    ]
  },
  {
    "file_path": "./devposts/booked-sgpq1y.html",
    "project_id": "booked-sgpq1y",
    "title": "Booked.",
    "tagline": "Squeeze in some story time with Booked.\n\nSchedule in reading breaks, organize book club meetings, and see what your friends have been 'booked on' - all in one place!",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "express.js",
      "figma",
      "mongodb",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hacklahoma 2025Winner1st Place - Meta Quest 3s",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/273/212/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We were inspired by self help apps that encouraged mindfulness and unplugging from your phone. We were also inspired by apps like Strava which tracks your progress on hobbies and can also be used in a competitive manner! What it does Booked. is an app that focuses on encouraging users to read more with less distractions. It has several features that surround the main 3 foundational characteristics we wanted to embody: schedule, connect, and expand. Schedule: Booked.'s schedule characteristic encompasses organizing the user's reading goals into tangible, set-in-stone time blocks that help them achieve their desired objective. It takes the mental load of planning out and remembering daily tasks by automatically detecting ideal times for the user to read and scheduling it in the calendar they already use, such as Google Calendar. We have several types of feature that surround schedule: Daily scheduling helper: as mentioned above, this feature takes in your current calendar events and suggests when the user should take personal reading breaks Book club scheduling helper: this feature takes yours and other Booked. user's schedule and compares it to schedule a time when each individual is free to meet. This is beneficial to arrange book club meetings or just to continue connecting with your friends! Progress stats: this feature falls under the schedule category by allowing the user to visualize their progress, making it easier for them to determine whether they are on track to their goals. Connect: Connection is the most important characteristic we planned this app for. Scheduling and expansion helps add onto this aspect. We based this app to not only connect individuals to a community of book lovers, but in doing so, it also aims to disconnect users from their phone: Disconnection - Phone lock: Booked. tracks not only how much you read, but also tracks how long you read: during your reading sessions, you can start a countdown timer or a stopwatch."
      }
    ]
  },
  {
    "file_path": "./devposts/bolted.html",
    "project_id": "bolted",
    "title": "Bolted",
    "tagline": "change later",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "chrome",
      "css3",
      "extension",
      "flask",
      "html",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/222/559/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration This project was inspired by observing students who often get distracted and sidetracked while browsing the web. With countless social media platforms, entertainment websites, and rabbit holes on the internet, it’s easy to lose track of time and focus on activities that don't contribute to academic or personal productivity.\nWe saw firsthand how students struggled to balance their time online, and many weren't fully aware of how much time they spent on unproductive websites. The need for a tool to help students monitor their online habits and distinguish between productive and non-productive sites became apparent. What it does This Chrome extension is designed to help users improve their productivity by tracking the websites they visit and generating a visual report of their online activity. The tool classifies websites into productive and non-productive categories based on predefined criteria, offering users valuable insights into how they spend their time online. How we built it We built the Chrome extension using a combination of frontend and backend technologies, APIs, and tools to help users track their productivity. Frontend:\nHTML, CSS, JavaScript, Bootstrap: These technologies were used to create the extension’s interface, allowing users to interact with the extension and view productivity statistics. Backend:\nPython (Flask & Pandas): Flask handles API requests, while Pandas processes and analyzes website usage data to determine productivity. YouTube API:\nThe YouTube API fetches video titles, tags, and descriptions to determine if a YouTube video is productive or not. Productivity Classification:\nChatGPT & Gemini API: These AI models classify websites as productive or non-productive based on their content. Development Tools:\nVS Code: Our primary IDE.\nGitHub Copilot & ChatGPT: Assisted in writing and optimizing code. Challenges we ran into Categorizing websites into productive or nonproductive sites, integrating frontend stuff with t"
      }
    ]
  },
  {
    "file_path": "./devposts/boop-jw5hrk.html",
    "project_id": "boop-jw5hrk",
    "title": "boop",
    "tagline": "Never miss a surprise moment with friends again!",
    "hackathon": "",
    "built_with": [
      "boop"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/626/614/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "built by boopers for boopers Built With boop Submitted to Hack the 6ix 2025 Created by Jess Huang Aayush Grover Weinna Zheng James Cai"
      }
    ]
  },
  {
    "file_path": "./devposts/blocscam.html",
    "project_id": "blocscam",
    "title": "Omellete",
    "tagline": "With many people are getting scammed, a platform that allow sharing and scam report data processing brings people together to fight against fraud.",
    "hackathon": "",
    "built_with": [
      "dart",
      "firebase",
      "flutter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/912/146/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Data Visualisation BlocScam Login Page Data Visualisation BlocScam Login Page Data Visualisation 1 2 3 4 Inspiration Our main idea is a community-based solution like Reddit. We aim to create a forum where users can share their recent experiences with scams. What it does The forum allows users to share their recent experiences with scams. By using this platform, others can be informed about the latest scam methods. This awareness helps users recognize potential scams and prevent themselves from falling victim. Additionally, we offer features like monthly scam analytics and educational resources to help users stay informed about scam tactics. How we built it We conceived the idea and built the application using Flutter for the front end and Firebase for the back end. Challenges we ran into As first-time hackathon participants, we faced challenges in brainstorming impactful ideas. Additionally, balancing time was difficult since all four team members were full-time interns with limited availability. Accomplishments that we're proud of We successfully implemented the fundamental functions of the application. What we learned We learned the importance of planning ahead and effective time management. What's next for BlocScam We plan to add more features and enhance the user interface to make it more pleasant and user-friendly. Built With dart firebase flutter Try it out GitHub Repo Created by Backend and database GERARDJM018 Matthew Ella Yovita Suwibowo wjacobw Wijaya Cathlin Theophilus"
      }
    ]
  },
  {
    "file_path": "./devposts/bobabae-2xk7ze.html",
    "project_id": "bobabae-2xk7ze",
    "title": "BobaBae",
    "tagline": "Find yourself your Boba Bae",
    "hackathon": "",
    "built_with": [
      "clerk",
      "firebase",
      "flask",
      "google-maps",
      "materialui",
      "nextjs",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/897/164/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Thousands of new college students are new to the world of Boba. We want to help connect them to new flavors and friends. What it does Social platform for students to swipe on boba flavors and meet up with friends of similar tastes. How I built it Front end: NextJS, Material UI\nBack end: Flask, Firebase, Clerk Challenges I ran into Managing user data between two different database services (Firebase and Clerk) Accomplishments that I'm proud of Allowing users to interact with other profiles and locations in real time What I learned Don't overcomplicate user data management. It makes everything else harder. What's next for BobaBae Deploy the website so that others can find new boba and friends in real life! Built With clerk firebase flask google-maps materialui nextjs python Try it out GitHub Repo Created by Rian Corcino i code stuff for fun Ethan Santos Aurelia Sindhu 아이스 아메리카노 ☕️ Aurelisa Juan Vouloir, c'est pouvoir."
      }
    ]
  },
  {
    "file_path": "./devposts/betreel.html",
    "project_id": "betreel",
    "title": "BeTreel",
    "tagline": "BeReel - but for it prompts you to take a photo of doing an environmentally friendly task (ex: picking up garbage)",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Highest overall score Created by Kieran Hulsman Dhyan Patel Daniel Larkin Nihal Menon",
      "The GoldenHack 4.0WinnerHighest overall score",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/239/417/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration BeReal What it does Once a day, users get a notification that it's time to post their BeTreel. There'll be a daily task each user has to complete (ex: picking up a piece of garbage), and once they post they'll be able to see how their friends completed the challenge. How we built it Node.js, CSS, HTML Challenges we ran into Connecting the front-end and back-end Accomplishments that we're proud of We got the logo working - shoutout official.larkin. Seriously though, this was our first hackathon as a team, and we're proud we built something we could submit. What we learned We learned that integrating the different parts of a problem is hard, and it's okay to get stuck. When it happens, it's important to not be too hard on yourself, and work as a team to work the problem. What's next for BeTreel We'd like to make it a mobile app. Built With css html node.js Try it out GitHub Repo Submitted to The GoldenHack 4.0 Winner Highest overall score Created by Kieran Hulsman Dhyan Patel Daniel Larkin Nihal Menon"
      }
    ]
  },
  {
    "file_path": "./devposts/block-bazar.html",
    "project_id": "block-bazar",
    "title": "Block Bazar",
    "tagline": "Buy and Sell through Blockchain",
    "hackathon": "",
    "built_with": [
      "next.js",
      "react",
      "soroban",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Soroban Created by Adam Stolnits 4th Year Computer Science @ York University Tanish S J",
      "NewHacks 2023WinnerBest Use of Soroban",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/657/565/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Block Bazar Logo Inspiration 🧠: The inspiration behind Block Bazar emerged from this dire need to redefine the way we buy and sell online. What it does 🤔: Block Bazar operates as a decentralized and autonomous organization governed by smart contracts and consensus mechanisms within a blockchain network. Our platform supports crytpo payments and enrichment activities, where users actively give ratings to products. Block Bazar rewards users with micropayments in cryptocurrency. These incentives are a testament to our commitment to fair compensation and cashless decentralized blockchain economy. Product integrity is at the core of Block Bazar. Our community actively engages in product validation and quality assessment. This could include tasks like community feedback and ratings. By empowering every member to be a vigilant guardian of product integrity, we ensure the highest standards of quality. Identify, report, and maintain the purity of our products in the economy. How we built it ⚙️: Block Bazar is a testament to the power of innovative technology. We've harnessed a versatile tech stack that includes Next.js, Tailwind CSS, React, and Soroban. Challenges we ran into ⚠️: As pioneers in this field, we've encountered numerous challenges along the way. From implementing blockchain governance to designing the intricacies of micropayments, every hurdle was an opportunity to innovate and redefine the path forward. Accomplishments that we're proud of 🥇: We're incredibly proud of bringing Block Bazar to life. The dream of a decentralized data utopia is now a reality. Our platform empowers users to be the masters of their data destiny, and our unique approach to micropayments ensures that no valuable contribution goes unrewarded. We're paving the way for a data-sharing revolution. What we learned 📚: This journey has been a profound learning experience. We've delved into the realms of blockchain governance, cryptocurrency micropayments, and data quality control. But, most imp"
      }
    ]
  },
  {
    "file_path": "./devposts/blockify.html",
    "project_id": "blockify",
    "title": "Blockify",
    "tagline": "Blockify is a tool that can cover up labels in diagrams for studying.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "google-cloud-vision",
      "handlebars.js",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/814/823/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Blockify Example Blockify Home Page Blockify Example Blockify Home Page Blockify Example 1 2 3 Inspiration We were inspired to work on this project after speaking with a current medical student, a brother of one of our teammates. He discussed how he needs to study diagrams for his medical school tests. The problem is that to quiz himself on his diagram knowledge, he has to manually cover up the labels by himself or hope that another classmate has already done so. We realized that by using artificial intelligence, we can automatically detect text on diagrams and cover it up. A tool using this technology would help students (medical or not) save time when studying for their exams. This encouraged us to create Blockify. What it does Our project automatically covers up text or labels in diagrams with black boxes. These boxes can be toggled to reveal and hide answers.  This tool allows students to avoid manually covering labels, saving their time when studying for exams. How we built it Express.js was utilized with the Handlebars templating engine to create a dynamic website. We used Google Cloud Vision API to detect bounding boxes of the text in pictures. Through the use of the Canvas API and Vanilla JS, we generated an image with bounding boxes covering text for the perfect study tool. Challenges we ran into Storage and rendering of uploaded images w/o database Templating engine limitations for sending image coordinates & properties from backend to frontend with Express.js Proper alignment of bounding boxes over text Accomplishments that we're proud of Minimalistic and slick frontend Intuitive and user-friendly UX Generating the bounding boxes using the Google Cloud Vision API What we learned Understanding of Express.js components for routing behaviors Understanding of Canvas API for graphics How to use the Google Cloud Vision API for text detection Integrating Node.js libraries with Express.js What's next for Blockify Allowing for PDF & other input file types Adding a"
      }
    ]
  },
  {
    "file_path": "./devposts/boyscout.html",
    "project_id": "boyscout",
    "title": "Boyscout",
    "tagline": "A real social networking page that crosses over for partiful for hacker house events,creates merit badges, allow the creation of merit badges, and uses  the agent to match people together .",
    "hackathon": "",
    "built_with": [
      "python",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/493/836/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 We provied merit badges for events that are created on partiful to be made among hacker house members and shared on partiful and our custom platform for hacker house sites How we built itInspiration The inspiration for Boyscout came from observing the disconnect in hacker house communities. While tech workers and startup founders were flocking to co-living spaces and collaborative environments, there was no dedicated platform to facilitate meaningful connections beyond surface-level networking. We noticed people using fragmented solutions - Partiful for parties, LinkedIn for professional networking, and various group chats for house coordination. The \"boyscout\" ethos - being prepared and helping others - perfectly captured the community spirit we wanted to foster in these spaces where builders live and create together. What it does Boyscout is a social networking platform that bridges the gap between Partiful's event coordination and professional networking for the hacker house community. It uses an intelligent matching agent to connect residents, visitors, and event attendees based on their skills, interests, and current projects. Users can create and RSVP to house events, find potential collaborators for late-night coding sessions, coordinate shared resources, and build lasting connections within the tech community. The platform makes it easy to discover who's working on what, schedule impromptu hackathons, and maintain relationships even after moving between houses.\nHow we built it\nWe built Boyscout using a modern tech stack optimized for real-time interactions and AI-powered matching. The frontend uses React with a mobile-first design inspired by Partiful's Gen Z-friendly aesthetic. Our backend runs on Node.js with WebSocket connections for instant messaging and event updates. The matching agent leverages OpenAI's API to analyze user profiles, project descriptions, and interaction patterns to suggest meaningful connections. We integrated calend"
      }
    ]
  },
  {
    "file_path": "./devposts/blocktrade.html",
    "project_id": "blocktrade",
    "title": "BlockAxis",
    "tagline": "Making stock trading globally accessible using blockchain",
    "hackathon": "",
    "built_with": [
      "adobe-xd",
      "alphavantage-api",
      "css3",
      "express.js",
      "html5",
      "javascript",
      "metamask",
      "mongodb",
      "node.js",
      "react",
      "web3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Blockchain Winner - 50 LINK (Chainlink Cryptocurrency) Winner Judges Pick (25 LINK) Created by Saff",
      "AlphaVHackWinnerBlockchain Winner - 50 LINK (Chainlink Cryptocurrency)WinnerJudges Pick (25 LINK)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/110/716/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 Inspiration A stock market is essentially an accurate representation of the overall economy of a country. With that said, the United States has been the world’s largest economy for the past few decades. Despite the cyclical crashes, the Dow Jones and S&P 500 indices are rising significantly faster than any other indices, making them the most profitable place for investors to park their money. However, investors outside of North America are at a significant disadvantage when it comes to investing in the S&P or DOW. This is primarily due to the high regulations set by their government regarding investing overseas in the foreign markets and investing in general. This regulatory structure causes people to stick to traditional cash, commodities, or real estate as their only form of investment. People in developing countries are discouraged to invest in the stock market due to the high requirements to qualify for a brokerage account. Among the ones who do get to set up a brokerage account, most of them are only allowed to invest in their local emerging markets, which aren’t as profitable as the S&P or DOW. For them to invest overseas, they would have to go through multiple intermediaries which ends up costing them a lot of money in fees and commissions. Other online-based brokerages such as eToro are not as reliable and are often prone to cyber attacks as they have a single point of failure. Hence, we want to solve this problem of making global trading more accessible to everyone. What it does BlockAxis is a blockchain-based hybrid trading platform that enables users around the globe to gain access and trade in the foreign equity markets. It mixes the elements of both centralized and decentralized exchanges and reaps their benefits. Instead of using fiat currency as the medium of stock purchases, it uses stablecoins such as DAI which are primarily designed to maintain its stable price and avoid market volatility "
      }
    ]
  },
  {
    "file_path": "./devposts/bird-box.html",
    "project_id": "bird-box",
    "title": "Bird Box",
    "tagline": "A multiparticipant AR-VR painting experience in which the work is experienced differently from each point of view.",
    "hackathon": "",
    "built_with": [
      "aftereffects",
      "arcore",
      "arfoundation",
      "googlepixel2",
      "googlepixel3",
      "logicpro",
      "maya",
      "microsoftmixedreality",
      "openvr",
      "photon",
      "photoshop",
      "rhino",
      "unity",
      "viu"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best in Art, Media & Entertainment Created by I worked primarily on the experience design and text",
      "Reality Virtually Hackathon at the MIT Media Lab Returns Year 3 January 17 - 21, 2019WinnerBest in Art, Media & Entertainment",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/742/593/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "VR world paint strokes VR Soundcage Cross-Dimensional Experience Sending signals from the real world. VR mirroring AR brush strokes Enter the Bird Box Two participants Sending messages from another dimension VR world real-time scene AR window into the VR world VR world paint strokes VR Soundcage Cross-Dimensional Experience Sending signals from the real world. VR mirroring AR brush strokes Enter the Bird Box Two participants Sending messages from another dimension VR world real-time scene AR window into the VR world VR world paint strokes 1 2 3 4 5 6 7 8 9 10 11 Location, Floor, and Room Building E15, Floor 2, Room 283 Project Summary Bird Box is a multiparticipant AR/VR experience in which one person paints in a VR world, the other person paints in AR-overlaid reality, and both people see transformed versions of each other's art appearing real-time in their own respective spaces. As humans, we each inhabit our own unique reality. We can never experience the rich synaptic context of thoughts, memories, and emotions that define another person's perception of the world. Therefore, even though we often feel or assume that we are communicating our ideas to others with complete clarity, this is almost never true. There will always be transformations and noise in the signal. Bird Box is a metaphor for all the layers of richness that are lost in the communication process. The title is a nod to the homonymous Netflix film, in which – upon viewing the same unknown entity – some people experience enlightenment while others encounter their worst fears. Participants in Bird Box share an audiovisual space in which their experience of each other's actions is largely similar, yet irreconcilably different. The participant in VR is enclosed in a soundcage, creating music with their motions as they paint in the canvas of a surreal virtual world. The participant in AR, who can digitally paint in the real world, can hear the VR participant's music but can never share the act of composi"
      }
    ]
  },
  {
    "file_path": "./devposts/budgetpal-6vmzo9.html",
    "project_id": "budgetpal-6vmzo9",
    "title": "BudgetPal",
    "tagline": "Your personal automated budget tracker that simplifies your finances with receipt-based expense tracking and smart budget calculations.",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "firebase",
      "flask",
      "html",
      "javascript",
      "mongodb",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/461/415/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Dashboard Mockup Mock up of a student using BudgetPal Homepage Mockup Dashboard Mockup Mock up of a student using BudgetPal Homepage Mockup Dashboard Mockup 1 2 3 4 Inspiration As students, we’ve both struggled and seen many of our peers struggle with basic financial literacy. This inspired us to learn more about personal finance and budgeting, and ultimately led to the development of an application that can help students and others in similar situations better manage their money. We believe that financial literacy is a crucial life skill, and we’re passionate about providing accessible resources to help others improve their financial wellness. What it does BudgetPal is your personal finance assistant that helps you manage your money more efficiently with a quick and automated method of tracking expenses. You can easily set a budget that works for you, track your expenses, and see how you're progressing towards your goals. After signing up and setting your budget, you can begin uploading pictures of your receipts. Once a receipt is uploaded, an itemized table and data graphs are populated to help visualize spending. You can also easily change your budget and saving goals to receive a more accurate spending analysis. Whether you're saving for a vacation, paying off debt, or just trying to manage your day-to-day expenses, BudgetPal is here to help. How we built it Our team, consisting of a designer and three developers, began our product development journey with research to better understand our target audience - students. Because we did not have time to conduct user interviews, we relied on secondary research to gain insights. The designer sketched and wireframed pages, which were reviewed with the developers to confirm potential functionality. Once features were confirmed, the designer created mockups, developed a style guide, and made high-fidelity prototypes all in Figma, collaborating closely with the web developer to prioritize our users while remaining within o"
      }
    ]
  },
  {
    "file_path": "./devposts/book-dook.html",
    "project_id": "book-dook",
    "title": "PlainText.ink",
    "tagline": "PlainText.ink is a $10 offline e-ink omnibook tablet powered by GPT-OSS, built for the 4 billion rural and urban poor whom current tech cannot reach.",
    "hackathon": "",
    "built_with": [
      "epub",
      "gguf",
      "gpt-oss",
      "huggingface",
      "llama-cpp-python",
      "llama.cpp",
      "ollama",
      "pdf",
      "pyqt6",
      "python",
      "transformers"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/734/166/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Billions remain unseen by today’s tech — 2.6 billion fully offline as of 2024, with many more urban poor who possess devices but cannot use them for education or civic services. In cities, paperwork stalls access; in rural regions, textbooks are few or nonexistent. PlainText.ink was conceived to bridge both divides — restoring clarity, connection, and learning to the 4 billion people left behind. ( ITU Facts & Figures 2024 ) What it does PlainText.ink is a $10 offline e-ink omnibook tablet powered by open GPT-OSS models. It works entirely offline and offers: Letter Explainer : Converts official letters into a concise TL;DR plus “next steps” checklist. Form Helper : Guided Q&A flow that auto-fills PDFs and produces review notes. Textbook Builder : Overnight generation of custom textbooks by grade, topic, and language. Multilingual support : GPT-OSS is trained on multilingual data; it supports multiple languages out of the box and can be fine-tuned to local ones. ( Codecademy on GPT-OSS multilingual capability ) Alignment with UN Sustainable Development Goals (SDGs) SDG 4: Quality Education — Delivers offline, multilingual educational content to underserved populations. ( sdgs.un.org/goal4 ) SDG 1: No Poverty — Empowers users with literacy, form assistance, and access to vital services. ( sdgs.un.org/goal1 ) SDG 10: Reduced Inequalities — Affordable and accessible design directly combats educational and digital inequality. ( sdgs.un.org/goal10 ) SDG 17: Partnerships for the Goals — Scaling will involve partnerships with NGOs, governments, and local organizations. ( sdgs.un.org/goal17 ) How we built it Demo backend: Ollama — fast for prototyping. Production backend: llama.cpp with GGUF quantization for resource-efficient deployment. The system architecture allows swapping inference engines via environment variable. Core logic (Letter, Form, Textbook) is implemented in clean CLI tools plus a minimal desktop UI using PyQt6. Uses open-source libraries fo"
      }
    ]
  },
  {
    "file_path": "./devposts/brainbyte-1tp4my.html",
    "project_id": "brainbyte-1tp4my",
    "title": "BrainByte",
    "tagline": "Imagine a crazy new future: headsets that can detect how you’re feeling, screen for diseases, and more–in real time. Some first steps? Detecting blinks to communicate. All possible with BrainByte.",
    "hackathon": "",
    "built_with": [
      "epocx",
      "google-cloud-(&-firebase)",
      "python",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/632/672/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "A snippet of the Python code in our back-end Adam and Nureldin testing out the headset! A map of our stack Stephen, Joy, and Adam hard at work! Adam and Stephen debugging! Stephen and Nureldin working out some kinks in the system! An example EEG graph of three groups of a series of three blinks A snippet of the Python code in our back-end Adam and Nureldin testing out the headset! A map of our stack Stephen, Joy, and Adam hard at work! Adam and Stephen debugging! Stephen and Nureldin working out some kinks in the system! An example EEG graph of three groups of a series of three blinks A snippet of the Python code in our back-end 1 2 3 4 5 6 7 Our inspiration Our team came together on Friday night with two things in common: a strong drive to build something that could potentially transform the future for the better, and a shared passion for the intersection of technology and neuroscience. We’ve all seen sci-fi movies like Ready Player One where the future is lived purely through the internet using VR or AR headsets, and they often portray a dim view of what’s in store for us. We believed that a better future was possible–that headsets and data collection may be inevitable, but what we do with that data is up to us, the next generation, to decide. Our fate rests in our hands. It’s hard to pin down any one source of inspiration, but one that made the biggest impact is The Diving Bell and the Butterfly by journalist Jean-Dominique Bauby, a memoir about his life before and after a massive stroke left him with locked-in syndrome. Locked-in syndrome is a condition where almost all voluntary muscles in a patient are paralyzed except for a few muscles that control eye blinking. The book is a deep foray into his feelings of despair, longing, and fleeting joy that come with being isolated inside a body that can comprehend everything around him but can’t interact with it. He wrote the entire book solely by blinking his left eyelid, taking over 200,000 blinks and more than one t"
      }
    ]
  },
  {
    "file_path": "./devposts/braille-interpreter.html",
    "project_id": "braille-interpreter",
    "title": "SightRead",
    "tagline": "An app to educate the world about braille and change the way the world interacts with the visually impaired.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "flask",
      "python",
      "swift",
      "swiftui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/345/598/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "💡 Inspiration 💡 In many countries around the world, braille is the preferred method of delivering information for people who are blind or partially sighted. Hence, those who aren't fluent in braille are missing out on the important dialogues and experiences from such groups who communicate in braille. This app aims to bridge that gap and increase global fluency in braille, leading to more accessible tools and resources being developed for the blind community. ⚙️ What it does ⚙️ Users can translate text into braille to communicate with the blind and partially sighted. Users can also take photos of braille and translate it into text. Lastly, users can take photos of braille and translate that into spoken English text (i.e. braille-to-speech). All of these features allow users to learn and practice braille, improving their braille literacy and thus strengthening their connectedness with the blind and partially sighted. 🏗️ How we built it 🏗️ We used Swift and SwiftUI to build a user-friendly frontend experience--i.e. a clean, minimal layout with high-contrasting colours so the partially sighted can navigate the app with ease. The back end is built using Python and uses OpenCV to identify the text and braille within images. 🚩 Challenges we ran into On the frontend side, one of the major challenges we encountered was making HTTP POST requests to our backend using SWIFT. Unlike certain languages such as JavaScript, the process of calling our backend endpoints on SWIFT proved to be quite time-consuming and required a significant amount of setup.\nIn addition, when working on the backend portion of the app, we encountered several difficulties. One of the biggest challenges we faced was finding APIs for braille to text translation, which was a key feature of our app. Unfortunately, braille is not a popular topic of research and development, and as a result, we found it challenging to locate suitable APIs. Furthermore, we discovered that most of the available APIs were built us"
      }
    ]
  },
  {
    "file_path": "./devposts/becturio.html",
    "project_id": "becturio",
    "title": "Edufile",
    "tagline": "Allowing students to upload files and share with other students around the world",
    "hackathon": "",
    "built_with": [
      "cloudinary",
      "figma",
      "nextjs",
      "postgresql",
      "prisma",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/518/542/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Upload Homepage Preview Upload Homepage Preview Upload 1 2 3 4 Inspiration Whether it's a colege student or highschool student, we've seen either of them struggling to find the appropriate notes for their topics online. 2023, Having so many resources online, it becomes difficult to find notes quickly and easily. What it does Edufiles give users an easy-to-use and clean user interface for viewing notes and pdfs posted by other students online as well as allow the student to contribute their own documents. Through this, we hope to bolster collaboration with students worldwide as they can work together to learn difficult concepts as well as share valuable information with students who might need it. How we built it We built Edufile primarily through Next JS as we could leverage its frontend and backend capabilities. We also used typescript in order to have a more efficient application that also does proper type checking. Also, we used Vercel database connections and storage to upload, view, and delete files easily and quickly. Lastly, for designing our app, we used Figma for its robust designing tools and popularity. Challenges we ran into Being Overseas, We ran into timezone differences which made it difficult for us to communicate at adequate times. Making it a slower development environment. We ran into multiple technical challenges with the latest module updates and auth bugs and being able to upload notes. Accomplishments that we're proud of We came together and worked as a team to solve our auth problem we pulled a all-nighter until around 5 am and did some pair programming to guide ourselves through the issue as a team. What we learned Hackathon isn't just where we come to win, it's where we come to learn and grow. Attending LearnHacks, We learned how to tackle problems with patience rather than continuously draining efforts to solve the problem, Doing smart work instead of hard work and Never giving up until the very end. What's next for Edufile Next, we plan t"
      }
    ]
  },
  {
    "file_path": "./devposts/bread-and-butter-ud9r1v.html",
    "project_id": "bread-and-butter-ud9r1v",
    "title": "Bread and Butter",
    "tagline": "Helping Restaurants get the Bread as Easy and Smooth as Butter",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "css3",
      "flask",
      "google-cloud",
      "html5",
      "javascript",
      "python",
      "sass",
      "sql-alchemy",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Epsilon HacksWinnerHyperX Alloy Origins",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/131/061/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Restaurant Recommender Main Register Map Choose Restaurant List Place Order Checkout Restaurant POV Restaurant Recommender Main Register Map Choose Restaurant List Place Order Checkout Restaurant POV Restaurant Recommender 1 2 3 4 5 6 7 8 9 10 Inspiration We noticed that many of our favorite restaurants (such as Sweet Tomatoes) could not continue to survive in this grueling COVID-19 economy, which has caused almost every restaurant to shut down and lose major business. We wanted to help! So, we created a platform where users and restaurants can collaborate to not only support restaurants but also create a pathway for support towards charities, helping the socioeconomically disadvantaged. What it does Using Bread and Butter, users are able to create posts, invite friends, and make orders at their favorite restaurants, knowing that they will be supporting charities as well because every time a purchase is made, a certain designated amount goes to their selected charities for social causes or to help business owners. Users can even take the app on the go and analyze receipts and different transactions which will directly support various charities in their community. Furthermore, we have a restaurant recommender page built in where users can enter the type of restaurant they want to go to (ex: I want to go to a restaurant with good food) and it will show them all of the restaurants in their area which match this description. From the restaurant's side of things, the restaurants can see the statistics about how many orders have been placed, total sales and total amount of money raised. How we built it Our team used a variety of tools and frameworks to build Bread and Butter. We built our front end, which is the dynamic website that serves as a tool for restaurants and users to communicate with our app, in Flask, Python and Bootstrap (HTML, CSS, JavaScript and SASS). As for our backend, we used various APIs such as the stripe API for the checkout gateway, Google Cloud Vis"
      }
    ]
  },
  {
    "file_path": "./devposts/bouji.html",
    "project_id": "bouji",
    "title": "Bouji",
    "tagline": "Live your life boujee with bouji!",
    "hackathon": "",
    "built_with": [
      "bluecart",
      "core-data",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/362/681/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Rooms Available for Rent Formal Clothing Put something up for rent Rooms Available for Rent Formal Clothing Put something up for rent Rooms Available for Rent 1 2 3 4 Inspiration The idea for Bouji came to us when when we attended the career fairs at TAMU during the beginning of the semester. We noticed that high-profile events, such as career fairs, were a common occurrence at TAMU, necessitating the need for proper attire, often on a short notice. However, buying expensive clothing, including but not limited to suits, ties, and dress shoes, and more, is often a long term economic investment that not everyone is ready for. Instead, we thought it would be ideal if a student could rent a suit, or dress shoes, or a tie for days at a time, since those items aren't worn daily my many people. As a result, we came up with Bouji. What it does Bouji is a platform on which students can both rent their clothes to other students and rent from other students. As a consequence of this, we realized that renting need not be limited to clothes, so we also decided to add two other sections to Bouji. Of the three sections, the first section is exclusively dedicated to formal attire, such as pansuits, suits, dress shoes, and ties. The second section is dedicated to renting textbooks, most likely a semester at a time, as we realized that textbooks, much like formal clothing, aren't used very frequently in the long term. Finally, we also integrated a section of the app where students can rent out their room for days at a time. How we built it Bouji was built using swift and core data in Xcode. It utilizes an API to simulate data in order to provide an accurate representation of what the marketplace would look like. Challenges we ran into We had difficulties with positioning the views within Bouji so that a keyboard would not interfere with them. For example, on the screen that users post something for rent, the keyboard initially covered up the textfields that were necessary to complete"
      }
    ]
  },
  {
    "file_path": "./devposts/buddy-better-studdy.html",
    "project_id": "buddy-better-studdy",
    "title": "Buddy Better Studdy",
    "tagline": "Buddy Better Study was a project designed to maximize your productivity while studying by tracking usage of sites you have \"blacklisted\", with your usage determining your punishments.",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "javascript",
      "json"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "LateNightHacksWinnerBest Productivity Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/994/902/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "An example of a blacklisted website when it is opened The main menu! The area where you input the link you want blacklisted An example of a blacklisted website when it is opened An example of a blacklisted website when it is opened The main menu! The area where you input the link you want blacklisted An example of a blacklisted website when it is opened An example of a blacklisted website when it is opened 1 2 3 4 5 Inspiration Our inspiration were the exams and final performance tasks that are coming up. At this point of time in the semester, we knew we had to step up our game, which means ABSOLUTELY NO distractions. That inspired us to make an application for the other students out there just like us, who need to lock in and finish off their semester strong. What it does Our application takes in what sites you have deemed as \"blacklisted\". This means that those are sites you wish to refrain from using during your study session. While your study session is running, our application will track when you visit those \"blacklisted\" sites, and based on the amount of times you have visited, the application will give you punishments. This should discourage you from visiting those sites during the time you are supposed to lock in and study hard. How we built it We built this project using a chrome extension maker, which allows our popup.html to be displayed. The code for this project was made using HTML, CSS(these were for the popup.html), JS, and json(these were used mainly for the tracking of the user visiting \"blacklisted\" sites). Challenges we ran into One of the challenges we ran into was figuring out how we were going to be able to track when the user accesses a blacklisted site. It was extremely difficult doing it with python, which is why we ended up trying it with JavaScript. Accomplishments that we're proud of An accomplishment that we are proud of is being able to carry through with our plans and goals without sacrificing our schoolwork. Our time management was ex"
      }
    ]
  },
  {
    "file_path": "./devposts/bit-16.html",
    "project_id": "bit-16",
    "title": "ReconPi",
    "tagline": "Construct a facial and voice recognition device.",
    "hackathon": "",
    "built_with": [
      "cv2",
      "python",
      "raspberry-pi",
      "visual-studio",
      "xml"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Reconpi is a fully portable device that will take privacy and security to the next level. Perfect for adding an extra layer of security; Reconpi, will recognize your face and your voice and used it as an extra security feature to give the owner access to devices/programs that required the specialized device. This product is exceptionally made for the individual/company, who needs more than double factor authentication. How it was made We used Raspberry Pi as the main computer, a built-in camera, and a microphone. We were inspired by OpenCV free source facial recognition software (Python), and Google Cloud voice recognition free source software (Python). Our prototype is put together in a portable box (wood), in the future, we hope to make it waterproof, dust and heat resistant, while also keeping it light and portable. Who can benefit:\nSecurity Services with highly classified information in their devices, thanks to Reconpi, the secrets of the country are secured. Companies that need to keep their information extra safe. Hopefully, no one can steal your idea for the next bitcoin. Anyone who thinks the government is watching them and needs an offline device to access their devices. Benefits This is an offline device, which only you will have access too while physically having it. You could add more than one database of faces, which can have different levels of user access to your protected programs; this adds an extra layer of security. Challenges we faced This was our first time working on a project with hardware. Our microphone was not working, which means that we were not able to test our open source software: we were unable to find another working microphone. Our camera needs to be upgraded, the pixel quality is low, which means that the facial recognition software runs into some issues, which are not visible while the program was being tested in a higher quality camera. Internet challenges: Harvard internet slowed us down a bit. Future work We need to"
      }
    ]
  },
  {
    "file_path": "./devposts/browserooms.html",
    "project_id": "browserooms",
    "title": "BrowseRooms",
    "tagline": "Browser Rooms is a Chrome extension and web app that transforms solitary browsing into a shared experience. It connects users in real time based on interests, enabling inclusive and peaceful community",
    "hackathon": "",
    "built_with": [
      "boring-avatar",
      "daisyui",
      "express.js",
      "flask",
      "mongodb",
      "nextjs",
      "openai",
      "pineconedb",
      "python",
      "scikit-learn",
      "shadcn",
      "tailwindcss",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In today’s digital age, browsing the internet is often an isolated experience. We wanted to create a space where people could connect, communicate, and collaborate based on shared interests – all while fostering inclusivity and peace. Inspired by the need for meaningful digital interaction and safe spaces for diverse communities, Browser Rooms was born. What it does Our goal is to help users find common ground, share knowledge, and promote peaceful discourse, even on complex topics. How we built it We developed Browser Rooms as a Chrome extension and web application, enabling real-time connections among users. Using MongoDB Cloud for data management and analysis, we designed a dashboard where users can view their browsing stats, track time spent, and analyze tab activity by category. Our AI tools utilize prompt engineering and LLM models, including the scikit-learn library, for real-time analysis of community messaging. To enhance user experience, we implemented features like light/dark themes and color-blind support for accessibility. Challenges we ran into One of the biggest challenges was ensuring sensitive and inclusive communication. Implementing pronoun correction, cultural context prompts, and filtering mechanisms required detailed attention to user behavior and preferences. Another challenge was designing a smooth real-time matching system, ensuring that users connect based on genuine interests without compromising privacy. Built With boring-avatar daisyui express.js flask mongodb nextjs openai pineconedb python scikit-learn shadcn tailwindcss typescript vercel Try it out GitHub Repo GitHub Repo GitHub Repo Submitted to Hack the Change 2024 Created by Satyam Singh Sathyajit Loganathan Kostiantyn Ilnytskyi Kapeesh Kaul KhoiPhNguyen Nguyen"
      }
    ]
  },
  {
    "file_path": "./devposts/boredboard.html",
    "project_id": "boredboard",
    "title": "boredboard",
    "tagline": "A personalized learning platform for high school students",
    "hackathon": "",
    "built_with": [
      "adobe-after-effects",
      "figma",
      "partyrock"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/806/357/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Side by side comparison of both the platforms Interactive learning module features Scholarship opportunities feature Tutoring locator feature Volunteer initiatives feature Side by side comparison of both the platforms Interactive learning module features Scholarship opportunities feature Tutoring locator feature Volunteer initiatives feature Side by side comparison of both the platforms 1 2 3 4 5 6 Who are we? We are team of students from CSU Long Beach studying Human Experience Design Interaction . We focused on designing platforms for real people and their needs leveraging PartyRock as a platform to create use cases for this technology. Inspiration BoredBoard is inspired from a need for a comprehensive and personalized platform for high school students. We took inspiration from user-friendly interfaces like dashboards, social media platforms and newsletters. What it does BoredBoard is an AI-powered web application crafted to change the high school learning experience. Tailored specifically for students, \"BoredBoard\" offers a dynamic and personalized dashboard that seamlessly integrates curated learning materials, scholarship opportunities, volunteer initiatives, and tutor location services, all accessible anytime, anywhere. Key Features include: 4 interactive Learning modules ( gamified quizzes, quick glance materials, recent innovation news ) Scholarship opportunities Volunteer Initiatives Tutoring locator How we built it We built BoredBoard using PartyRock, designed the dashboard on Figma, and edited our promo video on Adobe After Effects. We utilized the double diamond design methodology for implementation of this project. Challenges we ran into Our main challenge was integrating image generation. After unsatisfactory results during our first iteration, we conducted usability testing and opted for a minimal dashboard design without overwhelming elements. Accomplishments that we're proud of Designing a personalized dashboard, interactive learning modules, and in"
      }
    ]
  },
  {
    "file_path": "./devposts/betteraid.html",
    "project_id": "betteraid",
    "title": "BetterAid",
    "tagline": "A discrete and accessible app for young people to receive mental health treatment, free of charge.",
    "hackathon": "",
    "built_with": [
      "figma",
      "plotly",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "and 5 is the worst vs 1 being the worst and 5 being the best"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/803/351/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Composite visual representation of stress levels across age groups according to data from Statistics Canada. Composite visual representation of stress levels across age groups according to data from Statistics Canada. Composite visual representation of stress levels across age groups according to data from Statistics Canada. 1 2 Inspiration COVID-19 has undoubtedly impacted the mental health of many, and there has been an increase in discourse over mental wellness since the beginning of the pandemic, as people experienced the isolation of quarantine. We wanted to further investigate the changes in mental health, specifically anxiety, across different age groups during the COVID-19 pandemic, and provide them with the help they need. Through our research using a dataset from Statistics Canada, we used Python and plotly to create graphs showing anxiety trends in the population, which gave us a rough projection of the stress levels in different age groups of Canadians, with the group 15-24 being the most stressed and a mostly linear downward trend as we moved up the age groups. We wanted to tackle this issue and bring support to those who need it most. Our aim is to create a tool for young people to connect with government provided mental health professionals without any potential barriers. This interface also enables the government to collect more data surrounding this issue to improve their mental health resources. To reach people in our target audience, we decided that an app would be the most effective medium to connect young people with mental health guidance. However, as members of this age group, we understand that there could be situations where parents or guardians are unsupportive or dismissive about mental health issues and therefore these young people cannot access or afford any form of mental health support. This inspired us to create a solution -a discrete and accessible way for young people to receive mental health treatment, free of charge. What it does "
      }
    ]
  },
  {
    "file_path": "./devposts/bridge-t0oyer.html",
    "project_id": "bridge-t0oyer",
    "title": "Bridge",
    "tagline": "A Spotify-to-Apple playlist port!",
    "hackathon": "",
    "built_with": [
      "apple-music-api",
      "blender",
      "figma",
      "gpt-4-mini-api",
      "next.js",
      "procreate",
      "react",
      "spotify",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/115/521/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Recommender model interface Login page Main page Landing Page Recommender model interface Login page Main page Landing Page Recommender model interface 1 2 3 4 Inspiration Have you ever wanted to share your music tastes with your friends, but they only use Spotify and you have Apple Music? Bridge connects people across music platforms and enables you to share playlists (game cartridges in Bridge) with your friends even if you don't use the same platform. How we built it We used Next.js, Tailwind CSS, and React to build the web app. We used the Spotify and Apple Music APIs to connect and convert playlists across the platforms. We also used OpenAI's API to generate recommendations based on a given prompt. All of the frontend was planned and designed on Figma, and the assets were created on Procreate and Blender. Challenges we ran into Apple Music API was very difficult to use and did not have a lot of documentation for the tasks we wanted to implement. Getting the Apple Music API to connect and authenticate was also very time-consuming. Accomplishments that we're proud of We implemented a recommendation model that's able to take a user's emotions/entered prompt and generate a playlist based on that input. It can gauge the \"vibe\" of a user's existing playlists and recommend songs that the user would enjoy. Additionally, it can take any prompt, such as nouns, phrases, and descriptions, and expands the user's music library through recommended songs. What's next for Bridge Bridge currently lets Spotify users create playlists for their friends who use Apple Music. We hope to implement a 'blend' feature, which will allow users to create playlist mashups with friends, across both platforms. We also plan to look into expanding the conversion feature to other platforms like YouTube Music. Built With apple-music-api blender figma gpt-4-mini-api next.js procreate react spotify tailwind Try it out GitHub Repo Submitted to HackTX 2024 Created by Michelle Duru Harshitha Marepally K"
      }
    ]
  },
  {
    "file_path": "./devposts/boltinator.html",
    "project_id": "boltinator",
    "title": "Re-Bolt",
    "tagline": "Re-bolt is a compact and efficient solution that instantly sorts any pile of bolts. It uses a built-in camera to track bolts on a conveyor belt and organize them by length into 6 unique compartments.",
    "hackathon": "",
    "built_with": [
      "3dprinting",
      "arduino",
      "intellij-idea",
      "java",
      "opencv",
      "prusa",
      "solidworks"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Place Created by Developed all the Vision and computer side code responsible for categorizing",
      "JAMHacks 3WinnerFirst Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/807/769/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration From experience in working in a shop environment, we noticed that bolts would always be left lying around and eventually thrown out or lost. We thought that the best way to fix this would be to create a device that could take in a pile of bolts and sort them all into unique compartments so that they could be returned to their appropriate organizers. What it does Re-bolt takes a bunch of assorted bolts and sorts them by length. How we built it We first 3D modeled Re-Bolt in Solidworks, then 3D printed the parts using the models. While printing the parts, we used the OpenCV library to process the camera feed into contours of bolts on the conveyor belt. Once the visual processing and 3D printing was completed, we assembled the machine, wired it and programmed electronic components like the motors and encoders to automate the system. Challenges we ran into The toughest obstacle that we encountered was formatting the video taken from the phone to be compatible with the OpenCV library. Accomplishments that we're proud of We are most proud of the simplicity of the design as well as consistency of bolt measurement. What we learned We learned about how to control cameras over internet and video formatting. What's next for Re-Bolt Rebolt has several more potential iterations and improvement, here are a few: Feed from large container Bolt width and thread detection More rapid vision processing Active \"flicker\" mechanism to flick bolts into containers Built With 3dprinting arduino intellij-idea java opencv prusa solidworks Try it out GitHub Repo Submitted to JAMHacks 3 Winner First Place Created by Developed all the Vision and computer side code responsible for categorizing bolts and providing a position to the Arduino. Also printed various parts for the project and helped to develop the idea. Ethan Childerhose Helped design, 3d print, assemble and wire the mechanism. Also worked on Arduino control for motors and sensors. Ivan Yevenko I worked on the conveye"
      }
    ]
  },
  {
    "file_path": "./devposts/brutalitywatch.html",
    "project_id": "brutalitywatch",
    "title": "Peace Keeper",
    "tagline": "Stopping police brutality with AI-powered analysis and real-time help.",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-maps",
      "python",
      "react",
      "react-speech-skit",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "NSBE Hacks 2023Winner$3,000 Cohere credits",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/409/236/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Logo Logo 1 2 Inspiration A desire to harness the power of technology to address a critical issue that affects Black communities worldwide: police brutality. The goal of this system would be to alert people and raise awareness about incidents of police brutality and potentially hidden racism across the globe. We strive to create a safer and more just world and end police brutality. What it does Our website uses Google maps to automatically track and record incidents of police brutality with their location, date and description, making it easier to identify and expose these incidents as they occur. We also added a feature where the user can press a button to start recording the conversation between themself and the officer in case documentation is needed. If an emergency is detected in the recorded conversation, we’ve included a real-time “help” feature that instantly alerts authorities that empowers users to receive assistance. It also integrates an AI-powered conversation analysis system that analyzes the recorded interaction between the police officer and the victim. By analyzing it, the application can detect patterns of misconduct and microaggressions which could have swayed the officer’s decision to press a particular charge. How we built it For the backend, we used Python, Flask and SQL. We trained our LLM using highly effective and extensive input-output pairs to increase its accuracy when detecting racism in text. We also used the classify function to categorize the text into 3 categories: ‘Neutral’, ‘Intentionally racist’ and ‘Unintentionally racist’. Every time a marker is added, its location and date are generated by the backend and added to the database of markers, which can then be displayed by the Google Maps API on the Frontend. For the frontend, we used React. The speech-to-text to record the conversation was done using React-Speech-Kit. React was also used to display the map with all of the markers and show real-time updates and display the his"
      }
    ]
  },
  {
    "file_path": "./devposts/brevify-video-summarizer.html",
    "project_id": "brevify-video-summarizer",
    "title": "Brevify: Video Summarizer",
    "tagline": "Don’t have time to watch the whole video? Brevify can create a text summary of your video, so you can get the information easily and efficiently. Learn key information & concepts instantly!",
    "hackathon": "",
    "built_with": [
      "ai",
      "ajax",
      "assemblyai",
      "canva",
      "css",
      "express.js",
      "html",
      "javascript",
      "jquery",
      "node.js",
      "replit",
      "tailwind",
      "tailwindcss",
      "web"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/206/146/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "AI-Generated Video Summaries and Chapters Data Flow Diagram About Page User Upload (any Video of Any Length and Format) Generated Video Transcription AI-Generated Video Summaries and Chapters Data Flow Diagram About Page User Upload (any Video of Any Length and Format) Generated Video Transcription AI-Generated Video Summaries and Chapters 1 2 3 4 5 6 Inspiration Videos on YouTube are getting longer and longer over time - back then, youtubers get straight to the point but now they feel a need to have long intros, outros, and ad breaks, which keep the viewer from getting the information they want. In addition, as our lives are getting busier and busier in this modern, technological world, we simply don’t have the time to watch a full YouTube video for homework or for studying to understand the material. As Machine Learning enthusiasts, we wanted to find and use an AI or ML model to help solve this problem. Audience, Impact, Applications Our audience involves both student learners (K-12 and college) and adult learners, as they can turn teacher lectures and educational videos into shortened text summary notes to study from. We also have use cases for hearing impaired learners, as they can easily sift through information generated through our text transcriptions, and for court case recordings, as recorded court videos can be transformed into legal documents for legal purposes. What it does Brevify is a web app that ensures that all users, including students and adult learners alike, can always have a platform to enhance their learning by summarizing video content in a quick and convenient way. The user can upload a video file of their choosing, and AI algorithms will then transcribe and summarize it into easily digestible sections. Brevify can be used at any time, every day. Brevify has 3 pages: the home page/demo page, about page, and contact page. The Home page is where the user can try out our video summarizer. The About page describes the motivation behind us creati"
      }
    ]
  },
  {
    "file_path": "./devposts/boat-surfers.html",
    "project_id": "boat-surfers",
    "title": "Boat Surfers",
    "tagline": "Subway surf has been popular for a long time. But, it's time for something else to shine. Boat Surfers has spectacular graphics, with state of the art servers.",
    "hackathon": "",
    "built_with": [
      "blender",
      "c#",
      "google",
      "unity",
      "youtube"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Subway Surfers What it does A fun alternative to Subway Surf How we built it By using Unity, YouTube, unity documentation, and blender. Challenges we ran into, We ran into a lot of bugs, such as the character passing through the sharks. Another hard part was figuring out how to move the character, since standard arrow key methods wouldn't have worked. Accomplishments that we're proud of, A great game alternative to Subway Surf What we learned That making a successful game with one night and no sleep is hard. What's next for Boat Surfers We will be improving it further, with powerups and slowly put in ads as it gets progressively popular. Then release it globally. Built With blender c# google unity youtube Try it out GitHub Repo Submitted to Los Altos Hacks VII Created by Tejas Patel Sachit Gonur Adi Anand"
      }
    ]
  },
  {
    "file_path": "./devposts/calculatia.html",
    "project_id": "calculatia",
    "title": "calculatia",
    "tagline": "Simple website to automatically calculate using common formulas (quadratic, kinematic, etc.). All the user has to do is input values.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/569/045/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Quadratic formula page (only one so far) Quadratic formula page (only one so far) Quadratic formula page (only one so far) 1 2 Inspiration I'm a student and it's often annoying that I have to go through the arduous process of doing the entire quadratic formula or any other type of formula for a small piece of information I need to solve the overarching problem while I'm doing homework or an assignment. I wanted a faster way to use the formulas I already knew how to use so I decided to automate it. What it does User gives values based on what they need from the formula (solve for x, solve for final velocity, etc.) Website uses HTML to calculate the value Website returns value, i.e. the answer to the formula How we built it repl.it <3 (and netlify) Challenges we ran into To make it short, outside distractions. Also I wanted to make sure the code was as efficient and coherent as possible was a challenge. Accomplishments that we're proud of The colour-changing background! And putting in a Spotify playlist for the first time! Really simple but very cool feature imo. What we learned I learned about how to use forms and variables in HTML and JS, and a lot more about CSS than I expected. What's next for calculatia Develop it to support more formulas. Worst-case scenario it'll just be a bookmark on my browser to help me out with math homework. Also, make it look better Built With css html javascript Try it out frosty-mahavira-b68823.netlify.app Submitted to Hydrangea Hacks Created by Director, producer, manager, and employee. Iman Umair-Qaiser UWaterloo CE '26"
      }
    ]
  },
  {
    "file_path": "./devposts/bytesize.html",
    "project_id": "bytesize",
    "title": "ByteSize",
    "tagline": "Redefining video storage.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "flask",
      "javascript",
      "nextjs",
      "opencv",
      "python",
      "pytorch",
      "react",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/257/043/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GIF The uncompressed video with color inference Website Landing Page GIF The original video GIF The compressed, asciified video GIF The uncompressed grayscale video GIF The uncompressed video with color inference Website Landing Page GIF The original video GIF The compressed, asciified video GIF The uncompressed grayscale video GIF The uncompressed video with color inference 1 2 3 4 5 Inspiration We understand that storage space is a huge concern in the world. For the approximately four billion people with low-bandwidth connections, it is difficult to send large video files in a small amount of time. We wanted to provide a novel, yet efficient solution for compressing videos. What it does Submit a video file Converts it to ASCII text using Computer Vision with OpenCV You can view the compressed ASCII file as a video Submit a ByteSize’d text file Converts it back to mp4 video using Machine Learning with PyTorch Can re-add color to images (from absolutely zero color data in the text) In the end, our compression algorithm halves the size of an equivalent .MP4 file. How we built it Front-end React Next.js TailwindCSS Back-end Python Flask for API AWS S3 Machine Learning Python Torch OpenCV NumPy Challenges we ran into Each of us have fairly distinct Computer Science skill sets which made collaboration fun but challenging at times. Installing python libraries and figuring out how to get Torch and CUDA working was a pain. Connecting the front-end, back-end, and machine learning models together was especially challenging. ML in our model For our ML application, we used a wide variety of sources to achieve the many features in our project. FIrst, we experimented with bicubic interpolation, after generating a pixel file based on ascii encoded brightness in black and white. This allowed a slightly blurry, but less pixelated file to be created. From there we utilized a pretrained SRGAN model in order to create a super resolution version of our model, which is the basis of our "
      }
    ]
  },
  {
    "file_path": "./devposts/bloomberg-embedding-challenge.html",
    "project_id": "bloomberg-embedding-challenge",
    "title": "Bloomberg Embedding Challenge",
    "tagline": "Finding out the article title given the embedding",
    "hackathon": "",
    "built_with": [
      "blood",
      "sweat",
      "tears"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/248/202/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "What is this hot mess? The basic goal of this challenge is to turn the challenge embeddings into actual words that makes sense. We are given sample articles along with their respective embeddings. We are also given sample code to calculate the similarity between two embeddings. Welcome to the Kitchen! We took the sample code and imported pandas to format the .csv files that were provided to us for testing. We first formatted the file reading of the challenge file and both ccn and fed samples to grab their embeddings. We then compared the two sample embeddings with the challenge embeddings. We decided to use cosine similarity and then sorted the output embeddings with the most similar in front. The following code is what we ended up with: from scipy import spatial import pandas as pd import random ## Cosine similarity. def similarity ( a , b ) : return 1 - spatial . distance . cosine ( a , b ) df = pd . read_csv ( 'federal_samples.csv' ) challenge = pd . read_csv ( 'challenge.csv' ) output = pd . DataFrame ( columns = [ 'challenge' , 'sample' , 'similarity' ] ) for i in range ( len ( challenge . index ) ) : max = 0 max_j = 0 embd0 = [ float ( x ) for x in challenge [ 'embeddings' ] [ i ] [ 1 : - 1 ] . split ( \", \" ) ] for j in range ( len ( df . index ) ) : embd1 = [ float ( x ) for x in df [ 'embeddings' ] [ j ] [ 1 : - 1 ] . split ( \", \" ) ] if ( similarity ( embd0 , embd1 ) > max ) : max = similarity ( embd0 , embd1 ) max_j = j # print(f'Challenge: {i} to Sample: {j}     {similarity(embd0, embd1)}') output . loc [ len ( output . index ) ] = [ i , j , similarity ( embd0 , embd1 ) ] print ( f 'Max for #{i} is sample: {max_j} with {max}\\ntext: {df[\"text\"][max_j]}\\n\\n') output = output . sort_values ( by = 'challenge' ) output = output . sort_values ( by = 'similarity' , ascending = False ) output . to_csv ( 'out2.csv' ) The idea is basically compare the challenge embedding with every embedding in the given sample and spitting out the samples with the highest similari"
      }
    ]
  },
  {
    "file_path": "./devposts/bullitin.html",
    "project_id": "bullitin",
    "title": "Bullitin",
    "tagline": "Bulletin is a community bulletin board for upcoming events",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/499/817/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Logo Logo 1 2 Inspiration In light of the pandemic, we decided an application that is rooted in community and people would be very useful, especially given that social interaction is severely limited. We believe our idea will allow student/workers/families to destress by getting involved with their community What it does This web application displays important events that occur in the community with relevant information for the user to see and interact with. Users are also able to propose community events by filling the form in the \"Add an Event\" webpage. Proposed events will get stored in a separate database, where the admin will have to approve of the event before being shown in the \"official\"/public bulletin board (home page) How we built it We used python, in particular, flask for the backend. For the front end portion, we used html5 and css3 to appropriately style the website with a particular visual standard in mind. We also used DateTime to help us with the sorting algorithm when we wanted to show the events in a specific order. Challenges we ran into Working with 2 databases was extremely hard especially because we constantly had to sort out the data (for our drop-down filter). We also faced the challenge of using the DateTime module. We needed a method for the user input to be converted into a DateTime object, a method to sort our dataset based on DateTime comparisons, and a method to convert DateTime objects to string for the end-user Accomplishments that we're proud of We were able to make the website fully functional for a user, as well as in a short period of time, being adequate with frameworks that would work in our project. Figuring out how to use DateTime and getting better at OOP by working with classes What we learned We learned to better effectively work as a team together, to help each other out, and to collaborate on figuring out the best ideas to implement and use. We also dabbled with git actions and GitHub in general. We also got better"
      }
    ]
  },
  {
    "file_path": "./devposts/brain-rap.html",
    "project_id": "brain-rap",
    "title": "Brain Rap",
    "tagline": "Brain Rap is Neuro Powered Music - Connect with your audience, Reach your mental flow",
    "hackathon": "",
    "built_with": [
      "emotiv",
      "htc-vive",
      "neurable",
      "neurodata",
      "node.js",
      "php",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Reality Virtually Hackathon at the MIT Media Lab Returns Year 3 January 17 - 21, 2019WinnerPeoples' Choice",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/742/481/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Location: Media Lab Floor: 6th floor Room: Purple Room Development Tools: Unity, Python, PHP, Node.js SDKs:Unity, Neurable APIs: Centiment API outsourced assets: n/A libraries used: numpy, NMe, scikit learm, R, Unity Pre-existing components: Centiment API library(dplyr) #Data manipulation (also included in the tidyverse package)\nlibrary(tidytext) #Text mining\nlibrary(tidyr) #Spread, separate, unite, text mining (also included in the tidyverse package)\nlibrary(widyr) #Use for pairwise correlation Visualizations! library(ggplot2) #Visualizations (also included in the tidyverse package)\nlibrary(ggrepel) # geom_label_repel library(gridExtra) # grid.arrange() for multi-graphs\nlibrary(knitr) #Create nicely formatted output tables\nlibrary(kableExtra) #Create nicely formatted output tables\nlibrary(formattable) #For the color_tile function\nlibrary(circlize) #Visualizations - chord diagram\nrequire(memery) #memes - images with plots\nlibrary(magick) #memes - images with plots (image_read)\nlibrary(yarrr)  #Pirate plot\nlibrary(radarchart) #Visualizations\nlibrary(igraph) #ngram network diagrams\nlibrary(ggraph) #ngram network diagrams library(sentimentr)\nlibrary(DataCombine) Inspiration Brain Rap is inspired by the mis-characterization of Black music artists and interactive musical change. What it does Brain Rap uses EEG, emotion, and live performance to sharpen efficacy and performance skills for musicians. Not only does it enhance the creativity of artists through emotional response, but also the awareness of self on stage. By analyzing data captured with Brain Rap, musicians are able to tailor their performance. Brain rap takes out the guess work of what is working and what is not, leaving more time for the artists to focus on lyrics and performance. The only NAI+ (neuro artificial intelligence) marketing artist development tool on the market. How we built it Brain Rap is built using Emotiv SDK, Unity SDK, Touch Designer SDK, Neurable SDK Challenges we ran into Emotiv SDK didn't"
      }
    ]
  },
  {
    "file_path": "./devposts/cadabra-b0c2oq.html",
    "project_id": "cadabra-b0c2oq",
    "title": "CADabra",
    "tagline": "AI Powered Developer Toolkit for all things CAD!",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "cad",
      "claude",
      "flask",
      "gpt-4o",
      "nlx",
      "node.js",
      "opencv",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/100/168/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Overall Workflow Example Usage NLX Intent Workflow Logo Overall Workflow Example Usage NLX Intent Workflow Logo 1 2 3 4 5 Inspiration Computer Aided Design (CAD) is a technology that is used widely across manufacturing industries, no more so than the healthcare and biomedical industry. As of 2021, nearly 30% of prostheses incorporate CAD technology . However, there are several issues with how CAD projects are developed today: 27.9% of respondents in a survey (341) indicated that collaborating in CAD is extremely difficult 18.2% of respondents in a survey (341) indicated serious issues with file version control 7.1 hours of work a week are lost on average due to CAD Software issues Given the growth of CAD technology in healthcare and its general use in manufacturing industries, we decided to develop an AI-powered collaborative CAD Development tool. What it does CADabra is the first AI-powered CAD Development tool that enables collaboration on 3D files. We boast 5 key features that significantly increase the efficiency of CAD project development. Multimodal 3D model generation : Automatic generation of CAD files based on multimodal user prompt. The user can describe an object they wish to build a CAD file for in 5 different ways : Text Audio Video Image(s) Existing CAD files (.stl format) Automated Conflict Resolution in 3D : Developers can automatically merge files with conflict errors in 3D. This is a direct translation of Github's merge conflict abilities but in 3D! Multiple developers working on the same CAD part can now automatically combine their files with our application. Online CAD File Code Editor : Developers can edit CAD files directly on our app using our 3D code editor, and visualize their rendered 3D models in real time. Real-Time Feedback Loop : Developers can use natural language to iteratively improve the quality of the generated CAD file through a MerlinAI, which is GPT 4o fine-tuned on KCL (CAD Programming Framework). Version Control Tracking "
      }
    ]
  },
  {
    "file_path": "./devposts/calender-website.html",
    "project_id": "calender-website",
    "title": "Calender Pal (Cal-pal)",
    "tagline": "Cal-pal is a website where you can view the calendar by month. We expect to add event features in the future.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Web App with Qoom Created by I came up with the idea and helped with designing the pages and o",
      "Def Hacks Worldwide 3.0WinnerBest Web App with Qoom",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/581/414/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "✨ Inspiration ✨ Qoom was an amazing platform that allowed all of us to work on the website simultaneously no matter where we are in the world. We have half of our teammates from another country and it was awesome that they were able to work on the same thing as we were! This inspired us to create a project that allowed for hands on activity no matter the time. A calendar seemed like a project that we were able to conquer with the amount of days that we had. 💻 What it does 💻 This website allows you to create an account or log in if you have one. Once logged in, it brings you to the specific month you're on with the current day highlighted. You're able to log out once you're done and it will bring you right back into the log in page. 🔧 How we built it 🔧 Everyone worked on something a little different. One person had came up with the idea and adjusted the front end to look cohesive. We have another person that personalized the webpages to his liking as this was a great learning experience. One worked on the functionality of the website and another helped with the calendar functionality as well as auto-populating the days. ⛈ Challenges we ran into ⛈ At first we ran into issues with the date populating into the calendar, however we were able to get around that. Centering our divs and other blocks were a little difficult at first as things were interfering with each other. 🏅 Accomplishments that we're proud of 🏅 We're proud of being able to have a functional website that is able to have users create a username and password that works. 📚 What we learned📚 We learned a lot from each other as well as coding in JavaScript and HTML/CSS. 📅 What's next for Calender Website📅 We would eventually like to add some functionality in regards to being able to save events. Built With css html javascript Try it out spikygrass84.qoom.space GitHub Repo Submitted to Def Hacks Worldwide 3.0 Winner Best Web App with Qoom Created by I came up with the idea and helped with designing the pages and"
      }
    ]
  },
  {
    "file_path": "./devposts/bookmatch.html",
    "project_id": "bookmatch",
    "title": "BookMatch",
    "tagline": "Recommender system using unsupervised learning algorithms to suggest good reads based on your opinion on other books",
    "hackathon": "",
    "built_with": [
      "flask",
      "numpy",
      "pandas",
      "python",
      "react",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "2e prix - 2nd Prize Created by SarinaMashreghi Mashreghi Aly Shariff Jakob  Olivier Ren",
      "BrébeufHx 6.0Winner2e prix - 2nd Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/343/270/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "What it does a website that asks the users opinion about different books and recommends ones suitable to their interests How we built it python (flask for backend, scikit learn for machine learning models), React Challenges we ran into Connecting the backend to frontend, finding suitable algorithms, deploying the website Built With flask numpy pandas python react scikit-learn Try it out bookmatch.netlify.app GitHub Repo GitHub Repo colab.research.google.com Submitted to BrébeufHx 6.0 Winner 2e prix - 2nd Prize Created by SarinaMashreghi Mashreghi Aly Shariff Jakob  Olivier Ren"
      }
    ]
  },
  {
    "file_path": "./devposts/bullrun.html",
    "project_id": "bullrun",
    "title": "Bullrun",
    "tagline": "Unlock the secrets of trading with Bull Run, a groundbreaking game that leverages both generative AI and AI sentiment analysis to teach everyone how to navigate the world of financial markets.",
    "hackathon": "",
    "built_with": [
      "huggingface",
      "mongodb",
      "openai",
      "python",
      "pytorch",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/659/180/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Investing often appears complex and daunting, as the fear of financial losses overshadows the rewards, and the influence of various macroeconomic and governmental factors on stock prices can be confusing. While established financial institutions may seem to have endless resources to trade, individual and casual investors are often left on their own with no guidance at all. Many new investors looking to start are immediately overloaded with a vast amount of terms and \"gurus\" trying to sell their day trading course, and often quit before they can even learn the basics. We want to help these prospective traders by simplifying the basics and making it enjoyable to trade. What it does Our app revolutionizes the world of day trading education. By comparing user input to real-time data, it provides instant feedback, helping users refine their trading strategies. In addition to this, the app keeps users up to date with real-time financial news, market analysis, and stock prices, ensuring that they remain informed about market trends and events crucial for their trading decisions. Our AI simplifies intricate news, offers clear explanations, and empowers users to grasp complex market information. Furthermore, the AI model predicts future stock prices by analyzing current news and collecting sentiment on current news, granting valuable insights for well-informed decisions. With a commitment to making day trading accessible to all, our platform simplifies complexities, enhances comprehension, and fosters an engaging learning experience. How we built it Our development process was a collaborative effort that incorporated the strengths of each of these tools: Python: The backbone of our application, Python served as the primary programming language. It allowed us to build a versatile and efficient system, making the most of the various libraries and frameworks available within the Python ecosystem. PyTorch: We harnessed PyTorch, a cutting-edge deep learning fr"
      }
    ]
  },
  {
    "file_path": "./devposts/canon-ball.html",
    "project_id": "canon-ball",
    "title": "9 Lives",
    "tagline": "9 Lives: Build. Strategize. Protect. Guide your cat through an immersive AR obstacle course with only nine lives to spare!",
    "hackathon": "",
    "built_with": [
      "javascript",
      "lenstudio",
      "snapspectacles",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/124/971/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "9 Lives 9 Lives 9 Lives 1 2 Inspiration Our inspiration for 9 Lives stemmed from the desire to create an interactive AR experience that combines critical thinking and spatial awareness with a fun, immersive storyline. By leveraging Snap Inc.’s Spectacles and AR capabilities, we built a game that encourages problem-solving and creativity as players guide a cat across a series of dangerous obstacles. With each life, players must adapt and strategize to keep their feline friend safe, providing an engaging and educational experience. What it does The player navigates their cat avatar through a series of blockages by building a safe path using a multitude of different blocks. The weightless nature of the blocks allow the player to develop different solutions to save the avatar from its fiery fate. Players face increasing challenges at each level, requiring quick thinking and strategic planning as they construct structures to ensure the cat’s survival. With only nine lives to complete the journey, every decision counts! How we built it We built 9 Lives using Snap Inc.’s Lens Studio, utilizing intuitive hand interactions to let players pick up and place objects, creating a seamless and engaging user experience. TypeScript was used to program the core game mechanics, including logic for lives management, so the cat loses a life each time it fails to cross the lava safely. By combining these interactive elements with the immersive AR environment, we created a dynamic gameplay experience that integrates physical and digital interactions. Challenges we ran into The greatest challenge was learning an entirely new platform, Lens Studio. None of our team members had prior experience with it, so the learning curve was steep. Initially, we envisioned a cooperative game, but adapting our vision within the hackathon’s time constraints required us to shift focus. We leveraged the resources available to us, including support from Snap’s mentors, to overcome these barriers and bring 9 L"
      }
    ]
  },
  {
    "file_path": "./devposts/bthoc.html",
    "project_id": "bthoc",
    "title": "BTHOC",
    "tagline": "All-in-one portal for Texas A&M Students to receive custom safety tips and actions to BTHO covid. Get suggestions based on symptoms, connect with friends, read news, etc.!",
    "hackathon": "",
    "built_with": [
      "azure",
      "firebase",
      "github",
      "html",
      "jsx",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/815/647/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Backend Data Tracker Login Screen Upload Files Symptoms/Test Analysis Friends Calender Tracker Backend Data Tracker Login Screen Upload Files Symptoms/Test Analysis Friends Calender Tracker Backend Data Tracker 1 2 3 4 5 6 7 Inspiration Our inspiration came from one of our members coming into contact with covid and being unsure about how to proceed and what all she could do. We created this website to be a source for people who are in a similar situation to be not in the same position as her and be prepared with their virus. What it does The website allows a user to create a profile and enter their symptoms that allows for them to track their progression with covid and be able to get suggestions on what they can do. Additionally, it allows them to connect with friends and track their progression with the virus and plan accordingly. Furthermore, it keeps the student up to date with the news on the virus as well as tracking the progression in Texas A&M. How we built it We built the site using React, Firebase (Google Cloud), Microsoft Azure, as well as GitHub. Challenges we ran into Some challenges that we ran into include being able to sign up users as well as being able to push and pull our code to share it amongst the team as having trouble with this took away some time and progress. Accomplishments that we're proud of We are proud of being able to create a website having 2 people that are new to hackathon and most being inexperienced in creating a website. What we learned We learned how to make a website using React as well as embedding other websites within ours. What's next for BTHOC We are hoping to connect with Tamu and specifically with the teachers to be able to inform them when their student has covid rather than having the student self report it which takes sometimes up to 30 minutes. Built With azure firebase github html jsx react Try it out GitHub Repo bthoc.azurewebsites.net Submitted to TAMUhack 2022 Created by Anjali Kumar Rohan Lingala Harshitha Dhuli"
      }
    ]
  },
  {
    "file_path": "./devposts/bubble-sort-qzaocp.html",
    "project_id": "bubble-sort-qzaocp",
    "title": "Garbage bAIn",
    "tagline": "We built a garbage can. Literally.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c++",
      "cardboard",
      "cocossd",
      "glue",
      "opencv",
      "plasticbinsfromdollarama",
      "python",
      "wood"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Created by PM overlord >:D",
      "First Place Overall Created by PM overlord >:D",
      "TurtleHacksWinnerFirst Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/479/367/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Ever since kindergarten, we've all been told the same thing. \"One piece of misplaced garbage in the recycling bin can cause the entire bin to be thrown to waste.\" Some people do not know what bin an object belongs to or do not want to put the effort into putting their garbage in the correct bin. That is why we built a garbage can extensions that takes in any sort of trash, and places it into the correct bin automatically. What it does Our product is the bane of garbage's existence. With our product, the days of garbage sneaking into recycling bins will be over! Garbage is tossed onto the platform where a camera is set up above to detect the trash. Using OpenCV and CocoSSD, we determine what kind of object is being disposed of. With this information, an Arduino motor with an arm tilts the garbage on the platform into either the recycling or trash bin. How we built it We ran to the Dollar Store and asked the cashier if we can take some cardboard from the back. They said yeah. We used cardboard and popsicle sticks for the structure of the platform, and Arduino linked to an h-bridge linked to a servo motor for the tilting platform. For the detection, we used OpenCV with a CocoSSD database. To keep everything together we used lots of hot glue. Challenges we ran into We wanted to get computer vision and hardware working together so it was the first time we ever tried connecting those too. It was quite hard to program since we had to learn an entirely new language to get it working. We also had a lack of resources where we had to make a quick hour trip within a foreign town to urgently buy things in the little time we had left coding. Accomplishments that we're proud of Learning a new language and venturing out to do a more complicated hardware project was something we were proud of. We're also proud of completing on time and finding a place to sleep. What we learned We learned how to use Python, OpenCV, the overall design process, and using Arduino. What's nex"
      }
    ]
  },
  {
    "file_path": "./devposts/build-a-better-bolt-new.html",
    "project_id": "build-a-better-bolt-new",
    "title": "Build a Better Bolt.new",
    "tagline": "a one shot app for bolt to build a better bolt!",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Responsive design patterns with mobile-first approach"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/580/512/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Bolt Pro - Next-Generation Web Development Platform 🚀 Inspiration Traditional web development tools often feel fragmented, requiring developers to juggle multiple applications, terminal windows, and browser tabs. We envisioned a unified platform that could streamline the entire development workflow - from ideation to deployment - in a single, beautiful interface. 💡 What it does Bolt Pro is a comprehensive web development environment that brings together: AI-Powered Development Assistant - Get intelligent code suggestions, debug help, and architectural guidance Integrated File Explorer - Navigate and manage your project files with ease Advanced Code Editor - Write code with syntax highlighting, auto-completion, and real-time error detection Live Preview Panel - Test your applications across desktop, tablet, and mobile viewports instantly Project Templates - Kickstart development with production-ready templates for portfolios, e-commerce, SaaS dashboards, and more One-Click Deployment - Deploy directly to Netlify with built-in performance monitoring and analytics 🛠️ How we built it Frontend Stack: React 18 with TypeScript for type-safe component development Tailwind CSS for utility-first styling and responsive design Lucide React for consistent, beautiful iconography Vite for lightning-fast development and optimized builds Architecture: Component-based architecture with clear separation of concerns Custom hooks for state management and side effects Responsive design patterns with mobile-first approach Advanced CSS techniques including backdrop blur, gradients, and animations Key Features: Real-time syntax highlighting and code completion Responsive preview with multiple device viewports Template system with categorization and search Mock deployment dashboard with performance metrics AI chat interface with conversation history 🎯 Challenges we ran into Complex State Management - Coordinating state between the file explorer, code editor, and preview panel required ca"
      }
    ]
  },
  {
    "file_path": "./devposts/beautifly.html",
    "project_id": "beautifly",
    "title": "Bee",
    "tagline": "Helping people take time for themselves and for what they love to do.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "firebase",
      "firestore",
      "google-app-engine",
      "google-cloud",
      "google-cloud-speech",
      "google-cloud-vision",
      "multer",
      "node.js",
      "python",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Impactful Data-Driven Hack Created by I worked on all three machine learning algorithms",
      "s (Stanford TreeHacks 3x, HackMIT, HackPrinceton, PennApps 2x, Bitcamp, HackUVA 2x, and more)",
      "HackVioletWinnerMost Impactful Data-Driven Hack",
      "Chosen Track",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/379/557/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Profile Beaut App Splash Screen Dashboard Goals: Accountability with Friends Detailed Goals Page Calendar/Downtime Feature Circles Feature Circles: Anonymous Support Chat Gratitude Journal Journal Voice Journal Profile Beaut App Splash Screen Dashboard Goals: Accountability with Friends Detailed Goals Page Calendar/Downtime Feature Circles Feature Circles: Anonymous Support Chat Gratitude Journal Journal Voice Journal Profile 1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration During this pandemic, job losses, additional childcare, caregiving, and schooling duties as well as mental distress from prolonged isolation, and loss of routine has affected everyone. However, self-care and doing what we love are important for staying grounded and resilient during these trying times. Chosen Track Our chosen track is Health, in accordance with the suggestion of \"Making an app that provides mental wellness tips and guidelines\". What it does Beaut is a self-care mobile app, built with accessibility, convenience, and security in mind. By allowing different ways to interact with the app, a parent can enable the voice-journaling feature and jot down feelings for the day while walking her baby to sleep. Similarly, for someone who experienced loss of speech or simply prefers to journal the traditional way, they can handwrite their thoughts to upload as text through OCR in their journal. While the app performs sentiment analysis on journal check-in’s to figure out how they are feeling that day and prompts users to reach out to their circle if they are feeling down, that data is discarded after the session closes or when the next day arrives, unless users set in their profile preferences that they want to store and view their data later. Being a mobile app, we make it easy for women on the go to check in with themselves and others in their circle. Our app offers motivation to keep up with goals and develop healthy habits for self-care, using themes of growing your own sanctuary. Circles: First, "
      }
    ]
  },
  {
    "file_path": "./devposts/calisthenics-tracker.html",
    "project_id": "calisthenics-tracker",
    "title": "Calisthenics Tracker",
    "tagline": "Making fitness safer and more inclusive by using ML to fix bad posture with custom suggestions. Fitness Exercises are great, but they can ineffective and injurious if performed incorrectly!",
    "hackathon": "",
    "built_with": [
      "caffee",
      "css",
      "google-cloud",
      "html",
      "javascript",
      "opencv",
      "openpose",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/286/335/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Tracking the user's pose The Analysis Tracking the user's pose The Analysis 1 2 3 4 5 Inspiration \"Fitness exercises are very beneficial to personal health and fitness; however, they can also be ineffective and potentially dangerous if performed incorrectly by the user. Fitness exercises are very beneficial to personal health and fitness; however, they can also be ineffective and potentially dangerous if performed incorrectly by the user. Exercise\nmistakes are made when the user does not use the proper form, or pose.\" - https://arxiv.org/abs/2006.11718 With the advent of Covid-19, this problem has become even more exaggerated with a lot of people starting their own fitness routines but unable to seek proper advice from fitness trainers, paving the way for serious injuries. Thus, we set our sights on building an application that would bridge this gap by providing personalized feedback to users based on their posture. What it does Our Application uses computer vision to analyze user uploaded videos of their workout and then, deliver specific insights to users by comparing their posture to \"good\" workout routines. Specifically, we use key point estimation with the open source project, Open Pose, to track a sequence of joints during a video with a pretrained CNN (convolutional neural network). Then, we combine these vectors and analyze them to provide custom feedback based on the open source project, Pose Trainer. With Open Pose, we track over 25 different joints in the user's body to deliver directed insights! With our front-end, users can also record videos of themselves, leading to a fully immersive application and we also started a complete data pipeline on google cloud. How I built it Frontend The frontend was built using HTML, CSS, and a lot of JavaScript! Backend The backend was built using Python Flask to deliver the ML. Machine Learning We used keypoint estimation with a pretrained CNN on OpenPose to keep track of 25 different joints in the user's body. Then, w"
      }
    ]
  },
  {
    "file_path": "./devposts/byron-app.html",
    "project_id": "byron-app",
    "title": "Byron App",
    "tagline": "Making tech available for tech-newbies",
    "hackathon": "",
    "built_with": [
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned I learnt how to work with JSON Web Token. What's next for Byron App Built With react Try it out GitHub Repo Submitted to Global Hack Week: Open Source Created by Stephen Maina"
      }
    ]
  },
  {
    "file_path": "./devposts/buscaluz.html",
    "project_id": "buscaluz",
    "title": "BuscaLuz",
    "tagline": "BuscaLuz is an interactive social media platform created to help people with SAD. \"BuscaLuz\" means seeker of light, as light is one of the most common treatments for SAD.",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration One of our family members suffers from SAD, so we wanted to make a product to help them after seeing all of the negative effects SAD can cause. What it does It is an interactive social media platform where people can connect with others and share resources to overcome SAD. How we built it Though didn't have enough time to build a prototype, we came up with a detailed idea and its purpose, to solve the problem. Challenges we ran into Coming up with unique, effective solutions to help people suffering from SAD using a method that incorporated collaborating with other people. Accomplishments that we're proud of We are proud of coming up with a unique idea to solve a real-world problem that a large number of people are suffering from. What we learned We learned in detail about the causes and effects of SAD, as well as the most common treatments. What's next for BuscaLuz Our goal for the near future is to implement our idea by designing and launching our platform. Built With python Try it out www.loom.com Submitted to Steel City Hacks 2024: Winter Hackathon Created by Worked on the presentation slides Tejas Patel I came up with the project idea, and also worked on the presentation slides, Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/capsule-i2ors6.html",
    "project_id": "capsule-i2ors6",
    "title": "Capsule",
    "tagline": "Preserving Emotional Connections for Elderly & Disabled Users Through Immersive Memory Experiences",
    "hackathon": "",
    "built_with": [
      "blender",
      "c#",
      "figma",
      "metaquest",
      "skybox",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Immerse the Bay 2024WinnerMeta - 3rd",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/132/310/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 Inspiration Isolation and memory loss deeply affect elderly individuals, particularly those separated from loved ones. This isolation, coupled with memory challenges, can make it difficult to retain emotional connections and recall cherished moments. Elderly individuals face obstacles such as fragmented memories, the emotional toll of prolonged separation, and few opportunities to relive meaningful experiences. Even joyful memories fade with each missed call or delayed visit, widening the gap between loved ones. In response, we created Capsule—an immersive VR experience for the elderly, rooted in reminiscence and music therapy. Through \"memory capsules\" that represent unique, cherished moments, users can interact with personalized environments, familiar sounds, and music, encouraging comforting memory recall. Inspired by Matthew’s bond with his mother, our idea developed further through insights from a Unity AR workshop with Greg Madison and guidance from volunteer Anna Tee on integrating music therapy. These combined influences shaped Capsule into a tool for meaningful memory and emotional support. What it does Capsule provides a virtual \"Memory Palace\" where users explore mementos from loved ones, each linked to a cherished memory. Interacting with these artifacts—like a seashell in a bottle—transports users to a personalized environment that embodies the essence of that memory. Users can then store these mementos within their Memory Palace, building a growing archive that fosters connection and recall. How we built it Capsule combines advanced VR technology and thoughtful design to deliver an immersive memory experience for elderly users. Developed on Unity for Meta Quest 3, Capsule uses OpenAI's LLM prompting for Skybox AI to recreate memory scenes with vibrant visual and audio cues, immersing users in meaningful environments. We also used OpenAI's Whisper to extract the audio from the video into text for streamlining this process. For a cal"
      }
    ]
  },
  {
    "file_path": "./devposts/cabin-connect.html",
    "project_id": "cabin-connect",
    "title": "Cabin Connect",
    "tagline": "For those long flights when you feel lonely.",
    "hackathon": "",
    "built_with": [
      "astro.js",
      "css",
      "gemini",
      "javascript",
      "moviedb.org",
      "svelte",
      "threlte",
      "youtubeapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH - Best AI Application Built with Cloudflare Created by Shlok Bhakta Allen Thomas Hitansh Mendir",
      "TAMUhack 2025WinnerMLH - Best AI Application Built with Cloudflare",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/237/077/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "main entertainment page flight information page main entertainment page flight information page main entertainment page 1 2 3 Inspiration Inspiration Have you ever gotten onto a long flight alone? Are you too shy to talk to the strangers next to you? Are you a CS major who only interacts with others through discord or twitch chats? Well we have a solution for you. Imagine an infotainment system on a plane where you can, not only watch movies, but you can watch them with others. What it does This infotainment system provides an exceptional user experience through the ability to not only stream movies, but also host watch parties on a plane. Gone are the days where you have to watch your movies alone if you don’t bring friends on a flight. Now, with cabin connect you can host a watch party with the other people on your flight, featuring a real time chat feature and video syncing. Additionally, an infotainment system can’t be called an INFOtainment system without a bit of information on the flight. Our application also features a 3d rendering of the globe with the plane’s flight path plotted on top with the current progress of the trip displayed through an image of the plane on the path. How we built it We built our frontend with Astro.js and Svelte. We took advantage of the MovieDB.org to get a list of all the movies available on our website as well as metadata (parental conduct, release date, etc.) and the Youtube API to fetch trailers for movies since we couldn’t potentially show actual movies. We stored data pertaining to users, comments and watch parties in MongoDB. We also incorporated Gemini to empower our app with movie recommendations for the user. We used Blender and three.js to map out the trip on 3D globe on our flight info page. Challenges we ran into One of the biggest challenge that we ran into was most likely the steep learning curve for the freshman on the team because they were using techniques that were foreign to them for the most part. The other ma"
      }
    ]
  },
  {
    "file_path": "./devposts/bonk-to4ez2.html",
    "project_id": "bonk-to4ez2",
    "title": "Rosa's Adventure",
    "tagline": "In memory of Rosa, a beloved surrogate otter, we created a game where players journey through Bay Area attractions, celebrating her life and legacy as the heart of the experience.",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "nextjs",
      "opencv-python",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/982/683/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Cards and their descriptions the landing page to scan in all the player cards the main game page objective generation page End of the game Cards and their descriptions the landing page to scan in all the player cards the main game page objective generation page End of the game Cards and their descriptions 1 2 3 4 5 6 Inspiration Many of our group members were fond of Rosa the Sea Otter and her story but were heartbroken when she passed away and wanted to do something to honor her memory. The best bonds are created in person and the best games are played online. We wanted to have the good in both worlds and created a semi-online video game. This inspired us to create \"Rosa's Adventure\"! What it does Our game is an adventure-type game where Rosa travels through various parts of the Bay Area, which was her home. Certain events can either aid you in Rosa's journey or set her back. By using advanced image processing we can detect QR codes on the back of our cards. Scanning these QR codes lets our server track its progress, creating what we call a semi-online game! How we built it We used Python, nextjs, javascript, openvc-python, and flask. The Flask server hosted an instance of the game class, which stored each stage of the game. Each game contains an array of Otters. Each otter contains all the cards the user has, and the function of each card. By using the Game and Player we simulated the game before linking everything to the client. To get data from each card, we added a QR code to the front. This gave us the ability to read the information on the card quickly and efficiently. Combining all these ideas, we conflated each part into a Flask server. The server accepts requests from the client, Nextjs, making the game process. Challenges we ran into The QR codes on the physical cards did not always scan properly, and at first, the animations were glitching when the game was run. Accomplishments that we're proud of We are proud of many of the technical features we were ab"
      }
    ]
  },
  {
    "file_path": "./devposts/biolearn-awvgeb.html",
    "project_id": "biolearn-awvgeb",
    "title": "Biolearn",
    "tagline": "Making Biology Education interactive",
    "hackathon": "",
    "built_with": [
      "circleci",
      "echo3d",
      "github",
      "next.js",
      "react",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Usage of CI/CD sponsored by CircleCI We are using CircleCI for continuous integration and deploymen",
      "Usage of CI/CD sponsored by CircleCI Created by Worked on the frontend with React & Next, design, a",
      "[MLH] Best Usage of CI/CD sponsored by CircleCI Created by Worked on the frontend with React & Next",
      "UGAHacks 7Winner[MLH] Best Usage of CI/CD sponsored by CircleCI",
      "🛠 [MLH] Best Usage of CI/CD sponsored by CircleCI",
      "🌐 [MLH] Best Domain Name from Domain.com",
      "We were using CircleCI for the first time, so we had to learn how to use it.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/839/314/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Human Lungs Home page Select topics Human Skull Click on various parts of skull to know more Click on various parts of skull to know more Animated AR in action Animal Cell Plant Cell Human Brain Human Lungs Home page Select topics Human Skull Click on various parts of skull to know more Click on various parts of skull to know more Animated AR in action Animal Cell Plant Cell Human Brain Human Lungs 1 2 3 4 5 6 7 8 9 10 11 Biolearn 💡 Inspiration \"The heart is the size of the fist\" is one sentence almost every student learns in his/her middle school biology class. But what about the liver, stomach, or intestines? We never get perspectives on other organs vital to our body. All we have are static images on boring textbooks. This makes students disengaged with the study material and underperforms in their exams. The absence of an interactive biology education during our middle school inspired us to make Biolearn- an interactive education platform to learn Biology. 💻 What it does On Biolearn, students can learn about the organs part of the human body. The 3D models are interactive and students can interact with the organs and learn about their functions of the organs. Students can also view the 3D model in Augmented Reality (AR). Learning with the help of the 3D model is a great way to learn about various topics in biology and to understand the functions of the organs. Interactive 3D helps students to learn about the various topic in biology with ease. ⚙️ How we built it Next Js: For frontend CircleCI: For continuous integration Three.js: For 3D rendering and animation echo3D: For AR/VR Figma: For UI design ⛑ NCR - Eliminate the Friction We have created a web app. that can be used by students to learn with the help of Augmented Reality and help them to learn various concepts in a better way. 🛠 [MLH] Best Usage of CI/CD sponsored by CircleCI We are using CircleCI for continuous integration and deployment. CircleCI is a free service that provides continuous integration and"
      }
    ]
  },
  {
    "file_path": "./devposts/camp-pride.html",
    "project_id": "camp-pride",
    "title": "Camp Pride",
    "tagline": "A virtual summer camp program designed for queer, trans, questioning, and allied youth",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "html5",
      "javascript",
      "moment.js",
      "node.js",
      "socket.io",
      "wolfram-technologies"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Wolfram SimpliHacks 2",
      "Best Use of Wolfram SimpliHacks 2",
      "Third Overall Created by Anita Yip Product owner, project manager, retired hackathon-er",
      "FreyHacksWinnerBest Use of Wolfram",
      "Zoom also decided to share its recording bar as I recorded the video - a first!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/018/306/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Welcome to Camp Pride! Welcome to Camp Pride! Welcome to Camp Pride! 1 2 Inspiration As a kid, I looked forward to summers full of sun, friends, and learning in a non-traditional way (aka not in a classroom). Being a city kid, I got to experience the outdoors through summer camps. I can only imagine what it's like to have that taken away from me due to COVID. It’s never been more important for camps to offer programs in the online space. While the focus behind the push for virtual camps in 2020 was to stay compliant with social distancing recommendations, camps discovered that today’s campers and families expect flexible online programs that complement their busy schedules—and allow them to stay active and engaged from the comfort of their own homes. For the LGBT+ community, there's a need to have safe spaces that provide a break from judgment, unsolicited opinions, and having to explain oneself. I created Camp Pride to combine the two ideas of summer fun in an open and loving community. My goal is to expand my front end horizons from the basic website and see if I can seamlessly piece them together. What it does Camp Pride is a virtual summer camp program designed for queer, trans, questioning, and allied youth to not only explore their identify, the history of LGBT activism and the outdoors, but also connect with others who share their values and feel supported and respected. Virtual activities include: escape room - be a hero and rescue Camp Pride's mascot! scavenger hunt on symbols for LGBT activism listen to music in nature - to immerse ourselves in nature's healing effect, listen to ambient music for a calming effect, or jam to Korean pop group BTS (an avid supporter of LGBTQ community) firework celebrations - to celebrate small wins and bring a little of the outdoors indoors fireside chats - to connect with others who get you scrapbooking - learn more about the different symbols you find and come across at Camp Pride How we built it HTML, JS, CSS for the gene"
      }
    ]
  },
  {
    "file_path": "./devposts/camplance.html",
    "project_id": "camplance",
    "title": "Camplance",
    "tagline": "https://youtu.be/08CmD_z9tLw",
    "hackathon": "",
    "built_with": [
      "flask",
      "react-native",
      "repl.it"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "https://youtu.be/08CmD_z9tLw Built With flask react-native repl.it Submitted to LEC Hacks 2.0 Created by Worked on the middleware/backend Veerrohit Veeravadivel Aravindkrishna Arivudainambi"
      }
    ]
  },
  {
    "file_path": "./devposts/binge-6hzr90.html",
    "project_id": "binge-6hzr90",
    "title": "Binge",
    "tagline": "A virtual chat room convenient for businesses and friends",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "dart",
      "firebase",
      "flutter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/233/095/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Binge Inspiration Having to take online school and experiencing first hand all the struggles and hardships that go into making zoom work properly, my team decided to make an app based on the same concepts, but additional features such as a friends list, and a past meetings page to make it faster and more convenient. Furthermore, most businesses, in general, are being forced to go virtual, as according to forbes.com \"virtual events [have]  grown by 1000%. At these times there is an unprecedented need for virtual technology and we believe that Binge takes a current solution and improves on it. What it does My team wanted to retain all the features that zoom has, such as making private meetings and being able to record live what was happening, however, we felt we could improve on it. We figured one way we could make a better app is to make in-app friends and community system that allows you to track who you've been in a meeting with, and send them an invitation from the app itself. Having this feature brings an extra level of convenience when it comes to setting up meetings, as you would no longer need to spend tons and tons of emails since you can now just invite them in-app. Binge still carries over features such as a customizable profile page and profile picture. How I built it We used Flutter, a dart SDK that allows for rapid mobile development. My group uses flutter because it allows us to build on both Ios and Android devices simultaneously all while getting hot-reload, so we don't have to redeploy on every test. We also used a video calling service called Agora for streaming the video. Due to its compatibility with Flutter, the were able to achieve a good amount of utilization of the service. For the majority of the backend, we used Firebase. This was because the database had various convenient management features and integrated well with Flutter with FlutterFire. We used Agora to handle the video and voice while database tasks like storing and searching rooms, "
      }
    ]
  },
  {
    "file_path": "./devposts/bias-checker-q25yrh.html",
    "project_id": "bias-checker-q25yrh",
    "title": "Bias Checker",
    "tagline": "A bias Checker",
    "hackathon": "",
    "built_with": [
      "flask",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I was inspired by people who are biased and are not able to see it, or accidentally offend someone by a bias in writing. What it does It Checks bias in writing. How we built it We built it using python and flask. Challenges we ran into We ran into a big challenge of detecting bias. Accomplishments that we're proud of We are proud of being able to make this checker in python and flask. What we learned We learned how to develop good Web Apps. What's next for Bias Checker Making it better, and expanding the website. Built With flask python Try it out GitHub Repo Submitted to LancerHacks IV Created by Rohan Rao Shlok Shah"
      }
    ]
  },
  {
    "file_path": "./devposts/business-inc.html",
    "project_id": "business-inc",
    "title": "Business Inc.",
    "tagline": "A  website for small business to manage their products, teams and financial situations",
    "hackathon": "",
    "built_with": [
      "golang",
      "gpt",
      "jin",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Domain Name from Domain",
      "Los Altos Hacks VIIWinner[MLH] Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "TABLE 131 Inspiration We were inspired by the idea that small business fail at such a high rate. We wanted to reverse this trend by addressing the most common reasons for small business failure, a lack of mentorship and a negative financial situation What it does Our app allows business managers to manage their products, teams and their profit streams in order to keep afloat. How we built it We used react and generative pretrained transformer models (GPTs) in order to give sound and accurate advice on these various aspect of business Challenges we ran into 1) The GPT models were hard to interface with\n2) The UI had bugs at times Accomplishments that we're proud of We learned so much! What we learned We learned a lot about Golang and its Jin framework! What's next for Business Inc. Various bug fixes Adding financial and legal reports Expanding out application to other sectors Built With golang gpt jin react Try it out GitHub Repo Submitted to Los Altos Hacks VII Winner [MLH] Best Domain Name from Domain.com Created by Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly DevMello Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python"
      }
    ]
  },
  {
    "file_path": "./devposts/budget-defender.html",
    "project_id": "budget-defender",
    "title": "Dime Defender",
    "tagline": "Chrome extension that helps you curb excessive online spending habits and cross-examine your cart ‍⚖️",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "elevenlabs",
      "javascript",
      "plasmo",
      "python",
      "svelte",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2024 Finalists Created by I worked on the chrome extension, animations, and integrat",
      "Hack the North 2024WinnerHack the North 2024 Finalists",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/025/409/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Dime Defender Budget Adjustment Dime Defender Key Art Dime Defender Checkout Objection Dime Defender Deliberation Dime Defender Opposition Judgee 1 Judge 2 Deliberation 2 Dime Defender Budget Adjustment Dime Defender Key Art Dime Defender Checkout Objection Dime Defender Deliberation Dime Defender Opposition Judgee 1 Judge 2 Deliberation 2 Dime Defender Budget Adjustment 1 2 3 4 5 6 7 8 9 Live Demo Link: https://www.youtube.com/live/I5dP9mbnx4M?si=ESRjp7SjMIVj9ACF&t=5959 Inspiration We all fall victim to impulse buying and online shopping sprees... especially in the first few weeks of university. A simple budgeting tool or promising ourselves to spend less just doesn't work anymore. Sometimes we need someone, or someone's, to physically stop us from clicking the BUY NOW button and talk us through our purchase based on our budget and previous spending. By drawing on the courtroom drama of legal battles, we infuse an element of fun and accountability into doing just this. What it does Dime Defender is a Chrome extension built to help you control your online spending to your needs. Whenever the extension detects that you are on a Shopify or Amazon checkout page, it will lock the BUY NOW button and take you to court! You'll be interrupted by two lawyers, the defence attorney explaining why you should steer away from the purchase 😒 and a prosecutor explains why there still are some benefits 😏. By giving you a detailed analysis of whether you should actually buy based on your budget and previous spendings in the month, Dime Defender allows you to make informed decisions by making you consider both sides before a purchase. The lawyers are powered by VoiceFlow using their dialog manager API as well as Chat-GPT. They have live information regarding the descriptions and prices of the items in your cart, as well as your monthly budget, which can be easily set in the extension. Instead of just saying no, we believe the detailed discussion will allow users to reflect and make ge"
      }
    ]
  },
  {
    "file_path": "./devposts/campusfest.html",
    "project_id": "campusfest",
    "title": "CampusFest",
    "tagline": "Get a (social) life :D",
    "hackathon": "",
    "built_with": [
      "auth0",
      "javascript",
      "next.js",
      "reactleaflet",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for Uni Students (UW) Winner Best Use of Auth0, Presented by MLH Created by Claire Chen Yinuo",
      "Best Hack for Uni Students (UW) Winner Best Use of Auth0, Presented by MLH Created by Claire Chen Y",
      "JAMHacks 7WinnerBest Hack for Uni Students (UW)WinnerBest Use of Auth0, Presented by MLH",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/506/183/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Successfully added an event Map for finding events, sorted by proximity to current location Popup for viewing more event details Form for submitting event Auth0 login screen Successfully added an event Map for finding events, sorted by proximity to current location Popup for viewing more event details Form for submitting event Auth0 login screen Successfully added an event 1 2 3 4 5 6 Inspiration As high school students aspiring to enter the University of Waterloo, we look forward to having a life in university. The problem? Waterloo isn’t much of an eventful university. What makes matters worse, the few events that are out there are hard to discover. Sure, there’s a general club site, but how often does it get updated? There’s also social media, but how would you search for clubs without knowing they exist? Also: what about parties? Other social events? People don’t know about them, and there isn’t enough motivation to host events when no one joins. We want to fix that. What it does CampusFest is a website that notifies people of upcoming campus events via a map that updates in real-time. When a user goes on, they’ll see the most relevant events happening at the moment, determined by proximity and interest, sorted by tags. Additionally, our software features a search bar, a filter, and a hover. For security purposes, all users must create an account upon use, and hosts can restrict access to events. For instance, an event can be only available to students belonging to one faculty. Event hosts can also easily submit their events and information to let others be aware of the social gatherings that are happening via a form that is also located on the site. This way, it’s super easy for them to let others know of their events, and it’s also much easier for others to locate your event too. How we built it The website is built with Next.js and styled with TailwindCSS. The authentication system is implemented using the Auth0 API, which allows users to log in with an email"
      }
    ]
  },
  {
    "file_path": "./devposts/carbon-karma.html",
    "project_id": "carbon-karma",
    "title": "Carbon Karma",
    "tagline": "Do your climate-impacted communities feel forgotten? Worry no more; as with Carbon Karma, every voice is heard. We accept and sell unused credits and donate the proceeds to popular regulated charities",
    "hackathon": "",
    "built_with": [
      "elementor",
      "python",
      "wordpress"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best-of-the-Rest Created by I worked on the causes page for the website using Elemento",
      "The Climate Change-Makers Challenge: 2022WinnerBest-of-the-Rest",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/317/978/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "9 Cell Matrix Website Image 1 Website Image 2 Website Image 3 Adding New Segment to Climate Justice 9 Cell Matrix Website Image 1 Website Image 2 Website Image 3 Adding New Segment to Climate Justice 9 Cell Matrix 1 2 3 4 5 6 Inspiration When researching Carbon Credits, we stumbled upon the typical case of JP Morgan Chase & Co unintentionally buying worthless carbon offsets. These mentioned off set claimed to protect an otherwise already safe nature reserve in Pennsylvania called Hawk Mountain Sanctuary. This doesn’t take into account the principle of additionality or duration: this is not an outlier and is in fact common. The principal additionality is simply choosing a carbon storage/preservation that wouldn’t have been achieved. The second equally important principal duration is how long the carbon will be captured: like the life span of a tree but ideally indefinitely, such as a petroleum reserve. Nevertheless, Chase bank will still use this to claim it carbon neutral. The Carbon offsets market is seeing high growth, yet we aren’t seeing better regulations. For instance, the Taskforce for Scaling Voluntary Carbon Markets (TSVCM) survey suggested that the market size in 2030 can be between $5 billion and $30 billion. IF CORPORATIONS LIKE CHASE BANK CAN FREQUENTLY BE A VICTIM OF A CARBON SCAM, THEN WHAT HOPE DOES INDIVIDUAL ACTIVISTS HAVE? We must increase market regulation by recording transactions on the blockchain, as seen in our proof of concept. What it does Carbon Karma is a sustainable blockchain platform created to help companies reach their carbon-neutral goal while empowering grassroots campaigns & initiatives. Companies can contribute in the two following ways: Donation. Selling excess credits. We then allow the world's people to voice their opinion on what initiatives they want the resources allocated to. Based on the results, we can share the appropriate funds with a reputable foundation. For this reason, we would like to be considered for the The Tec"
      }
    ]
  },
  {
    "file_path": "./devposts/carryon-hg39kz.html",
    "project_id": "carryon-hg39kz",
    "title": "CarryOn",
    "tagline": "Don't get *trip*ped up figuring out what you can bring. Ask PackMate!",
    "hackathon": "",
    "built_with": [
      "azure",
      "css",
      "git",
      "github",
      "html",
      "javascript",
      "node.js",
      "python",
      "react",
      "reactstrap",
      "selenium",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/361/050/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Alternative Background Our Home Page UI/UX Template Gameplan Part 2 Our Gameplan Part 1 Alternative Background Our Home Page UI/UX Template Gameplan Part 2 Our Gameplan Part 1 Alternative Background 1 2 3 4 5 6 Inspiration Whether you're a frequent flyer or on your first well deserved vacation in years, it's easy to get mixed up in the hundreds of regulations the TSA has for carry on items. CarryOn serves to alleviate that problem in a friendly and easy to use chat-style application. \"For less throwing away souvenirs and expensive items that you could have easily left at home, more seamless travel, ask PackMate before you fly!\" What it does CarryOn features a carry-on item checker called PackMate! You can enter information on the airline, airport, bag dimensions, checked/carry-on status, and items you are travelling with. PackMate will tell you whether or not you can fly with the items you listed based on the TSA guidelines for your item! If PackMate cannot find your item, it will recommend a set list of items that seem to match, or ask you to re-try! How we built it We built this application using Javascript (TypeScript) & React.js , HTML/CSS (Tailwind CSS), Python (Selenium), Microsoft Cloud ( Azure Static Web Apps), and a .Tech domain name ( askpackmate.tech ) from Domain.com. Challenges we ran into Some challenges we ran into were in implementing the Material UI Component Library for React and learning to properly enable automatic deployment for our website using GitHub actions, which we successfully implemented. Naturally, with the time constraint, one notable challenge that we ran into was polishing our final UI and launching our full intended feature set, which is highlighted on our project planning flowchart! Accomplishments that we're proud of We are particularly proud of how aesthetically pleasing our UI is and how useful PackMate's core functionality is for expediting the packing process and accommodating for different Airlines' and Airports' policies (i."
      }
    ]
  },
  {
    "file_path": "./devposts/brevify-video-summarizer-s7pkoe.html",
    "project_id": "brevify-video-summarizer-s7pkoe",
    "title": "Brevify: Video Summarizer",
    "tagline": "Don’t have time to watch the whole video? Brevify can create a text summary of your video, so you can get the information easily and efficiently. Learn key information & concepts instantly!",
    "hackathon": "",
    "built_with": [
      "ai",
      "ajax",
      "assemblyai",
      "canva",
      "css",
      "express.js",
      "html",
      "javascript",
      "jquery",
      "node.js",
      "replit",
      "tailwind",
      "tailwindcss",
      "web"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Participation Prize Created by I worked on the UI, design, and front-end of the index/home, about,",
      "FunathonWinnerParticipation Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/208/595/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "AI-Generated Video Summaries and Chapters Home Page User Upload (Any Video of any length and format) Data Flow Diagram of Video Summarizer Algorithm About Page of Brevify Website Generated Video Transcription AI-Generated Video Summaries and Chapters Home Page User Upload (Any Video of any length and format) Data Flow Diagram of Video Summarizer Algorithm About Page of Brevify Website Generated Video Transcription AI-Generated Video Summaries and Chapters 1 2 3 4 5 6 7 Inspiration Videos on YouTube are getting longer and longer over time - back then, youtubers get straight to the point but now they feel a need to have long intros, outros, and ad breaks, which keep the viewer from getting the information they want. In addition, as our lives are getting busier and busier in this modern, technological world, we simply don’t have the time to watch a full YouTube video for homework or for studying to understand the material. As Machine Learning enthusiasts, we wanted to find and use an AI or ML model to help solve this problem. Audience, Impact, Applications Our audience involves both student learners (K-12 and college) and adult learners, as they can turn teacher lectures and educational videos into shortened text summary notes to study from. We also have use cases for hearing impaired learners, as they can easily sift through information generated through our text transcriptions, and for court case recordings, as recorded court videos can be transformed into legal documents for legal purposes. What it does Brevify is a web app that ensures that all users, including students and adult learners alike, can always have a platform to enhance their learning by summarizing video content in a quick and convenient way. The user can upload a video file of their choosing, and AI algorithms will then transcribe and summarize it into easily digestible sections. Brevify can be used at any time, every day. Brevify has 3 pages: the home page/demo page, about page, and contact page. Th"
      }
    ]
  },
  {
    "file_path": "./devposts/celonis-x6mw7p.html",
    "project_id": "celonis-x6mw7p",
    "title": "Celonis",
    "tagline": "We made a very sleek, green-friendly for how green it is, data visualization of Celonis, and also a tidbit of conformance.",
    "hackathon": "",
    "built_with": [
      "celonis"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/766/070/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Had fun, not enough luck though lol. Built With celonis Try it out GitHub Repo Submitted to TAMU Datathon 2021 Created by Joshua Chong Hunter Finch"
      }
    ]
  },
  {
    "file_path": "./devposts/chad-the-ad-bot-for-discord-servers.html",
    "project_id": "chad-the-ad-bot-for-discord-servers",
    "title": "chAD, the AD bot for Discord Servers",
    "tagline": "chAD allows Discord users to monetize social interactions and unlocks a new, more efficient way to advertise for marketers.",
    "hackathon": "",
    "built_with": [
      "airtable",
      "api",
      "css",
      "discord.py",
      "html5",
      "javascript",
      "logging",
      "python",
      "random.py",
      "requests"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/578/010/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Website for the Bot Logo, feel free to make a flag of it. Thumbnail for YouTube Submission Website for the Bot Logo, feel free to make a flag of it. Thumbnail for YouTube Submission Website for the Bot 1 2 3 4 💡Inspiration With almost all our day-to-day activities going virtual, Discord has become one of the most used social media platforms. With this in mind, our entrepreneurship background has led us to decide that we can monetize day-to-day life on Discord. All of our group members use Discord on an extensive day-to-day basis, and have many of our own servers. We thought that this was a great way to earn money as server owners but also to help other companies gain wide outreach on a massive platform. ❓ What it does chAD works like any other of your favorite Discord Bots such as Rythm, or Dyno, but chAD puts random advertisements into the text channels into your servers, depending on the number of messages sent into the server. This scales up with the amount of people on your server. As an advertisement appears, the Server owner will be rewarded with real cash depending on how many ads are generated in the Server, creating a Win-Win situation for both the Server owners and the companies running ads through the chAD bot. 🏗️How we built it The website was built using HTML, CSS (bootstrap), and JS. The Discord Bot itself was developed using Python and the Discord.py library. The entire system was built around the Airtable API. 🚧Challenges we ran into We never used the Airtable API before, and the only resources available to us was cURL commands and javascript scripts. It was too late to re-code the bot in javascript, so we took some time to learn how to translate cURL commands into python. ✅Accomplishments that we're proud of We’re proud of how our front-end and back-end turned out after the hackathon. We did not expect to produce such great results for us, especially on the website, but we managed to make it much better than what we expected. The bot also turned out"
      }
    ]
  },
  {
    "file_path": "./devposts/catapult-mcni5z.html",
    "project_id": "catapult-mcni5z",
    "title": "Catapult",
    "tagline": "AI-generated travel itineraries for anywhere in the United States.Travel the Intelligent way.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "express.js",
      "flask",
      "javascript",
      "mongodb",
      "node.js",
      "python",
      "react",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/256/956/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration As a team, we wanted to challenge the way people conventionally look at travel websites. Catapult was created as an innovative platform for users to explore possibilities for adventure and travel. What it does Catapult allows users to fully immerse into the world around them through thousands of instantly generated travel itineraries for cities across the United States. How we built it Catapult utilizes libraries including Selenium, Beautiful Soup, and Flask in the implementation of our own web scraping API and integrates it with the backend of our website. Challenges we ran into Some of the challenges we ran into was obtaining a free API that looks for hotels, activities, and restaurants. Another challenge we had was integrating Python in the API implementation and JavaScript in the backend as well as Next.js in the frontend. Accomplishments that we're proud of An accomplishment we are proud of is the implementation of our own API through web scrapping in response to not finding a free API applicable to our problem. Additionally, we are pleased with the design aesthetic and interactivity of our website. What we learned Although the concept of pulling request from the API to the program between different coding languages was foreign to all group members, we found it extremely rewarding to develop a sufficient understanding and successfully implementing this process. What's next for Catapult Catapult is looking forward to scale globally with a larger database and a smarter, more integrated AI to allow users an enhanced experience with travel options from all over the world. Built With beautiful-soup express.js flask javascript mongodb node.js python react selenium Try it out GitHub Repo Submitted to HackTX 2022 Created by Worked on both the front-end and back-end of this project. Technologies I used were Next.js, Express, Mongo and Tailwind. Learned Flask and Selenium. Cole Cline I used selenium, beautifulsoup4, and flask to build a web-scraping"
      }
    ]
  },
  {
    "file_path": "./devposts/c-gen.html",
    "project_id": "c-gen",
    "title": "C-Gen",
    "tagline": "AI-genned characters. Good for you.",
    "hackathon": "",
    "built_with": [
      "flask",
      "openai",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "We were looking for a fun way to integrate generative AI, as this was our team's first major project involving it. Therefore, we decided to make a website that allows users to take a personality test and generate a random character complete with a backstory. For most of the team, this was their first exposure to full stack development with React and Flask. Some of our teammates learned how to style components using TailwindCSS. We also learned about how to make API calls using the OpenAI package. Unfortunately, we ran into issues regarding the API key, and our team learned an important lesson about handling API keys and environment variables. C-Gen has some potential, and if we were to flesh it out more, it would look amazing. Built With flask openai python react tailwind Try it out GitHub Repo Submitted to TAMUhack 2025 Created by Obinna Nwakwue zhihangan Ansen Basil MadMadzz05"
      }
    ]
  },
  {
    "file_path": "./devposts/charify-ifa691.html",
    "project_id": "charify-ifa691",
    "title": "Charify",
    "tagline": "Providing the most Authentic Charities in Canada since 2021",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "css",
      "javascript",
      "mysql",
      "pandas",
      "php",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked on the data collection/ web scraping part using python. It was my first Hackathon and I had a lot of fun."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/506/328/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We decided to create this project after realizing the risks that many less-wealthy people face during the pandemic and provided a solution for people to donate to the charities that help the less-wealthy people the most. What it does The application provides users with the highest-ranked charity based on the percentage of their revenue that they use to support their mission of providing services to less-wealthy people. How we built it We first used Python, Pandas, and Beautiful-Soup to web scrape and store it to then import it to a local MySQL database. We then used PHP to read the data from the table and displayed it on another table on the website. We also incorporated a few features such as searching for a certain charity by name, link, or percentage and creating multiple pages for the website so that it wasn't too overcrowded. Challenges we ran into We ran into many challenges. Firstly, we were still planning out how to acquire the scrape the data from a website and we ran into challenges such as low efficiency and some difficulties with this complex topic. Secondly, we were debating how to import the data to a database(e.g., MySQL) to use for the website. We were initially thinking of using a remote MySQL server but because that was new to both of us, we aborted that idea. We thought of an idea to have Zefeng download the CSV file that contained all the data from the charity website and import it into his local database to use for the website. Accomplishments that we're proud of We were able to learn and use web scraping with Python, Pandas, and Beautiful-Soup to pull the majority of the charity data from link . We were then able to manipulate and display that data on the server and include some other features to go with it. We were able to finish the project with time to spare and our collaboration ran smoothly. What we learned From this experience, we learned how to collaborate with each other, our greatest strengths/weaknesses in programming, and"
      }
    ]
  },
  {
    "file_path": "./devposts/calorie-calculator-h1avjy.html",
    "project_id": "calorie-calculator-h1avjy",
    "title": "Calorie Calculator",
    "tagline": "We are ready to calculate your path to a better life!",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/306/277/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Second page where user can evaluate if their diet is good enough First page of our website, where user can put in their information Second page where user can evaluate if their diet is good enough First page of our website, where user can put in their information Second page where user can evaluate if their diet is good enough 1 2 3 Inspiration A lot of friends of mine have shown great interest in going to the gym. Besides how many bench presses or push-ups they did, they like talking about the diet. As far as I know, most of them follow diet instructions strictly. Then I wonder: is it possible that I can help people who don't go to the gym or have a personal trainer to know if they have a healthy diet? What it does The website takes in some personal information like age, height, weight, sex, and frequency of exercising to calculate the calories one needs per day. And it also helps one to evaluate if one's one-day diet meets this necessary calorie intake. How we built it We build this using Visual Studio Code and work online together on Replit. Challenges we ran into None of us learned anything about HTML, CSS, or javascript before. So I guess we are really challenging ourselves to build this project. Accomplishments that we're proud of We are proud that all of us are able to learn some knowledge in HTML, CSS, and javascript in such a short time! And the final website looks nicer than we would anticipate. What we learned We are very glad that we choose to challenge ourselves to learn about building up websites. We learn to code with HTML, CSS, and javascript. I believe that we won't feel confused next time we press F12 on a website. What's next for Calorie Calculator We expect that more food will be added to our database! And also more related factors would be considered to modify our evaluation of necessary calorie intake. Built With css html javascript Submitted to Hack the Change 2022 Created by Lucas Liu UBC second year stat Toby Li lasersoldier Zhou Tyler Tao"
      }
    ]
  },
  {
    "file_path": "./devposts/cartkeep.html",
    "project_id": "cartkeep",
    "title": "CartKeep",
    "tagline": "A multi-platform web app to scan your groceries and produce so you get phone message reminders to track expiry dates and food wastage easily.",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "html",
      "javascript",
      "netlify",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/303/818/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration After realizing 60% of the food produced in Canada is tossed away - our team got to work on fixing this problem from the lens of making it easy, attractive and convenient as much as possible to keep a track of soon-expiring food. What it does After logging in, the user scans the barcode of their product, from which we pull up the name and quantity of the product, and ask them to input the expiry date. After this product has been added to the user's expiring cart - when it comes close to expiring (in three days specifically), it sends the user a text message reminder. Additionally, another component of our product is the humidity detector, which detects if the food has gone bad through evaluating the environment near the food, built at an extremely cheap price for sustainability and profitability. How we built it We build our website using AI for Barcode Detection, Machine learning to evaluate the quality of produce food, and the website made through node.js, javascript, html, react and figma. Accomplishments that we're proud of Being able to run our product with our conceptual technologies drafted two days ago now working seamlessly on our website. What we learned As a team of people who didn't know each other before this hackathon, we learned how to value each other's strengths and help leverage them in the right context. In the technical sense, we learned to think bigger by being able to find databases that help us take this technology to the next level. What's next for Keep Cart We plan for Keep Cart to be even less frictionless in the future so people do not have to think before scanning their items to keep reminders (it becomes second nature to them). We hope to do this by: bringing Keep Cart to phones, for food banks to be connected to our product and lastly for an ambitious vision - for people to simply scan their barcodes and have their reminders set. Github repos Hardware & AI final product: https://github.com/HikaruSadashi/CartKeep-Hardware Kin"
      }
    ]
  },
  {
    "file_path": "./devposts/canvassist.html",
    "project_id": "canvassist",
    "title": "Canvassist",
    "tagline": "🔍📚 Query your course data with ease and simplicity! 💡🚀",
    "hackathon": "",
    "built_with": [
      "canvas",
      "fastapi",
      "langchain",
      "mongodb",
      "openai",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MHacks 16WinnerUM ITS - Generative AI and Teaching & Learning Data",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/675/470/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Teck Stack Chatbot File Uploading and Submission P1 File Uploading and Submission P2 Teck Stack Chatbot File Uploading and Submission P1 File Uploading and Submission P2 Teck Stack 1 2 3 4 Inspiration 🌟 Canvas layouts are a universal problem. Our team, hailing from multiple nationalities, bonded over our common frustration with unnavigable Canvas layouts. 😵 From scattered assignment files 📂 to unorganized submission slots, Canvas can be confusing . The solution? For students to be able to talk with Canvas and get the precise answer they need at lightning speed ⚡. More importantly, we provide critical accessibility support for students. 🎓 What it does 🚀 Canvassist is a personalized assistant for all Canvas needs. Students can navigate to Canvassist, select their course, and begin asking questions specific to each coursework! Our integrated AI 🤖 contains all pertinent information about student coursework such as assignments and syllabus and will accurately answer any questions presented. Additionally, we cut down inefficiency by allowing students to submit assignments directly from Canvassist. Simply navigate to the submission page, select your coursework, and a list of available submissions will be available to choose and instantly submit . ✅ How we built it 🔨 To bring this innovative web application to life, we incorporated a diverse technology stack that seamlessly integrates various components. Our software's front-end is developed using Streamlit , a diverse and resourceful Python library that allows for dynamic user interaction and seamless API integration 🌐. On the back-end, we used MongoDB as a vector database for our prompt as well as canvas information embed. We used Langchain to embed prompts and assignment data to and compare them using the OpenAI API . From the comparison, we return a response to the front end using Fast API . Challenges we ran into 🏃‍♂️💨 In the development of Canvassist, challenges emerged as we grappled with embedding assignments into M"
      }
    ]
  },
  {
    "file_path": "./devposts/chatify-42wgsp.html",
    "project_id": "chatify-42wgsp",
    "title": "Chatify",
    "tagline": "Share your geniosity for global issues with hundreds and discuss. Your insight is valuable!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "firebase",
      "github",
      "html",
      "javascript",
      "npm",
      "react",
      "tachyons"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/711/072/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chat Room Main Page Chat Room Main Page Chat Room 1 2 3 Inspiration Our team for sure wanted to create something that could help in some shape or form towards global issues. We bounced through several ideas, ranging from carpool tracking to tree planting. Chatify is a combination of all our ideas, in which users are able to discuss in small groups about a topic pertaining to a global issue. Through socially tough times like Covid-19, meeting new people will no longer be a challenge! What it does Choose from numerous different chat rooms, where unique topics have been assigned. The first to join a room is able to set a topic, which will be seen on the main page. Up to 10 people can join each room, and then, let the debate begin! There’s no right or wrong answer, it’s just an opportunity to share your thoughts and hear from everyone else. How we built it This site is built with Bootstrap and React, while the chat rooms are made with Firebase. It is a simple react app designed with Bootstrap, and when users click on a room, they’ll be redirected to a new page where different hosts can message one another. Challenges we ran into It took us a few hours to come up with a solid idea of what kind of project we wanted to make. We had a lot of different ideas, but we weren’t sure how practical they were to realize them. As well, since not everyone on the team is familiar with the same technology, it was difficult to modify certain aspects of the project that we weren’t a part of. There was a lot of new learning, especially with Firebase since only one member of the team was familiar with it. Accomplishments that we're proud of It works!! Although not all aspects of the project are completed, the general structure and framework is functioning. Users are able to first log in via Google account, and then choose a chat room that has a topic of interest to them. They can chat away! It was not easy to complete a project with a team that’s remote from each other, and that made the c"
      }
    ]
  },
  {
    "file_path": "./devposts/check-n-go.html",
    "project_id": "check-n-go",
    "title": "Check 'N' Go",
    "tagline": "Borrow, Don't Buy",
    "hackathon": "",
    "built_with": [
      "intellij-idea",
      "java",
      "mysql",
      "swing"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The idea itself came from a veteran hackathoner who's worked on 90+ projects having never written a",
      "The Reason We Decided on This Project in the First Place"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We throw out over 2 billion tons of household waste a year globally. That's more than 60 tons of waste every second. The world is drowning in trash, and the waste generation rates are only increasing, according to the World Bank. By 2050 the amount of household waste will grow by a staggering 70%. That is, if we don’t change our disposable lifestyle! The Reason We Decided on This Project in the First Place The idea itself came from a veteran hackathoner who's worked on 90+ projects having never written a single line of Java (any Java-based hacks were handled by other teammates and not integrated code-wise into hacker's own part of the project). Given how Java is great for inventory management as a beginner project, we thought of how an entity might have huge impact simply through inventory management like a library. Rather than books, which can be purchased online, we thought about one-off items that take up space like a ladder or kayak that people may occassionally use and thus would prefer to borrow over buying them. In the spirit of Rookie Hacks, said hacker started by using new IDE IntelliJ, coding in newly learned programming language Java, creating a GUI with Swing that injects cheer and colorful aesthetics (which observed Java projects tend to lack), and storing data in newly learned MySQL database. Since we're all looking to learn and expand our boundaries, said hacker even recruited a team of first-time hackers with little to no experience in Java and other technologies for this hack. What it does To reduce how many items go to the landfill, we created Check 'N' Go to offer a borrowing service to decrease the need to buy items, where less demand leads to producing fewer items to begin with, and we allow items to be used many times and to its fullest extent. Not only do we offer people access to items that make more sense to share than to buy outright, we help people save space that would be otherwise be used to store items. How we built it We co"
      }
    ]
  },
  {
    "file_path": "./devposts/charles-river-museum-of-industry-and-innovation.html",
    "project_id": "charles-river-museum-of-industry-and-innovation",
    "title": "Charles River Museum of Industry and Innovation",
    "tagline": "Generating new revenue streams",
    "hackathon": "",
    "built_with": [
      "bubble.io",
      "matterport",
      "thinglink"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Marketing Hack sponsored by Hubspot - Sales and Marketing Strategy Consulting Session Created by Au",
      "Best Marketing Hack sponsored by Hubspot - Sales and Marketing Strategy Consulting Session Created",
      "Deis Hacks 2021WinnerBest Marketing Hack sponsored by Hubspot - Sales and Marketing Strategy Consulting Session",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/440/151/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Google form that coincides with the escape room Google form that coincides with the escape room Google form that coincides with the escape room Google form that coincides with the escape room Google form that coincides with the escape room 1 2 3 Executive Summary With a potential loss of $200K in revenue (based on 2019 tax filing) from program services due to being closed to in-person visitation for the foreseeable future, the Charles River Museum of Industry & Innovation (CRMII) needs to find new revenue sources to survive COVID while positioning themselves for future growth activities (e.g. admission and membership) post-COVID. In the end, without margin there is no mission. In this marketing plan, we present CRMII some recommendations along with several working products to: expand online programming in line with MA teaching standards to become a go-to educational resource on the industrial revolution institute a visitor-centered process to engage visitors and donors with clear outcomes facilitate meaningful interaction with visitors and donors to inspire curiosity, generate enthusiasm, and encourage generosity create digital experiences to engage online audiences, improve visitor accessibility, provide possibilities for strategic partnerships and collaborations By leveraging technology, CRMII can have a stronger and more engaging virtual presence, be accessible, remain relevant, mitigate future risk in the face of unanticipated market changes, and build financial resilience. Inspiration We were inspired by the Museum's mission of educating people about America's industrial history and their passion for encouraging and inspiring future innovation. We were inspired to transform their mission into digital products to complement their in person offering. What it does Virtual Tour: By using the Matterport platform, which is linked in our submission, we were able to create a 3D visual of the Charles River Museum. Users feel like they’re inside the museum and can naviga"
      }
    ]
  },
  {
    "file_path": "./devposts/chatmd.html",
    "project_id": "chatmd",
    "title": "ChatMD",
    "tagline": "Revolutionize healthcare with interactive AI doctors: Input symptoms and get possible diagnoses and explanations, with both the power of LLMs and the honest consistency of trustworthy medical sources.",
    "hackathon": "",
    "built_with": [
      "ai",
      "css",
      "gpt",
      "html",
      "javascript",
      "json",
      "llm",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/595/715/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Many people use LLMs to get information about possible causes of a set of symptoms, in the same way that they'd use WebMD. However, the incentive of large language models to predict text in a way that is rated highly by humans, while generally tending to make their content helpful and honest, is not necessarily associated with truthful information. Meanwhile, although WebMD's system is likely based on a specific database of vetted facts, the user experience, absent a natural language environment enabled by LLMs, is quite lacking. What it does ChatMD takes in a list of symptoms from the user, and comes up with possible diagnoses. For each diagnosis, it finds a reliable source on the diagnosis, and then checks to see if this source says that the diagnosis is compatible with the symptoms. Finally, it outputs an explanation of where this diagnosis fits and doesn't fit the symptom descriptions, as well as other symptoms that may confirm the diagnosis. How we built it The back-end starts out by taking a user's list of symptoms and inputting it into GPT-4 to get some possible diagnoses. From there, these diagnoses are parsed into a Python list using some string slicing alongside GPT-3.5-turbo. Then, five possible links are found as resources for each diagnosis, by using GPT-4. After that, for each disease, the first link that isn't either broken or attached to too long of a website to parse is scraped to find the raw HTML, and this HTML is parsed into a more accessible format first by using libraries to remove any HTML that isn't text, and then by using GPT-3.5-turbo to remove top bars, sidebars, and other unnecessary text. Finally, this website is passed into GPT-3.5-turbo alongside the suspected disease and the reported symptoms, and an explanation of this disease and its consistency with the reported symptoms is given to the user. Challenges we ran into We tried at first to use IBM's Watson models for inference, but the models' APIs couldn't be easily access"
      }
    ]
  },
  {
    "file_path": "./devposts/chess-buddy.html",
    "project_id": "chess-buddy",
    "title": "Chess Buddy",
    "tagline": "Chess Buddy is an interactive chess bot meant for players to practice with, so they can refine and increase their knowledge and skill of chess.",
    "hackathon": "",
    "built_with": [
      "c++",
      "chatgpt",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Both creators really enjoy playing chess, but sometimes playing against another player who's skill level is much higher than yours can be quite annoying, so a chess bot would be much more suitable. What it does Chess Buddy is an interactive chess bot meant to calculate the best possible movie and play it against you, in order for you to get better. How we built it We used python and ChatGPT> Challenges we ran into For some reason, the chess bot is unable to detect borderline cases such as threefold repetition and 50 move draw. Accomplishments that we're proud of Creating a completely functional chess bot. What we learned How to better work with databases and calculations while coding. What's next for Chess Buddy We plan to refine the chess bot, and potentially even market it in the future. Built With c++ chatgpt python Try it out GitHub Repo Submitted to InnovateX hackathon Created by Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/cashcritic.html",
    "project_id": "cashcritic",
    "title": "CashCritic",
    "tagline": "Your expenses play an essential role in your daily lives. With the constant spending of money, CashCritic will help you have a more organized and more confident understanding of how your moneys spent.",
    "hackathon": "",
    "built_with": [
      "flask",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for CashCritic Built With flask react Submitted to HackTX 2023 Created by Andrew Chian Prithvi Patel Sebastian Oberg Ayo-Fatoye Fatoye"
      }
    ]
  },
  {
    "file_path": "./devposts/carried-on.html",
    "project_id": "carried-on",
    "title": "Carried On",
    "tagline": "An AI-powered solution for worry-free packing! ✈️",
    "hackathon": "",
    "built_with": [
      "arize-phoenix",
      "google-vision-ai",
      "next.js",
      "openai-api",
      "tailwind-css",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best hackathon showing yet for us."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/231/509/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Questions? Chat further to clear up anything you're wondering and receive tailored packing tips! Splash Card w/ UI Highlights Carried On Tech Stack Login using Auth0! Do a live scan, generate a list, upload an image, or make a list of the items you're packing! Receive in depth TSA guideline information on your itmes! Questions? Chat further to clear up anything you're wondering and receive tailored packing tips! Splash Card w/ UI Highlights Carried On Tech Stack Login using Auth0! Do a live scan, generate a list, upload an image, or make a list of the items you're packing! Receive in depth TSA guideline information on your itmes! Questions? Chat further to clear up anything you're wondering and receive tailored packing tips! 1 2 3 4 5 6 7 8 💡 Inspiration Our inspiration for Carried On was the desire to create a fast and convenient service that supports travelers hoping to pack efficiently and confidently by leveraging AI technology to streamline the packing process and help them navigate travel guidelines. ✨ What is Carried On ? Carried On provides a website platform where travelers can upload images of their luggage, and our AI system, powered by OpenAI's GPT-4o, detects the items inside. With this, users can receive packing suggestions and guidance based on TSA Guidelines, while also benefiting from an AI chatbot that helps answer questions and navigate nuances of TSA regulations, and more. ⚒️ How we built it We built Carried On using Next.js , a framework for creating server-rendered React websites, Tailwind CSS , a CSS framework with many pre-designed utility classes that can be used to build robust UIs, Auth0 , an identity and access management (IAM) platform used for authentication and authorization, .Tech Domains , OpenAI API for robust image detection and chatbot functionality, Arize Phoenix for monitoring and optimization of our AI-driven application, TypeScript for static typing in JavaScript, and Vercel , a cloud platform for deploying web applications. 💢"
      }
    ]
  },
  {
    "file_path": "./devposts/chevron-chefs.html",
    "project_id": "chevron-chefs",
    "title": "Chevron Chefs",
    "tagline": "Serving out clean and spicy data!",
    "hackathon": "",
    "built_with": [
      "github",
      "jupyter-notebook",
      "numpy",
      "pandas",
      "python",
      "r-studio",
      "sci-kit-learn",
      "seaborn",
      "starknet",
      "taipy",
      "vs-code",
      "xgboost"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Starknet Created by I worked on visualizations, cleaning data, application knowledge, d",
      "Rice Datathon 2024WinnerBest Use of Starknet",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/727/101/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "TaiPy Pair Plots Correlation Heat Map TaiPy Pair Plots Correlation Heat Map TaiPy 1 2 3 4 5 6 7 8 9 Inspiration In the chaotic realm of a hackathon, four fearless data scientists boldly established their base camp in the heart of their coding battleground—the 3rd-floor Duncan Hall kitchenette. We became accustomed to harmony between bytes and bites. With laptops open, we worked on our projects into the late hours of the night, deciding to name ourselves the Chevron Chefs. What it does The primary objective of the project is to develop models to predict peak oil rate given oil well data. In a real-world setting, this capability would be crucial for asset development teams. It enables them to make informed decisions before wells become operational. How we built it Visualize Given Data:\nLoaded dataset using Pandas in Python.\nUsed Seaborn to explore the data through visualizations. Checked for patterns, correlations, and outliers. Create Baseline Models:\nSplit our dataset into training and testing sets. Build simple baseline models without feature engineering to understand the initial performance. Feature engineering:\nExtracted key features and filled in empty columns while maintaining a large sample of data to work with. Imputation:\nImplemented a Linear Regression model alongside Imputation to fill missing values. Random Forest:\nImplemented a Random Forest model using scikit-learn to train the model on the training data using 25% of the available data.\nEvaluated the model's performance on the testing data using appropriate metrics. Challenges we ran into A significant challenge we encountered was the presence of large amounts of null values in the specific columns: average_stage_length, average_proppant_per_stage, average_frac_fluid_per_stage, and number_of_stages. These null values amounted to 90% of the entire sample size. This data gap poses obstacles to modeling, analysis, and accuracy. In our case, it appears that after dropping these columns and other non signifi"
      }
    ]
  },
  {
    "file_path": "./devposts/chalk-ai.html",
    "project_id": "chalk-ai",
    "title": "Chalk AI",
    "tagline": "Think. Draw. Solve. Smarter. Chalk AI is an online whiteboard with an AI-powered copilot that helps you brainstorm, solve problems, and visualize ideas faster than ever.",
    "hackathon": "",
    "built_with": [
      "elevenlabs",
      "next.js",
      "openai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/305/789/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Have an AI assistant guide you through the problem Homepage; Generate any problem Have AI Generate a problem for you Walking through a problem on the whiteboard Whiteboard Have an AI assistant guide you through the problem Homepage; Generate any problem Have AI Generate a problem for you Walking through a problem on the whiteboard Whiteboard Have an AI assistant guide you through the problem 1 2 3 4 5 6 Inspiration AI is revolutionizing education, but most tools today focus on passive learning—watching videos, reading explanations, or answering multiple-choice questions. We wanted to create something truly interactive, where students, educators, and professionals can engage in active problem-solving with real-time AI assistance. Traditional chalkboards are TRASH. Our vision was to merge the best of both worlds—a digital chalkboard enhanced with AI that helps users think, learn, and create solutions in real-time. What It Does Chalk AI is more than just an online whiteboard—it’s a real-time AI-powered copilot that actively assists users in problem-solving. Whether you’re a student tackling math problems, an educator designing lessons, or a professional brainstorming ideas, Chalk AI provides intelligent support. 🔹 Problem Generation – Need practice? Chalk AI can create problems based on your skill level and subject area, whether it’s algebra, physics, logic puzzles, or coding challenges. 🔹 AI-Powered Hints – Stuck on a step? Our AI provides context-aware hints, guiding users towards the solution without just handing them the answer—helping build real problem-solving skills. 🔹 Work Checking & Feedback – Made a mistake? No worries! Chalk AI analyzes your work, detects errors, and explains where you might have gone wrong, ensuring that learning is a continuous and constructive process. By combining AI with an interactive workspace, Chalk AI creates a frictionless, engaging, and effective learning environment for anyone looking to solve problems more efficiently. How We Bu"
      }
    ]
  },
  {
    "file_path": "./devposts/caminder.html",
    "project_id": "caminder",
    "title": "Caminder",
    "tagline": "Stressed about your overwhelming schedule? We provide an easy and free platform to schedule tasks. We provide algorithms to choose the best time to take a break outside so you can return refreshed.",
    "hackathon": "",
    "built_with": [
      "amazon",
      "css3",
      "docker",
      "flask",
      "framework",
      "github",
      "html5",
      "javascript",
      "python",
      "rest",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/826/307/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Our inspiration for the site was because of an article on ecopsychology. This specifically refers to the notion that spending time in nature improves brain function, reduces stress levels and overall makes you for calm. A study with 20,000 people proved that spending a minimum of 2 hours outside, per week would drastically make someone happier. This 20,000 pool of people included people of various ethnicities, occupations and some even with disabilities. With the new found understanding on how nature benefits one's mental health, there are many solutions floating around that could potentially improve someone's time outside. For example, forest schools are becoming more prevalent throughout the US which are schools that are located outside in nature. However, the problem with this is that these types of schools are extremely expensive and currently only a select group of people in society of able to afford these types of schools. If students aren't able to attend forest schools, then another solution needs to be put into place. Our website helps students schedule time outside by letting the user input activities and then proceeds to work around those activities to schedule time for the user to be in nature. Target Audience Students in middle school, high school, and college who have a busy schedule. What it does Allows users to fill out a form to schedule their daily tasks- has input fields of task names and start and end times of each task. Then, our algorithm chooses the most optimal block of time for the user to take a break. How we built it We built our web app using the collaborative code editor VSCode and split up everyone's roles based on their skill levels. We built this project using HTML, CSS, and JavaScript for the front-end and Python and Flask for most of the back-end. Lastly, we deployed our web app using Amazon Lightsail. Frontend The frontend task is to create a web app with a sleek and professional UI/UX design with neutral colors to "
      }
    ]
  },
  {
    "file_path": "./devposts/career-fair-xz0f67.html",
    "project_id": "career-fair-xz0f67",
    "title": "Careerly",
    "tagline": "Embark on a journey where career dreams meet reality. Careerly bridges the gap with an interactive AI-powered game that ushers inclusivity and innovation in career exploration and mentorship.",
    "hackathon": "",
    "built_with": [
      "c#",
      "cohere",
      "css",
      "express.js",
      "git",
      "javascript",
      "react",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "4K Smart Projector + MLH Winner Pins Winner Cohere’s Challenge: 1st Place Created by she11fish she1",
      "NSBEHacks 2024Winner4K Smart Projector + MLH Winner PinsWinnerCohere’s Challenge: 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/785/170/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "The ARTS area, including a musician Interacting with a flight attendant Learning about and connecting with a doctor mentor in a hospital The AVIATION area, including pilots, and a flight attendant The LIFE SCIENCES area, including a nurse, medical researcher, and doctor The TECHNOLOGY area, including game developers The ARTS area, including a musician Interacting with a flight attendant Learning about and connecting with a doctor mentor in a hospital The AVIATION area, including pilots, and a flight attendant The LIFE SCIENCES area, including a nurse, medical researcher, and doctor The TECHNOLOGY area, including game developers The ARTS area, including a musician 1 2 3 4 5 6 7 Inspiration Our inspiration comes from our desire to connect with others to learn more about our interests, build a stable future and to give everyone access to equal opportunities. What it does Careerly is a game that simulates a virtual job fair, allowing students to chat with professionals and real life mentors to learn more about different fields of interest and explore different careers. By making \ncareer exploration fun and accessible, Careerly is the best resource for students to plan their careers. Careerly also helps eliminate the underrepresentation of black people by demonstrating black excellence in important roles in our society such as doctors, pilots, and artists. How we built it We constructed the scene of a virtual job fair using Unity, where we gave life to the many different mentors and professionals by integrating Cohere's Artificial Intelligence API into our game. We also uploaded our game to a visually appealing website that allows the user to input information which will be helpful to their experience interacting with professionals and mentors in Careerly. Challenges we ran into We had trouble configuring Cohere's AI to give accurate, consistent, and humanlike responses. Another challenge we ran into was Integrating Cohere's API into our game and establishing communicati"
      }
    ]
  },
  {
    "file_path": "./devposts/cardwise-ai.html",
    "project_id": "cardwise-ai",
    "title": "CardWise AI",
    "tagline": "Boost your financial game effortlessly with the next generation AI platform CardWise - Your personal credit card advisor and financial planner! Finance is now Smart, Simple, and Secure.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "flask",
      "github",
      "llms",
      "opencv",
      "pandas",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH: Streamlit - Best Use of Streamlit Created by I worked on scraping the data and then cleaning t",
      "VTHacks 11WinnerMLH: Streamlit - Best Use of Streamlit",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/589/815/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "\"I have a credit score of 300. I want to get get the AMEX gold credit card in future. What should I do in the next 3 years to get it?\" Homepage UI Unstructured query to find the best credit card Result for the query of finding credit card Financial roadmap page Basic finance roadmap UI \"I am a 22 y/o student. I want to start saving money so that by I am 30 y/o, I have around $100K rn I save around $4K. What should I do?\" \"I have a credit score of 300. I want to get get the AMEX gold credit card in future. What should I do in the next 3 years to get it?\" Homepage UI Unstructured query to find the best credit card Result for the query of finding credit card Financial roadmap page Basic finance roadmap UI \"I am a 22 y/o student. I want to start saving money so that by I am 30 y/o, I have around $100K rn I save around $4K. What should I do?\" \"I have a credit score of 300. I want to get get the AMEX gold credit card in future. What should I do in the next 3 years to get it?\" 1 2 3 4 5 6 7 Inspiration Our curiosity was piqued by the lack of accessibility in most finance applications. Many of them require users to create accounts, and the information provided often lacks a personalized touch. Efficient Automating Financing hardly feels accessible. What it does Our product is a personalized tool that will seamlessly integrate with your life and can help you make safe and secure financial choices. It will help you find the perfect credit card based on your financial profile, define an intuitive and achievable financial goal plan, and summarise your day-to-day spending activities smartly and efficiently. 1 ) Financial Advising​: Instantly generates tailored recommendations through advanced algorithms to enhance your credit score proactively.​ 2) Credit Card Recommendations​: Swiftly generates personalized credit card guidance, while also identifying the most suitable credit card options for the user.​ 3) Roadmap to financial improvement!​: Leverages mathematics and computer s"
      }
    ]
  },
  {
    "file_path": "./devposts/cbre-office-space-supreme.html",
    "project_id": "cbre-office-space-supreme",
    "title": "CBRE Office Space Supreme",
    "tagline": "Algorithmically chooses optimal office space layout based on team interactions.",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "What it does This program calculates the optimal distribution of teams across floors based on the interaction between multiple parameters including: Challenge Parameters Team size\nFloor capacity\nTeam preference\nTeam tolerance \nTeam \"no ways\" User-Controlled Parameters We implemented interactivity through three sliders that allow user's to adjust the weight of each of the team's desires, and therefore, customize their output to their company's needs. How it works Once the analysis is started, all possible buildings with all possible floor combinations are calculated. Floors with <25% capacity or >100% capacity were culled. This data is saved, and the user-provided parameters select the optimal floor without needing to recalculate most information. The user decides how much to weigh team-interaction factors. Inspiration We were inspired by nostalgic early 2000's website design and minimalism. How we built it HTML, CSS, and JavaScript powers the frontend, with JavaScript also being used for all calculations. To maintain speed, no JavaScript libraries are used. Challenges we ran into While we were testing our algorithms, we mislabeled the arrays that contributed to inter-team like/dislike due to an indexing error. This error was easy to fix but hard to detect. An important challenge we faced was the large amount of possible team combinations per floor. To solve this we systematically culled impossible or unoptimal combinations in order to cut down on the number of algorithm iterations. Accomplishments that we're proud of We had to do a lot of troubleshooting to fine-tune our algorithm and avoid errors. In the end, we are proud of our solution and our teamwork throughout the project. Each member learned a lot which was great too. What we learned We gained a mildly subterranean level knowdledge of recursion. All of our team gained experience and knowledge of JavaScript, HTML, and CSS as well as how to work on collaborate programming projects. What's next for CBRE Office S"
      }
    ]
  },
  {
    "file_path": "./devposts/chat-proxy.html",
    "project_id": "chat-proxy",
    "title": "chat proxy",
    "tagline": "Ever missed a message notification while on your device or just not wanted to open that one messaging application? Chat proxy centralizes your messaging, so these things will never happen again!",
    "hackathon": "",
    "built_with": [
      "discord.py",
      "flask",
      "ngrok",
      "python",
      "slack"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/479/794/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "discord messages sent, slack messages received, profile images/usernames consistent slack messages sent, discord messages received, profile images/usernames consistent discord messages sent, slack messages received, profile images/usernames consistent slack messages sent, discord messages received, profile images/usernames consistent discord messages sent, slack messages received, profile images/usernames consistent 1 2 3 4 Inspiration We were initially inspired by our common aversion to using Slack--Discord was just the preferred method of communication for our entire team, and many team members had the experience of missing important messages altogether in messaging apps, despite literally being on the computer/phone at the time. Interestingly enough, a few friends of their team voiced a similar aversion to using Discord! And so, we got to work creating chat proxy . Of course, our first two messaging services were decided to be Slack and Discord, and we decided to make the service two-way to support both the Discord enjoyers as well as the Slack enjoyers. What it does chat proxy is a service that automatically ports messages from one messaging application to another, and it works both ways! In this hackathon, we implemented many other functionalities, including the ability to also port usernames and profile images with the message so that the recipient(s) know who is contacting them, the ability to port images and files over different messaging applications, so you're not limited to sending messages only, and the ability to mirror channels to the other application (for example, if you send a message in a new channel in Slack, the channel will be automatically mirrored to Discord as a new channel and future messages in that channel will remain in that channel). How we built it We built this service using an amalgamation of Python, discord.py, and the Slack API, and we used flask and ngrok as our web servers. Challenges we ran into Most of the documentation for the "
      }
    ]
  },
  {
    "file_path": "./devposts/certuary.html",
    "project_id": "certuary",
    "title": "Certuary",
    "tagline": "Certificates on Estuary. Digital certificates with blockchain and IPFS: A Truly Secure and Decentralized Version.",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/353/320/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Certificate Display Home Page Create Certificate Page Certificate Verified Certificate failed to verify Certificate Display Home Page Create Certificate Page Certificate Verified Certificate failed to verify Certificate Display 1 2 3 4 5 6 Inspiration The project involves the exploration and implementation of new technologies such as IPFS for decentralized storage and blockchain technology for secure verification. The project also explores new use cases for these technologies, such as in the management of digital certificates, an area where traditional centralized systems have proven vulnerable to hacking and manipulation. It also explores new ways to solve the problem of digital certificate management by using decentralized and immutable architecture provided by IPFS and blockchain technology. We are creating a blockchain-based certificate verification system that will empower individuals and institutions to break free from the vulnerabilities and inefficiencies of traditional systems. With decentralization, immutability, and the use of cutting-edge technology, our system will provide a secure and reliable platform for the management of digital certificates. By implementing this solution, we will be enabling individuals to reach their full potential and institutions to operate with integrity. We are not just building a technology, we are building a better future. What it does Our project was a blockchain-based certificate verification system that was built using IPFS and Estuary. The main goal of the project was to create a secure and tamper-proof way for individuals and organizations to verify the authenticity of certificates.\nThe project works by first creating a unique hash of the certificate using IPFS. This hash is then added to the Estuary blockchain as a new block. Each block on the Estuary blockchain contains information about the certificate, such as the issuer, recipient, and date of issuance, as well as the IPFS hash of the certificate.\nTo verify a certi"
      }
    ]
  },
  {
    "file_path": "./devposts/chess-website.html",
    "project_id": "chess-website",
    "title": "Chess Website",
    "tagline": "A website made for people to play chess",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I like to play chess, and it's nice to play with other people. So i wanted to create a website that me and someone else can play chess on. What it does A website to play chess. How we built it I used HTML, CSS, anad JS Challenges we ran into I was working solo, so I couldn't finish a lot of things I wanted to do. Accomplishments that we're proud of I am proud that I actually got a finished product by myself What we learned That working solo is never good What's next for Chess Website Creating a chess engine so people can play against it and get better. Built With css html javascript Try it out GitHub Repo Submitted to Los Altos Hacks 8 Created by Tejas Patel"
      }
    ]
  },
  {
    "file_path": "./devposts/callbuddy.html",
    "project_id": "callbuddy",
    "title": "CallBuddy",
    "tagline": "Making phone calls easy and accessible for deaf and hard of hearing people",
    "hackathon": "",
    "built_with": [
      "auth0",
      "azure",
      "next.js",
      "pubnub",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hard of Hearing HackathonWinner2nd Place",
      "This being one of our first times working with Figma, we had a lot to learn with:",
      "Winner",
      "Worked on the front end. First time using Next.js and a few other things."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/859/715/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Note: TEXTBOX to response is not apparent in the deployed site. It is here to \"Send message\" as a user (look at cursor) Restaurant workflow Note: TEXTBOX to response is not apparent in the deployed site. It is here to \"Send message\" as a user (look at cursor) Restaurant workflow 1 2 3 4 5 6 7 8 9 10 11 12 13 Quick Links Deployed App NOTE: We only implemented an example Restaurants flow (so only the Restaurant item is fully functional). Feel free to create an account, clicking to restaurant, filling out the form with the information you'd like in Restaurant, and enter your phone number in the +11234567890 to receive the call as the Restaurant. Side note: If you don't put in the your own phone number, it will go to the CallBuddy developer who may be a bit confused :) Code Repo Wireframes Prototype Introduction While many businesses communicate with their customers through multiple online channels, it would be hard for businesses to ignore how calls to businesses have significantly increased in response to the mass adoption of mobile phones. In fact, there are many reasons why people opt to call instead of using other methods: Source: http://www.biakelsey.com/research-data/current-research/call-commerce-1-trillion-economic-engine/ Simply put, communicating by voice is faster, easier, more effective, and convenient — but mainly for the hearing community. For the deaf and hard of hearing (HoH), talking on the phone is something they struggle with every day. Our teammate, who is HoH, faces this problem themselves: they get severe anxiety every time they have to call the pharmacy to refill their medication or call the local restaurant to make a reservation. Traditionally, a relay operator paired with hardware is the only option to translate speech-to-text on phone conversations, but lack of widespread adoption, slow and laborious processes resulting in delayed relays, and scammers abusing free relay services lead to access challenges or being hung up on. And if, for exampl"
      }
    ]
  },
  {
    "file_path": "./devposts/challengeher.html",
    "project_id": "challengeher",
    "title": "ChallengeHer",
    "tagline": "ChallengeHer: Empowering women in tech through shared experiences. Create profiles, join challenges, and connect. Collaborate on tech projects, or hobby-based adventures and meet others just like you.",
    "hackathon": "",
    "built_with": [
      "chakra-ui",
      "express.js",
      "mongodb",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of MongoDB Atlas Created by I built the entire Express",
      "TechNova 2023WinnerBest Use of MongoDB Atlas",
      "Our UI/UX designer learned Figma for the first time and mocked up our entire app",
      "One of our team members completed her first hackathon",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/599/201/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 💡 Inspiration The tech industry is currently grappling with a lack of gender diversity, primarily because many women in this field feel isolated and struggle to find mentorship. This isolation not only hampers their professional development but also perpetuates the gender gap within the tech sector. This is something we know too well. But it's not just us... Across the entire tech sector, the percentage of women in tech leadership roles is trending down, currently at 28% , according to DDI’s 2023 Global Leadership Forecast. \"Whether it’s an all-boys-club mentality or a lack of mentorship and training, many women often feel that they don’t have the same opportunities for promotions and career advancement as men.” (CNBC) \"The impact of mentorship on career satisfaction is striking: 40% of women cite lack of mentorship as one of the biggest challenges in the tech industry, alongside a lack of female role models and opportunities for advancement.\" (Acronis) So we asked ourselves: How might we create a supportive and inclusive environment in the tech industry that empowers women with easier access to mentorship and removing isolation, enabling them to thrive and contribute effectively while bridging the gender gap? 🤝 What it does Introducing ChallengeHer, a groundbreaking platform designed to foster mentorship and a sense of community among women in the tech industry. Our platform operates on a simple premise: members create profiles featuring bios and customizable tags that reflect their interests and expertise. Once profiles are set up, users can engage in challenges, which range from tech-focused projects to recreational activities like hiking. Upon selecting a challenge, members are matched with like-minded individuals, facilitating meaningful connections within the app. Users can seamlessly communicate to coordinate challenge activities, and upon successful completion, participants can upload proof as specified by the challenge creator. To increase engagem"
      }
    ]
  },
  {
    "file_path": "./devposts/city-search-tool-j1yc08.html",
    "project_id": "city-search-tool-j1yc08",
    "title": "City Search Tool",
    "tagline": "If you need to find where to go, use this tool to find what to know.",
    "hackathon": "",
    "built_with": [
      "csv",
      "google-colab",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our project was inspired by the multiple tools that provide data about cities, such as the tool that google provides covid cases. However, there is no conglomeration that handles multiple points of data and shows it to the user easily. What it does Our tool takes the top 200 most popular and sought out destinations in the Us and gives relevant data for a person who is desiring to move. They would first input their level of importance for each of our factors. Then, using our quartile based scoring algorithm, we output a map of the most relevant and up to date data that will inform the user. How I built it We made this program in Python due to the array of data analysis tools it provides. We first did research and got relevant data for covid cases, crime rates, pollution, and happiness index. We found that in these times, the four variables are the most impactful when one is choosing another city. Challenges I ran into When making our program, a big issue we were having was scraping and cleaning the data from the csv files we acquired. Many of the documents did not display the city but the metropolitian area and the state in the same cell. We had to split each document to where we could read only the name of the city and acquire the data we needed. For example, in the covid cases, there was only data for counties, so we had to get another csv file that converted each city into the FIPS number which corresponded to the appropriate city. Then, we used an algorithm to add each part together. Accomplishments that I'm proud of We are satisfied by the concise data that our map provided for the user. Especially during these times of covid-19 we felt that it was essential to provide this data for every person who was thinking of moving to a new city.\nIt also always feels great to finally have a working product after hours of errors and bug testing. What I learned We learned how to effectively use csv and pandas to manipulate data. We also learned to create a map a"
      }
    ]
  },
  {
    "file_path": "./devposts/chef-ai-wseqam.html",
    "project_id": "chef-ai-wseqam",
    "title": "chef.ai",
    "tagline": "Chef.ai: Input your ingredients and get personalized recipes instantly. Transform your kitchen creativity, no matter your dietary needs!",
    "hackathon": "",
    "built_with": [
      "gemini",
      "python",
      "reflex"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/855/839/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "web app home web app home web app home 1 2 Inspiration The idea for chef.ai sprang from a common dilemma: staring into a pantry full of random ingredients and wondering, \"What can I make with these?\" We wanted to eliminate the frustration of meal planning, especially when options seem limited or specific dietary needs must be met. Our goal was to harness AI to simplify cooking, making it more accessible and enjoyable for everyone. What it does Chef.ai is a revolutionary AI-powered tool that generates tailored recipes based on the ingredients users already have in their kitchens. Users input their available ingredients, and chef.ai provides recipe options that align with their taste preferences and dietary requirements. It can also suggest substitutions for missing ingredients and adjust recipes based on the number of servings needed. How we built it We used Python and Reflex for frontend and the AI Model is fetched by using Gemini API key. Challenges we ran into One major challenge was ensuring the AI accurately understands and processes the vast variety of ingredient inputs it might receive, especially with synonyms or regional terminology. Balancing the complexity of dietary preferences and restrictions with the need for a wide range of recipe suggestions was also demanding. Accomplishments that we're proud of We are immensely proud of chef.ai's ability to demystify cooking by providing easy, personalized cooking solutions. Additionally, achieving a user-friendly interface that can be navigated effortlessly by all users stands as a significant technical accomplishment. What we learned Throughout the development of chef.ai, we deepened our understanding of AI's potential in enhancing daily life activities like cooking. We also learned about the complexity of dietary needs and preferences across different cultures, which has broadened our perspectives on global culinary habits. We also learned how to make use of the pre-trained models of Gemini and incorporate in ou"
      }
    ]
  },
  {
    "file_path": "./devposts/chime-to-play.html",
    "project_id": "chime-to-play",
    "title": "Chime to play!",
    "tagline": "Chime to play! is an interactive game that features melodic windchimes in an ambient pastel sky. Play it in challenge mode to test your memory, or make your own tunes in free play! Please enjoy!",
    "hackathon": "",
    "built_with": [
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best UI Created by I worked on coding the graphical interface, creating the visual assets, importin",
      "HowdyHack 2021WinnerBest UI",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/650/940/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Free-play mode Main Menu of Chime to play Free-play mode Main Menu of Chime to play Free-play mode 1 2 3 Inspiration We wanted to create a program that simulated an instrument, but we also wanted it to be special and unique.  After thinking about different types of instruments such as piano and guitars, we quickly realized that their simulations have already been made by many many people. Then we started to think about unorthodox \"instruments\" (anything that makes a sound), and we came to wind chimes. Wind chimes can be considered as a musical instrument, but it is not typically something that people play. What it does The code simulates 5 notes of wind chime sounds that will activate once the cursor (wind) touches the chimes. There are 2 modes to the program: challenge and free play. In challenge mode, notes will be played for the user to replicate like a Simon Says game. In free play mode, the user will be able to freely play around with the chimes and make their own tunes! How we built it We used the pygame library in python to code most of the visuals and game mechanics. The physics of the game is made using a pendulum simulator which makes the chimes swing back and forth when touched. All of the artwork and visual assets for the program was created in Procreate, and all of the audio was created in FL Studio. We shed many tears for this. Please like it. Challenges we ran into Practically everything we did for this program had problems. The problems ranged from finding the right math, to playing sound, to python interpreter committing seppuku. Accomplishments that we're proud of We are very proud of our not shown physics created by Andrew, our beautiful music created by Sarah, our cute artwork by Mengting, and the background connecting work by Eric! What we learned We learned that no matter how simple we think our program is, it will still take more time than expected. \"I can code the physics in one hour\"\n20 hours later... \n\"I made the shirt, but the shirt does n"
      }
    ]
  },
  {
    "file_path": "./devposts/built-different.html",
    "project_id": "built-different",
    "title": "Built Different",
    "tagline": "Creating a realistic and inclusive study space for people with ADHD and Autism.",
    "hackathon": "",
    "built_with": [
      "autodesk-revit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DivHACK 2023WinnerMost Interdisciplinary Team",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/386/509/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Blueprint The rental room is in a central location Rooms come in many different forms Blueprint The rental room is in a central location Rooms come in many different forms 1 2 3 4 5 6 7 8 Breaking Down Barriers: Solutions for Neurodivergent Students in Study Rooms Ryan Kerstetter, Adam Garsha, Krish Vora, Will Borchers\nFebruary 18, 2023 Introduction Based on a study in 2022, 15-20% of the world’s population is neurodivergent (“Neurodiversity”). Despite making up such a large section of the population, there are few spaces made to accommodate their study needs. We have designed a study space to accommodate their needs, which will serve the neurotypical population as well. Variety Variety Variety! Creating a space that accommodates individuals with Autism and ADHD requires a multi-pronged approach. Our team has designed a study complex that incorporates colors, tactile, auditory, and other critical elements to ensure a space designed for neurodivergence. We have a variety of rooms to offer to accommodate whatever the students need for the day. Whether they need to finish some last minute homework, or they want to relax in the garden, there is a location for whatever is needed. \nThe blue rooms are our individual study rooms where students have a chair, desk, whiteboard, and shelves to get their work done. These individual study rooms are enclosed, and meant to be tight in order to not only help focus, but also help students who may feel safer in a tighter space (“Sensory Issues: Seeking and Avoiding”). The green rooms are our group study rooms; in case the students need to work together in a group on a project they can hop in a study room and get their work done. They come complete with conference tables for more general meetings or drafting tables for more hands-on activities. They also include a variety of plants to give a natural feel. The garden is an outdoor retreat where students can escape the hassle, and stress of study. The garden comes complete with a wide va"
      }
    ]
  },
  {
    "file_path": "./devposts/cindr.html",
    "project_id": "cindr",
    "title": "CNDR",
    "tagline": "CNDR is a web application that uses NASA satellite data to determine the risk of wildfires, and as a result, tailors mitigation methods, all in an easy-to-view and accessible platform.",
    "hackathon": "",
    "built_with": [
      "figma",
      "google-maps",
      "html",
      "javascript",
      "nasa-eonet-api",
      "node.js",
      "openweathermap",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/223/219/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Search Feature Home Page Who are we? Map Info-graphic Mitigation Methods Search Feature Home Page Who are we? Map Info-graphic Mitigation Methods Search Feature 1 2 3 4 5 6 Inspiration Wildfires around the world have destroyed billions of square feet of forestry and fertile land, causing irreversible environmental and economic damage. While there exists a plethora of government agencies in Canada and around the world that track and manage wildfires for public property, relevant data and mitigation strategies continue to remain inaccessible to the agricultural and lumber sectors. We thought to ourselves, there has to be a better way. How can we connect the private and public sectors? How can we make relevant information as openly accessible as possible? And most importantly, how can we make a tangible impact through tech? Ever since a young age, we have all been passionate about fighting climate change in our own ways. Our group has especially been fascinated with leveraging tech to solve tomorrow’s problems. With bushfires in Australia and recent wildfires in BC, counteracting the impact on real people is needed now more than ever.  As proactive high school students, it is now our responsibility to help shape the world we wish to inherit. We cannot sit idle while entire ecosystems are getting wiped out and hardworking lumber and agriculture workers are unable to put food on the table. Introducing CNDR. What it does CNDR uses satellite data from NASA through their EONET (Earth Observatory Natural Event Tracker) API to (1) display the risk level of their land, (2) tailor mitigative measures for landowners to protect their livelihoods and (3) connect clients with wildfire relief initiatives and support systems. With a clean UI/UX, we’re able to display relevant information to the user, hoping to improve ecosystems and safeguard businesses. How we built it In order to enhance the backend and UX, CNDR uses React, Figma (incl. CSS). We imported 3 APIs into our program. NA"
      }
    ]
  },
  {
    "file_path": "./devposts/check-go-8qg1ly.html",
    "project_id": "check-go-8qg1ly",
    "title": "Check & Go",
    "tagline": "Go Deal or Go Home",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "google-maps",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Searching for the best price on google while on a supermarket is quite annoying to do :/"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/701/785/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Google Places Autocomplete Dashboard Homepage Product listing Search page Search results Submit a product Google Places Autocomplete Dashboard Homepage Product listing Search page Search results Submit a product Google Places Autocomplete 1 2 3 4 5 6 7 8 Inspiration Searching for the best price on google while on a supermarket is quite annoying to do :/ Besides, instead of frantically searching for the best deals by running around the supermarket, wouldn't it be better if all the information was on one site? You could plan your journey ahead and leave satisfied. Therefore, we decided to come up with a platform where users can share, collaborate and contact each other about the best prices in supermarkets around them. What it does Check & Go is designed to help shoppers to find the best deals in their area, whether it's from a supermarket or from the comfort of the user's home.\nFeatures of the site: User collaboration - users upload items and products in a supermarket, including the location. This data will then able accessible to anyone in the world. Image upload, giving the user a better idea of what's being sold - Don't worry, if you forgot to take one, there's a default image there! Quick, easy navigation around the site. Intelligent autocomplete suggestions of places while uploading, ensuring precise locations (we don't want to go to the wrong supermarket!) User's email at the bottom, so users can contact each other and communicate Quick, accurate navigation link to the supermarket (no matter where in the world you are!) Product search - search for the items and products you want by the product name, description, store location or item tags. Free! No login, signup, or payment required - everyone deserves to save their time and money. How we built it Brainstorming UI prototyping Setting up Places API, Google Firebase and the rest of the site Styling the front-end Challenges we ran into Getting the API to work Saving a picture to firebase Small bugs A CSS file wen"
      }
    ]
  },
  {
    "file_path": "./devposts/circular-fashion-economy.html",
    "project_id": "circular-fashion-economy",
    "title": "Circular Fashion Economy",
    "tagline": "Join the circle for fashion in the new normal!",
    "hackathon": "",
    "built_with": [
      "express.js",
      "firebase",
      "firestore",
      "netlify",
      "node.js",
      "react",
      "sass",
      "stripe",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Women Hack Created by Anita Yip Product owner, project manager, retired hackathon-er",
      "Best Women Hack Created by Anita Yip Product owner, project manager, retired hackathon-er",
      "EcoHacksWinnerBest Women Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Fashion is killing the environment. Every year, the fashion industry: uses 93 billion cubic meters of water — enough to quench the thirst of 5 million people - that could be used to help with extreme weather events caused by climate change (Welcome to the United Nations Conference on Trade and Development, 2020) produces 20% of wastewater worldwide from fabric dyeing and treatment, which go on to contaminate and decimate wildlife and their natural habitats (World Resources Institute, 2017) dumps half a million tons of plastic microfibers into the ocean, the equivalent of 50 billion plastic bottles that cannot be extracted from the water and ends up poisoning our oceans and food supply and disrupting ecosystems (Ellen MacArthur Foundation, 2017); and accelerates climate change by producing up to 10% of global carbon dioxide output—which is more than the amount produced by all international flights and maritime shipping combined (United Nations Environment Programme, 2018). By 2030, fashion is on track to increasing carbon emissions by 60% due to the demand for fast fashion. (McKinsey and Company, 2018) Many of us are painfully aware that the rate at which we're producing and wearing apparel is not sustainable. What it does CFE connects people to their local tailors and seamstresses who can meet their clothing repair or upcycling needs and ultimately reduce the amount of waste while supporting the popular desire to remain on trend. How we built it I used React for front end, Node and Express for server side rendering, and Google's Firebase and Storage Buckets to store data and images for security and practical reasons. I used sass and typescript for styling. Challenges we ran into I never got Google authentication to work until now, and creating all the different components for an ecommerce site was a tall order for a solo hack (I wanted to learn by doing it all myself!). Accomplishments that we're proud of I got it done and learned a lot!!! What we learne"
      }
    ]
  },
  {
    "file_path": "./devposts/chatgpt-in-discord.html",
    "project_id": "chatgpt-in-discord",
    "title": "ChatGpt in discord",
    "tagline": "Search engine in discord",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack sponsored by Fidelity Created by I worked on the bot Satyam Singh Documentation",
      "Best Accessibility Hack sponsored by Fidelity Created by I worked on the bot Satyam Singh Documenta",
      "EduHacksWinnerBest Accessibility Hack sponsored by Fidelity",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The main purpose of buiding this project is to deploy our knowledge of programming endeavours to create something unique and innovative. \nChatGPT in discord is an intuitive use of AI to make user interface on discord server more responsive and interactive.\nThe important aspect of creating this project is to contribute to the community by our work for educational purposes. What it does The chatGPT in discord is a live AI chatbot that can answer any questions, and works as a search engine on a given discord server. \nThe user can access the chatBot using a link and choosing their discord server. To elaborate, to get into the chatbot,\nthe user needs to give the command /chat. The chatbot will start working in discord server and the user can enjoy using it. How we built it The chatGPT in discord project has been built in the python programming language with revChatGpt package. \nIt has be implemented using some various modules such as msg, discord and json. The chatGPT doesn't \nhold the official API yet. Thus, an unofficial API is used to built the project. Challenges we ran into A great challenge to face while creating this project is that, a good amount of research was required to search \nfor the API of chatGPT as it only comprises an unofficial API and not an official API. \nMost of us from the team were participating for the first time in a hackathon, so with tight deadlines it was quite difficult to led this research. Accomplishments that we're proud of The remarkable rewards of implementing this project is to utilize latest technology and getting acquainted with AI. What we learned The essential takeaway from this hackathon experience is working on close deadlines, teamwork and patience. What's next for ChatGPT in discord We have decided on improvising this model of chatGPT in discord, by adding some notable features like private chat,\nthat would provide user the privacy and comfort to ask questions in a more confidential manner. Built With python Try it "
      }
    ]
  },
  {
    "file_path": "./devposts/church-of-end2end.html",
    "project_id": "church-of-end2end",
    "title": "church of end2end",
    "tagline": "the only way forward is end2end",
    "hackathon": "",
    "built_with": [
      "e2e",
      "end2end"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "2nd Prize ($1250): comma 3X Created by data collection and labeller Clayton Haight Chief data colle",
      "comma_hack_4Winner2nd Prize ($1250): comma 3X",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/608/709/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "example of \"turn right\" data priest of the E2E church GIF painting the latent space with a comma body brush GIF great artists steal GIF pixels in, torque out simple is sacred example of \"turn right\" data priest of the E2E church GIF painting the latent space with a comma body brush GIF great artists steal GIF pixels in, torque out simple is sacred example of \"turn right\" data 1 2 3 4 5 6 7 Inspiration In an age where technology is increasingly compartmentalized with multiple components working in tandem, we wanted to return to the roots. The beauty of end-to-end solutions lies in their simplicity and elegance. Inspired by comma.ai's vision of pushing the boundaries of what's possible, we envisioned an indoor navigation solution that's truly end-to-end. Enter Luigi, our end-to-end trained robot. The church of end2end is not just a project; it's a testament to the power of holistic solutions. What it does Luigi, the comma body, is trained to navigate indoor courses seamlessly. Using a dataset comprising commands like \"turn left\", \"turn right\", and \"straight\", Luigi processes real-time inputs and linearly interpolates between the model outputs for these classifications. This allows Luigi to steer itself and navigate any indoor path presented to it, making decisions that are akin to an intuitive understanding of its environment. How we built it We started by collecting a diverse set of data within indoor environments, encompassing a myriad of scenarios Luigi might encounter. This dataset was then used to train our model using deep learning techniques, ensuring that it could generalize well across different indoor settings. The linear interpolation between model outputs served as our control system, bridging the gap between discrete commands and continuous navigation requirements. Challenges we ran into Training a model that can interpolate between classifications with high accuracy was a challenge. Ensuring that Luigi responded smoothly, especially during transitions (e"
      }
    ]
  },
  {
    "file_path": "./devposts/character-io.html",
    "project_id": "character-io",
    "title": "Character.io",
    "tagline": "Generate a fresh set of characters or avatars with the power of Generative Adversarial Networks",
    "hackathon": "",
    "built_with": [
      "flask",
      "generative-adversarial-networks",
      "python",
      "pytorch",
      "replit",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/039/329/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Websites like coolors.co help UI designers with finding their ideal color palette, but what if there's a website that does the same for cartoon characters? This idea could be beneficial to comic writers and game designers whenever they want characters for their games or comics. What it does Character.io loads a new set of cartoon characters whenever the page is reloaded. If you don't like that set, just press the space bar and it'll load a new one for you! The algorithm behind character.io uses the power of generative adversarial networks, which are nothing but just two neural networks competing against each other. Where the generator would generate a character set, and the discriminator would evaluate if the character set is good or not. Both of them are trained against each other. How I built it Back-end: Python, Flask, Tensorflow, Keras, Deep Learning: GANs, Neural Network Front-end: HTML, CSS, JS Dataset: https://google.github.io/cartoonset/ Challenges I ran into Clarity of Images, High training time for Generator. Accomplishments that I'm proud of I'm proud of developing a launchable open-source project within the span of 48 hours. What we learned I learned about the concept of Generative Adversarial Networks and learned how to build them with TensorFlow and load them with Keras. What's next for Character.io I'll be making the website responsive and will include auto-update in the model so that new characters are added to the repl. References [1] https://www.tensorflow.org/tutorials/generative/dcgan [2] https://google.github.io/cartoonset/ [3] https://github.com/taki0112/GAN-Tensorflow Built With flask generative-adversarial-networks python pytorch replit tensorflow Try it out characterio.neeltron.repl.co replit.com GitHub Repo Submitted to Data Day Grind III Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/charalearn.html",
    "project_id": "charalearn",
    "title": "CharaLearn",
    "tagline": "Character.AI for Language Learning",
    "hackathon": "",
    "built_with": [
      "bright-data",
      "inworld.ai",
      "llamaindex",
      "mcps",
      "python",
      "react",
      "vapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of InWorld Winner Top 5 Overall Teams Created by Provided original draft and overall idea",
      "Best use of InWorld Winner Top 5 Overall Teams Created by Provided original draft and overall idea",
      "A2A - Agents HackathonWinnerBest use of InWorldWinnerTop 5 Overall Teams",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/641/785/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 CharaLearn - Character.AI for Language Learning Canva Slide Deck Inspiration Language learners can read perfectly but freeze when speaking. 65% of students experience high speaking anxiety, with physical symptoms like trembling and complete speech avoidance. We were inspired by Character.AI's success in creating engaging AI personalities and realized: what if those characters could actually teach? We envisioned a world where learners build relationships with AI tutors who make speaking feel safe from day one, not after months of grammar drills. What it does CharaLearn is the first platform where anyone can create and use AI language tutors with distinct personalities. Users choose from characters like Yuki (anime-loving Tokyo convenience store clerk) or Marie (warm Parisian café owner), then have natural voice conversations that gradually transition from mixed language to target language fluency. Each AI tutor has unique teaching styles, cultural contexts, and gentle correction methods. Think Character.AI meets Duolingo, but voice-first and confidence-focused. How we built it We orchestrated multiple AI systems to create persistent character personalities: Vapi AI : Real-time speech-to-speech conversations with <300ms latency Inworld : Character personality engines and emotional intelligence LlamaIndex : Context-aware curriculum generation based on character backstories Bright Data : Real-world cultural context and authentic scenarios Our architecture maintains character consistency across conversations while dynamically adapting difficulty. Each character has 500+ word personality prompts that define their teaching philosophy, cultural background, and correction style. Challenges we ran into Character Consistency : Maintaining Yuki's anime references and encouraging tone across multiple conversation turns while teaching effectively required extensive prompt engineering and context management. Multi-Modal Orchestration : Coordinating voice processing, personalit"
      }
    ]
  },
  {
    "file_path": "./devposts/chrome-music-overlay.html",
    "project_id": "chrome-music-overlay",
    "title": "Pain Drain Overlay",
    "tagline": "Have you ever fallen asleep while trying to get work done? Well the Pain Drain Overlay will spice up your work session with both music and an animated color background.",
    "hackathon": "",
    "built_with": [
      "aubio",
      "cython",
      "ffmpeg",
      "flask",
      "flask-restful",
      "html5",
      "javascript",
      "json",
      "madmom",
      "matplotlib.pyplot",
      "numpy",
      "pandas",
      "python",
      "requests",
      "scipy",
      "selenium",
      "subprocess",
      "sys",
      "time",
      "youtube-search-python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/766/086/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We wanted to create something that would provide a stimulation to users like coders who stay up late at night. In addition we gained some visual tips from the Windows Media Player from old systems such as Windows XP. What it does We take in a user input into a chrome extension, that would then find the music video from YouTube. After this, music is played along with colored animated border that will move based on the beat of the song that is currently being played. How we built it We created a chrome extension that is linked with an API that will take in user inputs and send it to the back end, where a program will search YouTube for the song. This will generate a link to the song, that is then used to auto play the song. At the same time, another program will analyze the song and generate an array of timestamps for the beat of the song, that is then used to animate a background that will move based on the beat of the song. Challenges we ran into The libraries for audio analysis required other libraries to be preinstalled, so we ran into a lot of issues when trying to download/import the libraries. Another issue we ran into was trying to animate the border that would sync with the beat of the song that is currently being played. Accomplishments that we're proud of We are proud of creating a chrome extension that takes the user input and finds the resulting video on YouTube correlating to the song title that was inputted into the extension. What we learned We learned that some libraries although they may not seem complex, require a lot of background work to be done before being able to be used. For example, the Aubio library used, requires Visual C++ 2019 and other libraries to be preinstalled before Aubio can be installed. What's next for Untitled The next step for this project would be to integrate this with a music company's program such as Spotify in order to gain access to their music servers. This will allow the program to animate the background and"
      }
    ]
  },
  {
    "file_path": "./devposts/chads.html",
    "project_id": "chads",
    "title": "Predictive Combat Arena",
    "tagline": "Upload your data, pick two ML algorithms, watch them train in your browser, then battle! Real training results become combat stats. Learn ML through gaming.",
    "hackathon": "",
    "built_with": [
      "ai",
      "csv",
      "ml",
      "pokemon",
      "react",
      "svelte",
      "sveltekit",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/642/899/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Dataset upload Battle configuration Pokedex card Performance analysis Pokedex Tactical battle gamemode Main page Pokemon battle gamemode Dataset upload Battle configuration Pokedex card Performance analysis Pokedex Tactical battle gamemode Main page Pokemon battle gamemode Dataset upload 1 2 3 4 5 6 7 8 9 Inspiration Machine learning and Artificial Intelligence can seem overwhelming, with concepts like gradient descent sounding too complicated or being presented in ways that don't engage audiences. We decided to create something completely original: a combat system where machine learning algorithms battle each other using real performance data. The Pokemon-style extension came later when a soundtrack played during our 3 AM development session, inspiring us to add the familiar gaming aesthetics to make the concept even more engaging. What it does Predictive Combat Arena transforms machine learning algorithms into fighters that battle using real performance data from your uploaded datasets. Upload a CSV file and watch six different algorithms train on your data using real scikit-learn running directly in the browser. Each algorithm becomes a custom-designed character with unique sprites, movesets, and combat stats derived from actual performance metrics like accuracy, precision, and recall. Select two algorithms to battle in a comprehensive Pokemon interface with health bars, type advantages, and special moves (attaques/boosts) representing real ML concepts like \"Bootstrap Assault\" for Random Forest or \"Kernel Trick\" for Support Vector Machines. The application features two battle modes: Pokemon-style combat for engaging battles and tactical mode focused on educational algorithm understanding. The application features a complete Pokedex for exploring algorithms, real-time training visualization , and comprehensive analytics dashboards with D3.js charts showing performance comparisons and interactive data exploration. How we built it Built with SvelteKit and TypeScript"
      }
    ]
  },
  {
    "file_path": "./devposts/chuckle.html",
    "project_id": "chuckle",
    "title": "Chuckle",
    "tagline": "Humor comes with practice 😉",
    "hackathon": "",
    "built_with": [
      "icanhazdadjoke",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I also spent a lot of time behind styling, and animations, which is not the best use of a Saturday evening."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/486/638/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Loader Dashboard don't judge my sense of humor based on the upvotes (you should see the downvotes) Loader Dashboard don't judge my sense of humor based on the upvotes (you should see the downvotes) Loader 1 2 3 4 (disclaimer: any jokes cracked on the duration of this post are purely unintentional. This kid has spent the last 18 hours coding a humor app- side effects were inevitable) Inspiration Before I start, here's a joke to crack you up:\n\"What do Alexander the Great and Winnie the Pooh have in common? Same middle name\" (source: Chuckle. ) As a young boy, I spent countless hours reading joke books titled, \"101 school jokes,\" \"500 animal jokes,\" \"200 puns that make you sound intelligent\" etc. I liked being the class clown and having smart comebacks. Joke books > text books From my experience, I believe that humor is a form of pattern recognition that can be improved by constant practice. It involves seeing everything around you from a new lens. Like your emotional quotient(EQ), your humor quotient(HQ)(yes I made that up) is also flexible. Chuckle is the new evolved version of joke books that enable you to improve your sense of humor. I seriously needed this(you'll see soon enough). What it does Chuckle is an educational platform to learn clever jokes and improve your sense of humor. On Chuckle, users can find a dashboard that contains some of the cleverest jokes on the internet. Users can upvote or downvote jokes to identify what they find funny. Based on the upvote and downvote, the dashboard is reorganized to show the highest rated jokes at the top and the most downvoted jokes at the bottom. Moreover, the upvotes dynamically update emojis on the side to become more extreme (funny --> funnier --> funniest). And downvotes make the emojis angry. If you've tired of your current selection of jokes, you can press the \"Clear dashboard and get new jokes button\" to be served some of the finest, funniest one liners on the world wide web. If your appetite for jokes is massi"
      }
    ]
  },
  {
    "file_path": "./devposts/classai-hw84is.html",
    "project_id": "classai-hw84is",
    "title": "ClassAI",
    "tagline": "A classroom platform that utilizes AI to pinpoint and summarize important sections of a lecture",
    "hackathon": "",
    "built_with": [
      "assemblyai",
      "css3",
      "express.js",
      "firebase",
      "html5",
      "javascript",
      "node.js",
      "scss",
      "tailwind",
      "vue",
      "vuex"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "PolyHacks - Hackatown 2022WinnerAssemblyAi challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/833/631/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ClassAI Home Page ClassAI Home Page ClassAI Home Page 1 2 English Inspiration As students, we struggle with online learning (especially online lectures) because they are often overwhelming and often filled with \"fluff\" (or technical issues). As a result, we want labels and/or timestamps that tell us the most important parts of a lecture. With AssemblyAI's API and the social challenge, we felt that it was a good opportunity to create something useful that we (and possibly other students) need. What it does ClassAI is a classroom platform where teachers can post video lectures. These video lectures are uploaded to Google's Firebase Cloud Storage, and then processed by both our backend and AssemblyAI's API to pinpoint and summarize the most important parts of the lecture. Once the video is processed, the teacher will be able to see the recommended timestamps and summaries. The teacher will then verify these timestamps/summaries and confirm the upload. The uploaded lecture, its timestamps, and summary can then be seen by students. We also implemented a class discussion for students to discuss with each other. We also have an amazing UI/UX as well as dark mode (so we can study at 2AM the night before the exam 😆) How we built it We built the core feature (processing the video with AI) using the following workflow: Upload video to our backend -> Upload the video from our backend to the cloud and get the public URL -> Pass the URL to AssemblyAI's API to process the video -> Get the resulting data from AssemblyAI's API -> Process/clean the data for the core information we need -> Upload the information and metadata to our Firebase database -> Show the information to the teacher for configuration -> Save teacher's configurations -> Video and timestamps/summaries can now be seen by students The database design was inspired by tree structures (in CS) and modified so that it worked with \"mini-hashtables\" The frontend was built using Vuex and Tailwind CSS to support dark mode. We"
      }
    ]
  },
  {
    "file_path": "./devposts/carhaj.html",
    "project_id": "carhaj",
    "title": "CarHaj",
    "tagline": "We are revolutionising the car owner's manual in a gamified experience.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "godot",
      "krita",
      "python",
      "rest"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Domain Name from GoDaddy Registry || Digital Gift Card Created by UX and AI integration",
      "HackUPC 2025Winner[MLH] Best Domain Name from GoDaddy Registry || Digital Gift Card",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/406/068/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Main menu Cupri gives you introductory tips Oh no! An indicator lit up! What could it be? Cupri is a silly folk Main menu Cupri gives you introductory tips Oh no! An indicator lit up! What could it be? Cupri is a silly folk 1 2 3 4 5 6 7 8 9 Inspiration SEAT's unique challenge stood out to the team.  We saw an opportunity to learn technologies we had never used, such as game engines and LLMs. We also got to flex our creative skills in a way a hackathon has never demanded from us before. Game design and asset creation are a whole beast we had to tackle face on for the first time in this fast-paced environment. What it does CarHaj allows new owners of the Cupra Tavascan to familiarize themselves with the unique features of their new car. Through fun, fast-paced activites and with the help of Cupry, users can build an intuitive sense of all the indicators on their car. CarHaj also serves as a quick-reference manual, and the users can send questions directly to Cupry, and get an answer on topics related to the CUPRA Tavascan. How we built it CarHaj is built using the Godot game engine, an open source game engine that provided us with a ton of flexibility to make this project possible. We also tried out LLMs - Communicating via REST with Google Gemini 1.5 Flash, we were able to give Cupry an aloof but encouraging personality. Challenges we ran into We encountered some issues with Godot and vanishing files, which we believe may have been due to some git shenanigans. We also encountered issues with Gemini. We wanted to use 2.0 Flash at first, but it turns out it has a massive bug that affects the caching function for free users, disallowing us from using it at all. Accomplishments that we're proud of We're really proud of the courage we had as a team to attempt a project so alien to us. Building CarHaj demanded us to develop new abstract skills like game design and asset creation. What we learned We all learned how to use Godot and GDScript, as well of touching up on using"
      }
    ]
  },
  {
    "file_path": "./devposts/clean-up-the-beach.html",
    "project_id": "clean-up-the-beach",
    "title": "Clean Up The Beach",
    "tagline": "Combating global plastic pollution via beach cleanups—TOGETHER",
    "hackathon": "",
    "built_with": [
      "axios",
      "css3",
      "geolocation-api",
      "html5",
      "javascript",
      "leaflet.js",
      "openstreetmap",
      "three",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Empowerment Hack HackBytes Coastal Hacks Winner Third Overall Created by Anita Yip Product owner, p",
      "Best Empowerment Hack HackBytes Coastal Hacks Winner Third Overall Created by Anita Yip Product own",
      "Hydra HacksWinnerBest Empowerment Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/005/173/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Marine litter is human-created waste that has been discharged into the coastal or marine environment. Most of it is plastic, and it is one of the most pressing global environmental challenges impacting the planet. Marine litter is not only ugly – it can harm ocean ecosystems, wildlife, and humans.  The amount of plastic waste entering the ocean from land each year exceeds 4.8 million tons. And because plastic takes a long time to degrade, the issue only multiplies as the litter increases. One way coastal communities respond to this challenge is through the civic environmental stewardship practice of volunteer beach cleanups. Beach cleanups can reduce litter, protect our ocean, and raise awareness about litter and plastic pollution. What it does I created a website to raise awareness, enable people to organize beach cleanups, and contact organizations working to make this happen at a global scale. How we built it We used HTML, JavaScript, and CSS to build the website. Leaflet and openstreetmap were used for the map, Axios for API calls, and Google Cloud's geolocation API to convert addresses to lat/lon coordinates to place markers on map. Three.js and Vite.js were used for the game. Challenges we ran into Learning front end and CSS animations and having them coordinate with one another in terms of timing and interactivity and how it shows up was challenging! While it left less time to work on more functionality, but I thought it important to learn how to use website design to tell a story. There were also files too big for github to take in for the 3D graphic assets, so I had to zip the folder. Accomplishments that we're proud of Created a website and thought about how to design one where website design aids the message and helps tell a story. Also used geolocation api, leaflet, and openstreetmap for the first time!!! What we learned Lots of animation in 2d and 3d, connecting front end to a map, and in retrospect how to structure website better. What's ne"
      }
    ]
  },
  {
    "file_path": "./devposts/clipcut.html",
    "project_id": "clipcut",
    "title": "ClipCut",
    "tagline": "ClipCut provides users with complete end-to-end video editing services. Our product gives users the ability to transcribe their videos, segment them, and get sentiments with our AI automated system.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "javascript",
      "openai",
      "opencv",
      "react",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/594/592/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ClipCut ClipCut 1 2 3 4 Inspiration As fans of films and being part of the generation that grew up with much of its video entertainment deriving from the internet, we were always drawn to video as a medium for personal expression. That being said, the industry has been hit with copious amounts of criticisms lately.\nWhile the public is currently aware of the mistreatment of entertainment employees with the actors' and writers' strikes, they are still vastly aware of the undercompensation, mistreatment, and overworking of the people behind the scene. Though critics have been harsh on current CGI and editing choices, the truth is the crew behind the scenes is overloaded with vast amounts and work and are not given the proper amount of time to complete their projects. They are rushed and forced to push uncompleted work to make unrealistic quotas. This is where ClipCut comes in. Clip cut efficiently automates the preprocessing of the film leaving the user with digestible clips anywhere to sections of the movies to significant scenes of the film. ClipCut allows users to take each segment one by one describing it with transcribable text gathered from the scenes themselves. Moreover, Clip also uses generative AI to assign each segment a tone metric to aid users with basic scene analysis. What it does ClipCut brings the power to the editors of films from animation to feature films. The software automates the preprocessing of the film, so film crews can allocate more of their time to use their artful skills to craft a more beautiful film. Our product does all of the busy work of the film maker such as background noise suppression and stabilization. It is also able to transcribe scenes of the film and use that transcribable data along with sentiment analysis to sense the tone of the scene for the editor to swiftly work in. The program gathers these scenes and cuts and creates segments which can be contextualized and identified by the transcripted dialogue. As the program compa"
      }
    ]
  },
  {
    "file_path": "./devposts/classify-skupw3.html",
    "project_id": "classify-skupw3",
    "title": "Classify",
    "tagline": "Create informational, visually stunning class schedules using AI!",
    "hackathon": "",
    "built_with": [
      "gemini",
      "nextjs",
      "react-flow",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/385/914/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 ✨ Inspiration Let's be real, trying to figure out courses at UCR (and tbh, most unis 😬) is kinda a hot mess 🔥. Info is scattered everywhere , some departments are gatekeeping 🤫, and the stuff you do find is confusing af. Trying to plan your 4-year sched? Especially as a freshman? Good luck, fam 😩. We were tired of the stress, so we decided to build something to fix it. ✌️ It's the disorganization and the struggle to plan that really got us wanting to create Classify. 🚀 What it does Meet Classify! ✨ Your new academic BFF. It's got this super smart AI Chatbot 🤖 – just tell it what courses you've slayed so far, and it'll recommend what's next on your academic glow-up journey. But wait, there's more! 💅 It doesn't just list courses; it maps them out in a visually stunning ✨ prerequisite flowchart. It's interactive too! Click on any course bubble to get the lowdown (course description, units, etc.). Planning just got a major level up. 🚀 🛠️ How we built it We cooked this up with some cool tech! 🧑‍💻 Here's the stack: Next.js ⚡️ (Frontend & Backend vibes) React ⚛️ (Making the UI pop) TypeScript ⌨️ (Keeping our code clean) Tailwind CSS 🌬️ (For that ✨aesthetic✨ styling) shadcn/ui 🎨 (Sweet pre-built components) Google Gemini AI 🧠✨ (The brains behind the chatbot) React Flow 🌊 (Making those flowcharts flow) 😭 Challenges we ran into Ngl, the struggle was real sometimes 😅. Data Hunt: Hunting down course data scattered across random UCR websites felt like a treasure hunt gone wrong 🗺️❌. Seriously, why is it hidden like that?! Schema Drama: Figuring out how to organize all that inconsistent data (the schema) gave us major headaches 🤯. Flowchart Boss Battle: Don't even get us started on making the prerequisite flowchart algorithm actually work and display everything correctly – that was a whole boss battle! 👾 Getting those lines and prereqs to look good and be accurate took some serious brainpower. 🎉 Accomplishments that we're proud of Honestly, we kinda slayed this? 💅 We're sup"
      }
    ]
  },
  {
    "file_path": "./devposts/climaquiz.html",
    "project_id": "climaquiz",
    "title": "ClimaQuiz",
    "tagline": "ClimaQuiz is a fun and informative trivia game designed to test your knowledge about climate change aiming to educated players in an entertaining quiz format",
    "hackathon": "",
    "built_with": [
      "google",
      "java",
      "slides"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I have noticed many negative environmental changes in the past few years, especially with air quality. One thing I noticed in particular is that most of my friends and family had no clue about Climate Change, and what it was. What it does My product quizzes the user on Climate Change, with three different difficulty levels and three different categories. How we built it I used java, and also google slides. Challenges we ran into I found it extremely difficult to read questions from a text file, but eventually figured it out. Accomplishments that we're proud of That I made a fully functioning project using things such as file io and threads, which I have never learned before. What we learned I learned a lot more about Climate Change while making this quiz, and also learned a lot more about file io and threads in Java. What's next for ClimaQuiz I plan to add even more questions and categories, and make a UI displaying the timer for the user. I also plan to use UI to make the game more visually aesthetic. Built With google java slides Try it out GitHub Repo Submitted to CS Base Climate Hack Sparkhub 2024 Hackathon KITE Hacks Nova Hacks I - (Internship, Project Article, $24K Non-Cash Prize) Created by Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/casu.html",
    "project_id": "casu",
    "title": "Casu",
    "tagline": "At CasaTutor, we let students do the teaching. Senior students get to mentor their juniors in structured environments, creating a sustainable tuition ecosystem that exchanges experience for knowledge.",
    "hackathon": "",
    "built_with": [
      "flask",
      "html5",
      "react",
      "scss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Chosen theme and problem statement Giving back, Question 1 Inspiration --\nThe members of Casu come from diverse educational backgrounds, and we’ve all been fortunate to study in well-structured, resourceful academic environments. However, with those experiences comes a greater awareness of the inequality that plagues our society, and more specifically, our education system. Some of our team members are volunteer tutors and therefore have first-hand insight into the academic barriers many underprivileged students face. As such, it was an appropriate juncture to create a product that allowed students like ourselves to do their part in leveling the playing field, so that we can all have brighter futures to look forward to. What it does CasaTutor is a matchmaking web platform that connects older, more experienced students with their juniors around Singapore. Allowing users (both prospective tutors and tutees) to narrow their searches based on subject, syllabus, and academic level, the platform is aimed at developing a tuition ecosystem that is underpinned not by monetary transactions but the equally beneficial exchange of experience and knowledge. How does your hack answer the problem statement We developed our hack to act as a direct response to the problem statement, by offering an accessible and sustainable volunteering opportunity to students who want such opportunities. How we built it The application was built with these main technologies: Bootstrap CSS JS We chose these low-tech alternatives as they suited the timeframe of the project, and allowed us to implement features as quickly as possible. Challenges we ran into A main challenge we ran into was organization. Given the hectic schedule of the project and the amount of boilerplate code that needed to be written, things got out of hand quickly. Thankfully, we were able to take a step back and refactor our code by the end. Accomplishments that we're proud of Full backend integration \nDesigns\nFiltering List\nCodin"
      }
    ]
  },
  {
    "file_path": "./devposts/clothology.html",
    "project_id": "clothology",
    "title": "Clothology",
    "tagline": "Not sure what to wear in unpredictable weather? Clothology allows you to choose your clothing attire based on what others in your area are wearing.",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-cloud",
      "inception",
      "javascript",
      "kaggle",
      "keras",
      "numpy",
      "opencv",
      "python",
      "react-native",
      "sqlite",
      "tensor-flow",
      "weatherstack"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/913/009/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Weather screen Splash screen Main screen 1 Main screen 2 Weather screen Splash screen Main screen 1 Main screen 2 Weather screen 1 2 3 4 Inspiration Toronto's temperature is extremely sporadic and as such, can sometimes get confusing when choosing clothes to wear. Sometimes its too hot for a thick jacket and too cold for a hoodie. We wanted to address this problem. What it does Through our mobile app, users are notified of what other people in their area are wearing by analyzing publicly available live-camera footage from CCTV cameras and other sources. This greatly helps users in choosing the right attire for the unpredictable outdoor weather. How We built it Our cross-platform app is built with a React Native frontend and powered by a Flask backend. We also utilize extensive image detection and recognition through our implementation of OpenCv and Inception V3 to detect and classify clothing from video feeds. Challenges We ran into Clothing is extremely similar in nature and thus, it is extremely challenging to distinguish between them. This is extenuated by the fact that there are very few clothing classification datasets to train on, leading to a class imbalance problem while training data. Furthermore, there were problems with collaborative editing while training models which could not be committed to git. Accomplishments that We're proud of We are proud of putting together an idea in such a short period of time and achieving our main goals for the application in the time frame. What We've learned This experience was a great opportunity to further our teamwork skills and the ability to deliver solutions in fast-paced work environments. What's next for Clothology We will be working on this solution more in our freetime, and are looking to deploy our app by the end of Q2. Built With flask google-cloud inception javascript kaggle keras numpy opencv python react-native sqlite tensor-flow weatherstack Submitted to UofTHacks VII Created by I worked as UI/UX and front-"
      }
    ]
  },
  {
    "file_path": "./devposts/civilaization.html",
    "project_id": "civilaization",
    "title": "civilAIzation",
    "tagline": "A historical roleplay game centered around forming alliances and wars to establish global domination! Intended as a fun way to learn history.",
    "hackathon": "",
    "built_with": [
      "ai",
      "gpt",
      "hlsl",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Video Game Hack Created by Arihan Sharma Edem Hoggar",
      "Hack the 6ix: Best Video Game Hack Created by Arihan Sharma Edem Hoggar",
      "Hack the 6ix 2023WinnerHack the 6ix: Best Video Game Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/566/866/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Ever mused over Canada being the ultimate boss of the world? We took leaders like Putin and Hitler, imagined their strategies in Canadian hands, and thought, \"Why not game it?\" What it does You helm Canada. Your mission: global domination. Navigate tricky trade routes, master diplomacy, or go full combat mode against iconic historical leaders. It's strategy, fun, and history all in one. How we built it Unity is our main stage. We wanted the terrains to look stylized and the animations smooth, which meant a lot of painstaking hours for our front-end team. Now, the actual gameplay, like negotiating with Churchill or strategizing against Cleopatra, is where GPT-4 kicks in. We used some clever API integrations to get the AI to generate responses based on historical facts and possible outcomes. Yep, you can have an actual debate with AI-modeled world leaders! Challenges we ran into Meshing GPT-4 with Unity was an extremely difficult task. Getting GPT-4 to output anything formatted in a certain way is hard enough, so syncing real-time game events with AI decision-making had its moments. We also wanted the game to be more than just point-and-click, so blending historical accuracy with intuitive gameplay was crucial. We ended up spending the first 8-hours of development (roughly 1/4 the time) just perfecting the initial prompt, to the point where it can cost upwards of 2 cents per use! On the other hand, we wanted the entire game to use real-world map data that responds dynamically to our requests, which was quite difficult to mesh again with the massive JSON dumps from GPT-4. In the end, however, we ended up being able to assemble all the systems together just in time! Accomplishments that we're proud of We feel we accomplished a very significant amount on both the front-end and back-end. As aforementioned, creating a prompt that would be easy to interpret within Unity, fit within the scope of the actions and events of the game, etc. was an extremely arduous ta"
      }
    ]
  },
  {
    "file_path": "./devposts/cleant.html",
    "project_id": "cleant",
    "title": "CleanTech",
    "tagline": "A uniquely integrated system to identify and eliminate pollution.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "flask",
      "javascript",
      "keras",
      "machine-learning",
      "mapbox",
      "networking",
      "nextjs",
      "python",
      "tensorflow",
      "tinydb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/857/572/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Getting data from gps Flowchart of our implementation Image of the app Getting data from gps Flowchart of our implementation Image of the app Getting data from gps 1 2 3 4 The problem There is an immense amount of plastic and other waste scattered around populous cities. Clean-up efforts by nonprofit organizations require a large number of volunteers and are inefficient because they must check and clean up large areas of the city. Our solution We are utilizing drones to scan urban areas for trash density, processing and storing the data on a server, and using an app to mark locations for volunteers and to track clean-up efforts. How we built it We have attached a flowchart in the project media detailing how the solution we built works. What's next for CleanTech Testing of our drone data collection at high altitudes and speeds Building a larger model to more accurately detect a variety of pollution Integrate the data collection that currently runs on a phone connected to the drone into a programmable drone Built With expo.io flask javascript keras machine-learning mapbox networking nextjs python tensorflow tinydb Try it out GitHub Repo Submitted to Hacktech by Caltech 2024 Created by Vyaas Baskar Aravindkrishna Arivudainambi"
      }
    ]
  },
  {
    "file_path": "./devposts/chill24.html",
    "project_id": "chill24",
    "title": "Chill24",
    "tagline": "A chill project for the Check24 challenge.",
    "hackathon": "",
    "built_with": [
      "cpp",
      "go",
      "mysql",
      "python",
      "sql",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/151/941/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chill gives you recommendations based on your situation, so you don't have to worry about hyper-parameters Chill24 is the new way of browsing the best offers You can talk to Chill to obtain better recommendations for your trip Chill gives you recommendations based on your situation, so you don't have to worry about hyper-parameters Chill24 is the new way of browsing the best offers You can talk to Chill to obtain better recommendations for your trip Chill gives you recommendations based on your situation, so you don't have to worry about hyper-parameters 1 2 3 What it does Chill24 allows you to transform your thoughts into a more sensible intermediate representation, which narrows down the search space to more sensible queries. This allows to focus the available compute to a smaller number of parameter combinations, which allows much better scaling of the infrastructure. This approach aims to take away the pressure to keep optimizing the search speed, since this will eventually reach a plateau if one does not scale up horizontally. Challenges we ran into We went through quite a journey to end here... First we tackled the challenge through a go frontend both with a naive key-value store (badgerdb) and then through MySQL. We quickly realized that although using Go was a good approach due to its speed, we needed to develop in a language where we had more experience to decrease prototyping times. We decided to tackle the problem from a very  different angle, and took the opportunity to change to c++. Through all of this, we divided our forces to develop a completely different approach which was the one we liked the most and pursued further, which is the result of Chill24. Accomplishments that we're proud of Rapid prototyping, not fear of pivoting, using 5 different programming languages :) Built With cpp go mysql python sql typescript Try it out GitHub Repo Submitted to hackaTUM 2024 Created by Francisco Kusch emsilouise Adrian Lieven"
      }
    ]
  },
  {
    "file_path": "./devposts/codefusion-v9eq2x.html",
    "project_id": "codefusion-v9eq2x",
    "title": "CodeFusion",
    "tagline": "Talk, gesture, and bring your code to life.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini",
      "intersystems",
      "openai",
      "opencv",
      "visual-studio-code"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Warp: Best Developer Tool (Keychron Mechanical Keyboard per team member) Created by Varun Sahni Dav",
      "TreeHacks 2025WinnerWarp: Best Developer Tool (Keychron Mechanical Keyboard per team member)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/270/252/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration 💡 We were inspired by the thought of, \"what if Cursor could do this?\" Cursor composer, a powerful tool in it of itself, how much crazier would it be for Cursor to have access to video and audio, along with our terminals so not only could it write code, it would verify it's capabilities and more. What it does ⁉️ You start with screen recording and talking to describe the issue or enhancement needed. We then process this using gemini flash 2.0 and turn it into a structured schema organized by timestamps. We extract relevant files and urls and then extract html from the web pages and turn them into embeddings. We extract relevant text using a RAG pipeline with Intersystems-IRIS. Once we have all this info we use codegen to edit relevant code and verify correctness by running the application. How we built it 📝 TypeScript/React - VSCode Extension Python-Flask - Server Backend Codegen + Langchain - Agentic Code Editing Gemini - Video recording parsing IRIS - RAG\n-OpenAI - Embeddings Challenges we ran into 😡 Streaming using the gemini live API was very difficult. We were able to stream video and audio and get real time responses asynchronously, but the text inputs stopped working. We instead processed the video before sending it to gemini flash 2.0 with a specific schema enforced. Setting up the VS Code extension to have the UI in the side panel instead of the tab was challenging. In addition, the extension was a web view and restricted display capture so we had to find a workaround to send video to the backend. Accomplishments that we're proud of 😸 We are proud of getting a fully functional backend with a multifaceted backend. We were able to get 3 distinct components (along with the frontend VS code extension) working: the video processing into a structured schema by gemini, the RAG with intersystems, and the agentic flow and tool calling with codegen. Built With flask gemini intersystems openai opencv visual-studio-code Try it out GitHub Repo Submitted to Tr"
      }
    ]
  },
  {
    "file_path": "./devposts/city-scout.html",
    "project_id": "city-scout",
    "title": "City Scout",
    "tagline": "City Scout is an AI-powered GPS app using Azure to help you live like a local—guiding you safely around crime hotspots, accidents, and speed traps while discovering the best city attractions.",
    "hackathon": "",
    "built_with": [
      "api",
      "cloud",
      "database"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/336/826/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration Google Maps has, on several occasions, routed users into dangerous areas, leading to serious consequences. Notable incidents include a tourist being fatally shot in a Brazilian favela after being misdirected, hijackings in South Africa, detours through high-crime neighborhoods in Atlanta, and tourists getting stranded on unsafe roads in Norway and Colorado. In Hawaii, some users were even led across hazardous lava fields. These incidents often stem from the app prioritizing speed over safety, lacking crime data integration, and failing to account for local context. While Google has started implementing features to avoid unsafe areas, the coverage remains limited, and users are advised to stay cautious, cross-check routes, and avoid unfamiliar shortcuts. What it does Existing navigation apps prioritize speed and convenience but often neglect user safety, frequently guiding travelers through crime-prone areas or hazardous intersections without warning. Numerous real-life incidents highlight this critical oversight—tourists and commuters unknowingly entering unsafe neighborhoods because their apps lack crucial local safety insights. City Scout was inspired by the need to empower users with tools to safely explore urban environments, allowing them to confidently \"live like a local\" by avoiding potential dangers while enjoying authentic city experiences. How we built it The integration process involves three key steps. First, we’ll fetch road network data using the Azure Maps Route API. Next, we overlay crime data sourced from public platforms, such as city crime reports. Finally, we apply a gradient-based pathfinding method to calculate the safest routes based on these inputs. Challenges we ran into Some of the challenges we ran into involved managing real time routing accuracy as well as assigning crime rates from the databases we obtain from the city of Houston Police Department. Accomplishments that we're proud of Some accomplishments we are p"
      }
    ]
  },
  {
    "file_path": "./devposts/chungus.html",
    "project_id": "chungus",
    "title": "Project: Sixtainability",
    "tagline": "More and more people are ditching their personal cars for carsharing and carpooling services. We propose a future-proof and sustainable solution that is oriented towards electrical vehicles.",
    "hackathon": "",
    "built_with": [
      "canva",
      "digitalocean",
      "fastapi",
      "flask",
      "husky",
      "python",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/304/983/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Facts With long-term benefits in mind! The cycle of increased car-sharing and reduced private cars The dashboard, used to analyze both simulated and real life API data Tools used to build the project Facts With long-term benefits in mind! The cycle of increased car-sharing and reduced private cars The dashboard, used to analyze both simulated and real life API data Tools used to build the project Facts 1 2 3 4 5 Inspiration A typical passenger vehicle emits about 4.6 metric tons of carbon dioxide per year. Luckily our generation seems to be the one to take this number seriously. As such, experts predict a massive 80% drop in car ownership by 2030. This alone leaves a ton of room for preparations, programs that welcome the change, future alternatives, and Sixt seem to share our vision in building a greener future! What it does The project “Sixtainability” is a long term project idea that would not only prepare the metropolitan cities for a greener future, but also help Sixt expand their EV fleet due to increased awareness and access to charging stations. Our “Sixtainability” platform allows real time analysis of problematic areas regarding charging and similar bottlenecks. Our proposed solution comes in the form of a loyalty status and a mutually beneficial contract between the loyal customer and Sixt as a reward. The platform runs using completely real-world data with exception of Sixt specific car information and user information that we didn't get the access to this weekend. Fortunately the switch between simulated and Sixt data is a couple clicks away allowing to easily integrate the official Sixt developer API into the dashboard. How we built it Ashmi, our backend Expert, got the responsibility of building the backend for our system using Python and FastAPI. We built different end-points using FastAPI - a modern, high performing Python framework.  The app was then dockerised and deployed on DigitalOcean. Gilles, our trusty frontend guy, was responsible for build"
      }
    ]
  },
  {
    "file_path": "./devposts/civicup.html",
    "project_id": "civicup",
    "title": "CivicUp",
    "tagline": "Local citizens lack a simple and trustworthy platform where they can participate in local decisions and clearly understand the information presented.",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/407/336/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were heavily inspired by websites like the Davis county's towns meeting site, along with many others such as the government official websites for voting reminders and information, which all commonly showcased accessible open information to dates, locations of towns meeting and also information about the local government. We wanted to have a similar colorful and easy to navigate interface for our project as well. What it does CivicUp provides an accessible and reliable source of different resources in health, housing, to provide an easier breakdown of topics and ideas related to how they can reach for help and get accurate up to date information related to elections and government events. They can also learn about politicians, directly connecting to them and sharing their anonymous thoughts about the current political situation. How we built it Through Figma, we created various lo-fi to mid-fi and high-fi demonstrations of CivicUp. In our initial stages of sketching and brainstorming, we established pain points that users tend to face upon their engagement with the local government. Being able to understand and listen to their common struggles, helped guide us in the right direction of including features that would help alleviate their challenges. We settled on creating a verification process, allowing our users to sign up and create an account. We truly wanted this app to have an element of personalization. Thus in the process, we decided to customize the app to be as useful and helpful to the user as possible, with filters and self assessments in the beginning of the app evaluating their needs and ideas they are most passionate for. Challenges we ran into Some challenges we faced during the Design stage, was establishing a consistent brand identity across our app. The main colors we selected to represent CivicUp was orange and purple. For our onboarding images, we wanted to include a consistent arrangement of orange backgrounds for each page. However"
      }
    ]
  },
  {
    "file_path": "./devposts/climasky-innovations.html",
    "project_id": "climasky-innovations",
    "title": "ClimaSky Innovations",
    "tagline": "IMAGE-based environmental (sky) analysis with AI.",
    "hackathon": "",
    "built_with": [
      "asyncio",
      "flask",
      "io",
      "jsx",
      "matplotlib",
      "nextjs",
      "os",
      "pathlib",
      "pil",
      "progressbar",
      "python",
      "react",
      "torch",
      "torchvision",
      "typescript",
      "utils"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall UNity Hacks Winner 3rd Place Overall High School Hack for UN's 17 Goals HackQuest 24' Creat",
      "Advanced Hackathon: Best Overall UNity Hacks Winner 3rd Place Overall High School Hack for UN's 17",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/774/860/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home Page Cinematic Demo Home Page Cinematic Demo Home Page 1 2 3 4 Inspiration Air quality is a pressing issue that affects populations worldwide. Nearly 7 million lives are prematurely cut short every year due to air pollution, making it one of the most pressing threats to worldwide health. While air pollution causes hazardous conditions worldwide, it affects every person living on the Earth in one way or another. Our inspiration derives from the danger and risks that air pollution poses, with the intention of bringing greater awareness to air pollution. This mainly aligns with goal 13 of Climate action in creating a greener future but also intersects goal 3 and 10 of good health and reduced inequalities. What it does This program utilizes images to analyze air quality in many areas, especially in areas that are not able to afford expensive air quality monitoring stations. This is an AI for accessibility or health. How we built it The program was built using Python's Tensorflow module to create an AI/ML model trained on images of various levels of air pollution. Images were positively attributed to certain air pollution levels and fed into the model in order to train the model. Then, this model was placed into a UX-friendly interface and placed onto a website with ease of access through a photo upload. Challenges we ran into We had to develop through the night. One of the biggest challenges was getting the ML model to successfully learn and discern images, as well as integrating two coding languages to post the ML model on a website. Accomplishments that we're proud of We were able to successfully develop an ML model that could correctly identify images between bad and good air quality as a team of high school students, creating an app that anyone in the world can use to save the lives of millions of people. What we learned We needed to be thinking about code integration as the ML model was developed. This way, the code would be ready to be integrated and it would"
      }
    ]
  },
  {
    "file_path": "./devposts/climate-change-quiz-daiwrc.html",
    "project_id": "climate-change-quiz-daiwrc",
    "title": "Climate change quiz",
    "tagline": "My team is doing a climate change quiz to raise awareness on the environment.",
    "hackathon": "",
    "built_with": [
      "html"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "It's a quiz (10 questions) about climate change. Built With html Submitted to MariHacks 2020 Created by Laurence Liang"
      }
    ]
  },
  {
    "file_path": "./devposts/classmate-kqsn18.html",
    "project_id": "classmate-kqsn18",
    "title": "ClassMate",
    "tagline": "An interactive classroom assistant that allows students to utilize OpenAI to further their understanding with teacher-given prompts to guide learning and discourage unsanctioned cheating.",
    "hackathon": "",
    "built_with": [
      "c",
      "css",
      "flask",
      "html",
      "openai",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/390/526/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration ClassMate was inspired by the boom of OpenAI and ChatGPT. We sought a way to integrate the powerful tool of ChatGPT into classrooms to help students further explore academic concepts while also mitigating cheating and abuse of the AI tool. What it does ClassMate compiles together a student's classes and topics covered in each class. Upon clicking each topic page, students are given concept-related prompts written by their teachers to help guide their exploration. Moreover, they are also given fill-in-the-blank sentence frames which they can fill out with specific topics/skills they would like to improve. These pre-generated prompts aim to guide students utilizing AI instead of allowing free roaming in order to discourage cheating. Prompts selected by the student are then inputted via the OpenAI API and an answer is returned to the student. How we built it We started by building the core functionalities of our website through HTML, CSS, and Flask. We also used SQLite to build a database to store key website information like user logins and user class topics/questions. Once we had the website up, we embedded the OpenAI API to the class topics section to help with student questions. Challenges we ran into Building a database from scratch using SQLite was definitely not easy and took a lot of trial and error to get going. Also, it was challenging to code the HTML and CSS formatting, as well as getting correct inputs and outputs for various functions like user logins and user questions for the OpenAI API. Accomplishments that we're proud of We're proud of being able to integrate the OpenAI API into our aesthetically pleasing and user-friendly website. We were also proud that we were able to turn a tool that is associated with possible academic abuse into a tool for improved student learning and teaching. Built With c css flask html openai python sqlite Try it out GitHub Repo Submitted to TreeHacks 2023 Created by Kenan Erol winiboya Aboyure Jennifer Truon"
      }
    ]
  },
  {
    "file_path": "./devposts/codeconnect-me6y5p.html",
    "project_id": "codeconnect-me6y5p",
    "title": "CodeConnect",
    "tagline": "Connect, Collaborate, Code Better!",
    "hackathon": "",
    "built_with": [
      "express.js",
      "firebase",
      "github",
      "mongodb",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/557/181/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "chatbody motive users to get connected with matchedUsers with whom the user can chat chatbody motive users to get connected with matchedUsers with whom the user can chat chatbody 1 2 3 4 5 ConnectCode: A Coding Buddy Matchmaking Platform 💡 Inspiration 💡 ConnectCode draws inspiration from popular matchmaking apps like Tinder, aiming to connect developers and programmers based on their skills and talents. As hackathon participants ourselves, we understand the value of finding the right coding buddy. We wanted to create a platform that not only fosters collaboration but also provides a distraction-free communication channel for developers to find their perfect coding partners. ⚙️ Functionality ⚙️ ConnectCode is a comprehensive platform built on the MERN (MongoDB, Express, React, Node.js) stack with Firebase for authentication. The platform consists of three main components: Landing Page The landing page introduces users to ConnectCode's mission and functionality. It sets the stage for developers seeking coding partnerships and emphasizes the platform's benefits. Connect Dashboard The heart of ConnectCode is the Connect Dashboard, where users can browse through profiles of fellow developers. Users can like or dislike profiles based on skills, interests, and talents. When a mutual \"like\" occurs, both users become eligible to communicate with each other. Communication Channel Once a match is established, ConnectCode provides a secure communication channel for users to engage in direct messaging. This feature ensures a distraction-free environment, focused solely on productive coding collaboration. 🏗️ Technology Stack 🏗️ Frontend: The user interface is developed using React, offering an intuitive and responsive design. Backend: The backend logic is powered by Express.js, providing a robust foundation for handling user interactions and data management. Database: MongoDB is used to store user profiles and match data efficiently. Authentication: Firebase authentication ensure"
      }
    ]
  },
  {
    "file_path": "./devposts/city-search-9gzx0b.html",
    "project_id": "city-search-9gzx0b",
    "title": "City Search",
    "tagline": "An interactive algorithm and map that recommends a place to live",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/254/581/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "The final output map in the web application Screenshot of what the parameters section looks like within the original notebook Rendered display after filling out the questionnaire within the original python notebook The final display of the sliders in the web application The final output map in the web application Screenshot of what the parameters section looks like within the original notebook Rendered display after filling out the questionnaire within the original python notebook The final display of the sliders in the web application The final output map in the web application 1 2 3 4 5 Inspiration We were given the idea by the organizers of the event as the beginner challenge for the TAMU Datathon. What it does City Search recommends a city to the user based on their perceived importance of certain characteristics of a location. Some characteristics are rather straightforward, such as crime rate or average cost of rent, but others were more subjective, such as how \"happy\" residents consider themselves to be or how \"developed\" the country a city is located in is. How I built it This application was built using python with the panda and plotly libraries. The datasets utilized for its creation are cited within the README in the provided GitHub link. Challenges I ran into One of the largest challenges was finding constants to multiply the variables by so nothing was skewed towards a certain value. For example, some characteristics are within a range of 0 to 1, while others are in the thousands of dollars, and constants had to be applied to said values so they were all roughly within the same range. (Fun fact- I had my roommate test the algorithm and found that originally our results were skewed towards Sweden). Accomplishments that I'm proud of I'm proud of finding the datasets! It was a lot more difficult than previously expected. What I learned I learned a lot about libraries within python that are used for analyzing and visualizing data. What's next for City Searc"
      }
    ]
  },
  {
    "file_path": "./devposts/cleancurrent.html",
    "project_id": "cleancurrent",
    "title": "CleanCurrent",
    "tagline": "Using a systematic approach of targeting local processing facilities, CleanCurrent will be able use AI to automate the trash sorting process and bring a much higher level of accuracy.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "pytorch",
      "tensorflow",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/447/254/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Problem Our Mission Title page The Product The Problem Our Mission Title page The Product The Problem 1 2 3 4 5 Inspiration Millions of marine animals are being affected by the increased pollution of the oceans from materials that could be easily recyclable. Let's put this into perspective. According to a statistic in 2018 from EPA.gov, roughly 292.4 million tons of MSW (or municipal solid waste) was generated. “However, only 69.1 million tons were actually recycled. That’s only 24% or roughly 1/4th of waste that is recycled.” What it does This is where CleanCurrent takes over. We decided to embrace a more strategic approach by working with trash centers at the local level. This helps us mitigate the waste issues of more people than any PSA. Using Artificial Intelligence, CleanCurrent automates the trash sorting process and helps the landfills bring trash to their correct locations. Challenges we ran into Learning how to create the AI that could recognize the waste, with google collab having some package errors. Accomplishments that we're proud of Some accomplishments that we're proud of are our front end and ability to create such a complex model in such a short time. What we learned Coming into this hackathon we did not know too much about the topic of waste management and how recyclables affect the environment, but through further investigation and research into the topics we learned the importance of the situation (such as the amount of recyclable plastic that ends up in landfills and pollutes the ocean). We also picked up on several new technologies while working on the project such as TensorFlow to create the AI and new HTML tags to create more sophisticated UI controls. What's next for CleanCurrent We will expand CleanCurrent's capabilities to Live predictions. Then, we will get into contact with waste processing facilities and convince them to use our product. Built With css3 html5 javascript pytorch tensorflow unity Try it out GitHub Repo Submitted to L"
      }
    ]
  },
  {
    "file_path": "./devposts/clark-communities.html",
    "project_id": "clark-communities",
    "title": "Clark Communities",
    "tagline": "Messaging app designed to increase intimacy between students and faculty members as well as their peers",
    "hackathon": "",
    "built_with": [
      "flask"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/913/328/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Email is inconvenient and we wanted an easier way to message students and teachers. What it does This is a messaging app that allows students to create groups with other members within their community. How we built it Built using ReactJS and Flask Challenges we ran into Accomplishments that we're proud of What we learned What's next for Clark Communities Built With flask Submitted to Clarkathon 2022 Created by Caleb Sacks"
      }
    ]
  },
  {
    "file_path": "./devposts/clique-hbipvx.html",
    "project_id": "clique-hbipvx",
    "title": "Clique",
    "tagline": "Semantic search for efficient onboarding",
    "hackathon": "",
    "built_with": [
      "bash",
      "flask",
      "modal",
      "mongodb",
      "openai",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Education Hack -- Track Prize🎓 Clique caters to research groups, aiming to unify programming with d",
      "Best Developer Tool by Warp🛠️",
      "Best Education Hack -- Track Prize🎓",
      "Best Use of AI in Education👨‍🏫",
      "Best Use of MongoDB Atlas📊",
      "Best .Tech Domain Name 🥬"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/830/159/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Commit edit box Issue generation Commit generation Commit edit box Issue generation Commit generation Commit edit box 1 2 3 Inspiration💡 In the real of software engineering, teams constantly encounter the challenge of onboarding new members while maintaining productivity and efficiency. Whether it's a research group embarking on uncharted territories or developers immersing themselves in a new project, mastering new commands and understanding their usage can be an intimidating endeavor. Entering a new coding environment poses several challenges for an aspiring developer: learning proper and efficient ways to utilize commands, figuring out  the relevant branches to work on, and learning to report the contributions you've made in a proper manner. These challenges are especially prevalent in the academic circles because of how inherently interdisciplinary STEM research is. A new prospective researcher is expected to not only work on the topic of their choice, but often also acquire the relevant programming skills on the side. Additionally, some commands require a multitude of arguments to be usable. The time it takes to figure out such commands could be better spent. Even if there aren't Recognizing these challenges we embarked on the journey to bridge the gap between experienced and novice developers. Bridging this gap could help a new generation of researchers and developers reach their full potential within their role. Introducing Clique - a virtual command-prompt environment manager aiming to leverage the experience of senior developers to make the onboarding process a more painless and quick experience. What it does🤔 Clique sets up a virtual CMD environment (called ph on the CLI) for any group of or even individual developers. While a standard virtual environment (e.g. Python venv) isolates code dependencies, a Clique environment isolates commands and Git repository information. Users can create a new Clique environment (via ph --gname [envname] ) for a specific p"
      }
    ]
  },
  {
    "file_path": "./devposts/concepify.html",
    "project_id": "concepify",
    "title": "Concepify",
    "tagline": "Revolutionizing education through AI-driven mindmaps",
    "hackathon": "",
    "built_with": [
      "mongodb",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/576/365/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Concepify 💡 Inspiration 💡 We were ignited by the challenge: How can we make learning complex topics not just easier, but also incredibly exciting? Welcome to Concepify, where we're pioneering the future of education through AI-driven mindmaps and next-gen interfaces. 🚀 🌟 What it Does 🌟 🌈 A Revolutionary Way to Learn: The Mindmap Interface 🌈 Concepify is more than just a tool; it's an electrifying experience that reshapes how you engage with knowledge. Imagine a kaleidoscopic network of your thoughts and queries, transformed into a dynamic, interactive landscape by our state-of-the-art Language Learning Models (LLMs) and generative AI. 🤖 🎓 Mind-Bending Understanding of Complex Topics 🎓 Say goodbye to dry textbooks and hello to a vivid, 3D mindmap that makes even the most intricate subjects as intuitive as a morning stroll. 🌳 And get ready to be amazed as our AI serves you analogies that simplify the complex into the comprehensible. 📘 🔥 Ignite Your Creativity: Dynamic Brainstorming 🔥 It's time to set your imagination on fire! With Concepify, every node in your mindmap is a gateway to deeper understanding and endless curiosity. Each \"Why?\" opens a new layer of insight, turning your brainstorming into an exhilarating treasure hunt. 🏆 🎨 Multi-Modal Learning Experience 🎨 Concepify isn't just for the eyes; it's a sensory feast. From visual mindmaps to AI-generated analogies, we cater to learners of all styles and ages. It's not just educational; it's a thrilling escapade into the universe of knowledge! 🌌 ✨ Additional Features for Unmatched Versatility ✨ 📋 Grading Rubric 📋: Our AI doesn't just evaluate; it enlightens, offering unprecedented feedback on your learning journey.\n👩‍🏫 TA Mode 👨‍🏫: Whether it's academic advice or emotional support, our TA Mode has you covered, all within the same versatile platform.\n💬 Chat Channels 💬: Multiple chat interfaces are at your disposal, each tailored for different academic or therapeutic discussions.\n🚀 Unleash the Power of"
      }
    ]
  },
  {
    "file_path": "./devposts/climaction.html",
    "project_id": "climaction",
    "title": "Climaction",
    "tagline": "App to help with Climate Change",
    "hackathon": "",
    "built_with": [
      "azure",
      "css",
      "firebase",
      "google-cloud",
      "html",
      "javascript",
      "repl.it"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TechTogether AtlantaWinnerBest Transportation Hack with Cox Automotive",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/810/837/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Google Cloud Mission. Past Petitions Ongoing Petitions Past Events Upcoming Events Advocacy Page Event Page Home Page Climaction Microsoft Azure Deployment Project Page Google Cloud Mission. Past Petitions Ongoing Petitions Past Events Upcoming Events Advocacy Page Event Page Home Page Climaction Microsoft Azure Deployment Project Page Google Cloud 1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration With all of the climate crises occurring these days, we were inspired to create a web app that addresses environmental damage in two ways. Our first way is to advocate and raise awareness of climate change by hosting webinar series, partnering with green organizations, and giving petitions a bigger audience/platform by posting petitions onto our web page. Lastly, our second way is to provide an easy platform to schedule online events to encourage more people to create online events rather than in-person meetings, conferences, etc. This ensures that the amount of car or air travel would decrease. What it does This website has a page to sign up for webinar events that has popular figures and companies talk about what they are doing and what they have done to conserve the environment. This helps incentivize the common people and our webinar audience to do the same as well. This website is also hosted on Microsoft Azure as it is deployed there and it is tied up with google cloud and amazon concepts. This website also has it’s github code hosted in google cloud. How we built it We built this using HTML, CSS, and Javascript. We also deployed the app on Microsoft Azure. Challenges we ran into After coming up with the idea, we were having trouble thinking of what exactly we should put in our website. We also struggled with whether to create a sign in/sign up page or just a registration page. Accomplishments that we're proud of We were able to create a functioning website in only 2 days, that has both the front end and back end done. What we learned We learned to collaborate and split task"
      }
    ]
  },
  {
    "file_path": "./devposts/community-9l4ugv.html",
    "project_id": "community-9l4ugv",
    "title": "Community",
    "tagline": "Revolutionize the community-making experience in universities and colleges... speed dating style!",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "html",
      "intellij-idea",
      "javascript",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/727/463/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "3 Statistic 1 Title page 2 Problem 3 Statistic 1 Title page 2 Problem 3 Statistic 1 2 3 4 Inspiration We all have experiences coming into a new environment whether it's as a freshman in college or as a new resident to Canada. We all had difficulty at the beginning to make friends with similar experiences and culture, so we wanted to find a solution to this problem. What it does Community is a web app that allows users to make new friends with similar interests and ask questions to other peers in the same college or university. How we built it We used Figma to prototype the project. Challenges we ran into Although we had some difficultly confirming our concept at first, we were able to talk out our ideas, take down possible options and weigh out the feasibility and wow factor of them all. Accomplishments that we're proud of As a group , we are proud to have been able to allocate tasks and communicate between the design and dev side efficient so that we could all work on the project as soon as possible. On the design side, we are proud of the use of more advanced smart animations that make the prototype interact like a real web app. What we learned Since hackathons are new to all of us, we learned to work with others in a group and centralize our ideas to create one solution. What's next for Community In the future, community can scale to become a tool for not only schools but offices and other workplaces to enhance the sense of community. Built With css figma html intellij-idea javascript visual-studio Try it out www.figma.com Submitted to Hackville 2024 Created by I worked on this project as the UI/UX designer to facilitate ideation and research. I designed wireframes to create lo-fi and high-fi prototypes of the web app. I used components and auto layout to help developers use dev mode on Figma to efficiently implement my designs. I learned to create some more advanced animations using smart animate on Figma, so feel free to check out the prototype link below! Jane"
      }
    ]
  },
  {
    "file_path": "./devposts/classif-ai-j59f3o.html",
    "project_id": "classif-ai-j59f3o",
    "title": "Classif.ai: A Classroom Sensei",
    "tagline": "Introducing Classifai, an app that uses artificial intelligence to help students study more efficiently. Students can spend less time reviewing their notes and more time studying for exams.",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "language",
      "natural",
      "processing",
      "python",
      "react",
      "transformers"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/543/316/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Sensei The Sensei The Sensei 1 2 **Loading time is around  1min 30, in the video, we cut for the purpose of demonstration. You may review the code : ) * Classify.ai A personalized teacher, note-taker and summarizer to accompany all students in their journey to academic and social success! Inspiration With more students touched by ADHD and other concentration problems, the educational system has had difficulty adapting... but we haven't! What it does Inspired by the Feynman method, Classif.ai transcribes, summarizes, and returns a neat point-formatted set of notes, to help YOU study your lectures better! Introducing... PenPal! Steps: Send your audio, it could be an MP3 file, a transcript, OR, you can even LIVE RECORD the lecture you are attending. WAIT a few minutes, and let the magic happen! The transformers on the flask backend are now working hard to transcribe speech to text, and to effectively summarize and reformat YOUR newest lecture notes! MOREOVER! Using the string that were sent through the notes, we are also calling another transformer function, which is able to extract relevant subjects, and creates a set of relevant flashcards, that can be studied!\nWe call this... Intellicards! AND Why not add another language model that can answer your questions based on the notes that you send in?\nDone! We hope you enjoy the new app!\nEnjoy! The technologies Backend models:Many transformer models tested: A question-answering model , that was implemented with the pipeline on hugging face A summarizer model that consists of the distilgpt2, and the summarizer model on pipeline huggingface A speech recognition system A react frontend with flask backend, connected via simple requests in the body of the calls. The model itself receives either a \"transcription\" or an encoded mp3 or wav video, in bit64. If a video is received, the speech recognition model, implemented with pyaudio, is activated, and returns a transcript in JSON format, before the front end can call for a su"
      }
    ]
  },
  {
    "file_path": "./devposts/community-engine.html",
    "project_id": "community-engine",
    "title": "Community Engine",
    "tagline": "A XR citizen participation engine to help communities better visualize change (in large infrastructure projects)",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Many community members struggle to convey the impact of long term projects to their people. Statistics, words and even pictures are often insufficient to communicate the necessity of starting (or stopping) an investment. What’s more, people often absorb this information in a vacuum, unaware of their larger community’s thoughts on the matter. Community Engine is a Collaborative XR (CEXR) app that gives any individual the ability to share their vison for infrastructure developments that impact their lives. It also lets them build a case for their idea by collecting feedback from the community based on both time and space. Innovation Each survey response is a position + time coordinate, and can easily be shared using a XRurl.xyz Combines AR and VR in a single view for data visualizations in large scale survey results. The analogy of VR as the empathy machine carries when we switch to seeing the individual's literal perspective in the aggregate data. What it does Help communities understand complex data and long term investment plans. Give individuals an opportunity to give feedback on proposed developments and learn how others in their community feel. Empower even individuals to easily get their idea in front of their peers in an engaging way and also generate highly granular research on their opinions about a proposal. An AR marker PostCard-based activism campaign Submitted to Reality Virtually Hackathon at the MIT Media Lab Returns Year 3 January 17 - 21, 2019 Created by I worked on art assets, interface, and concept. Jordan Pelovitz I work in 3D assets. Marlon Romero 3D and VFX Technical Artist | I leverage cutting-edge technologies like Computer Vision to create interactive and immersive XR experiences. Ezequiellenard Siddhesh Gupte Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)"
      }
    ]
  },
  {
    "file_path": "./devposts/collabcube.html",
    "project_id": "collabcube",
    "title": "CollabCube",
    "tagline": "CollabCube: Your Nexus for Collaboration, Innovation, and Beyond!",
    "hackathon": "",
    "built_with": [
      "adobe-illustrator",
      "figma",
      "miro",
      "photoshop"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/556/723/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Invite members or quick add previous teammates Our Personal Dashboard Tasks dashboard Invite members or quick add previous teammates Our Personal Dashboard Tasks dashboard Invite members or quick add previous teammates 1 2 3 4 Inspiration After working in many group projects with different team members, me and my teammate faced some overlapping issues, there were time when our teammates used to ditch the projects or were non-serious for it. We found it difficult to work with remote teams because of lack of authenticity and transparency in the process. After a heavy User Research, we came up on a conclusion that we need a reward and punish system for people to me responsible and credible for the work they, It's not your same team management workspace. Now college students can join teams based on their skillset and credibility without taking stress of their teammates. What it does The prototype we made is a complete collaboration tool, It does it all from collaboration to communication and scheduling to notification. We are their in every stage or your project. CollabCube maintains a record of your projects, credits and responsibility, which increases your chance of visibility on our platform and lets you enjoy easy team building. Join the teams that require your skills and create the innovation for future. We believe that unity does it all. How we built it We asked our users what they wanted because we are building for them and certainly did our part of brainstorming, research and took guidance of each other. Our team was complementary with logics and design. First of all we created the Userflow map UserJourney then we moved on to Wireframe, we created a prototype which was a mess, but we continued with our work and then made the UI, style guides as well as the prototype again. It was a journey of ups and downs. Challenges we ran into We were unsure of how to implement the credibility so that it impacts the user in a positive way, Because if the credits are lost, the"
      }
    ]
  },
  {
    "file_path": "./devposts/coefficient.html",
    "project_id": "coefficient",
    "title": "CoEfficient",
    "tagline": "Multi-point, variable-order route optimization using quantum machine learning.",
    "hackathon": "",
    "built_with": [
      "google-maps",
      "ibm",
      "ibm-cloud",
      "ibm-q",
      "ibmq",
      "machine-learning",
      "matplotlib",
      "networkx",
      "numpy",
      "python",
      "qiskit",
      "quantum"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "to help slow it as best as we can"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/940/123/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "CoEfficient Climate change and global warming are counted amongst the foremost threats to humanity. While we struggle to find a way to reverse climate change, we must do our best to help slow it as best as we can. To that effect, we thought of focusing on the tourism transportation and travel industry. The problem is that every year, vehicles waste gas, time, and money by driving extra distances when there is often a shorter route available. Every year, 8 trillion tons of carbon dioxide are emitted into the atmosphere from transportation sources. If we could reduce our trip lengths by as little as 0.5% when there are shorter routes available, we could reduce our carbon dioxide emissions by 40 million tons! Our project solves that problem. What it does CoEfficient is an application that finds the most efficient route between multiple points on a map. This is often very useful for a variety of clients including: coach bus operating businesses who are looking to give their vacationing passengers a great time visiting many landmarks but also want to take the most efficient route possible school bus operating businesses who are seeking to pick-up/drop-off children at multiple points in the most efficient way possible travelling individuals who want to visit multiple landmarks and spend more time at each landmark instead of wasting time driving in between landmarks people running errands who need to visit multiple locations as fast as possible How we built it We built our app in Python. We used the Google Maps API to compute the distances in between nodes on the map. We used numpy, networkx, and matplotlib to efficiently compute and create a representative graph of the map and its nodes and edges. Finally we used Qiskit, a quantum information science kit, along with IBM-Q, a cloud-accessible quantum computer to compute the most efficient route to the problem. This would allow for exponentially more efficient mass scaling in the future. Challenges we ran into Not every mem"
      }
    ]
  },
  {
    "file_path": "./devposts/concussify.html",
    "project_id": "concussify",
    "title": "ConCussify",
    "tagline": "AI Powered Concussion Detection ⚡ On your browser, in one minute.",
    "hackathon": "",
    "built_with": [
      "css3",
      "google-auth",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/550/861/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Mobile App Screen Mobile App Screen 1 2 3 4 5 6 7 Our submission to the Advanced Hackathon Division Inspiration Concussions are known for going undiagnosed, particularly in sports, where there’s pressure to play through injury and more obvious symptoms may not immediately be evident. My sister, for instance, experienced multiple concussions as a competitive cheerleader without realizing, and this resulted in her receiving delayed medical attention and suffering through worsened symptoms. We were motivated to address this problem by developing a convenient and accessible solution for athletes and other individuals prone to concussions, empowering them to independently assess their condition on the spot and seek medical help promptly. By combining a user-friendly and interactive interface with AI features to fill-in for potentially unavailable healthcare professionals, our web app aims to make concussion diagnosis more accessible and efficient than ever before. What it does Concussify determines the likelihood of a concussion based on whether it detects a difference in the pupil size of the right and left eye (a common indication of a concussion). We had also planned for users to be able to take a series of baseline tests that can be repeated after a head injury to determine if there’s been a change in their cognitive speed, memory, or awareness. How we built it The frontend was written in CSS and HTML, and we developed the backend using Cloudflare Workers, which is an edge-based serverless provider that is based upon the WinterCG runtime; through this, we are able to create a highly-scalable and mobile backend able to tackle almost any challenge. We do not have any lock-in as it is based on the Winter CG Runtime which allows us to move to other providers such as Vercel or Deno. We decided to implement Google sign-in to reduce development time while still providing ease-of-use.\nThe pupil size detection function was built using two pretrained machine learning models. T"
      }
    ]
  },
  {
    "file_path": "./devposts/community-foodbank.html",
    "project_id": "community-foodbank",
    "title": "Community Foodbase",
    "tagline": "In many places there are no supermarkets or delivery services, just families selling a specific good each. CF allows locals to make grocery lists and have courier assemble the cart from local families",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "express.js",
      "javascript",
      "mysql",
      "node.js",
      "passport",
      "react",
      "react-native",
      "redux"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/233/372/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Many of our friends and classmates come from regions with no shipping infrastructure/addressing mechanisms in place, nor supermarkets which aggregate all their basic food needs in one place. They have smartphones but no way to get what they need 100% of the time or in time. Instead, families tend to specialize in growing one plant/crop or preparing one kind of meat/dish and they sell these from their home. The range of influence for these families who sell a single good (potatoes, fish, tomatoes, etc) is limited to close neighbors rather than province, county, or even village. What it does Community Foodbase is an app that allows those who are not able or do not wish to stop by many locations to buy and pick up each item of food to instead create a list of their needed foods and a courier who owns a vehicle or a motorbike will be able to accept the list and then go fulfill the list at the places they know best / usually go for each item. They will then deliver the goods to the original request-er. The family-run business will also benefit from increased reach/consumer base. How we built it A relational mySQL database on top of Node and Express in the back, connected to a React Native app through express. Challenges we ran into Initially we struggled with an idea. However we discussed with 3 of our friends here at Clark University who come from Nepal and they gave us this idea as something that could improves lives all around. We hit some tough bugs which could take up to an hour to resolve. Accomplishments that we are proud of With the backend, we learned how to authenticate users with passport.js and experienced implementing REST APIs. We also become more comfortable with routing in Express. By 8 AM, we had an almost complete backend. What we learned React, how to squash bugs, and some global perspective What's next for Community Foodbase IPO ;)  ...jk, unless...?\nIn all seriousness though we love this idea and the potential it has to impact people's li"
      }
    ]
  },
  {
    "file_path": "./devposts/close-connect.html",
    "project_id": "close-connect",
    "title": "Close Connect",
    "tagline": "Every day, we are limited to meeting the people who live in a very close vicinity. What if we could talk to random people from other countries thousands of km away? Introducing... Close Connect!",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "html",
      "javascript",
      "react-router-dom",
      "react.js",
      "reactjs-alert"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "WaffleHacks 2022WinnerHonorable Mention in Diversity & Inclusion",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/010/267/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chat Interface Homepage About Us Our Contacts Login Page Chat Interface Homepage About Us Our Contacts Login Page Chat Interface 1 2 3 4 5 6 Inspiration Recently I found out that my friend's older sister held the position I was aiming for. This made me realize how small the world is... Or more accurately how small MY world is. This made me realize how big the world was. We are missing out on so many could-be meaningful connections! What it does CloseConnect pairs you with people who live all over the world. This allows for people to tread out of their region and meet others who live in different worlds and to celebrate their different cultures and backgrounds. We have also implemented a list of topics that could be talked about just in case the conversation gets dry! How we built it We built the majority of the front-end using react.js, html5, and css3, we built the navigational bar with react-router-dom, and created alerts with reactjs-alert. On the other hand, we used firebase for the back-end database and log-in/log-out system. Challenges we ran into We had a plethora of installation issues, after that, we have a multitude of coding errors. One of our members was even sick! It is not great coding while constantly coughing every minute. :) Accomplishments that we're proud of We are proud of creating a functional, interactive website that allows for people to chat online less than 48 hours!. This was the first time any of us touched a back-end database and a log-in/log-out system. Furthermore, this was half of our group's first Hackathon! We are proud to have made a completed product after a seemingly endless river of errors! What we learned We became more experienced with the fundamentals of react.js, learned a variety premade components, and we have learned how to create responsive, interactive websites. We also learned how to implement a log-in/log-out system as well as store id's in a database using firebase. What's next for Close Connect CloseConnect wants to "
      }
    ]
  },
  {
    "file_path": "./devposts/conductor-ai.html",
    "project_id": "conductor-ai",
    "title": "Conductor AI",
    "tagline": "Agentic routing at scale for 66x cheaper and 4x faster — Powering the Agentic Future",
    "hackathon": "",
    "built_with": [
      "agents",
      "ai-agents",
      "contrastive-learning",
      "knn",
      "python",
      "pytorch",
      "recommendation-systems"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Codegen: Best Code Generation Application ($1",
      "TreeHacks 2025WinnerCodegen: Best Code Generation Application ($1.5k Cash)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/274/188/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF our team GIF our team 1 2 3 4 5 6 7 8 Agentic Routing At Scale: The Cornerstone of an Agentic Future Enterprises run a large number of agents, and being able to choose which agent to run a query on is a complex and expensive task. Routers exist today that can handle O(10) agents, but what about O(1000). Salesforce has O(10000) agents and — in a future where agents seem poised to replace many jobs — organizations may come to rely on the orchestration of O(1,000,000) agents with O(100,000,000) prompts/day . If we want a future driven by agents, with companies formed of agents, and to maximize performance/$ for inference, we need to solve the large-scale routing problem. The routing space is large and continuing to explode, and there exist no systems that can scale to the size that is needed. We develop a novel recommendation-system based algorithm for prompt routing, drawing inspiration from the TikTok algorithm Fortunately, our team (check below) is adept at handling matching problems at scale. Taking inspiration from the recommendation system at TikTok, ConductorAI matches queries and routers through a two-stage embedding approach, learning prompt and agent embeddings from exploring the interaction between the two and without manual encoding or intensive processing of either. Check out the technical details in our slides! ConductorAI: 66x cost savings, 4x latency reduction, better than any single AI model , and exponentially better performance with many agents ConductorAI provides unheard of speed and cost reduction at reasonable accuracy for an agent-driven future. Conductor implicitly learns a mapping between a semantic-embedding space and an agentic-embedding space, where coordinates correspond to features such as problem difficulty, tools required, and context that may be relative when deciding between agents. Additionally, adding agents to the system requires no hard-coded rules or descriptions, Conductor can naturally learn agent embeddings that exceed hum"
      }
    ]
  },
  {
    "file_path": "./devposts/climbdb.html",
    "project_id": "climbdb",
    "title": "ClimbDB",
    "tagline": "All in one dataset for bouldering!!! Utilize handgathered tabular, video, and pose data to analyze trends in the different styles, physical characteristics, and skills of climbers!",
    "hackathon": "",
    "built_with": [
      "jupyternotebook",
      "numpy",
      "opencv",
      "pandas",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMU Datathon 2023WinnerBuild Your Own 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/643/496/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Experience vs. Strength! Us at the climbing wall! GIF Pose estimation + Classification! GIF Climb #1! Us at Stone Co.! GIF #Climb #2! Experience vs. Strength! Us at the climbing wall! GIF Pose estimation + Classification! GIF Climb #1! Us at Stone Co.! GIF #Climb #2! Experience vs. Strength! 1 2 3 4 5 6 7 The Surge of Bouldering, The Problem, and Our Purpose In recent years, the world of climbing, especially bouldering, has experienced a remarkable surge, with a considerable growth rate of 11.7% according to 99Boulders . As a result of the lack of readily available information for newcomers (currently no other real datasets), there is little known to newbies about how to train, how to approach different boulders, or even how to stay safe. The Solution: Our Framework To solve this issue, we've created a dataset that encompasses a wide range of climbing routes, replays, and insights from climbers of varying skill levels. We wanted to go beyond stale online sources and dive deep into the field. For that reason, we went beyond our screens into the real world to collect data! Our goal is to analyze physical trends, shed light on the nuances of different routes, and provide real, but hidden information to climbers seeking to enhance their understanding of the sport. In addition, we extend this data to illustrate how climbing is accessible , climbing improves overall fitness , and that pose estimation can help decrease risk while attempting routes. The dataset not only addresses the technical, numerical aspects of climbing, such as efficiency and route planning, but also delves into an artistic expression of poses on the wall. By analyzing different body patterns, we can improve safety, athletic development, and overall fun through pattern recognition and other relationships apparent in the data. Our Story First, our team headed to Stone Co., College Station's local climbing gym to collect the data. Before each route, we captured frames of only the bare holds with no perso"
      }
    ]
  },
  {
    "file_path": "./devposts/connexion.html",
    "project_id": "connexion",
    "title": "ConnexionAI",
    "tagline": "We aim to revolutionise the way people with different communication abilities converse with each other using machine learning",
    "hackathon": "",
    "built_with": [
      "canva",
      "figma",
      "flask",
      "google-cloud",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Hack (3rd Place) Created by I worked on the front-end, building out the front-facing interf",
      "Best Overall Hack (3rd Place) Created by I worked on the front-end, building out the front-facing i",
      "s Presenting to Judges Winning Medal Arrived at Harvard Cool company logo Harvard Champions Presenti",
      "HackHarvard 2019WinnerBest Overall Hack (3rd Place)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/866/057/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Arrived at Harvard Cool company logo Harvard Champions Presenting to Judges Winning Medal Arrived at Harvard Cool company logo Harvard Champions Presenting to Judges Winning Medal Arrived at Harvard 1 2 3 4 5 Inspiration Often times we’ve seen people post live streams on social media, use video calling for a more personal touch to a conversation, and engage in activities which require extensive expression of emotion through language. However, with over 430 million people around the world having hearing disabilities and less than a fourth of people fluent in sign language, our team was sought to bridge this significant, yet ironically, unattended problem. What it does ConnexionAI.tech is a web application that converts video input of sign language to three most popular languages English, Spanish, and French. The application also has in built capability of converting speech to text and also translate various languages to English - Text . In the future, ConnexionAI can be deployed in video chats and live streams to caption people with speaking disabilities to caption sign language and it could be used as a live ASL to text convertor. How I built it The machine learning model was trained on google cloud’s autoML platform, the web framework we’re using is flask, the website was built in HTML5, CSS, JS, and the project integration was in python. Challenges I ran into Our biggest challenge was to find a reliable dataset and deciding the hyper parameters for training the model under such a time constraint. The other challenge we ran into was integrating the video format in the web browser and taking inputs to backend and pushing outputs to the browser again. Accomplishments that I'm proud of We are proud of having the opportunity to solve a problem that affects the lives of millions of people in a fun learning environment! What I learned All of us worked with something that we had worked with before. Using google cloud for the first time was fascinating and the idea of conn"
      }
    ]
  },
  {
    "file_path": "./devposts/college-unlocked.html",
    "project_id": "college-unlocked",
    "title": "College Unlocked",
    "tagline": "Your one stop shop to choosing the college right for you!",
    "hackathon": "",
    "built_with": [
      "deso",
      "figma",
      "github",
      "react",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Participatory Prize Hacky Birthday MLH! 2022 Winner Dream Big and Create More Cheers with AB InBev",
      "Hacky Birthday MLH! 2022 Winner Dream Big and Create More Cheers with AB InBev Created by Sarvesh M",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/039/016/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "College Results Page Homepage Advice Page Submit Advice Page College Finder Page College Results Page Homepage Advice Page Submit Advice Page College Finder Page College Results Page 1 2 3 4 5 6 🌐 Domain Name: https://college-unlocked.tech/ Gitbook API Documentation ☁️ Inspiration So many people have trouble finding the right college. They wonder, what majors does the college offer? Is my GPA good enough? How much does it cost? Then, they waste their time writing essay after essay to maximize the chance of getting into their preferred college. We wanted to change that by making an application which helps people find the perfect college for them. This application is especially suitable for hackers as they are occupied with coding, and it takes a lot of time to search through numerous computer science colleges to find the right match. 🚧 What It Does Our application helps people unlock college , by giving them the advice and tools they need to find a perfect college. Our app allows them to talk to real people and get real feedback. It has a very use friendly UI and allows anyone and everyone to find a college. 👨🏾‍💻 How We Built It For the frontend, we made the styles using Figma and exported them to React components, then integrating with the backend. For the frontend, we used React and a wrapper around it called NextJS. This allowed us to utilize performance techniques such as client side and server side rendering overall optimizing our application. We used fetch requests to communicate with our backend for this full stack application. We also used Tailwind CSS for its helpful utility classes as the team did not have much experience with CSS. The backend used many different technologies: Core Server: flask as it's a very easy framework to use and is highly extensible. Hosting and Database: replit as it has free unlimited hosting and it's database is big. Text Engine: markdown2html as more hackers use markdown so it appeals to them. File Storage: Deso as it provides be"
      }
    ]
  },
  {
    "file_path": "./devposts/cognispeak.html",
    "project_id": "cognispeak",
    "title": "CogniSpeak",
    "tagline": "CogniSpeak is an AI powered dementia detection platform aiming to help users identify early signs of dementia based on their speech patterns.",
    "hackathon": "",
    "built_with": [
      "cloudflare",
      "defang",
      "fastapi",
      "javascript",
      "next",
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This was my first ever hackathon and I worked on the front end to create the UI. It was first time using React."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/075/920/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Project Overview: Early Dementia Detection Through Voice Analysis Our project aims to leverage cutting-edge machine learning and clinical cognitive computing (MLCC) techniques to detect early signs of dementia using voice recordings. Dementia is a progressive condition that affects cognitive functions like memory, thinking, and communication, and early detection is crucial for effective intervention. More than 55 million people live with dementia, with 10 million new cases occurring each year. In addition more than 60% of dementia patients live in low and middle-income countries, highlighting the need for accessible monitoring services. How It Works Voice Recording : Users are prompted to record their voice through a simple and user-friendly interface. The recordings can be short narratives, answering guided questions, or performing specific verbal tasks. Machine Learning Analysis : Once the recording is submitted, our system uses our own ML model we trained with advanced MLCC algorithms to analyze various aspects of the voice, including: Speech Patterns : Speed, rhythm, and fluency of speech. Voice Modulation : Changes in pitch, tone, and inflection. Pauses and Hesitations : Frequency and duration of silent pauses or hesitations during speech. Language Content : Analysis of word usage, sentence structure, and complexity of the language. All training data is open source! ### Purpose and Innovation\nThe key goal of this project is to identify subtle changes in voice and speech patterns that may indicate early cognitive decline, which is often an early sign of dementia. By integrating MLCC with voice analysis, we aim to provide: Non-Invasive Screening : A simple, accessible way for users to check their cognitive health without the need for extensive clinical testing. Early Detection : Identifying signs of dementia at its earliest stages allows for timely medical consultation and intervention, which can significantly improve patient outcomes. Personalized Insights :"
      }
    ]
  },
  {
    "file_path": "./devposts/climaction-tbl7qj.html",
    "project_id": "climaction-tbl7qj",
    "title": "Climaction",
    "tagline": "An app for Climate change!",
    "hackathon": "",
    "built_with": [
      "azure",
      "css",
      "firebase",
      "google-cloud",
      "html",
      "javascript",
      "microsoft",
      "repl.it"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/810/853/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Google Cloud Past Petitions Our Mission statement Ongoing Petitions Past Events Upcoming Events Advocacy Page Event Page Home Page Climaction Microsoft Azure Deployment Project Page Google Cloud Past Petitions Our Mission statement Ongoing Petitions Past Events Upcoming Events Advocacy Page Event Page Home Page Climaction Microsoft Azure Deployment Project Page Google Cloud 1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration With all of the climate crises occurring these days, we were inspired to create a web app that addresses environmental damage in two ways. Our first way is to advocate and raise awareness of climate change by hosting webinar series, partnering with green organizations, and giving petitions a bigger audience/platform by posting petitions onto our web page. Lastly, our second way is to provide an easy platform to schedule online events to encourage more people to create online events rather than in-person meetings, conferences, etc. This ensures that the amount of car or air travel would decrease. What it does This website has a page to sign up for webinar events that has popular figures and companies talk about what they are doing and what they have done to conserve the environment. This helps incentivize the common people and our webinar audience to do the same as well. This website is also hosted on Microsoft Azure as it is deployed there and it is tied up with google cloud and amazon concepts. This website also has it’s github code hosted in google cloud. How we built it We built this using HTML, CSS, and Javascript. We also deployed the app on Microsoft Azure. Challenges we ran into After coming up with the idea, we were having trouble thinking of what exactly we should put in our website. We also struggled with whether to create a sign in/sign up page or just a registration page. Accomplishments that we're proud of We were able to create a functioning website in less than 2 days and deploy it as well. What we learned We learned to collaborate and spli"
      }
    ]
  },
  {
    "file_path": "./devposts/coding-resource-finder-crf.html",
    "project_id": "coding-resource-finder-crf",
    "title": "Coding Resource Finder (CRF) Challenge #4",
    "tagline": "CRF, designed with Python and Kivy, allows the research of useful webpages from a given programming language, subject and type. It’s madea main page, a filter page and a results page.",
    "hackathon": "",
    "built_with": [
      "kivy",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "find the best coding resources"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/327/734/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration An old project idea What it does find the best coding resources How I built it writing python Challenges I ran into I had some problems with kivy Accomplishments that I'm proud of The rapid progress. What I learned What's next for Coding Resource Finder(CRF) Add more functions such as rating a resource Built With kivy python Try it out drive.google.com Submitted to BrébeufHx 4.0 Created by Rukun Dou Aly Shariff Rupeng Dou Alex Cheng"
      }
    ]
  },
  {
    "file_path": "./devposts/compassutd.html",
    "project_id": "compassutd",
    "title": "CompassUTD - PaLM 2 powered chatbot",
    "tagline": "UT Dallas chat bot with up-to-date information using PaLM2, MongoDB and Langchain",
    "hackathon": "",
    "built_with": [
      "langchain",
      "next.js",
      "palm",
      "palm-2",
      "react",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/533/113/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF PaLM 2 ReAct in action: Asking on how to register for classes GIF The bot does remember past chat history and give appropriate response GIF The bot giving an accurate information about a professor and courses at UT Dallas GIF PaLM 2 ReAct in action: Asking a question comparing 2 professors GIF PaLM 2 ReAct in action: Asking on how to register for classes GIF The bot does remember past chat history and give appropriate response GIF The bot giving an accurate information about a professor and courses at UT Dallas GIF PaLM 2 ReAct in action: Asking a question comparing 2 professors GIF PaLM 2 ReAct in action: Asking on how to register for classes 1 2 3 4 5 Try It Here https://compass-utd.vercel.app/ Inspiration As UT Dallas students, we observed that our advisors were often overwhelmed with answering simple questions that could easily be found by simple Google. This will take away resources from student who required actual advising. Inspired by the reasoning abilities of PaLM 2 and the expert-level LLM of Med_PaLM 2 in answering complex medical questions, we decided to fine-tune PaLM 2 using Langchain with UT Dallas' public information database to help our advisors. The results from our advisor bot have shown exceptional accuracy and quality compared to the basic Bard model and ChatGPT, and we have received many positive feed back from our early testers. What it does CompassUTD can provide answers to a wide range of questions about UT Dallas, offering the most up-to-date and accurate information. Its capabilities include: Searching for course information and descriptions using natural language or shorthand names (e.g., \"Comp Arch\" instead of \"CS 2340: Computer Architecture\"). Providing professor ratings from RateMyProfessors.com for UT Dallas faculty. Offering information about the majors and minors available at UT Dallas. Supplying general information about UT Dallas, such as tech support, parking, and more. Providing details about staff, schools, and departments,"
      }
    ]
  },
  {
    "file_path": "./devposts/corgi-58j6fv.html",
    "project_id": "corgi-58j6fv",
    "title": "Corgi",
    "tagline": "Corgi is a fun corgi-themed website that provides a soothing UI for a challenging corgi Trivia Quiz.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Iman liked quizzes, so she wanted to try her hand at making one. Izaan wanted to learn more CSS so we put it on a website. What it does It's a website with a quiz about corgis and pictures of corgis How we built it Using VS Code, research, and patience Challenges we ran into We originally wanted to write it in C++, then we realized we had no idea how to make GUIs. We thought about using a website as a GUI but then couldn't figure out how to use C++ on a website so we switched entirely to HTML. Accomplishments that we're proud of The layout of the website is nice, and the quiz is functional What we learned How to make HTML quizzes, and what web hosting is. What's next for Corgi more pictures and features, like a dietary recommendation software and health plans Built With css3 html5 javascript vscode Try it out izaanq.github.io Submitted to CorgiHacks Created by I made the quiz and coordinated most of the Javascript Iman Umair-Qaiser UWaterloo CE '26 I created the web page which served as the UI for the quiz. I created the 3 individual pages within the site, and attached the pre-existing pictures and quiz into said pages. Izaan Qaiser"
      }
    ]
  },
  {
    "file_path": "./devposts/collabworks.html",
    "project_id": "collabworks",
    "title": "CollabWorks",
    "tagline": "A platform for the users to connect with the community in a better way, have access to happy hacking and collab with other hackers!",
    "hackathon": "",
    "built_with": [
      "android",
      "chatgpt",
      "dart",
      "figma",
      "firebase",
      "flutter",
      "git",
      "github",
      "godaddy",
      "hedera",
      "sendgrid",
      "studio",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hacky New Year!WinnerMost Innovative Hack",
      "Best Blockchain Project Using Hedera 🔐🔐",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/334/919/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Team Registration Team Overview CollabWorks Hedera + Contract_Config Hackathon registeration for Organization Screen Hacker Home Screen Landing Screen Team Chat Team Registration Team Overview CollabWorks Hedera + Contract_Config Hackathon registeration for Organization Screen Hacker Home Screen Landing Screen Team Chat Team Registration 1 2 3 4 5 6 7 8 9 Inspiration 🔥🔥 Our inspirations came from devpost, discord, and other social platforms where hackers could collaborate with one another but were restricted in their ability to connect with the community. We thought to develop a mobile application that would enable hackers and the hacker community to come together and enjoy hacking. This app enables hackers to connect with one another, form teams, and manage those teams, and allows organizations to view the teams and plan hackathons for their events. What it does ⚒️⚒️ It is a platform where hackers and organizations can connect with each other, make teams, participate in hackathons, chat and interact with each other and have fun hacking together! It's a prototype but hopefully, it is a great start for an app to help hackers. How we built it 🏗️🏗️ We built it using the UI toolkit by google->flutter and dart, firebase as the backend, Figma for designing, GitHub for collaboration and Twilio for sending the emails to the user along with Hedera for tracking user votes, and also we have used our blood and sweat to make it(jk) Best Blockchain Project Using Hedera 🔐🔐 It's evident from our past experiences that folks use temporary emails to generate multiple fake Devpost accounts and then vote projects to get a competetive edge over others. To fix that, we have extensively used Hedera in our project to make sure that each Upvote is genuine and verificable! We have used Hedera’s testnet to deploy smart contracts for our app. Hedera is a decentralized public network that utilizes the Hashgraph consensus algorithm to overcome the traditional limitations of blockchain and allow o"
      }
    ]
  },
  {
    "file_path": "./devposts/cognitio-onjmu9.html",
    "project_id": "cognitio-onjmu9",
    "title": "Cognitio",
    "tagline": "me when learn stuff",
    "hackathon": "",
    "built_with": [
      "css3",
      "firebase",
      "firestore",
      "gin",
      "gingonic",
      "go",
      "golang",
      "react",
      "ts",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "By SpellCast#4196 (backend), narutopig#0960 (frontend), and EkansTCG#8840 Inspiration Studying is hard. Especially when there are paywalled tools out there. What it does This is an app to help studying (it has sets of flashcards), an account and google oauth system,and more. It also has a tailored restapi. How we built it -Gin gonic and golang for the backend and restapi\n-React and typescript for the frontend Challenges we ran into -CSS\n-Using firebase; I (gaurav Bansal) had never used firebase before with as much intensity, so I had to overcome many challenges with using it. Accomplishments that we're proud of -Being able to establish a working restapi and backend with golang, and being able to get data from the firestore db. Being able to make a working app with Oauth, etc. Having decent css What we learned How to use Firebase well How to create a quiz app Handle oauth repo is currently private What's next for Cognitio Probably going to launch it into a productionscale project Built With css3 firebase firestore gin gingonic go golang react ts typescript Try it out GitHub Repo Submitted to Falcon Hacks 2022 Created by Gaurav Bansal Redger Xu Evan Li"
      }
    ]
  },
  {
    "file_path": "./devposts/converge-iya7s5.html",
    "project_id": "converge-iya7s5",
    "title": "Converge",
    "tagline": "Virtual Learning Environment with novel, renewed accessibility for the Neurodivergent. Replaces commonly used online classroom tools such as Canvas and Piazza.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gpt-3",
      "javascript",
      "next.js",
      "nltk",
      "openai",
      "prisma",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/386/480/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Write or draft a post! Save it privately for your own notes or show it to other community members! Read other students' posts! Detect sarcasm and sentiment of text! Condense long text using a Machine Learning summarizer model! Write or draft a post! Save it privately for your own notes or show it to other community members! Read other students' posts! Detect sarcasm and sentiment of text! Condense long text using a Machine Learning summarizer model! Write or draft a post! Save it privately for your own notes or show it to other community members! 1 2 3 Inspiration All brains are Different! Neurodiversity embraces all the different ways our minds process information, perceive actions, and present behaviors. Virtual Learning Environments have become not only increasingly popular, but increasingly necessary as in the wake of COVID-19, the world has realized the capabilities of technology are able to support online classrooms. On the other hand, only, \"15.2% (N = 16) declared they (web developers) consider people with cognitive disabilities on their projects” (NCBI 2018). Because of this, much existing software fails to fully satisfy the needs of the neurodivergent. Therefore, it is essential to research and update current tools to add features to adequately solve and enhance the experience these individuals face. In order to solve this, we delved into research about each different type of neurodivergence and looked for features we could implement in our learning environment that would ease those respective users' experiences What it does Our main goal is to foster an inclusive, virtual learning environment that satisfies and creates a balance of 3 challenges: \"Beneficial Sensory Environment\", \"Ambiguity\", and \"Interactivity\". Beneficial Sensory Environment In order to satisfy this challenge, we put a lot of effort into designing a clean, minimalist UI. To this regard, we used a smooth transitions, clear fonts, and cohesive color theme. For audio, we provide options to "
      }
    ]
  },
  {
    "file_path": "./devposts/classif-ai.html",
    "project_id": "classif-ai",
    "title": "Classif.ai",
    "tagline": "A personalized teacher, note-taker and summarizer to accompany all students in their journey to academic and social success! This app is designed to help students boost their performance at school.",
    "hackathon": "",
    "built_with": [
      "flask",
      "react",
      "speechrecognition",
      "transformers"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/540/795/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Classif.ai! Classif.ai! Classif.ai! 1 2 **Loading time is around  1min 30, in the video, we cut for the purpose of demonstration. You may review the code : ) * Classify.ai A personalized teacher, note-taker and summarizer to accompany all students in their journey to academic and social success! Inspiration With more students touched by ADHD and other concentration problems, the educational system has had difficulty adapting... but we haven't! What it does Inspired by the Feynman method, Classif.ai transcribes, summarizes, and returns a neat point-formatted set of notes, to help YOU study your lectures better! Steps: Send your audio, it could be an MP3 file, a transcript, OR, you can even LIVE RECORD the lecture you are attending. WAIT a few minutes, and let the magic happen! The transformers on the flask backend are now working hard to transcribe speech to text, and to effectively summarize and reformat YOUR newest lecture notes! Enjoy! The technologies Backend models:Many transformer models tested: A question-answering model , that was implemented with the pipeline on hugging face A summarizer model that consists of the distilgpt2, and the summarizer model on pipeline huggingface A speech recognition system A react frontend with flask backend, connected via simple requests in the body of the calls. The model itself receives either a \"transcription\" or an encoded mp3 or wav video, in bit64. If a video is received, the speech recognition model, implemented with pyaudio, is activated, and returns a transcript in JSON format, before the front end can call for a summarization. (see the React app and speech_rec.py) Summarization model thought process: The summarization is done repetitively.\nThe transformer returns two elements The main subject of the given transcript/passage. To find the main subject, a summarizer is recursively passed on to the given transcript, to narrow it down, in the same way that in a Convolutional Neural Network, each image is repetitively summar"
      }
    ]
  },
  {
    "file_path": "./devposts/congo-under-chains.html",
    "project_id": "congo-under-chains",
    "title": "Congo Under Chains",
    "tagline": "Bringing to light the atrocities committed by King Leopold toward the Congo.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration History Class What it does Educates reader about Belgian Congo How we built it Html, jss, reactjs, css Challenges we ran into Link did not work for the sites Accomplishments that we're proud of Building an entire functioning web page What we learned How to input clickable links on web pages What's next for Congo Under Chains tbd Built With css html react typescript Try it out congounderchains.netlify.app docs.google.com Created by Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/code-flow.html",
    "project_id": "code-flow",
    "title": "Code Flow",
    "tagline": "Remove the need for tedious onboarding by demystifying new repositories.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "flask",
      "mongodb",
      "python",
      "pyvis",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Cohere Created by Apar Ahuja Quantitative Researcher at AlphaGrep Securities, Singapore",
      "Hack the North 2023WinnerBest Use of Cohere",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/586/982/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Inspiration All of us have gone through the painstaking and difficult process of onboarding as interns and making sense of huge repositories with many layers of folders and files. We hoped to shorten this or remove it completely through the use of Code Flow. What it does Code Flow exists to speed up onboarding and make code easy to understand for non-technical people such as Project Managers and Business Analysts. Once the user has uploaded the repo, it has 2 main features. First, it can visualize the entire repo by showing how different folders and files are connected and providing a brief summary of each file and folder. It can also visualize a file by showing how the different functions are connected for a more technical user. The second feature is a specialized chatbot that allows you to ask questions about the entire project as a whole or even specific files. For example, \"Which file do I need to change to implement this new feature?\" How we built it We used React to build the front end. Any folders uploaded by the user through the UI are stored using MongoDB. The backend is built using Python-Flask. If the user chooses a visualization, we first summarize what every file and folder does and display that in a graph data structure using the library pyvis. We analyze whether files are connected in the graph based on an algorithm that checks features such as the functions imported, etc. For the file-level visualization, we analyze the file's code using an AST and figure out which functions are interacting with each other. Finally for the chatbot, when the user asks a question we first use Cohere's embeddings to check the similarity of the question with the description we generated for the files. After narrowing down the correct file, we use its code to answer the question using Cohere generate. Challenges we ran into We struggled a lot with narrowing down which file to use to answer the user's questions. We initially thought to simply use Cohere generate to re"
      }
    ]
  },
  {
    "file_path": "./devposts/colour-sense.html",
    "project_id": "colour-sense",
    "title": "ColourSense",
    "tagline": "Discover the world through your phone",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "javascript",
      "opencv",
      "python",
      "react",
      "react-native",
      "render.com"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the HillWinnerMaker Con Challenge",
      "This is one of the first times we’ve used mobile development",
      "First time working with Computer Vision",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/408/893/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 ColourSense Inspiration Since beginning our journey in Hack The Hill, our team were looking to apply Computer Vision and Machine Learning using open-source libraries to our submission. After being introduced to the MakerCon categories, we knew that we wanted to work towards creating a more convenient solution for color blind and the elderly people. We drew from the colour blind corrective glasses. What it does ColourSense uses AI to determine accurate colour detection for any items from the camera. We also have  a range of colourfully descriptive words to help the users to have better understanding of the colour. How we built it We used React Native as we wanted a cross platform application available to both iPhone and Android users. We used Flask and OpenCV in the backend to incorporate all the central features in the backend, allowing for a performant but simple solution. Challenges we ran into The biggest challenge for us was learning React Native for the first time. As the entire team had never utilized said framework. It was also surprisingly hard to detect the colours on the screen and get an accurate description of every unique colour. Accomplishments that we're proud of: Learning to use React Native within 36 hours We all pushed ourselves to push the app out in time This is one of the first times we’ve used mobile development First time working with Computer Vision Built With: JavaScript, Python, React Native Built With expo.io javascript opencv python react react-native render.com Try it out GitHub Repo Submitted to Hack the Hill Winner Maker Con Challenge Created by Cormick Holland Tom Miller Jack Wang Spencer Wong"
      }
    ]
  },
  {
    "file_path": "./devposts/codebro.html",
    "project_id": "codebro",
    "title": "CodeBro",
    "tagline": "Have you ever been stuck in your home with no internet after a huge storm? Or on a road trip with no connection? Craving your daily dose of code. No need to panic. Enter... Codebro!",
    "hackathon": "",
    "built_with": [
      "codemirror",
      "css3",
      "figma",
      "html5",
      "pwa",
      "react",
      "tailwind-css",
      "typescript",
      "workbox"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hacky Birthday MLH! 2022WinnerMost Creative Use of GitHub",
      "🌐 Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/039/200/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 💡 Inspiration Imagine this: You’re on a road trip, and being the code monkey you are, you seem to hate every minute of it being offline and away from your code. While we’re somewhat kidding and would strongly urge you to enjoy your trip, we understand that the best way to improve in coding is to practice, and what better platform to practice on that than a platform that works offline? From the get-go, we recognized that there are several problems for coders, especially if they are just starting out: Learning code can, well, be kinda boring. Not everyone learns efficiently through 10-hour tutorials or endless documentation sites, thus our idea partly stemmed from a shared struggle that there is a lack of variety when it comes to learning and practicing code. There’s a goal: as you come to familiarize yourself with the platform, the two tracks both offer a goal-oriented style of learning, allowing users to stay motivated and engaged with their learning. \nAs we learn to code, practice becomes the key to solidifying our understanding, which is why we saw the inherent potential of CodeBro and decided to bring it to life. 🔍 What it does At its core, CodeBro is an offline programming suite that allows users to practice both their web design and competitive problem-solving skills. The first of the two tracks focus on web development, where the user practices their HTML and CSS skills by replicating a reference image as quickly and accurately as possible. Throughout the process, users have a live view of their code and are able to see immediate updates made within their code, on the display. We then use a visual similarity algorithm to locally score how similar the user’s code is in comparison to the reference image. This track is both fast and secure and includes the option to go onto another display in the case that they are either satisfied with their replication or they prefer another image. The second track centers around competitive/logic-based coding que"
      }
    ]
  },
  {
    "file_path": "./devposts/coolvid-19-bot.html",
    "project_id": "coolvid-19-bot",
    "title": "COVID-BOT-19",
    "tagline": "Delivering efficient, trustworthy and real-time COVID-19 data right to your doorstep",
    "hackathon": "",
    "built_with": [
      "discord",
      "geo.js",
      "google-cloud",
      "ipinfo.io",
      "json",
      "python",
      "radar.io",
      "wolfram-technologies"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/210/992/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Data News Fact Data News Fact Data 1 2 3 4 Inspiration During COVID-19, it's hard to find information about COVID-19 quickly and efficiently. However, with the COOLVID-19 BOT, you no longer have to worry about that at all. What it does The bot takes real time data from multiple different APIs and sources, and gets the best data for you. \nThe bot can teach you how to stop the spread of COVID-19, tell you a fact about COVID-19, find COVID-19 data based on your location, find COVID-19 data based on a specific country, specific COVID-19 data of the entire world, and show you the most important or popular news stories on COVID-19. How I built it I made a discord bot using discord.py and heroku, and I queried from multiple APIs including Google APIs(sheets API, drive API, maps API), geocaching APIs(radar.io, geo.js, IPinfo, geonames), news APIs, covid19 APIs (covid19PY), wolfram alpha’s API, and web scrapers like python’s scrapy to get and compile data. I compiled, analyzed, and checked the data to make sure that it was accurate, then sent it to the user. \nI stored the info in a sheets/csv or json format. Challenges I ran into I had trouble getting some of the APIs to work, and it was difficult to parse the JSON files, but I thankfully I figured it out. Accomplishments that I'm proud of The bot worked really well, and there were no errors. Also, it worked relatively fast even with a bunch of API calls. What I learned I learned how to use APIs really quickly, how to do real time updating and querying, efficient data analysis, and how to get things done efficiently in very little time. What's next for COOLVID-19 BOT In the future, I could develop this bot into a website/API framework, add more functions, focus on efficiency and runtime as well as UI, and make it even cooler than it already is! Built With discord geo.js google-cloud ipinfo.io json python radar.io wolfram-technologies Try it out GitHub Repo Submitted to CodeHax 2020 Created by Jerry Zhu CS @UWaterloo | Retire"
      }
    ]
  },
  {
    "file_path": "./devposts/conditional-wrapping-simulation-platform.html",
    "project_id": "conditional-wrapping-simulation-platform",
    "title": "NexusWrap",
    "tagline": "Streamlining efficiency with conditional wrapping based on inter-ledger protocol.Shaping the future of blockchain transactions.",
    "hackathon": "",
    "built_with": [
      "api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Challenges we ran into: As it was the first time for most of us, we faced hurdles in the ideation."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration:\nStemmed from the pressing need to improve interoperability in the blockchain ecosystem, our team aimed to address the challenge of rethinking the facilitation of seamless and secure transfer of digital assets across different blockchain networks through token interoperability. We were noticed the challenges faced by financial institutions in leveraging digital assets due to fragmented blockchain platforms thus our team created a unified digital assets landscape, where seamless asset transfer across blockchains could become a reality. This vision was fueled by our recognition of the untapped potential in decentralized finance (DeFi) and the desire to make these opportunities accessible across various blockchain networks. What it does:\nOur project, across-chain bridging platform called NexusWrap aimed at enabling conditional wrapped-token transfers within an XRP-based interledger-connected ecosystem. NexusWrap uniquely addresses the interoperability challenge by introducing a system that seamlessly integrates dual transaction flows: Atomic Swaps and Wrapped Tokens. This dual-mode operation allows for direct peer-to-peer asset exchanges and broader market access through wrapped tokens. Our conditional token wrapping feature further enhances transaction efficiency by minimizing unnecessary wrapping, thus optimizing network resources. This system not only increases transaction flexibility but also paves the way for integrating private and public blockchain assets, potentially revolutionizing how financial institutions interact with digital assets. How we built it:\nOur project uses cross-chain bridging with several key features, namely the use of Dual-Mode Operations, Support for Interledger Protocols and XRP Ledger. HTML, CSS, JS. Challenges we ran into:\nThe ideation phase posed significant challenges, especially in aligning our diverse perspectives on how to best approach blockchain interoperability. We encountered technical hurdles in integrating different"
      }
    ]
  },
  {
    "file_path": "./devposts/contentmind.html",
    "project_id": "contentmind",
    "title": "ContentMind",
    "tagline": "Turn your ideas into engaging content with ContentMind, where we meet your creative vision, empowering you to craft the perfect posts and captions effortlessly.",
    "hackathon": "",
    "built_with": [
      "genai",
      "llama",
      "llava",
      "nebius",
      "nextjs",
      "tailwind",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "$325 Colega AI prize Winner super awesome cool prize Created by Aditi",
      "s Winner $325 Colega AI prize Winner super awesome cool prize Created by Aditi",
      "Nosu AI Hackathon $11,300+ in prizesWinner$325 Colega AI prizeWinnersuper awesome cool prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/226/158/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Features of Content Mind The main landing page The generate caption page The post generation page Features of Content Mind The main landing page The generate caption page The post generation page Features of Content Mind 1 2 3 4 🚀 Inspiration In today's digital age, the demand for efficient and intelligent content creation tools is at an all-time high. With social media at the heart of business and personal branding, creators need smart, innovative solutions to generate captivating content quickly and consistently. 🌟 What it does ContentMind is an all-in-one intelligent content creation platform designed to supercharge digital creators by enabling them to: Generate attention-grabbing captions for Instagram , X , YouTube , and LinkedIn Maintain a consistent brand voice across platforms Elevate their online presence and maximize social media impact 🛠️ How we built it Our development followed a structured and iterative approach : Conducted deep research to understand creators’ pain points. Designed an intuitive and seamless user interface for ease of use. Built the platform using modern frameworks and cutting-edge AI models. Ensured stability and quality with rigorous testing protocols. 🚧 Challenges we overcame Our journey wasn’t without obstacles! We tackled: Optimizing AI response times while maintaining exceptional content quality . Building a scalable system to handle diverse content formats like text and images. Implementing rock-solid error handling to ensure a reliable user experience. 🏆 Accomplishments we're proud of Successfully launched Version 0.5 of ContentMind, laying the groundwork for scalability. Developed a working prototype showcasing the platform's game-changing potential for creators. Addressed critical challenges with innovative solutions, delivering a seamless experience. 📚 What we learned Our journey provided invaluable insights: Striking the perfect balance between AI efficiency and content quality . Adapting to the ever-evolving needs of digita"
      }
    ]
  },
  {
    "file_path": "./devposts/coris.html",
    "project_id": "coris",
    "title": "Coris",
    "tagline": "91% accurate COVID-19 risk factor prediction based on user's demographics",
    "hackathon": "",
    "built_with": [
      "r",
      "shiny"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/261/900/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Presently there has been a large panic among people regarding COVID-19 and there has been a huge problem with the treatment of a large number of people in hospitals. Some of the patients tend to show early signs and go voluntarily to get the covid test done but it leads to a huge number of people visiting hospitals wherein the hospital's capacity is not able to accommodate the number of people visiting it. In order to streamline the process of delivering healthcare, we propose a method that identifies the risk for a person in terms of having COVID-19 based on their demographics. What it does We developed an accurate machine learning model that can be used to predict the level of risk of a person based on age, race, gender, date of exposure, and pre-existing illness to inform them whether to go for a checkup to the doctor or not and not panic in case any primary symptoms are shown. Model details C5.0 machine learning model 2 fold cross-validation trained over COVID-19_Case_Surveillance_Public_Use_Data Accuracy : 90.60% How I built it Checks for a risk factor for a particular user of having specific age, gender, race, and medical condition - 4 levels of risk factor are given: 0 - No risk (shouldn't visit a doctor), 1 - minimal risk, 2 - moderate risk (should plan on visiting doctor within a week if illness pertains), 3 - High Risk (Should visit a doctor immediately) Based on the risk factor, the user can either visit the doctor or stay at home to avoid infections.\nWe also identified the attributes that were mostly used for making a prediction. In other terms, the risk of having COVID-19 is dependent primarily on the following factors: Attribute Usage for making prediction 100.00% medcond_yn 100.00% age_group80+ Years 94.78%    age_group70 - 79 Years\n-12.73% cdc_report_dt 9.75% age_group60 - 69 Years 6.52% age_group50 - 59 Years 4.72% Race.and.ethnicity..combined.Asian, Non-Hispanic 4.47% age_group40 - 49 Years 3.49% Race.and.ethnicity..combined.Unknown 2.9"
      }
    ]
  },
  {
    "file_path": "./devposts/companionai-8t3fk1.html",
    "project_id": "companionai-8t3fk1",
    "title": "Companion AI",
    "tagline": "Feeling unsafe walking/riding alone? Our app puts a context-aware, proactive AI companion in your hand to provide reassurance and notify emergency contacts if anything goes wrong.",
    "hackathon": "",
    "built_with": [
      "bolt.new",
      "expo.io",
      "flask",
      "openai",
      "react-native",
      "v0",
      "vapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/499/571/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration Imagine a loved one: your daughter, sister, or friend, walking home alone at night. The streetlights are too far apart, the silent atmosphere feels tense, and they grip their phone tightly like it’s the only thing keeping them safe. This fear isn't just a feeling; it's a daily reality. More than 50% of women in the United States are afraid of walking alone at night, according to Gallup's 2023 annual crime poll. We conducted a survey with women around us: our mom, friends, teachers, colleagues, ... about their experience taking an Uber ride or walking home alone. In those situations, they usually let someone else where know where they are at or talk on the phone. But ... what if you don't have someone to talk to? We’ve all seen those Tik-Toks of fake calls people play on speaker to feel safer just something to break the silence and let others know they’re not alone. So, we were so inspired to build CompanionAI who can talk to you on every of your ride or walk alone. It is companion that doesn't just wait for the worst to happen, but actively works to prevent it by providing a sense of presence and safety. What it does Companion AI is a proactive AI safety companion that provides a real-time, reassuring voice presence for anyone feeling unsafe on a solo journey. Here are the features our app support: Voice companion: We created four unique personas that users can talk to, each with their own personality and style of conversation.\n1) Mom: Soft-spoken, warm & calming. She checks in on you and is here for you.\n2) Dad: Supportive & protective. He makes sure you feel safe and never alone on the road.\n3) Sophie: Chill & talkative. She’ll distract you with fun topics and honest girl talk.\n4) Nick: Relaxed, funny, keeps it light. He’ll talk about anything to help you feel more at ease. Two-way conversation: Our companion can hold natural, two-way conversation to directly counters our users' feeling of being a vulnerable target, making their solo jour"
      }
    ]
  },
  {
    "file_path": "./devposts/connecthlete.html",
    "project_id": "connecthlete",
    "title": "Connecthlete",
    "tagline": "A mobile app that connects you with other people near your area to play any kind of sports in an available time of period by reaching out to them with phone number!",
    "hackathon": "",
    "built_with": [
      "android",
      "android-studio",
      "database",
      "firebase",
      "github",
      "java",
      "mobile-java-push",
      "xml"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/261/433/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Find the people nearby your location that are planning to play the same sport as you. (prototype under early access) Sign up with your information. (By signing up, you agree to sharing your current location). Sign in to the app. Select the sport you'd like to play today. Find the people nearby your location that are planning to play the same sport as you. (prototype under early access) Sign up with your information. (By signing up, you agree to sharing your current location). Sign in to the app. Select the sport you'd like to play today. Find the people nearby your location that are planning to play the same sport as you. (prototype under early access) 1 2 3 4 5 Inspiration The inspiration for the project was Covid-19. As we all know, because of the pandemic we remained seperate from our beloved sports and activities and even now, we are still having difficulties finding people around us to gather around for a sports event. This app has been designed to overcome that situation by bringing sports enthusiasts more closer to each and allowing people to meet in a simpler way with a goal. What it does After signing up and logging in Connecthlete, you will be asked for the \"sport you'd like to play\". After choosing one sport, you will be redirected and will be shown under people that wants to play that sport just like you do. Afterwards, you can access the person's number and discuss it further about when to organize the meetup for the sports event. How we built it We have built Connecthlete using android java and XML. After coding each activities in android studio, we've created a firebase database to store the usernames and their passwords with a randomly generated \"key\". Moreover, to test the app, we've used \"android-studio\" which allowed us to simulate the app on an emulator allowing us to keep track of the progress and minor bugs. Challenges we ran into Extracting a random key from a database was a serious problem. In order to store multiple functionalities, we have "
      }
    ]
  },
  {
    "file_path": "./devposts/costcogroceryshare.html",
    "project_id": "costcogroceryshare",
    "title": "Herd",
    "tagline": "Save money by herding together.",
    "hackathon": "",
    "built_with": [
      "css",
      "fastapi",
      "flask",
      "google",
      "html",
      "javascript",
      "postgresql",
      "python",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/646/104/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Code snippet for populating the dropdown on the orders page + helps identify the product page / costco URL Herd Logo Hi-Fi Edition Hi-Fi Edition v2 Design Process Flow Herd - Design Manual Code snippet for the confirmation E-mail Send Code snippet for populating the dropdown on the orders page + helps identify the product page / costco URL Herd Logo Hi-Fi Edition Hi-Fi Edition v2 Design Process Flow Herd - Design Manual Code snippet for the confirmation E-mail Send Code snippet for populating the dropdown on the orders page + helps identify the product page / costco URL 1 2 3 4 5 6 7 Inspiration Costco is a wholesale company that sells bulk items at a discounted rate. Primarily, Costco targets businesses or families that quickly go through large amounts of food. However, this is not oriented towards single individuals, who ultimately could still benefit from the lower prices of bulk buying. Herd aims to allow single individuals to partake in the cheaper prices of wholesale, without having to commit to massive amounts of food that mostly end up going to waste anyways. Herd allows users to bid on products sold in bulk, so that it can be split into different portions based on how much the users want. What it solves Students benefit hugely from the benefits of the cheaper wholesale prices . With Herd, we've created a solution that allows college students to partake in a 'Herd', where each participant is buying a part of a wholesale item. Whether that is a massive package of 20x beef patties, or something entirely different, these products can be split up into bite-sized chunks for the students, based on their needs and wishes. On average, over a single year, one would save $1,000 USD a year from buying all your grocery needs at Costco, instead of other options (source: https://www.cnet.com/home/kitchen-and-household/how-much-can-i-save-shopping-at-costco/ ). That amount of money is a lot, especially for a student. The problem that it solves is twofold. For one, in many "
      }
    ]
  },
  {
    "file_path": "./devposts/course-assistant.html",
    "project_id": "course-assistant",
    "title": "Automated Reasoning for Course Scheduling",
    "tagline": "A Python algorithm that utilizes Z3-Solver to automatically assign the appropriate time slot and location for a given course",
    "hackathon": "",
    "built_with": [
      "github",
      "google-calendar",
      "pandas",
      "python",
      "sat",
      "smt",
      "z3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Research Track Projects Created by Keerthi V Private user Suruchi Walekar Meliora Ho A student, res",
      "Technica 2022WinnerResearch Track Projects",
      "Winner",
      "Part of the Tech + Research track!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/258/153/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Visual of the final result on Google Calendar Visual of the final result on Google Calendar Visual of the final result on Google Calendar 1 2 Inspiration Course scheduling is a real problem at many universities, as it is difficult to account for multiple factors like instructor availability, room sizes, etc., while making sure that all classes are eventually scheduled. Since much of this process is still done manually for departments at UMD, we wanted to come up with an automated solution to satisfy scheduling requirements with less intensive manual effort. What it does To put it simply, it is a class-to-room scheduler. Using SMT or SAT modulo theories, the course assistant takes in data about classes, including number of student, professors, available rooms, and room sizes to make the most efficient matches so that all classes are scheduled in rooms without any time conflicts. How we built it We set constraints for making class-to-room matches in Python, and used the Z3 SMT solver to find a solution that would take all of them into account and work around them. We then loaded the results into a .csv file that could be uploaded onto a Google Calendar to view the schedule more easily. Challenges we ran into It was difficult to make sure that the correct constrains were passed into the Z3 solver, add additional functionality like different class durations and professors, and integrate it with Google Calendar to display the finalized schedule as a sample for a week. Since we were working both virtually and in-person, we relied on good communication between team members to make sure code was combined accurately. Accomplishments that we're proud of Over the course of the weekend, we were able to implement (almost) all the features we planned for, and present a program that UMD could use to schedule their own classes if developed further. The progress we made is exciting and shows that SMT could be a viable solution for the problem of scheduling classes. What we learned S"
      }
    ]
  },
  {
    "file_path": "./devposts/concussify-alftbd.html",
    "project_id": "concussify-alftbd",
    "title": "ConCussify - The Idea",
    "tagline": "AI Powered Concussion Detection ⚡ On your browser, in one minute.",
    "hackathon": "",
    "built_with": [
      "video"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/550/118/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Our submission for the Ideathon Division Inspiration Concussions are known for going undiagnosed, particularly in sports, where there’s pressure to play through injury and more obvious symptoms may not immediately be evident. My sister, for instance, experienced multiple concussions as a competitive cheerleader without realizing, and this resulted in her receiving delayed medical attention and suffering through worsened symptoms. We were motivated to address this problem by developing a convenient and accessible solution for athletes and other individuals prone to concussions, empowering them to independently assess their condition on the spot and seek medical help promptly. By combining a user-friendly and interactive interface with AI features to fill-in for potentially unavailable healthcare professionals, our web app aims to make concussion diagnosis more accessible and efficient than ever before. What it does Concussify determines the likelihood of a concussion based on whether it detects a difference in the pupil size of the right and left eye (a common indication of a concussion). We had also planned for users to be able to take a series of baseline tests that can be repeated after a head injury to determine if there’s been a change in their cognitive speed, memory, or awareness. How we built it The frontend was written in CSS and HTML, and we developed the backend using Cloudflare Workers, which is an edge-based serverless provider that is based upon the WinterCG runtime; through this, we are able to create a highly-scalable and mobile backend able to tackle almost any challenge. We do not have any lock-in as it is based on the Winter CG Runtime which allows us to move to other providers such as Vercel or Deno. We decided to implement Google sign-in to reduce development time while still providing ease-of-use.\nThe pupil size detection function was built using two pretrained machine learning models. The image is first processed through OpenCV’s "
      }
    ]
  },
  {
    "file_path": "./devposts/covid-19-reviews.html",
    "project_id": "covid-19-reviews",
    "title": "COVID-19 Reviews",
    "tagline": "A Chrome extension that aggregates customer data to provide an accurate rating for how well businesses are following COVID-19 protocol.",
    "hackathon": "",
    "built_with": [
      "chrome",
      "cockroachdb",
      "css",
      "extension",
      "google",
      "google-cloud",
      "google-maps",
      "html",
      "javascript",
      "maps",
      "postman",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "None of us have made a Chrome extension before and this is the first hackathon for half of our team members!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/347/036/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration As of writing, there have been 94 million cases of COVID-19 worldwide. Many of these cases come from public places, such as grocery stores, banks, or other businesses, where water droplets can be easily transmitted through the air or onto public surfaces. Although the government has mandated precautions such as mandatory masks and social distancing, businesses provide varying levels of safety — both on the onus of business enforcement and customer compliance of these guidelines. I’m sure we’ve all experienced the anxiety that comes with being near someone wearing their mask wrong or entering your 2-metre bubble. For many citizens, it is difficult to perform daily routine tasks without a concern of lenient measures occurring in areas they frequent. Our COVID-19 Reviews extension was created to give customers specific information about businesses while still being closely integrated with apps they often use for navigation (Google Maps). What it does COVID-19 Reviews is a Chrome extension that augments the Google Maps platform by adding a new set of ratings related to pandemic guidelines for businesses. The extension shows the aggregated average rating of any given business across various criteria (eg. customers/employees observing social distancing, adherence to maximum occupancy guidelines, etc.) and allows users to submit their own review. Customers will give higher ratings to stores that follow these precautions, which will in turn attract other customers to choose this store over one with less strict enforcement of health safety protocol. How I built it The backend consists of a Google Cloud Compute virtual machine running Node.js as a server with a CockroachDB database. The Node.js server acts as an API, with multiple endpoints for pulling and submitting reviews.\nThe Chrome extension is a React app injected directly into the DOM. Challenges I ran into Working with CockroachDB was a challenge in that it was a software that we did not have experience be"
      }
    ]
  },
  {
    "file_path": "./devposts/covid-safe-gatherings.html",
    "project_id": "covid-safe-gatherings",
    "title": "COVID-Safe Gatherings",
    "tagline": "This app helps facilitate the planning of meetings during the COVID-19 pandemic. With the help of the app you can see when/if it is safe to organize meetings.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "flask",
      "html5",
      "javascript",
      "python",
      "sqlalchemy",
      "werkzeug"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Beginner Project Winner Finalists Created by victorbosneag Bosneag",
      "Best Beginner Project Winner Finalists Created by victorbosneag Bosneag",
      "Hack3 (2021)WinnerBest Beginner ProjectWinnerFinalists",
      "I'm really proud of the fact that I coded my first web application during my first ever hackathon.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I am a part of my high school's robotics team. During this pandemic it was though to see at a glance which participants are able to meet. So I was thinking that an application that could instantly provide everyone's COVID status (vaccinated, positive, negative) and then I came up with the idea that this application can be extended in other types of activities like parties, sports, cultural events and so on. What it does This app instantly provides you with information about all your attendees  and in case it wouldn't be safe to meet on the planned date to calculate the next safer date. How I built it I built a full stack web application using a Flask back-end and Bootstrap front-end. For the database I used a sqlite3 database managed with Flask SQL Alchemy. User's data is stored in 3 separate  tables: Users, User_history and Party which store the user info (username, password, email), COVID status history and meeting info respectively. Challenges I ran into While coding this app I ran into a lot of integration challenges between the front-end and the back-end. Accomplishments that I'm proud of I'm really proud of the fact that I coded my first web application during my first ever hackathon. What I learned Making this I learned quite a lot about working with databases in Python and using SQL Alchemy.\nI also learned to manage my time well when working within tight deadlines. What's next for COVID-Safe Gatherings I plan to improve this app by adding more security measures, email notifications, public user profiles as well as deploying on a server being accessible for people around the world. Built With bootstrap css flask html5 javascript python sqlalchemy werkzeug Try it out GitHub Repo Submitted to Hack3 (2021) Winner Best Beginner Project Winner Finalists Created by victorbosneag Bosneag"
      }
    ]
  },
  {
    "file_path": "./devposts/courseify.html",
    "project_id": "courseify",
    "title": "Courseify",
    "tagline": "Courseify is a platform that automatically generates a crash course for any subject by combining a video tutorial with relevant information and questions in order to check understanding and practice.",
    "hackathon": "",
    "built_with": [
      "api",
      "css",
      "html",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/383/478/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "What does Courseify do? Landing Page Example Work From Home What's the problem? What does Courseify do? Landing Page Example Work From Home What's the problem? What does Courseify do? 1 2 3 4 5 6 💡Inspiration: The COVID-19 pandemic has affected everybody in one way or another. Many have lost their jobs, or have started working from home. In Ontario, Canada, students all across the province have gone through months of quarantine, where they were forced to learn from home. This drastic change was grueling for all, and drastically affected the learning of every individual. Many people struggled with the adjustment since there aren’t many free online tools that can help students teach themselves in the case when staring at a Google Meet just isn't enough. That’s exactly where Courseify comes in, it brings a whole new level of online learning by automatically generating crash courses by keyword. Courseify isn’t just a platform strictly used for distance learning. It’s meant to make every day learning more effective. Most students tend to forget the content found in videos and lessons they have watched. With Courseify’s novel method of watching educational videos, it allows for students to more thoroughly compound on the content that is given to them. The best way to learn is to do, and we capitalize on this very theory. ❓What it does: Courseify strives to improve students' learning by creating a platform where they can have access to both instructional materials as well as a wide range of other practice questions and other practice material for a topic of their choice. Through scraping the internet Courseify finds the perfect set of materials and amalgamates everything to semantically generate a crash course. 🏗️How we Built it: Frontend: The frontend was designed in Adobe XD and Illustrator, and then built using HTML, CSS, and JavaScript, with bootstrap as our fundamental library. The use of React and other frontend frameworks was considered, although for this use case, "
      }
    ]
  },
  {
    "file_path": "./devposts/climate-control.html",
    "project_id": "climate-control",
    "title": "Climate Control",
    "tagline": "An immersive VR experience offers a story of hope for our shared future on Earth.",
    "hackathon": "",
    "built_with": [
      "c#",
      "eye",
      "glsl",
      "hlsl",
      "htc",
      "javascript",
      "maya",
      "mixamo",
      "pro",
      "shaderlab",
      "tiltbrush",
      "unity",
      "vive"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/918/204/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "In action Go solar! Inner peace Permaculture fields Terra and Auccu Team Climate Control Hacking af In action Go solar! Inner peace Permaculture fields Terra and Auccu Team Climate Control Hacking af In action 1 2 3 4 5 6 7 8 Inspiration Upon the principle of doing more with less, Buckminster Fuller designed the geodesic dome, a system that maximizes the structural integrity of a contained, hemispherical volume with minimal material resources organized in triangular patterns. Under domes of glass and steel, artificial biospheres have been cultivated to shelter and sustain life in otherwise inhospitable environments. Our changing climate implores us to reflect on the consequences of our shared impact on the living Earth system and how our grandchildren might fare in the latter half of the 21st century. What it does Climate Control delivers a hopeful story about the resilience of life on Earth to survive, despite the effects of our anthropogenic pollution, or as Fuller framed it: \"nothing but the resources we are not harvesting.\" We must venture beyond only behavioral changes at the individual level and must become stewards of our planet on a societal level now to prevent potential futures of societal collapse from coming to fruition. How we built it Unity/C#, Tilt Brush, Google Poly, Maya, Visual Studio, HTC Vive Pro Eye, Bellus 3D, Adobe Mixamo, Android Voice Recorder, Mixcraft Studio 9, Akai Professional MPK Mini MKII, Freesound. Everything in the Biosphere is replicated to focus on real life solutions, used in places like Biosphere 2 in Arizona and how life can be sustainable with the right resources in a climate controlled environment. Challenges we ran into We began development with Quest then pivoted half way through to Vive Pro Eye. We also recorded both English and Spanish dubs as well as translated text of our script to implement closed captioning for users who are deaf or hard of hearing. We imported a package developed by another group to display these clo"
      }
    ]
  },
  {
    "file_path": "./devposts/crescendo-yt3wc1.html",
    "project_id": "crescendo-yt3wc1",
    "title": "Crescendo",
    "tagline": "Your personal AI music coach — analyze your practice sessions, get instant feedback on tone and technique, and follow a smart, personalized plan to master your instrument before your next lesson.",
    "hackathon": "",
    "built_with": [
      "ai-studio",
      "gemini",
      "next",
      "react",
      "tailwind-css",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/500/941/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chatbot Home Choose your instrument Record piano practice Practice strengths Practice weaknesses Practice resources Chatbot Home Choose your instrument Record piano practice Practice strengths Practice weaknesses Practice resources Chatbot 1 2 3 4 5 6 7 8 🎵 Inspiration As passionate musicians, we’ve all experienced the frustration of practicing alone—without timely feedback, it’s easy to reinforce bad habits or feel unsure about progress. Regular lessons can be costly, and many learners—especially beginners—lack consistent access to expert guidance. We built Crescendo to bridge this gap and democratize access to high-quality musical feedback using AI. 🤖 What it does Crescendo brings the power of AI to your music practice sessions. Our platform, Crescendo, offers four core features: 🎹 A home page with intuitive navigation and instrument selection. 🧑‍🏫 An AI assistant music tutor tailored for each instrument. 📚 Skill-based learning resources based on user experience. 🎙 A voice-activated chatbot to interactively discuss feedback. Here’s how it works: Upload or record your music directly in the app. Click “Analyze Performance” to receive AI-driven feedback. Our fine-tuned Gemini prompt, acting as a virtual music teacher, gives ✅ 3 strengths, ⚠️ 3 areas for improvement, ⏱ time-stamped callouts and suggestions on what to replay and fix, and 🔗 linked resources (e.g., YouTube clips) to model proper performance. You can also “Save Recording” to track your musical growth over time.\nFinally, our voice chatbot extends the learning experience—allowing users to speak naturally to the AI assistant to clarify feedback or explore additional musical tips. 🧰 How we built it Google AI Studio Gemini Next.js React Tailwind CSS 🚧 Challenges we ran into Integration Issues: Embedding our chatbot into the Next.js homepage proved tricky since the chatbot was built with TypeScript and React. Due to time constraints, we embedded it using an iframe instead of a full integration. Audio Compatibil"
      }
    ]
  },
  {
    "file_path": "./devposts/crush-dem-demons.html",
    "project_id": "crush-dem-demons",
    "title": "Crush Dem Demons",
    "tagline": "Crush your inner demons while playing this game - literally!",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "of Show Best Gaming Hack Hackers Choice [MLH] Best Domain Name from Domain",
      "Accessibility Hack sponsored by Fidelity Inspiration Belonging in tech is a work in progress for mi",
      "of Show - First Place Winner Best Gaming Hack - First Place Created by Anita Yip Product owner, pro",
      "Winner Best Gaming Hack - First Place Created by Anita Yip Product owner, project manager, retired",
      "Best of Show - First Place Winner Best Gaming Hack - First Place Created by Anita Yip Product owner",
      "YCP Hacks 2022WinnerBest of Show - First PlaceWinnerBest Gaming Hack - First Place",
      "Best of Show",
      "Best Gaming Hack",
      "[MLH] Best Domain Name from Domain.com",
      "[MLH] Best Accessibility Hack sponsored by Fidelity",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/285/001/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Categories for Consideration Best of Show Best Gaming Hack Hackers Choice [MLH] Best Domain Name from Domain.com [MLH] Best Accessibility Hack sponsored by Fidelity Inspiration Belonging in tech is a work in progress for minorities. There's a shortage of women in development roles in the industry, and there are even fewer female game developers and BIPOC women developers. Because reading books and online articles don't cut it for instilling confidence I need and absorbing information, I wanted access to new ways to learn. Given my interest in creating games for social good and wanting to work on more Unity projects, I thought it'd be opportune to learn how to create a turn-based game where I can visualize myself defeating my inner demons. What it does Crush Dem Demons is a turn-based RPG game where you (Player 1) and your sidekick of courage defeat inner demons personified like fear, comfort zone, naysayer Ned, and inner voice Ivy. Games can help develop our resilience by allowing us to digest and retain information in new ways. How we built it I built this in Unity, C# Challenges we ran into Learning Unity/C# again after months of not working on a Unity project - always feeling like a beginner. Accomplishments that we're proud of I did this hack solo! What we learned The importance and usefulness of singletons, avoiding triggering events and routines accidentally, reading documentation, a lot of game design and software architecture/planning, and piecing together tutorials! What's next for Crush Dem Demons Flesh out this hack!!! Built With c# unity Submitted to YCP Hacks 2022 Winner Best of Show - First Place Winner Best Gaming Hack - First Place Created by Anita Yip Product owner, project manager, retired hackathon-er"
      }
    ]
  },
  {
    "file_path": "./devposts/cowokr.html",
    "project_id": "cowokr",
    "title": "Coworkr",
    "tagline": "An AI-powered know-it-all bot tailored for your team's need.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "clerk",
      "cohere",
      "fastapi",
      "gpt",
      "langchain",
      "nextjs",
      "node.js",
      "openai",
      "pinecone",
      "python",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/522/538/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Edit Bot High level design Your Bots Chat New Source Your Sources Keys Edit Bot High level design Your Bots Chat New Source Your Sources Keys Edit Bot 1 2 3 4 5 6 7 8 Inspiration 💡 Our inspiration stems from recognizing the challenges individuals face in their daily information retrieval and communication needs. We understand the difficulties of obtaining past documentations to effectively complete tasks, the importance of streamlined onboarding for new employees, the necessity of researching product information for customer inquiries, the complexity of analyzing content from multiple sources, and the time sensitivity in quickly citing sources for information. With Coworkr, we aim to provide a comprehensive service that addresses these challenges by offering a centralized platform for efficient document retrieval, seamless onboarding processes, streamlined access to product information, intelligent content analysis tools, and a reliable source citation system. Our goal is to empower individuals and organizations with the necessary tools to enhance their productivity, streamline their workflows, and ultimately achieve their goals with ease. What it does 🙋‍♂️ Coworkr is a dynamic service that simplifies and enhances various aspects of information retrieval and communication. Our platform excels in providing easy access to past documents, eliminating the tedious and time-consuming process of searching through archives. With Coworkr, onboarding becomes seamless and efficient through a combination of a comprehensive knowledge base and AI-powered chat capabilities, ensuring new employees have the necessary resources at their fingertips. Our advanced technology simplifies content analysis by aggregating and analyzing information from multiple sources, enabling users to gain valuable insights effortlessly. Additionally, Coworkr offers quick and reliable source citation capabilities, allowing users to seamlessly cite their references. By seamlessly addressing these needs, Co"
      }
    ]
  },
  {
    "file_path": "./devposts/crash.html",
    "project_id": "crash",
    "title": "Crash!",
    "tagline": "Our project is a driver controlled car that tries to avoid 3-d obstacle set on a terrain filled with houses/trees.",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We play many games which were fun, so we thought of what made a game fun. A game that looked professional and never-ending. What it does An android game where we touch left or right part of the screen to control a 3-d car. The obstacles set on the terrain are meant to be avoided. How we built it We used unity and c# Challenges we ran into The interface was confusing and it was hard for all of us to work on the program. Accomplishments that we're proud of We had no clue of how to use c# or unity so it was interesting to figure out how to program and make a simulation. What we learned We learned  game development and how to use unity to build an android game. What's next for Crash! We didn't have enough time to finish the game.(Where the car should stop when it hits and obstacle) Built With c# unity Submitted to HackSB 2018 Created by Arnav Nayak Neel Shah Student Ankit Chadha Debesh Sahu"
      }
    ]
  },
  {
    "file_path": "./devposts/connect-four-ai.html",
    "project_id": "connect-four-ai",
    "title": "Connect Four AI",
    "tagline": "hether it be Grad Nite, End-of-Year Parties, or College Orientation, the party game classic Connect Four is always there.  This project uses a Neural Network to find the best move in this game!",
    "hackathon": "",
    "built_with": [
      "ai",
      "css3",
      "express.js",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I’ve studied and read about them before, but this was my first time making a convolutional neural network!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/019/369/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Demo Picture Demo Picture Demo Picture 1 2 Inspiration Whether it be Grad Nite, End-of-Year Parties, or College Orientation, the party game classic Connect Four is always there. And every time, I trusted my quick thinking and logic skills to bring me to a Connect Four victory. (Needless to say, I lost every time.) But this hackathon was my chance at redemption; I would finally defeat my nemesis. Using Neural Networks, Convolutions, and Genetic Algorithms, I finally have beaten the game that has tormented me for so many weeks! What it does I wrote and trained a neural network to play Connect Four. How we built it Uses a self-made convolutional neural network, trained by a genetic algorithm.  Essentially, in each generation, the bot is pitted against a mutated (changed) version of itself, and scored on its performance.  The low performing bots are discarded and the highest performing AIs repopulate and mutate the next generation. This is also a full-stack project where the AI is run on a server and communicates that info to the front-end via post requests. Challenges we ran into Training and figuring out how to optimize the model has been difficult. Accomplishments that we're proud of I’ve studied and read about them before, but this was my first time making a convolutional neural network! What we learned Every machine learning problem has many nuances and facets to take into account in order for training to go smoothly.  I also gained a bit more valuable experience with backend server communication. What's next for Connect Four AI I might explore by altering the fitness functions to guide training in a less haphazard way. Built With ai css3 express.js html5 javascript Try it out connectfourai.archimedesli.repl.co Submitted to Hack3 Created by Archimedes Li"
      }
    ]
  },
  {
    "file_path": "./devposts/copy-right.html",
    "project_id": "copy-right",
    "title": "copy-right",
    "tagline": "Why copy wrong when you can copy right with no copyright? That's right! You can copy anything from any device and paste anything to any device with no issues using the copy-right web app!",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "firebase",
      "google-cloud",
      "heroku",
      "html",
      "javascript",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/984/741/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Meet the Team Logo Logic Figma Design Meet the Team Logo Logic Figma Design Meet the Team 1 2 3 4 5 Inspiration Have you ever wanted to send something quickly from one device to another but got a brain freeze because you didn’t know how to? Well, say no more! Using copy-right helps to eliminate this problem by logging into our website and copy-pasting with ease! What it does Copy-right is a web application that makes copying things from one device and pasting it to another much easier. All you have to do is log in to our website copy-right.tech and copy any file from your device and log in to our website again on another device and paste it there. How we built it We built our web application copy-right using React, HTML, CSS and javascript for the frontend and github for branching and version control. As for the backend, we started with cockroach DB but moved to firebase since cockroach caused dependencies conflicts. We also used Google Oauth 2.0 authentication for user verification. Challenges we ran into We encountered challenges with learning some JS libraries such React, and firebase. We started off by using CockroachDB but soon moved to firebase due to some challenges with documentation and multiple proprietary frameworks. We also had troubles with framer motion and incorporating some of its libraries into our project. Accomplishments that we're proud of We are proud of all the process that we went through in this project. Each of us improved in different aspects and skills including designing, coding, using new libraries, encountering and fixing bugs, communication, time management and creativity. What we learned Although we learned a lot of technical skills such as how to use new JS libraries, we also learned that it is okay to encounter problems and tweak our initial idea as we go. What's next for copy-right Our future steps include ensuring security for users by preventing personal files to be stolen by other users or hackers. Built With css figma firebase "
      }
    ]
  },
  {
    "file_path": "./devposts/con-anima.html",
    "project_id": "con-anima",
    "title": "Con Anima",
    "tagline": "\"Con Anima\" - in a spirited manner, referring to music. This is a platform to inspire songwriters and help in the songwriting process, supplying inspiration and a space to work their magic.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "browserrouter",
      "css3",
      "firebase",
      "genius",
      "github",
      "html5",
      "javascript",
      "python",
      "react",
      "spacy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/651/175/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Share to soundcloud and youtube Idea inspiration screen Login Screen Firebase (stores user data) Sheet Music Brainstorming page Store Final Lyrics Python script running plagiarism check (red text is not error) Share to soundcloud and youtube Idea inspiration screen Login Screen Firebase (stores user data) Sheet Music Brainstorming page Store Final Lyrics Python script running plagiarism check (red text is not error) Share to soundcloud and youtube 1 2 3 4 5 6 7 8 Inspiration Our name, Con Anima, means \"with spirit\" in Italian and is typically used as a musical direction. In this theme, our team wanted to create a platform to inspire and support songwriters through the songwriting process so they can capture their spirit in their music. We have many features that we felt would be conducive to the creative process, including a space for brainstorming both lyrics and musical notation. We also wanted to give them an avenue to check for accidental plagiarism and directly upload to Soundcloud, all on the same platform. What it does This is a website designed to aid the songwriting process in multiple ways. It's password-authenticated to make users feel secure and contains space for the songwriter to brainstorm both lyrics and musical notation. We also have a space where songwriters can select a specific emotion and get words to jump-start the lyric writing process. They can also select a musical key and get a suggested chord progression to build off of. Later on, the songwriters can run their lyrics through a plagiarism detector in order to prevent accidental plagiarism. How we built it We decided to split up the project into parts with each of us working on one tab of the entire project. We used React on the frontend and firebase for the login authentication. We also used HTML and CSS in the IDE Visual Studio Code, however, when connecting the back end and front end, we had to convert the code into JavaScript. For the plagiarism detector, we used a Genius API to bring in"
      }
    ]
  },
  {
    "file_path": "./devposts/create_your_mark-debug_thugs.html",
    "project_id": "create_your_mark-debug_thugs",
    "title": "SharkTanks - Debug_Thugs",
    "tagline": "\"Join the battle, forge your destiny.\"",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "html",
      "node.js",
      "railway.app",
      "socket.io",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/338/753/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GamePlay playgame LandingPage GamePlay playgame LandingPage GamePlay 1 2 3 4 Inspiration We were inspired to build an online multiplayer game because we all have always been a fan of video games and the idea of being able to play with others from across the world and it really excites us. What it does It is a type of video game that allows multiple players to play together over the internet with each other. Also even if there is no one around to play we have also implemented a bot that can work as an additional player. How we built it We used HTML and CSS for the landing page, Three.js, Express.js and Node.js for the game environment and all other controls; Railway. app as a host and socket.io as a client-server interaction tool. Challenges we ran into To be honest, there were many challenges that we ran into some of them are as follows:- Network Latency: In the beginning, we were using the rendered tanks and because of that same there was a lot of lag in the gameplay. Server scalability: As more players were joining the game, the game server was overloaded and unable to handle the increased traffic. which was again causing a decrease in performance and causing a bad user experience. Page overrides: The index page was being overridden by the canvas of the game and in order to avoid that we have to make a few changes in the particular layouts. Function Workability: The particular function for counting the hit so that, the damage on the tank can be noted was not working properly, but we performed a few debug techniques and got it fixed. Accomplishments that we're proud of “Impossible is just an opinion.” —Paulo Coelho We were able to learn many things and implement them in under 24 hrs which is an accomplishment in itself. What we learned “Live as if you were to die tomorrow. Learn as if you were to live forever.” ― Mahatma Gandhi\n We learned how to build an online multiplayer game with working functionality and host it on the server so that it is accessible to other "
      }
    ]
  },
  {
    "file_path": "./devposts/covid-19-risk-assesment-k0xcm6.html",
    "project_id": "covid-19-risk-assesment-k0xcm6",
    "title": "COVID 19 Risk Assesment",
    "tagline": "Powered by ML, our tool can calculate a user's covid 19 risk to help hospitals prioritize limited hospital resources to those that need them the most. Click and evaluate. It is that simple.",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "machine-learning",
      "python",
      "sikit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Time since they first exhibited symptoms."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/443/800/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The website's homepage Getting your COVID 19 Results The website's homepage Getting your COVID 19 Results The website's homepage 1 2 3 Covid 19 Risk Assesment Try it out! Project Github Project Video Explanation Inspiration The project was inspired by the world's initiative to flatten the curve for covid19 in the global pandemic to ensure that critical risk patients receive the care that they require. The effect that covid 19 can have on a person is highly dependant on how quickly they get medical care as soon as symptoms are onset as well as their age and gender. Thus we created a risk calculator to prioritise patients based on their needs. What it does The app uses machine learning based on thousands of previous covid cases to asses the risk for an individual based on their: Gender Age Time since they first exhibited symptoms. The app then gives the user a score out of 10 based on the above factors to gauge their risk of death from covid 19. It does so by using machine learning to create a model that can then be extrapolated from to gauge an individual's risk based on these 3 key factors. The machine learning algorithm uses a polynomial regression algorithm to create a model for each of the 3 factors, normalises the user's score for each factor and then displays the risk to the user out of 10 How we built it We searched the internet for useful covid 19 patient data which was quite hard to find due to patient confidentiality laws. We then formatted the data that we found into csv files that would be read into the program. Once the data was read into the program, we used the following to parse the data: numpy Numpy was used to transform the data arrays into a format that can be used by the polynomial regression algorithm scikit-learn Scikit-learn was a simple to use machine learning library that was used to create the models. We used a polynomial regression algorithm to model the effects of: Age Days since symptoms appearing and going to the hospital As for the effe"
      }
    ]
  },
  {
    "file_path": "./devposts/condensation-by-13-labs.html",
    "project_id": "condensation-by-13-labs",
    "title": "Condensation by 13Labs",
    "tagline": "Video condensation",
    "hackathon": "",
    "built_with": [
      "llamaindex",
      "openai",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/671/759/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Motivation Unlike text, you cannot easily query specific sections of video. With Condensation by Thirteen Labs, you can ask your video any question and we will direct you to the relevant timestamp that answers your query. What it does Condensation does video analysis by enabling a detailed breakdown of video content into its essential elements. Users can pose specific questions about any aspect of the video directly to this interface. This system is particularly beneficial for users who need to analyze video content in depth, including researchers, educators, content creators, and media professionals. It offers a practical and efficient way to navigate and understand complex video content, significantly enhancing productivity and insight in video analysis. Condensation aims to improve learning and enhancing education for educators and students. Educational content are made more accessible and interactive, leading to a more engaging and effective learning experience. Features that condensation aims to accomplish: Interactive Learning: By allowing students and educators to interact with video content through queries, Condensation makes learning more engaging and participatory. Students can explore topics in-depth by asking questions about specific video segments, fostering a more active and exploratory learning style. Customized Education: Educators can use Condensation to tailor educational content to individual learning needs. For instance, students struggling with certain concepts can receive targeted video segments that address their specific challenges, aiding in personalized learning paths. Enhanced Understanding of Complex Subjects: Complex subjects are often difficult to grasp through traditional teaching methods, can be broken down into easily digestible segments. This segmented approach can help in simplifying and explaining intricate topics, making them more accessible to learners of all levels. Additional potential for human enhancements are as follows: In"
      }
    ]
  },
  {
    "file_path": "./devposts/creatoon.html",
    "project_id": "creatoon",
    "title": "CreaToon",
    "tagline": "An Online Tool to Cartoonify your Images",
    "hackathon": "",
    "built_with": [
      "firebase",
      "flask",
      "javascript",
      "python",
      "react",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/599/207/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Designing each and every scene for a Comic or even a small comic strip can be hectic, especially when the inspiration is taken from real-world scenarios. It may take hours or days to draw and color them. What it does CreaToon is an online tool, that you can use to convert real-world images into their cartoonified versions, like the ones you see around in comics. It can be used for something from creating your next profile picture to creating background images for your comics to give you a kickstart. How we built it Front-end - React, HTML, CSS, Javascript\nBack-end - Python, Flask, OpenCV\nHosted on Firebase (Google Cloud)\nTech Domain - https://createtoonswith.tech/ Challenges we ran into Connecting Front-end to Back-end API using GET/POST Requests. DNS Configuration for our .tech domain. Accomplishments that we're proud of We're proud of completing all the functionalities of this project, and hosting it with a .tech domain, within the weekend. What we learned API Integration, Hexadecimal Conversions, URL Encoding, DNS Management. What's next for CreaToon More efficient UI/UX Built With firebase flask javascript python react replit Try it out GitHub Repo GitHub Repo createtoonswith.tech creatoon-40449.firebaseapp.com Submitted to Hacktoon Created by Neel Adwani yeet Bailey Luu Hi everyone! My name is Bailey. I’m a third-year student major in computer security."
      }
    ]
  },
  {
    "file_path": "./devposts/cyberguardian-hbeouf.html",
    "project_id": "cyberguardian-hbeouf",
    "title": "DataDefender",
    "tagline": "DataDefender is a chrome extension that provides users with a comprehensive analysis of the security and ethical standards of every website they visit!",
    "hackathon": "",
    "built_with": [
      "chrome",
      "css3",
      "extension",
      "html5",
      "javascript",
      "openai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by Built the browser extension prototype, created the presentation, and formu",
      "All In HackathonWinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/432/326/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration The inspiration for DataDefender came from the growing concern around online privacy and security. We noticed that as more people rely on the internet for their daily activities, there was a lack of tools that could help them evaluate the safety and privacy of the websites they visit. We wanted to create a solution that could empower internet users to take control of their online privacy and security. We believe that everyone deserves to feel safe and secure while navigating the digital world. With the rise of cyber threats such as hacking and data breaches, it's more important than ever to have a tool that can help users make informed decisions about their online activities. We saw an opportunity to make a difference in this space and developed DataDefender to provide users with a comprehensive analysis of the security and ethical standards of every website they visit. Our goal is to help people feel confident in their online activities, knowing that they are protected from cyber threats and that their privacy is being respected. What it does DataDefender is a chrome extension that provides users with a comprehensive analysis of the security and ethical standards of every website they visit. It generates a security score and cyber ethics analysis for each website, giving users an understanding of the risks associated with their online activities. In addition to analyzing the security and ethical standards of websites, DataDefender also provides alternative options for websites with subpar privacy policies. This enables users to make informed decisions about the websites they visit, ensuring that their online activities align with their privacy and ethical standards. By providing users with the information they need to make informed decisions, DataDefender empowers users to take control of their online privacy and security. The extension is designed to help users navigate the digital world with greater confidence, knowing that they are protec"
      }
    ]
  },
  {
    "file_path": "./devposts/cryptomed-6qz489.html",
    "project_id": "cryptomed-6qz489",
    "title": "CryptoMed",
    "tagline": "A web app that uses Cryptography to secure medical records and prescriptions",
    "hackathon": "",
    "built_with": [
      "coil",
      "cryptography",
      "fernet",
      "flask",
      "python",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Web Monetization Project Created by Neel Adwani yeet",
      "BorderHacks 2021WinnerBest Web Monetization Project",
      "I applied cryptography for the first time in a deployed project, so I'm proud of that.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/672/154/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Carrying and managing prescriptions or even files that contain health records can be difficult in today's world. A lot of times patients lose track of them, which can make it difficult for them to get newly prescribed medicines, carry them around at places, and they have to explain their history while switching doctors. What it does CryptoMed digitizes the medical records and prescriptions and stores them in a database, after applying cryptography to them via fernet, and makes it easier to access them at any time and anywhere. Not just that, CryptoMed stores all the sensitive health data after encrypting it with a private key, which cannot be decrypted even if the database is breached unless the attacker has access to the system physically. How I built it Back-end: Python-Flask, Fernet (cryptography) Monetization: Coil Front-end: HTML, CSS, JS Challenges I ran into String to byte conversion and key decryption was the most difficult part. Accomplishments that I'm proud of I applied cryptography for the first time in a deployed project, so I'm proud of that. What I learned I learned about cryptography, fernet, and integrating them with flask. What's next for CryptoMed I'll be adding a better UI, developing a proper doctor/patient sign up and securing the account credentials as I did with the medical records and prescription. Built With coil cryptography fernet flask python replit Try it out GitHub Repo cryptomed.neeltron.repl.co Submitted to BorderHacks 2021 Winner Best Web Monetization Project Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/crosssight.html",
    "project_id": "crosssight",
    "title": "CrossSight",
    "tagline": "Empowering the visually impaired with an app that uses a phone camera to analyze cross-walks, cars, and traffic signals to find a safe time and path to the other side of a road crossing.",
    "hackathon": "",
    "built_with": [
      "flask",
      "keras",
      "nextjs",
      "opencv",
      "yolov8"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack Cupertino 2024Winner1st Place - 3D Printer",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "What it does Visually impaired or blind people have difficulty crossing busy roads. The app we have created empowers them by detecting road crossings and incoming cars and communicating the information audibly to the user. How we built it Our app is written with next.js and either sends live camera frames or frames of a video to a Flask server. The Flask server handles the processing of the data in three parts. First, using OpenCV, it detects the crosswalk lines and extrapolates to find the centerline. Then, using a Keras classification model we trained, it uses the traffic signals to figure out whether it is time to cross the road. It additionally uses a YoloV8 model to detect any cars that are near the crosswalk. The resulting data is sent back to the app, which communicates it to the user using text-to-speech. Challenges we ran into and solutions The phone couldn't process the data fast enough --> Data was sent to and processed on a separate server\nSending the image over the network was too slow --> Using better compression and lowering the resolution (and compensating with better processing code)\nInference with the YOLO model was slow\nCV wasn't nearly accurate enough to get traffic lights, especially at a difference --> Trained a Keras model for classification What's next for CrossSight Testing and training models for various types of crosswalks\nFaster detection\nHaptic motors and a more integrated experience for the user\nReady-to-release mobile app Built With flask keras nextjs opencv yolov8 Try it out GitHub Repo Submitted to Hack Cupertino 2024 Winner 1st Place - 3D Printer Created by Aravindkrishna Arivudainambi Vyaas Baskar"
      }
    ]
  },
  {
    "file_path": "./devposts/csulb-dining.html",
    "project_id": "csulb-dining",
    "title": "CSULB Dining",
    "tagline": "This is CSULB Dining, a solution to student's daily meal worries. With an easy to navigate UI along with a rating and review system, it will be much easier to find the best meals for the day.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "mongodb",
      "next.js",
      "nextauth",
      "python",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Competition Category: Best Social Goods"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/849/150/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Food Detail Page Login Page Home Page Food Cycles Food Detail Page Login Page Home Page Food Cycles Food Detail Page 1 2 3 4 5 Title of Project: CSULB Dining Competition Category: Best Social Goods Software and Project Type: Website Purpose of Project:\nCSULB Dining aims to address the challenge faced by dorm students at California State University, Long Beach, in planning their meals. By providing a user-friendly platform, the project streamlines the dining experience, offers nutritional information, and facilitates informed food choices. Description of Project:\nIntroducing CSULB Dining, your ultimate solution to the meal planning woes faced by students at California State University, Long Beach. As a fellow dorm resident, I understand the frustration of navigating outdated dining hall websites. That's why we've created CSULB Dining, a user-friendly platform designed to streamline your dining experience. With three dining halls to choose from, including options open to non-residents, deciding where to eat has never been easier. Simply sign up on our website and gain access to a comprehensive menu for each dining hall, updated daily. Whether it's breakfast, lunch, or dinner, you'll find all the available options at your fingertips. Additionally, if a user has any allergies, there are allergen tags conveniently displayed for items that contain common allergens. For those seeking healthier options, easily compare calories to make informed decisions about your meals. Dive deeper into nutritional information by clicking on any menu item to view comprehensive dietary content. Plus, our interactive platform empowers you to rate and review your food items, contributing to a dynamic community of student feedback. Built With beautiful-soup mongodb next.js nextauth python react.js Try it out csulbdining.vercel.app Submitted to MarinaHacks Mini 3.5 Created by I worked on Backend, focusing on scraping the data from the website using Python. Also, I worked on the frontend to crea"
      }
    ]
  },
  {
    "file_path": "./devposts/cosmic-smile.html",
    "project_id": "cosmic-smile",
    "title": "cosmic smile",
    "tagline": "what if the universe can smile back at you? - a one shot app",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/595/704/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Interactive Fireworks Display 🎆 Inspiration We wanted to create a digital experience that captures the wonder and excitement of real fireworks shows, making it accessible anytime, anywhere. The goal was to build something that would bring joy and provide a satisfying interactive experience through beautiful visual effects. What it does Our Interactive Fireworks Display is a web application that creates stunning firework explosions wherever you click or tap. Each firework launches with realistic physics, travels to its target height, and explodes into vibrant bursts of colorful particles with trailing effects. The application features: Realistic Physics : Fireworks launch with proper trajectory, gravity, and air resistance Particle Systems : Each explosion generates 25-50 particles with individual physics properties Dynamic Color Palettes : Six carefully curated color schemes for visually appealing combinations Trail Effects : Both fireworks and particles leave glowing trails as they move Mobile Responsive : Full touch support for mobile and tablet devices Smooth Animation : 60fps canvas-based rendering for fluid motion How we built it The application is built using modern web technologies: React with TypeScript for component structure and type safety HTML5 Canvas for high-performance rendering and animation Tailwind CSS for responsive styling Custom Physics Engine implementing gravity, velocity, and particle lifecycle management Optimized Animation Loop using requestAnimationFrame for smooth 60fps performance The core challenge was creating realistic particle physics while maintaining smooth performance across devices. We implemented custom algorithms for: Firework trajectory calculation Particle explosion patterns with radial distribution Trail rendering with fade effects Memory-efficient particle lifecycle management Challenges we ran into Performance Optimization : Rendering hundreds of particles simultaneously while maintaining 60fps required careful optim"
      }
    ]
  },
  {
    "file_path": "./devposts/concerto.html",
    "project_id": "concerto",
    "title": "Concerto",
    "tagline": "To simplify and destress buying and selling concert tickets and ensure profits go to the artists, not the resellers.",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase-auth",
      "firestore",
      "next.js",
      "react",
      "tailwind-css",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/023/438/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "A little bit about us! Home Page Log In with Google Profile Page Events Dashboard Compose Concert Concert Info Page (Compose Result) A little bit about us! Home Page Log In with Google Profile Page Events Dashboard Compose Concert Concert Info Page (Compose Result) A little bit about us! 1 2 3 4 5 6 7 8 9 Inspiration We all love music. We all love concerts. However, we don't love the frenzy everyone gets in when their favourite concert ticket drops, rushing to buy a ticket before it sells out and they have to buy them from an overpriced reseller. Enter Concerto! What it does Concerto provides a simple platform for fans to buy and artists to sell concert tickets in a quick and simple fashion. Concerto aims to destress the high stress concert buying experience ticket minimize reselling through a standard auctioning system. The highest bids are reserved the best spots and vice versa. This way, we can minimize the rush of concert ticket hoarding and reselling as the auction take time to end and tickets will be bought at their true value. This way the profit will not go to the resellers, but instead the people who deserve it, the artists. How we built it The UI was designed through Figma. The front end was built with React and TailwindCSS, while the pages were routed using Next.js's built-in router. Our authentication system was built with firebase auth while the back-end data was stored in firestore and accessed through firebase hooks. Challenges we ran into We ran into a multitude of syntax errors and the CSS not working the way we wanted it to. We also ran into issues with our liveshare shutting down. Furthermore, this was also the first time we implemented Twilio inside of a project. Specific problems we ran into include\n• Getting User ID from Firestore\n• Implementing a bidding system through an array of references in a collection \nFinally, it was a challenge planning, researching, and implementing a complete project from scratch in under 48 hours. Accomplishments th"
      }
    ]
  },
  {
    "file_path": "./devposts/covidhexcam.html",
    "project_id": "covidhexcam",
    "title": "X-Detect COVID",
    "tagline": "With the spike of COVID patients, radiologists are busier than ever. To ease the burden of constant chest x-ray examinations, our web app is an easy tool that tells you the patient status right away.",
    "hackathon": "",
    "built_with": [
      "fastai",
      "flask",
      "html",
      "machine-learning",
      "python",
      "react-native",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In the midst of a pandemic, we sense the grave urgency of patient treatment in order to prevent reaching full patient capacity in hospitals. As data scientists who are passionate about health and medicine, we wanted an easy tool that can be used by doctors and nurses to easily determine the severity of a patient's respiratory status based on chest radiographs. Our teammates who are experienced with front-end development are passionate about making the tool as user-friendly and accessible as possible. What it does We have developed a web app to detect both the occurrence of COVID and pneumonia in patients from their chest radiographs. To do this we have trained a series of machine learning algorithms (random forest, support vector machines, and logistic regression) to detect the presence of COVID; and a VGG16-based CNN (convolutional neural network) to detect the presence of pneumonia from the scans. We achieved validation (training, validation, test) AUC of 0.99 and 0.97 for both predictions respectively. From a user perspective, a user would upload their x-ray image in .jpeg format and the web app returns a data-table of predictions from each model. How we built it We sourced an open-source chest x-ray data set with labels for normal and pneumonia, and a subset of these individuals had labels for normal and COVID (n=6263, n=166). We used python sklearn, tensorflow and keras to build our machine and deep learning models. We employed a random forest, support vector machine, and logistic regression model to predict the occurrence of COVID (since the data subset was small). We additionally built a VGG16 model for the pneumonia classification model. We then built a web app using Flask and React. By using a React framework to create a web app, and using a Flask framework as the 'middleman', we are able to connect the machine learning model to the frontend React.js website. Also, we utilized Render.com to deploy our REST API, which allows us to get prediction "
      }
    ]
  },
  {
    "file_path": "./devposts/creatify-t3cpd1.html",
    "project_id": "creatify-t3cpd1",
    "title": "Creatify",
    "tagline": "A next-gen tool for graphic designers and artists to ideate and explore their ideas to their maximum potential.",
    "hackathon": "",
    "built_with": [
      "openai",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/588/308/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡 Inspiration 💡 Creativity is the most beautiful gift for humankind, but it can be nuanced, with creaters an artists often struggling with mental blocks . We build a tool that helps creaters and artists to stay in their flow zone using an AI native mindmap interface. 🌟 What it Does 🌟 🌈 A Revolutionary Way to Create: The Mindmap Interface 🌈 🎨✨ Visualize Ideas: Our AI-native interface allows you to visualize your thoughts and ideas like never before. Instead of a linear approach, you can create intricate mind maps that showcase the intricate connections between your concepts. 🧠🚧 Overcome Mental Blocks: Say goodbye to creative roadblocks. The Mindmap Interface comes equipped with smart suggestions and prompts to help you break through any mental barriers that may hinder your creativity. 🤝🌍 Collaborative Innovation: Collaboration has never been easier. You can seamlessly collaborate with other creatives, sharing your mind maps and co-creating in real-time, whether you're in the same room or on opposite sides of the globe. 🤖🔍 Adaptive AI Assistance: Our AI system learns from your creative process. It adapts and evolves with you, offering increasingly tailored insights, recommendations, and enhancements as you continue to use the interface. 🗂️🧩 Effortless Organization: Keep your creative chaos organized. The interface lets you structure your thoughts, projects, and ideas logically, making it a breeze to revisit and expand upon them later. 💡🔥 Inspiration on Demand: Feeling stuck? Need a burst of inspiration? Our Mindmap Interface can pull from a vast database of creative resources, from art and literature to music and design, to reignite your creative spark. 🛠️🔄 Seamless Integration: Whether you're a writer, artist, designer, or any other type of creative, our interface seamlessly integrates with your existing tools and workflow, ensuring a smooth transition to this new, empowering way of creating. Built With openai react typescript Try it out GitHub Repo creatify-eigh"
      }
    ]
  },
  {
    "file_path": "./devposts/cropcareai.html",
    "project_id": "cropcareai",
    "title": "CropCareAI",
    "tagline": "\"Guarding Harvests, Empowering Farmers: Unveiling the Secrets of Crop Health.\"",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I actually saw a movie a long time ago about farmers and how difficult their life is. They work extremely hard and don't get paid a lot, and they are also don't get recognized enough for their work. I wanted to make an app that makes life a little bit easier for them. What it does Our website is really easy and simple to use, and it uses AI to identify viruses on crops. It checks for specific viruses or fungi on crops and is meant to prevent crop loss. How we built it We used teachable machine, which is an AI technology that makes it easy to train machine learning models. We taught it the differences between a healthy crop and a crop infected with the disease. We made multiple pages for each fruit and vegetable, and we also made the UI/UX very useable and eye-catching. Challenges we ran into Some challenges we ran into was making the UI very useable. The circular menu and the background took a lot of lines of CSS, but it was worth it in the end. Accomplishments that we're proud of We are proud of our infection detection, because it works almost every time, and it can make farming much easier with just a click of a button. What we learned We learned about teachable machine and how AI can make things so much simpler, and we also got much better at HTML and formatting with CSS. What's next for CropCareAI We could incorporate detecting multiple infections for fruits and vegetables, and sort them in order or most effective to least, and we could also just add more crops to the list. Built With css html javascript Try it out plant-disease-app.lagonthegod.repl.co Created by Sid Pellakuru Ashish Ramanan \"Python\" \"Java\" \"GDscript\" \"Html\" \"CSS\" \"JavaScript\" \"React\" \"React Native\" Geethik Konitineni"
      }
    ]
  },
  {
    "file_path": "./devposts/crypro-tracker.html",
    "project_id": "crypro-tracker",
    "title": "Crypro Tracker",
    "tagline": "So this project is made with React JS and by using CoinGecko market API the data is fetched to the site. This helps to keep track of the crypto market.",
    "hackathon": "",
    "built_with": [
      "api",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Postman Student Summit Hackathon: Visualize for the Prize",
      "As I am a blockchain developer and works with crypto I thought of making my own crypto site to keep a track of maket."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/644/066/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 As I am a blockchain developer and works with crypto I thought of making my own crypto site to keep a track of maket. So it fetches the data from the CoinGecko market API and shows it in a simple way on my site. So I build I using React JS and market API; I have faced many challenges as I have not worked more with APIs but I make it here and I tried to find teammates but no one in the team is serious it's like everyone is here for swags. So as I made this project in a limited time, I could not focus on more features but definitely add more cool features. Source-code https://github.com/pruthvirajjadhav1/Crypto-Tracker Built With api react Try it out pruthvirajjadhav1.github.io Submitted to Postman Student Summit Hackathon: Visualize for the Prize Created by pruthviraj jadhav"
      }
    ]
  },
  {
    "file_path": "./devposts/createflowai.html",
    "project_id": "createflowai",
    "title": "CreateFlowAI ( One-Shot )",
    "tagline": "Cursor for Content Creation",
    "hackathon": "",
    "built_with": [
      "bolt.new"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Targeted Tracks → One-Shot Competition + We Didn’t Know We Needed This + Most Beautiful UI"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/550/470/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Targeted Tracks → One-Shot Competition +  We Didn’t Know We Needed This + Most Beautiful UI Team Name: CreateFlowAI Inspiration 💡 We were inspired by Cursor 's sleek, minimalist code editor UI and the growing demand for efficient social media content creation. The idea for CreateFlowAI sparked from creators' needs for a fast, platform-tailored tool. We envisioned a one-shot web app using Bolt.new AI , mimicking Cursor's aesthetic with a dark-themed, neon-accented design and GT Super font , to streamline prompt-based content generation. In today's fast-paced digital world, content creators often struggle with generating platform-specific content that resonates with their audience across multiple social media platforms. Traditional content creation tools can be overwhelming, time-consuming, and lack the specialized features needed for different platforms' unique requirements and formatting constraints. What it does 🤔 CreateFlowAI is a one-shot web app that enables creators to generate platform-specific captions/posts for X (Twitter) , Instagram , YouTube , and LinkedIn . Users begin by selecting a platform via an interactive sidebar , which triggers an adaptive preview in the middle editor. The sidebar provides comprehensive tools including AI-generated suggestions , a history panel for revisiting previous ideas, and a gamified dashboard that tracks posts and badges to encourage consistent content creation. The platform automatically adapts content generation based on each social media platform's unique requirements: X (Twitter) : Optimized for 280-character limit with trending hashtags Instagram : Focus on visual storytelling with strategic hashtag placement YouTube : Engaging titles and descriptions for video content LinkedIn : Professional tone with industry-relevant keywords Styled with glassmorphism , neon accents , and a monospace editor , CreateFlowAI delivers a focused creative environment that transforms the content creation process from tedious t"
      }
    ]
  },
  {
    "file_path": "./devposts/createmylovepoem-online.html",
    "project_id": "createmylovepoem-online",
    "title": "CreateMyLovePoem.Online",
    "tagline": "Can't write a love poem? Let a computer do it for you!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/392/505/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration We were inspired by our non-existent ability to write love poems What it does It generates a love poem for you to share with your loved ones. It also features old English so you can also sound smart and your poem can sound exquisite. How we built it We built a python function (backend) that generates a love poem using sample love poems, then connected it to a website using Flask. Challenges we ran into We had to learn Flask because we started the project without knowing that you can't directly connect a python program to a website Accomplishments that we're proud of Learning Flask What we learned Flask What's next for CreateMyLovePoem.Online Make poems that make a bit more sense (better cohesion) Built With css flask html javascript python Try it out GitHub Repo Submitted to Hackthrob Created by Ryan Lam UWaterloo Physics Jax Wang uwo 24' intermediate FE"
      }
    ]
  },
  {
    "file_path": "./devposts/cure-ify.html",
    "project_id": "cure-ify",
    "title": "Cure-ify",
    "tagline": "Cure-ify is data-driven personalized food and recipes recommendation progressive web app enhanced with soothing herbs and spices food items and recipes.",
    "hackathon": "",
    "built_with": [
      "assemblyai",
      "axios",
      "css3",
      "excel",
      "google-cloud",
      "googlespreadsheet",
      "html5",
      "javascript",
      "matlab",
      "node.js",
      "python",
      "react",
      "reacttoastify",
      "sql",
      "toast"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/313/549/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Cure-ify AssemblyAI sandbox speech recognitions for user voice command AssemblyAI sandbox speech recognitions for user voice command AssemblyAI sandbox speech recognitions for user voice command Landing Page Cure-ify AssemblyAI sandbox speech recognitions for user voice command AssemblyAI sandbox speech recognitions for user voice command AssemblyAI sandbox speech recognitions for user voice command Landing Page 1 2 3 4 5 Inspiration Herbs and Spices have been long standing home remedies to cure sickness not only complimentary treatments for the symptoms of chronic condions like menopause: arthritis, bone density loss, hot flashes, and anxiety. So food of interest with nutritional content can not only act as optimal nutrition for recovery but for preventative medicine. We chose to focus on chronic illnesses because other conditions are, by nature, random, thus producing too sparse of a signal to track. A patient often compromises with the food items which are tasteless and something with does not align with their interest. Food being so importantly co-related with the mood of the person and hence with their physiological processes. What it does Cure-ify intakes data from user in the form of questionnaire which are as follows:\nQ0. What type of physiological help you seek from the food? (In form of health target options)\n       a. Digestive\n       b. General Health\n       c. Brain\n       d. Infection\n       e. Cardiovascular\n       f.  Female Health Q1. Do you have any allergies ?\nQ2. What are your dietary restrictions?\nQ3. How are you feeling now? Q4. What would you like to eat? (Answer could be abstract as much possible like, in speech) eg - \"Something **chicken**, **soup** and **asian**\" From the above sentence the AssemblyAI will transfer the speech to text and the highlighted words will be taken as keywords and the recommendation system will search through the datasets with respect to the given keyword. The datasets have the (food, recipes, time to m"
      }
    ]
  },
  {
    "file_path": "./devposts/credibility.html",
    "project_id": "credibility",
    "title": "Credibility",
    "tagline": "Stop using untrustworthy sources. Research with confidence using Credibility.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gpt-4o",
      "llm",
      "natural-language-processing",
      "nextjs",
      "openai",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/992/316/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Analysis of The Flat Earth Society Credibility Analysis of Live Science Analysis of The Flat Earth Society Credibility Analysis of Live Science Analysis of The Flat Earth Society 1 2 3 4 Problem Imagine you're deep into your research, sifting through countless articles, blogs, and websites. How often have you wondered: \"Can I trust this source? Is this information accurate?\" After all, how can your research be trusted when your sources can’t be? Researchers, students, and professionals alike face a common challenge: ensuring that the information they rely on is accurate, credible, and trustworthy. In a world filled with heaps of fake information, hidden biases, and misleading data, how can we distinguish what is real from what is fake? What it does Introducing Credibility, the smart tool that revolutionizes how we verify sources. Credibility is a web-based program designed to intake any URL link and analyze its reliability for research purposes based on objective criteria. It evaluates the source's content quality, bias, sentiment, publisher reputation, and visual components using AI content analysis. The tool also considers key metrics like domain age, traffic rank, and whether important information such as the author and publish date is listed. Using this information, it computes a Credibility score, ranging from 0 to 100, to help researchers determine the trustworthiness of their sources. How we built it Credibility was built by integrating AI technologies to analyze the textual and visual content of web pages. The program accesses the URL in a Google Chrome browser via Selenium, reads the page's content, and captures screenshots for visual analysis. It then feeds this information to GPT-4o for multimodal reasoning, generating bias, sentiment, reputation, and quality scores along with comments. Credibility combines this AI-driven content analysis with additional data points such as domain age, traffic rank, and the presence of essential metadata. All this informa"
      }
    ]
  },
  {
    "file_path": "./devposts/crowd-story-fvzg3d.html",
    "project_id": "crowd-story-fvzg3d",
    "title": "CrowdStory",
    "tagline": "Write stories together.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "figma",
      "mern",
      "mongodb",
      "node.js",
      "react.js",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/226/084/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Discover Story Profile Discover Story Profile Discover 1 2 3 Inspiration Will.i.am had inspired us with his opening speech at Hack the North 2022. We took his example of combining tech with music to heart. Rather than music we wanted to spread knowledge through other important skills, reading and collaboration. What it does CrowdStory is a web application that allows users to create open source stories that can be contributed by people all around the world and allows the reader to get a taste of many different experiences and thoughts instead of something said by 1 figure. Each story has ai-generated thumbnails and titles, constantly changing to fit the ever-changing story. Additionally, discover stories to add onto, like them, save them, share them, comment on them and more. How we built it We built this website in the Node.js environment using Typescript, React.js, mongodb, express.js and Figma to design our website. Challenges we ran into We had run into a lot of challenges while trying to host our backend on Heroku. Heroku unfortunately does not support typescript natively so that was a challenge to get around. We were also learning new things we had not done before, for example we had to make different directories for our frontend and backend. Accomplishments that we're proud of We finished most of the features we intended do in the time that we had and learned many new skills. What we learned We learned how to utilize figma to design our websites and implement mongodb in a server configuration. What's next for CrowdStory We would like to try to expand this idea to something big that is used in English classrooms as a creative form of writing. Built With express.js figma mern mongodb node.js react.js typescript Try it out GitHub Repo GitHub Repo Submitted to Hack the North 2022 Created by Chris Pan Ammar Ahmed John Fernandez Ayush Garg"
      }
    ]
  },
  {
    "file_path": "./devposts/crate.html",
    "project_id": "crate",
    "title": "CRATE | Your mental health toolbox",
    "tagline": "CRATE provides users with tips and motivation to help improve their mental health.",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "html",
      "qoom"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/367/897/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Daily Routines Page which Links to More Images Index Page Journal Page Self Care Page which Links to More Images Daily Routines Page which Links to More Images Index Page Journal Page Self Care Page which Links to More Images Daily Routines Page which Links to More Images 1 2 3 4 5 Inspiration CRATE is a web-based community that provides users with tips and motivation to help improve their mental health. What it does Aggregating resources across the web as well as hosting an online journal and habit/mood tracker, CRATE makes mental health management accessible to all. How we built it The website was created with HTML and CSS. We also used Qoom occasionally to share code and information for the design and overall colours/theme of our website. The branding and overall UI of our site was created on Figma and we used this as well as Google Slides to collaborate. Challenges we ran into The time constraints were defiantly a challenge we ran into. Also, our team wasn't very experienced in web development so we struggled with a lot of the backend stuff such as implementing a login page and getting input from the journal page. We decided to redesign our idea mid way through our project to fit our skill sets. Qoom was also quite inefficient to work with because the owner had to be on the file for the other team members to edit the code. Accomplishments that we're proud of Initially, our team had many great ideas that we all wanted to implement into the website but along the way, we discovered that a lot of those functions required skills and languages we weren't familiar with. In addition due to time constraints, we had to make a lot of adjustments and think outside the box to complete our website. What we learned We learned that it's easy to be overly ambitious when it comes to product/web development. We think our concept is great, but the execution could have been better managed. We didn't have time to learn new languages or software, but we did take advantage of the oppor"
      }
    ]
  },
  {
    "file_path": "./devposts/crsh.html",
    "project_id": "crsh",
    "title": "crashout shell (crsh)",
    "tagline": "like bash but it crashes your computer when you make a mistake.",
    "hackathon": "",
    "built_with": [
      "c"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/247/132/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "What it does It is a unix shell that crashes the computer on a non-zero exit code. Link https://github.com/wang-edward/crsh How we built it C Challenges we ran into None Accomplishments that we're proud of Crashing the computer What we learned syscalls What's next for crashout shell (crsh) tab completion, colors, maybe a GUI that plays a jumpscare before it shuts down Built With c Try it out GitHub Repo Submitted to ConUHacks IX Created by Tysh Saai151 Arora edward wang Jay Phan"
      }
    ]
  },
  {
    "file_path": "./devposts/covid-19-simulator-fztbpx.html",
    "project_id": "covid-19-simulator-fztbpx",
    "title": "Covid-19 Simulator",
    "tagline": "This project strives to simulate the Covid-19 results based on state restrictions, controllable by county.",
    "hackathon": "",
    "built_with": [
      "eazyml",
      "excel",
      "google",
      "java"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best use of EazyML Created by Victor Cheng co-founder of vly",
      "HackTable2020WinnerBest use of EazyML",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/300/202/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Research and Details Projection Research and Details Projection Research and Details 1 2 3 Inspiration I was inspired by my research on the Covid-19 pandemic. The full project details, research, etc, can be found here: https://docs.google.com/document/d/1CdJ-Lh5l6so0cMZeuuUVPjLQLxyA_2zOahIQi3OmUXY/edit?usp=sharing What it does This project model allows you to input a Covid-19 response sequence, along with which county you would like results for, and produces the expected number of cases. How I built it I used EazyML and a variety of data compiled from all 3143 counties. Challenges I ran into I had major issues with all the data I was using, along with many problems trying to create my models on EazyML. I also had to change my strategy many times. The data cleaning took the longest. Accomplishments that I'm proud of I am proud of how I am able to complete a model and developed our understanding of the effects of many factors on Covid-19 infections. What I learned I learned that the United States virus spread largely had to do with the population of each county and the mandates they imposed. What's next for Covid-19 Simulator I will continue producing more complicated models, using more data, and larger training sets with over a million rows. Built With eazyml excel google java Try it out docs.google.com Submitted to HackTable2020 Winner Best use of EazyML Created by Victor Cheng co-founder of vly.ai (YC F24)"
      }
    ]
  },
  {
    "file_path": "./devposts/creative-juices-come-later.html",
    "project_id": "creative-juices-come-later",
    "title": "Coffee Coach",
    "tagline": "Coffee Coach uses emotional recognition and AI to provide real-time feedback during coffee chats with professionals! Just hop in a meeting and get reports on body language, expressions, and more!",
    "hackathon": "",
    "built_with": [
      "auth0",
      "css3",
      "face-api",
      "figma",
      "javascript",
      "microsoft-cloud",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Microsoft Cloud for Your Community, Presented by MLH Created by My job was to integrate",
      "JAMHacks 7WinnerBest Use of Microsoft Cloud for Your Community, Presented by MLH",
      "This project was the first time most of us experimented with computer vision, and it was definitely a learning curve.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/506/208/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Giving interview prompt Using chatbot for questions and suggestions mid-interview Logging in with the help of Auth0 Giving interview prompt Using chatbot for questions and suggestions mid-interview Logging in with the help of Auth0 Giving interview prompt 1 2 3 4 Inspiration Due to the absence of in-person interactions during the COVID-19 pandemic, many students today struggle with controlling their expressions and body language while communicating with others face-to-face. Furthermore, there aren't many platforms that help hone these skills that are so crucial to expressing confidence and interest during conversations. This puts individuals who may be less socially adept at a loss on how to improve their communication skills. With Coffee Coach, we aim to help train people's non-verbal communication skills in order to help them achieve success! What it does Coffee Coach helps ensure student success during coffee chats with industry professionals. To start off, the student can input information about who they're meeting as well as the length of the meeting. Our AI chatbot will suggest a potential schedule that the student can use to structure the coffee chat. Moreover, the Coffee Coach will provide a few sample questions the student can ask to ensure an informative and friendly experience. During the coffee chat, the Coffee Coach will be analyzing the student's non-verbal communication skills—in particular, it will focus on facial expressions. Using sentiment analysis and machine learning, Coffee Coach will give feedback on the facial expressions of the student during the coffee chat. For example, if the student was showing an unfriendly or irritated expression, Coffee Coach would send the student a message to remind them to have an excited and engaging expression. How we built it Coffee Coach was built with Auth0 to implement an authentication system, as well as React and Javascript to create the interface, which constitutes what the user interacts with. We used a p"
      }
    ]
  },
  {
    "file_path": "./devposts/ddakji-prediction.html",
    "project_id": "ddakji-prediction",
    "title": "Big Boss Blastoise",
    "tagline": "Using Gemini to make predict the outcome hasn't failed yet.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "python",
      "scikitlearn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration\nThe Ddakji prediction challenge inspired us to explore the intersection of traditional games and cutting-edge artificial intelligence. We wanted to leverage Google Gemini, a state-of-the-art multimodal AI model, to tackle complex prediction problems while learning from its capabilities. The idea of using AI to master a game rooted in skill and precision felt like a creative way to blend tradition with technology. What it does Our solution predicts the outcome of Ddakji flips with high accuracy by analyzing player stats, throw dynamics, and other key features. Using Gemini, we built a robust model that processes intricate datasets, identifies patterns, and delivers predictions. The system is designed to assist players in strategizing their throws and improving their gameplay. How we built it We used Google Gemini as the backbone of our project. Gemini's multimodal capabilities allowed us to: Process and clean complex datasets with missing values. Perform advanced regression and classification tasks. Generate insights into player behavior and throw dynamics. We trained the model on three levels of challenges, creating a complete prediction pipeline that included feature engineering, hyperparameter tuning, and validation. Challenges we ran into While we completed three challenges with ease, the fourth challenge pushed us to our limits. Despite coming close, we couldn't fully solve it. The intricate nature of the Ddakji dataset required higher precision than initially anticipated. However, working alongside Gemini allowed us to iterate quickly and learn from each attempt. Accomplishments that we're proud of Successfully completing three challenges with high accuracy. Building an entire predictive model using Gemini's capabilities. Gaining deeper insights into how AI can process and predict outcomes in dynamic systems like Ddakji. What we learned Working with Gemini taught us how to creatively approach problem-solving using AI. We learned: The importance of d"
      }
    ]
  },
  {
    "file_path": "./devposts/dabble.html",
    "project_id": "dabble",
    "title": "Dabble",
    "tagline": "A collaborative way to get more done. By showing what your friends are doing, when they're doing it, and how efficient they are, Dabble provides some powerful extrinsic motivation for its users.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "html",
      "javascript",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/269/227/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Mainpage Logo Mainpage Logo Mainpage 1 2 Inspiration Our idea sparked when our friend Sheshank was working out at the IMA. As he looked around, he clearly observed what everyone else was doing - what exercises, what weights, what programs, etc. All of this information was available to him, but rather than overwhelm him, he told us how much it motivated him. Seeing everyone else lift bigger weights and do more reps gave him a sense of urgency. As he recanted how this made him feel like he too needed to do more and get stronger, we began to realize how powerful this extrinsic source of motivation was. \nWe realized that this feeling was something that we could apply to school, the one place we all could frankly use more motivation. That openness of data is not something that we experience in an academic setting, but if we did, we would begin to really see where we stand and what we need to be doing. That is why we came up with Dabble, a web application with the purpose of publicizing this data among peers. By seeing what assignments others are doing, how long it is taking them, and how efficient they are, that same extrinsic motivation can be experienced in a school-setting. What it does Dabble aims to increase productivity through extrinsic sources. The Dabble application brings together friends in a so-called ‘fight’ for efficiency. Dabble allows users to write out all their tasks, then sorts it by due date. It then allows the user to make friends, and see if their friends are working and what they are working on, as well as how long they have been in a work session for. It also allows users to be able to time their sessions, telling the total hours they worked on a task for, with a nudge feature that is used to “nudge” their friends who they can see have not been active. How we built it We built the application from scratch using a ReactJS framework along with Google Firebase for the backend database. It required the downloading of various Node dependencies includin"
      }
    ]
  },
  {
    "file_path": "./devposts/dead-inside.html",
    "project_id": "dead-inside",
    "title": "Dead Inside",
    "tagline": "Dead Inside is a darkly comedic VR game where you don’t kill zombies. You’re their therapist, you unpack their trauma, decode their past lives, and save what’s left of their humanity.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "openai",
      "p2p",
      "photon",
      "redis",
      "stt",
      "tts",
      "unity",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Unity (URP): Core VR experience with Oculus/Quest SDK for hand tracking and scene design",
      "GPT + Emotion Logic: Custom dialogue engine blending GPT responses with emotional state tracking"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/625/939/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration We wanted to subvert the typical zombie shooter formula. What if instead of fighting the undead, you had to understand them? Dead Inside is inspired by Call of Duty: Zombies, The Last of Us, and therapy-based narrative games like Papers, Please and The Stanley Parable. The idea: confront horror not with weapons, but with empathy. What it does Dead Inside is a multiplayer VR game where you provide therapy to zombies instead of killing them. Using voice input, emotional inference, and real-time choices, players conduct 1-on-1 sessions with the undead. They unpack trauma, discover backstories, and try to preserve fragments of their humanity. Zombies respond with AI-generated dialogue, facial expressions, and branching behavior based on your decisions. How we built it Unity (URP): Core VR experience with Oculus/Quest SDK for hand tracking and scene design GPT + Emotion Logic: Custom dialogue engine blending GPT responses with emotional state tracking Redis: Temporary game session database Whisper ASR: Real-time transcription and sentiment parsing of player voice input Blender + Mixamo: Zombie models and animations rigged with subtle microexpressions State Machine AI: Each zombie has a procedural emotional arc influenced by player choices and tone Challenges we ran into Syncing real-time voice input with branching narrative logic Creating zombie models that were unsettling yet expressive (without breaking immersion) Balancing tone: ensuring the game was darkly comedic without trivializing mental health themes Optimizing GPT calls and fallback responses for lag-free interaction in VR Accomplishments that we're proud of Designed a fully immersive VR narrative mechanic that felt emotionally impactful Built a functional in-game therapy system using AI and real-time voice feedback Created believable undead characters with individual backstories and emotional variance Balanced horror and humor without leaning too hard on tropes What we learned How to inte"
      }
    ]
  },
  {
    "file_path": "./devposts/cov-audio.html",
    "project_id": "cov-audio",
    "title": "Cov-Audio",
    "tagline": "Cov-Audio is a remote COVID detection platform delivered through a web application. It uses machine learning to help potential Covid-19 related diseases in patients screen their symptoms from home.",
    "hackathon": "",
    "built_with": [
      "adobe-illustrator",
      "flask",
      "keras",
      "librosa",
      "pandas",
      "photoshop",
      "python",
      "react",
      "react-native",
      "scikit-learn",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/281/821/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Our inspiration is to help health professionals avoid overwhelming hospital infrastructure with non-critically ill patients seeking initial Covid-19 screenings through machine learning.\nMachine-learning has made significant progress in sound analytics for medical applications. Recent studies have shown that multiple diseases, such as Alzheimer’s and Parkinson’s, are detectible from respiratory audio. We believe distinguishing COVID-19 from other respiratory illnesses would allow large-scale systematic screening & isolation of patients, with no scaling limitations of cost or time. The model could reduce cases globally and prevent a new wave of the disease.\nWe set out to develop an application that will allow the general public to submit their symptoms and receive a high-quality COVID-19 risk assessment, even among asymptomatic individuals, without creating an additional burden for global healthcare infrastructure. What it does Cov-Audio is a mobile COVID detection platform delivered through a web application. It uses machine learning to help potential Covid-19 patients screen their symptoms from home. \nBy uploading a 6-second audio sample of their cough to check for respiratory illnesses and answering additional questions about their symptoms and medical history, users will receive a COVID-19 risk assessment. From this assessment, they can predict if they require further testing with a reasonable degree of certainty. How we built it We build two applications, one that allows users to answer screening questions and another that will enable users to upload a cough audio sample so that our application can use machine learning to detect respiratory ailments. The combined data of a COVID-19 risk score and respiratory illness detection can be used to determine the likelihood of someone having Covid-19. Challenges we ran into Collecting the data to build machine learning prediction models was challenging. There are few data sets containing cough sample"
      }
    ]
  },
  {
    "file_path": "./devposts/cryptovote.html",
    "project_id": "cryptovote",
    "title": "CryptoVOTE",
    "tagline": "A Decentralized Blockchain Web Application For Secure Election Voting",
    "hackathon": "",
    "built_with": [
      "blockstack",
      "css3",
      "express.js",
      "gaia-storage",
      "ganache",
      "html5",
      "javascript",
      "metamask",
      "mongodbatlas",
      "tensorflowjs",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/112/638/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "OCR Verification Log in Page OCR Verification Log in Page OCR Verification 1 2 3 DEMO FOR OCR READER (Since it got corrupted in our video): https://imgur.com/xcbU6Gi Inspiration The COVID-19 Pandemic has led to many people wondering how they are going to vote for their selected leaders in the upcoming elections, especially in the United States where the presidential election will take place this November. People are hesitant to go to voting booths to vote due to the risk of catching the virus. The only options left are online voting, and mail-in voting. However, our traditional system for online voting is very unsafe and there have been many cases in various countries of hackers messing with the votes. As well, many have expressed fears of mail-in voting due to vote spoofing, and a rigging of the election. Motivated by this demanding issue that people keep forgetting about, we have decided to create CryptoVOTE. What it does CryptoVOTE is a decentralized web application that securely counts people's votes using a blockchain. The web application also has a verification Optical Character Recognition (OCR) system which reads the user's Voter ID or driver’s licence and verifies it with a simulated government database using MongoDB Atlas to make sure that the individual voting is eligible and real. The utilization of an OCR alongside the blockchain system makes it virtually impossible to hack, through brute force or any other malicious strategy - creating a safe way for people to vote online. How we built it We built CryptoVOTE using a wide variety of tools and frameworks. These include ReactJS for the front end, a Blockstack Gaia storage/MongoDB Atlas combo to act as a decentralized backend and store user votes in a blockchain format, Blockstack for the decentralization log in/log out process, and TesseractJS for the OCR verification as well as NodeJS and Express for the non-voting backend. Challenges we ran into Most of our challenges lied in deploying the actual applic"
      }
    ]
  },
  {
    "file_path": "./devposts/decentralized-charity-donation.html",
    "project_id": "decentralized-charity-donation",
    "title": "Decentralized Charity Donation",
    "tagline": "We made a decentralized charity donation",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Part of the project doesn't work, we thought we would submit what we had. Built With css3 html5 javascript Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sohan Bhatt Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/covid-bias-checker.html",
    "project_id": "covid-bias-checker",
    "title": "COVID Bias Checker",
    "tagline": "Revealing The Biased News Articles About COVID-19",
    "hackathon": "",
    "built_with": [
      "anaconda",
      "flask",
      "heroku",
      "mediabiasfactcheck.com",
      "natural-language-processing",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Innovation in STEM HackathonWinnerAirpods",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/116/379/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Arguably, the biggest problem in America and most other western countries is that the media from both the left and the right often lies about facts in order to get their ratings up. Donald Trump likes to criticize them for this by calling them fake news. This problem is especially important during times of crisis, such as this. The COVID-19 pandemic is wreaking havoc across the world and part of the reason it has gotten so serious is because people are trusting media sources that are lying about the virus. For example, CNN lied a lot in May about the number of corona virus cases. They exaggerate the death toll by thousands and this caused unnecessary panic among citizens which made things a million times worse. We realized the gravity of this problem and decided that we wanted to help. What It Does Our website's main app page allows the user to input in the URL of the article that they want to read. Our website then applies two main algorithms to it. It uses both a natural language processing model algorithm that scans the article and gives out a numerical bias rating, and it shortens the URL that the user inputted into just the domain name and runs it through the mediabiasfactcheck.com API to determine the political bias of that news source. After it has these two pieces of information, the website gives the user the bias rating of the article. The user can then use the information that they have received to become more weary of how fake or real the COVID-19 article they are reading is. By being more weary, they can avoid unnecessary panic and stay safe. Apart from the main page, the web app also has two static about us and submission pages. How We Built It We built this website using Python, Flask, Bootstrap, Javascript, CSS, HTML Jinja, and a variety of Natural Language Processing and linear regression algorithms. Challenges We Ran Into We had to combine a few NLP and classification algorithms which took a lot of time for processing and made"
      }
    ]
  },
  {
    "file_path": "./devposts/cyberemail.html",
    "project_id": "cyberemail",
    "title": "33 - CyberEmail",
    "tagline": "Your one stop shop to having a safe emailing experience free from viruses",
    "hackathon": "",
    "built_with": [
      "cohere",
      "github",
      "golang",
      "nextjs",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our inspiration for this project was the many spam or fraudulent emails people come across. Across the world, some company employees receive an average of 49 emails per year per employee that is fraudulent. One example of such an attack was on a gas pipeline in Florida, the result of this hack was a rise in gas prices in the area during the period of the attack and a 4.4 million dollar ransom. This was a big problem that we hoped to solve. What it does Our software is a software extension that uses machine learning to detect whether an email sent is fraudulent and if so, it makes sure to make it and thus inform the user that such a result has occurred. How we built it We built it using a NextJS Landing Page, React Frontend and Golang Backend. The Golang Backend handled custom built authentication and handing Machine Learning Requests. The NextJS Landing page invited users to the extensions and prompted them to install the extension. The React Frontend modal allowed users to receive information about emails and sign-in of necessary Challenges we ran into Golang Errors (it was fairly new), Using React with Chrome Extensions (completely new) and doing Machine Learning with Co:here Accomplishments that we're proud of Completing the application! What we learned Co:here for Machine Learning and Golang for the Speedy Backend. What's next for CyberEmail Extending support for other mail services and adding new Machine Learning models to enhance the User Experience. Co:here Co:here was a wonderful sponsor as it helped us build our different machine learning models. It was an easy process to build our machine learning models and the accuracy that came out of the co:here models were fantastic Github GIthub made it a breeze to host our software development source code onto a cloud platform to share it to the world in a way that made coding more accessible to people and overall helped the hacker community (a clear goal both MLH and Github). Built With cohere github go"
      }
    ]
  },
  {
    "file_path": "./devposts/decharity-gvhxw2.html",
    "project_id": "decharity-gvhxw2",
    "title": "Tokens For Good",
    "tagline": "Tokens For Good aims to use NFTs to support a positive cause by gifting people who donate collectable NFTs, providing an incentive for people to donate.",
    "hackathon": "",
    "built_with": [
      "chakra-ui",
      "css3",
      "deso",
      "html5",
      "javascript",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of DeSo, Presented by MLH Created by Edison Qu rule the world Alex Lu University of Waterl",
      "JAMHacks 6WinnerBest Use of DeSo, Presented by MLH",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/985/288/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We were inspired by the creative and innovative designs of NFTs and recognized the potential of turning them into collectibles that can be used to support a good cause. What it does Our project gives people who donate to charity an NFT. This gives people the novelty of possessing limited-time collectables and a sense of pride knowing they supported a good cause, increasing the incentive to donate. How we built it Frontend: React.js + Chakra UI Blockchain Backend: DeSo Utility Library Authentication: DeSo Login Challenges we ran into We realized that there was a flaw on our first project and we had to start from scratch. Then a thunderstorm caused an electrical outage, shutting down our internet. Finally, our main back end coder had an emergency and did not send the github repository, meaning we had to start from scratch again. Accomplishments that we're proud of We are proud that despite all of our unexpected hurdles, we managed to learn DeSo, a whole new concept that none of us had seen beforehand. We brainstormed, coded, and almost finished a new project. Unfortunately, we ran into a few towards the end of the code. Nonetheless, we are proud of how far we have come within the span of a few hours. What we learned We learned how to utilize React to create an interactive front-end web page. More specifically functions, classes, components, hooks, and a variety of React applications. We have learned all about the risks and benefits of blockchains and all about DeSo, as well as implementing DeSo to React to create a decentralized social blockchain. What's next for Token for Good We plan on extending to a vast expanse of charities and creating a variety of collectible NFTs. Built With chakra-ui css3 deso html5 javascript react.js Try it out GitHub Repo Submitted to JAMHacks 6 Winner Best Use of DeSo, Presented by MLH Created by Edison Qu rule the world Alex Lu University of Waterloo CS '27 Stephen Ni Aritro Saha comp. eng student @ uwaterloo"
      }
    ]
  },
  {
    "file_path": "./devposts/craven.html",
    "project_id": "craven",
    "title": "Craven",
    "tagline": "A kitchen security system to keep your roommates in check and your snacks in stock.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "dlib",
      "node.js",
      "opencv",
      "tensorflow",
      "twilio",
      "x"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2024 Finalists Created by Dhyan Patel Abhinav Bala Sumedh Dhanvanthry",
      "Hack the North 2024WinnerHack the North 2024 Finalists",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/024/805/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Catching snack burglars... Meet the team! Catching snack burglars... Meet the team! Catching snack burglars... 1 2 Inspiration 🍪 We’re fed up with our roommates stealing food from our designated kitchen cupboards. Few things are as soul-crushing as coming home after a long day and finding that someone has eaten the last Oreo cookie you had been saving. Suffice it to say, the university student population is in desperate need of an inexpensive, lightweight security solution to keep intruders out of our snacks... Introducing Craven , an innovative end-to-end pipeline to put your roommates in check and keep your snacks in stock. What it does 📸 Craven is centered around a small Nest security camera placed at the back of your snack cupboard. Whenever the cupboard is opened by someone, the camera snaps a photo of them and sends it to our server, where a facial recognition algorithm determines if the cupboard has been opened by its rightful owner or by an intruder. In the latter case, the owner will instantly receive an SMS informing them of the situation, and then our 'security guard' LLM will decide on the appropriate punishment for the perpetrator, based on their snack-theft history. First-time burglars may receive a simple SMS warning, but repeat offenders will have a photo of their heist, embellished with an AI-generated caption, posted on our X account for all to see. How we built it 🛠️ Backend: Node.js Facial Recognition: OpenCV, TensorFlow, DLib Pipeline: Twilio, X, Cohere Challenges we ran into 🚩 In order to have unfettered access to the Nest camera's feed, we had to find a way to bypass Google's security protocol. We achieved this by running an HTTP proxy to imitate the credentials of an iOS device, allowing us to fetch snapshots from the camera at any time. Fine-tuning our facial recognition model also turned out to be a bit of a challenge. In order to ensure accuracy, it was important that we had a comprehensive set of training images for each roommate, and tha"
      }
    ]
  },
  {
    "file_path": "./devposts/dd-dhws53.html",
    "project_id": "dd-dhws53",
    "title": "HealthFocus",
    "tagline": "HealthFocus is an innovative and user friendly platform that allows individuals to obtain trustworthy and verified advice on their health related issues.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "github",
      "html",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/858/870/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Despite the abundance of health-related information on the internet, individuals find it difficult to find trustworthy information and advice that pertains to their health concerns. Many existing health forums do not allow individuals to freely express their concerns, nor do they give people the opportunity to share their own experiences with others. What it does Technically, HealthFocus is a website that hosts forums that are organized by \"most recent\" as well as categories in which posts are grouped into. It also enables them to make informed medical decisions after reading about other people's medical experiences. How we built it Using VisualStudioCode as our text editor, we also downloaded Flask in order to code with Python for our backend. Collaboration was possible with GitHub Desktop. Challenges we ran into HTML was a new language that two of the three members on the team was unfamiliar with. Adding functionality was difficult. Accomplishments that we're proud of Incorporating multiple templates together and learning to understand which part of the code corresponds to which component despite our lack of experience under an extremely short time span. What we learned We've learned how to collaborate using GitHub and were able to make a good-looking website. What's next for HealthFocus We hope to add in a functionality that allows only certified doctors to be verified for their expertise and prevents them from being able to answer posts that do not fall under their expertise. Built With css flask github html visual-studio Try it out docs.google.com Submitted to AdaHacks V Created by Worked on downloading the Flask pip; the \"About Us\" page and incorporated GitHub into the coding process. Youjia He Cinty Lin"
      }
    ]
  },
  {
    "file_path": "./devposts/de-unos.html",
    "project_id": "de-unos",
    "title": "De-UNOS",
    "tagline": "Decentralizing UNOS' organ donation and transplant system",
    "hackathon": "",
    "built_with": [
      "blockchain",
      "docker",
      "hyperledger",
      "leaflet.js",
      "node.js",
      "python",
      "react-leaflet",
      "reflex",
      "shell",
      "terra",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/776/203/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration This project was inspired partially by Grey's Anatomy ✨👩‍⚕️, but mostly by stories we've heard from friends studying medicine and by the incredible amount of research recently published in this field. Despite the life-saving potential of organ transplants, we learned that the process is often plagued by issues such as lack of transparency, unfair access, susceptibility to cyberattacks, and the existence of a black market. De-UNOS is a web app project that uses a Hyperledger Fabric blockchain network to decentralize the way that UNOS currently manages organ donation and transplants in the United States in attempts to reduce system inefficiencies. We used Hyperledger Fabric because it allows for a permissioned blockchain which means not EVERYONE in the general public will have access to this data - only doctors and patients, allowing for a more secure, transparent, and equitable solution. Background As hospitals embrace the digital age and electronic patient healthcare records become prevalent, there is a need to manage this ever-growing amount of sensitive data, paying maximum attention to security and digital privacy. A great effort has been made by UNOS to design a transparent and fair organ allocation system with a centralized system and centralized data storage. The problem however, is that centralized database systems are far more prone to cyberattacks and hacking, like the last ransomware attack on COVID-19 vaccination registration portal in 2021 in Lazio (an Italian region). This is where blockchain has been proposed by many researchers as a solution ( https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9945518/pdf/ti-36-10800.pdf ). What it does The app works as follows. When doctors login to the web app, they will have access to the entire list of transplant patients as well as donors that have recently become available. Doctors can add patients and donors onto the list by pulling from their electronic health record (EHR) and current bed"
      }
    ]
  },
  {
    "file_path": "./devposts/dag.html",
    "project_id": "dag",
    "title": "DAG",
    "tagline": "Decentralized data aggregation across all of machine learning.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "flow",
      "mongodb",
      "next.js",
      "react",
      "soroban",
      "syro",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Flow Winner Best Use of Soroban Created by Worked on the frontend using React and Next Justi",
      "Best Use of Flow Winner Best Use of Soroban Created by Worked on the frontend using React and Next",
      "Hack the North 2023WinnerBest Use of FlowWinnerBest Use of Soroban",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/589/861/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration The current landscape of data aggregation for ML models relies heavily on centralized platforms, such as Roboflow and Kaggle. This causes an overreliance on invalidated human-volunteered data.  Billions of dollars worth of information is unused, resulting in unnecessary inefficiencies and challenges in the data engineering process. With this in mind, we wanted to create a solution. What it does 1. Data Contribution and Governance DAG operates as a decentralized and autonomous organization (DAO) governed by smart contracts and consensus mechanisms within a blockchain network. DAG also supports data annotation and enrichment activities, as users can participate in annotating and adding value to the shared datasets.\nAnnotation involves labeling, tagging, or categorizing data, which is increasingly valuable for machine learning, AI, and research purposes. 2. Micropayments in Cryptocurrency In return for adding datasets to DAG, users receive micropayments in the form of cryptocurrency. These micropayments act as incentives for users to share their data with the community and ensure that contributors are compensated based on factors such as the quality and usefulness of their data. 3. Data Quality Control The community of users actively participates in data validation and quality assessment. This can involve data curation, data cleaning, and verification processes. By identifying and reporting data quality issues or errors, our platform encourages everyone to actively participate in maintaining data integrity. How we built it DAG was used building Next.js, MongoDB, Cohere, Tailwind CSS, Flow, React, Syro, and Soroban. Built With cohere flow mongodb next.js react soroban syro tailwindcss Try it out GitHub Repo Submitted to Hack the North 2023 Winner Best Use of Flow Winner Best Use of Soroban Created by Worked on the frontend using React and Next Justin Lau Computer Engineering @ UWaterloo Emma Shi cs @uwaterloo Jerry Zhu CS @UWaterloo | Retired | Fanatic"
      }
    ]
  },
  {
    "file_path": "./devposts/defensive-math.html",
    "project_id": "defensive-math",
    "title": "Defensive Math",
    "tagline": "2020 has effected all of us in detrimental ways. Due to the Covid-19 pandemic schools went virtual. We aim to bridge the learning gap caused by lack of education through educational video games.",
    "hackathon": "",
    "built_with": [
      "css",
      "glitch",
      "html",
      "java",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/626/859/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Defensive Math Innovation Virtual Classrooms Expectations vs Reality (zoom) Virtual Loss was a Significant Loss Defensive Math Innovation Virtual Classrooms Expectations vs Reality (zoom) Virtual Loss was a Significant Loss Defensive Math 1 2 3 4 5 6 Inspiration Due the Covid-19 Pandemic, millions of students have had education go virtual. Because of this there have been significant learning Now we probably spent more time going through different ideas, languages, iterations, even finishing multiple programs that we didn’t use. For example we spent the entire first day creating a website using AI to find whether people are wearing masks or not, but then we found the most optimal way to bright the learning gap especially younger kids affected by the pandemic the most which was by using an educational video game. What it does It is a website that outputs math problems every single time the creeps(opponent) make it to the end goal in tower defense. How we built it We used GitHub code initially however modified it and using JS and CSS we were able to program the tower defense game and once finished with that we tried implementing it to make it display math problems every time the user did bad in the game and lost a life to the creeps. Challenges we ran into There were lots of challenges we ran into. Mainly that the time zones didn't really match up and we had less time to brainstorm. We also had tons of different errors and as beginners to CSS we had to watch lots of tutorial videos to get a good grasp of what was going on. Accomplishments that we're proud of We're proud that we were able to learn more CSS and accomplish this device because we think it has market potential and if given to even just our friends siblings or cousins who love playing tower defense it could make a real world impact. What we learned We learned lots of CSS, but more importantly that no matter the conditions its always worth giving something a try. At first we weren't sure about this entire hac"
      }
    ]
  },
  {
    "file_path": "./devposts/curavue.html",
    "project_id": "curavue",
    "title": "CuraVue",
    "tagline": "Bring awareness to breast cancer",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "machine-learning",
      "python",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AIHacks4GoodWinnerMost Creative Use of Twilio",
      "Best Domain from Domain.com",
      "Moreover, implementing Twilio and using ML was a bit difficult as this was our first time.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/239/506/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "This is the support page. This is our Home page. Here user need to Sign up. Here user will Login. Here user needs to upload the mammogram csv file. Here our ML model will evaluate and show the results. This is the support page. This is our Home page. Here user need to Sign up. Here user will Login. Here user needs to upload the mammogram csv file. Here our ML model will evaluate and show the results. This is the support page. 1 2 3 4 5 6 7 Inspiration Breast cancer is one of the most common cancers among women. In fact, 1 in every 8 women will be diagnosed with breast cancer at some point in her life. Furthermore, it is the 2nd leading cause of death among women worldwide. Therefore, awareness is very important because early detection can help catch cancer at a more treatable stage, and help saves lives. This inspired us to create CuraVue, a web platform that uses machine learning to detect breast cancer, using mammogram data. This will greatly help women to regain control of their health. What it does When the user arrives to our platform, they will come to the homepage where they can learn more about the website, such as what we do, how it works, etc. How we built it HTML, CSS: frontend Python/Flask: backend ML: for analyzing data Cockroach DB: for storing user data Twilio: email/login Best Domain from Domain.com https://curavue.tech Challenges we ran into There were quite a few challenges we had while building this project. We had to brainstorm and come up with a feasible idea that was innovative and could be implemented within the given time frame. Some of our teammates did not have much experience using building a website and they had to learn more about it especially when it came to fixing issues. Due to the difference in the time zone, we had some difficulty collaborating, but we managed to get the project done. Moreover, implementing Twilio and using ML was a bit difficult as this was our first time. Accomplishments that we're proud of Completing the project"
      }
    ]
  },
  {
    "file_path": "./devposts/debate-time.html",
    "project_id": "debate-time",
    "title": "Debate Time",
    "tagline": "Have you ever struggled to have your voice heard in class discussions because some people dominate the conversation? Not to fear! Introducing DebateTime, the app that organizes classroom debates!",
    "hackathon": "",
    "built_with": [
      "c++",
      "cmake",
      "dart",
      "docker",
      "flutter",
      "html",
      "rethinkdb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We found that participating in debates in online classroom settings with online classes has always had problems, and we’ve noticed that the teacher often struggles to keep track of things organized. What it does We have created a discussion management tool for classroom usage. So we have a platform where students can request to participate in the debate, and the platform also allows students to describe what their stance on the discussion is. It will also show the current queue of people interested in talking. How we built it We're using Flutter for the frontend and Docker + RethinkDB for the backend. Challenges we ran into Utilizing Flutter and its software. Accomplishments that we're proud of Coming together as a team to create a practical real-life application that will be useful to help classrooms run and teachers teach. What we learned We learned that it takes a longer time to add many additional features to our application than we planned on doing, so we had to leave some features. What's next for Debate Time We plan on adding voice chat using Twilio. Built With c++ cmake dart docker flutter html rethinkdb Created by Krishna Cheemalapati Arsal Khan Daniel Livshits Yahya Elgabra"
      }
    ]
  },
  {
    "file_path": "./devposts/deep-relay-ueq5fa.html",
    "project_id": "deep-relay-ueq5fa",
    "title": "Deep Relay",
    "tagline": "A visualization of depth charts for 0x Relays",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/605/456/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Depth Plot in Unity3D Depth Plot in Unity3D Depth Plot in Unity3D 1 2 Inspiration Wanted to use a 3D space to visualize several depth charts in comparison with eachother, to help in deciding which relays are ideal to use at a given moment What it does It calls a http orderbook get request to the Radar Relay for How we built it We built it in the Unity3D Game Engine Challenges we ran into Accomplishments that we're proud of What we learned What's next for Deep Relay Built With c# unity Try it out GitHub Repo Submitted to ETHDenver Created by Created the http request through Unity, built a C# parser, and plotted using the lineRenderer in Unity Adam Sauer Kristoffer Josefsson"
      }
    ]
  },
  {
    "file_path": "./devposts/desmos-art-generator.html",
    "project_id": "desmos-art-generator",
    "title": "Desmos Art Generator",
    "tagline": "Collaborating to create and promote the creative intersection of technology and art to provide intellectual stimuli for students and adults alike.",
    "hackathon": "",
    "built_with": [
      "canva",
      "css",
      "desmos",
      "express.js",
      "html",
      "javascript",
      "jsx",
      "node.js",
      "potrace",
      "react",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "3rd Place Overall Created by I worked on the UI, design, and front-end of the index/home, about, an",
      "Space City Hacks 2022Winner3rd Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/010/898/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration Many of us in our hackathon team are both technology, STEM, and art enthusiasts ourselves; every time we see novel and astounding interdisciplinary tech/stem+art creations, such as Google’s Quick Draw, it always blows us away to see how creative and mesmerizing they are. In our math classes, we have explored using Desmos graphs to create drawings such as snowmen and utilized processing.js to code scenery and houses. Since expressing creativity for both students and adults alike is important for bonding together, education, and for expressing experiences, stories, and emotions, we decided to create from scratch a desmos art generator for the hackathon. With the power of computer vision, math, and a pinch of artistic talent, with our generator, anyone can create their own art on a Desmos canvas! What it does Desmos Art Generator is a web app that ensures that all users can always have a platform to express their creativity by visualizing their drawings. When a user opens Desmos Art Generator, they will see its information and how-to-guide of our generator and are prompted to upload a picture of any image or drawing. The image is then processed and passed through a computer vision algorithm called sobel edge detection, which used convolutions and a Gaussian filter. The algorithm highlights the edges within the drawing/image, so it could be traced by a tracing library called Potrace.  After learning the locations of the edges, the algorithm then finds the curve equations that replicate it, before it outputs to the user a desmos graph version of the image - that is, the image in the form of hundreds of desmos equations put together. In addition, the output includes the exact equations of the curves and lines so users can replicate the image themselves using desmos.com and save it. They can also make minor changes to the image in desmos if necessary. The about page has information about our mission and future plans for Desmos Art Generator. The h"
      }
    ]
  },
  {
    "file_path": "./devposts/dis-locate.html",
    "project_id": "dis-locate",
    "title": "Dis-Locate",
    "tagline": "An Early Disaster Warning System",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/922/827/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The all seeing eyes of the social media will help us pinpoint any kind of disaster that might have struck a city in the world. What it does It uses the twitter scraper api to scrape the tweets and then create a database that would finally predict the top 5 location where a disaster may have struck. How we built it We used a twitter api to create a back-end and then created a front-end using html, css and javascript to create a front end Built With css html javascript python Try it out GitHub Repo Submitted to TAMUhack 2020 Created by Vatsal Modgil Jayesh Tripathi Prajwal Iyer"
      }
    ]
  },
  {
    "file_path": "./devposts/d-day.html",
    "project_id": "d-day",
    "title": "D-Bit",
    "tagline": "Expedited asteroid drill research.",
    "hackathon": "",
    "built_with": [
      "numpy",
      "pandas",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/294/732/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Feature Correlation! KNN Analysis! PDA Analysis! Feature Correlation! KNN Analysis! PDA Analysis! Feature Correlation! 1 2 3 4 5 6 D-Bit\nHackUTD2022 EOG challenge DevPost = https://devpost.com/submit-to/16723-hackutd-ix/manage/submissions/370578-d-day/project_details/edit Inspiration\nGiven a wide variety of data, with an open ended prompt, we were excited to use classic unsupervised and supervised learning techniques to classify techniques. What it does\nD-Day is a website that takes in data about asteroid drills sent in by the user and uses ML techniques to present accurate and useful analytics. The code promotes and very modular design for reproducibility and easy access. Our website design illustrates flawless user interface for the most efficient, streamlined process possible. How we built it\nWe utilized primarily Python, Numpy, Pandas, and Scikit-learn for the true processes behind our project. We used a variety of mathematical and statistical techniques in order to normalize and transform the given data in order to achieve the desired results. Challenges we ran into\nOne problem we faced was the numerous occurrences of bad data which we needed to clean. Most of our time went into creating features and doing routine data processing in order to create a strong foundation for our model. In addition, we faced the challenge of selecting a model in order to best fit the problem. While we could have used some sort of CNN and deep learning for the base of the project, we decided it would be much more efficient and cost-smart to utilize a simpler model such as a K-nearest neighbors algorithm. Accomplishments that we're proud of\nWe were able to answer all of the given questions given as part of the project prompt. In addition, we were able to successfully devise a way to monitor and check live user data through the functionality of data submission on the website. We were able to normalize and process the results in order to make an readable output for any user. We were ab"
      }
    ]
  },
  {
    "file_path": "./devposts/destores.html",
    "project_id": "destores",
    "title": "Hero NFT",
    "tagline": "creating a web of everyday heroic deeds, one NFT at a time",
    "hackathon": "",
    "built_with": [
      "canva",
      "css",
      "html",
      "javascript",
      "json",
      "matic",
      "metamask",
      "opensea",
      "polygon",
      "tallyforms",
      "typedream",
      "walletconnect"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from GoDaddy Registry [APAC Only] Created by i did everything :))) Kanha Korgaonka",
      "Hero Hacks IIWinnerBest Domain Name from GoDaddy Registry [APAC Only]",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/907/641/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 💡 Inspiration💡 A long time ago in a galaxy far, far away India, a children's book titled \"Your Turn Now\" started a movement of small, selfless deeds of kindness. It all began when the author's uncle met with an accident and was taken to a hospital by a lady who was passing by. The lady stayed with the author's uncle till his family arrived. When they saw him in good hands they were relieved. They tried to find some way of rewarding the lady for her kindness, but she simply said, “If you are kind to someone else in need, that would be thanks enough.” The author couldn’t stop thinking about this incident. The lady’s generosity was very inspiring. And then an idea took root in his mind—do a good deed and in return request the person you helped to perform a good deed for someone else. This could be made into a chain of good deeds that impacted thousands of lives as one good deed passed from one person to another. I wanted to revive this movement and maximize its impact, with web3 magic this time! The blue paper cards get worn out and damaged easily, but if they were NFTs, they would be on the blockchain forever, and the HERO NFT project fixes so many such problems with the Your Turn Now movement, making it so more effective, giving everyone a chance to be a hero in their local community !! 🏇 What it does 🏇 A HERO NFT is a non-fungible token on Polygon that you give someone after you show a \"heroic\" deed, which is any small, selfless kind action that you performed. The HERO NFT project gets momentum when the person you helped is encouraged by the NFT to do a good deed himself and pass on the token to someone else. Thus, a chain, if not a web, of good deeds is formed as the NFT passes from one wallet to another. 🏗️ How we built it 🏗️ There are 9,999 HERO NFTs in existence on Polygon - ( https://opensea.io/assets/matic/0x2953399124f0cbb46d2cbacd8a89cf0599974963/15451584504981989505193894127635794359356309168813899731634104674175175108367 ). The NFT was designed in Ca"
      }
    ]
  },
  {
    "file_path": "./devposts/dengl.html",
    "project_id": "dengl",
    "title": "Knowron_WhAI <DengL>",
    "tagline": "Report generation tool with code-mixed translation using neural machine learning model.",
    "hackathon": "",
    "built_with": [
      "css",
      "fastapi",
      "html",
      "javascript",
      "pydantic",
      "python",
      "svelte",
      "typescript",
      "uvicorn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Brainstorm first, code second Stay focused and within scope Don't order 150 pizzas at once"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/466/786/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "The Team Logo GIF a demo of our mvp The Team Logo GIF a demo of our mvp The Team 1 2 3 Inspiration Despite their excellent skills, foreign workers face many inconveniences and restrictions due to unfamiliar language. We were inspired by multilingual speakers using a mix of languages in one sentence. And we also focused on the fact that they are ready to continue learning and using a foreign language. DengL helps foreign workers communicate in a mixture of their mother tongue and foreign language. So that they can take advantage of the words and phrases they have learned. What it does The app allows a streamlined and simplistic approach to tracking field data as a labourer. Mainly to be used on Smartphones, we provide quick voice input to take memos. For immigrants, we encourage the use of the already learned chunks of the new language by allowing textual input to be in multiple languages, all to be translated into a target language. Furthermore, reports can be automatically summarised once they reach an adequate length. All entries can be consolidated into a PDF output. How we built it DengL is realised as a web-app that communicates with AI backend services via REST. For the web frontend, we used Svelte with Vite as our build toolset and leverage GitHub pages for deployment. Our AI driven backend uses azure, openai and cohre to master the complex task of translation and transcription. We use FastApi for our endpoint and pydantic for type validation. Challenges we ran into Microsoft Azure has a lot to offer, but tricky to get into\nFinalizing features gets more tricky the more you test it Accomplishments that we're proud of aruuning mvp in the web great team work What we learned Brainstorm first, code second\nStay focused and within scope\nDon't order 150 pizzas at once What's next for DengL Refining our language models\nAdding more features (image, video logging)\nCreating a business plan Built With css fastapi html javascript pydantic python svelte typescript uvicorn T"
      }
    ]
  },
  {
    "file_path": "./devposts/devcrowd-tech.html",
    "project_id": "devcrowd-tech",
    "title": "devcrowd.tech",
    "tagline": "A place for developers to share and discover cool websites and web technologies.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/114/977/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Homepage Login Sign Up Upload projects Custom URL for projects Homepage Login Sign Up Upload projects Custom URL for projects Homepage 1 2 3 4 5 6 Inspiration For mobile apps, there's the play store, for games there's steam and for web games - there's itch.io. But what about people who want to showcase their websites, and what about people who want to discover cool web technologies. That's how devcrowd.tech was born, to be a platform for developers to discover web technologies. What it does Devcrowd.tech provides a platform for developers to create and discover projects. It provides an online marketplace for the site and How we built it We built it using Python and the Flask framework, along with HTML, CSS and a little bit of Javascript. Challenges we ran into No hackathon project can be completed without a challenge and a massive array ;) of problems. For us, one of the biggest challenges was the sheer scale of the project. How would we manage to make such a big project in a matter of hours? What we decided was to make it an MVP, or a minimum viable product, which we have succeeded in making Accomplishments that we're proud of We're really proud of what we were able to accomplish and create an MVP in such a short time What we learned We learnt a lot from this hackathon, learning how we could work in a team and collaborate creating this project. What's next for devcrowd.tech Devcrowd.tech aims to become THE online platform for developers to showcase and discover web technologies, and we'll try our best to make this come true as we will continue to work on the project even after the hackathon ends. Built With css flask html5 javascript python Submitted to NotUniversity Hacks Created by I worked on the backend of the project and designed most of it. raghav nautiyal I worked on the frontend of the project and I created the user interface for the project Siddhant Bhargava"
      }
    ]
  },
  {
    "file_path": "./devposts/dejavu.html",
    "project_id": "dejavu",
    "title": "DejaVu",
    "tagline": "Eliminating déjà vu by reviving memories one video at a time",
    "hackathon": "",
    "built_with": [
      "ai",
      "ffmpeg",
      "flask",
      "google-cloud",
      "hardware",
      "llm",
      "next.js",
      "openai",
      "opencv",
      "pyaudio",
      "python",
      "semantic-search",
      "software",
      "transformers",
      "vectorization",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2023 Finalist Created by i tried to make it work Ian Korovinsky i made it work Rajan",
      "Hack the North 2023WinnerHack the North 2023 Finalist",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/589/363/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "API Visualization Landing Page Main UI Hardware - Front View Hardware - Back View API Visualization Landing Page Main UI Hardware - Front View Hardware - Back View API Visualization 1 2 3 4 5 6 Inspiration Behind DejaVu 🌍 The inspiration behind DejaVu is deeply rooted in our fascination with the human experience and the power of memories. We've all had those moments where we felt a memory on the tip of our tongues but couldn't quite grasp it, like a fleeting dream slipping through our fingers. These fragments of the past hold immense value, as they connect us to our personal history, our emotions, and the people who have been a part of our journey. 🌟✨ We embarked on the journey to create DejaVu with the vision of bridging the gap between the past and the present, between what's remembered and what's forgotten. Our goal was to harness the magic of technology and innovation to make these elusive memories accessible once more. We wanted to give people the power to rediscover the treasures hidden within their own minds, to relive those special moments as if they were happening all over again, and to cherish the emotions they evoke. 🚀🔮 The spark that ignited DejaVu came from a profound understanding that our memories are not just records of the past; they are the essence of our identity. We wanted to empower individuals to be the architects of their own narratives, allowing them to revisit their life's most meaningful chapters. With DejaVu, we set out to create a tool that could turn the faint whispers of forgotten memories into vibrant, tangible experiences, filling our lives with the warmth of nostalgia and the joy of reconnection. 🧠🔑 How We Built DejaVu 🛠️ It all starts with the hardware component. There is a video/audio-recording Python script running on a laptop, to which a webcam is connected. This webcam is connected to the user's hat, which they wear on their head and it records video. Once the video recording is stopped, the video is uploaded to a storage bucket"
      }
    ]
  },
  {
    "file_path": "./devposts/dealdrill.html",
    "project_id": "dealdrill",
    "title": "DealDrill",
    "tagline": "Sharpen Your Sales Skills with AI-Powered Simulation",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "pinata",
      "sambanova",
      "shadcn",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/142/669/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Competitor Analysis Thumbnail Landing Page Problem Statement Tech Stack What do we do? What do we do (pt.2) ? Competitor Analysis Thumbnail Landing Page Problem Statement Tech Stack What do we do? What do we do (pt.2) ? Competitor Analysis 1 2 3 4 5 6 7 8 Inspiration The inspiration for DealDrill came from the realization that both product people and technical professionals often struggle with selling or negotiating their ideas and products . Effective negotiation and selling are crucial skills in today's business world, yet many lack the tools or training to do so effectively. This led us to explore how simulation training could be used to address this gap. What it does DealDrill is a simulation-based training platform designed to help individuals and teams improve their negotiation and selling skills . Powered by SambaNova's advanced AI models , the platform delivers realistic simulations of high-stakes conversations, such as sales calls or business negotiations. It provides detailed, real-time feedback to both employers and trainees, helping them refine their approach, build confidence, and drive results. The platform is particularly suited for recruitment and training in roles that require negotiation, persuasion, and decision-making. How we built it Frontend : Next.js was used to create a dynamic, responsive, and seamless user interface, ensuring an engaging experience for trainees. Backend : Pinata was utilized for storage and management of the simulation data, enabling efficient handling of video, text, and other content generated in the simulations. API : Samba Nova powers the AI-driven feedback system that analyzes user performance in real-time, providing detailed insights and suggestions to improve negotiation skills. Challenges we ran into Integrating SambaNova’s AI Models : One of the biggest hurdles was configuring the LLMs to provide feedback that felt intuitive, actionable, and context-aware, particularly for diverse negotiation scenarios. Customer Ac"
      }
    ]
  },
  {
    "file_path": "./devposts/connections-ai-79i0qw.html",
    "project_id": "connections-ai-79i0qw",
    "title": "Connections AI",
    "tagline": "Connections AI Solver is a bot that automates the gameplay of The New York Times' Connections game, using AI to group 16 words into four categories based on semantic analysis and pattern recognition.",
    "hackathon": "",
    "built_with": [
      "api",
      "git",
      "github",
      "openai",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/129/766/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Connections Logo Inspiration Inspired by the challenge of the Connections game from The New York Times, we wanted to explore how AI can replicate human-like categorization abilities and solve complex word association puzzles. What it does We built a Connections AI Solver which automates the gameplay of the Connections game, using natural language processing and LLM techniques to categorize 16 words into four distinct groups. How we built it We developed the solver using Python with natural language processing (NLP) methods, leveraging pre-trained models, and the OpenAI API to analyze word meanings and semantics. A Flask-based web app interfaces with the bot which allows us to engage in submissions. There were multiple methods that we tried throughout the project. For example, we began by taking a NLP approach by embedding words then using the K-Means algorithm supported by cosine similarity. On the other hand, we also attempted to characterize the words as embeddings, create a graph where each word is a node, and weigh the edges with their similarity. Lastly, we applied the Louvain algorithm as a means to cluster words with the limitation of four words per cluster. Challenges we ran into Ensuring accurate categorization with varying word associations was challenging. Balancing model performance and computation time to provide near-instant solutions for all game levels was also tough. Accomplishments that we're proud of We successfully created a program that can psuedo solve the Connections game, demonstrating the power of NLP and machine learning in real-time applications. The bot categorizes words with somewhat accuracy. What we learned We learned how to apply advanced machine learning models for semantic analysis, the importance of optimizing AI for user interaction, and how to improve the speed and efficiency of NLP systems. What's next for Connections AI We plan to refine the model's accuracy, expand its ability to handle more complex word groupings, and explore"
      }
    ]
  },
  {
    "file_path": "./devposts/datacation-28kusy.html",
    "project_id": "datacation-28kusy",
    "title": "DATACation",
    "tagline": "DATACation provides high school students with a one-stop site to find resources for assistance in Mathematics, English, Science, and Social Studies.",
    "hackathon": "",
    "built_with": [
      "css3",
      "github",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/352/017/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "An example of a resource page for Grade 9 Mathematics with clickable links Home page Second page with drop down menus to select grades and subjects An example of a resource page for Grade 9 Mathematics with clickable links Home page Second page with drop down menus to select grades and subjects An example of a resource page for Grade 9 Mathematics with clickable links 1 2 3 4 Inspiration With the current circumstances of COVID-19 and the shift to online learning, school has gotten much harder for many of us, especially high school students. To help ease the stress a bit, we decided to create a single website with learning resources for assistance in mathematics, english, science and social studies. Many of these sites are reusable as a refresher before the start of a course, as a learning guide or for practice before a major test. This site is made by high school students, for high school students. What it does DATACation provides high school students with a one-stop site to find resources for assistance in mathematics, english, science, and social studies. Based on the users grade and specified subject they would like assistance with, the website would redirect them to new page consisting of helpful resources the student can use. How we built it We built this website with HTML, CSS, Javascript and collaborated through GitHub. Our project was primarily front-end work as the main functions of our site were completable with these languages. We also used additional resources such as Wireframe and Google Slides to plan out and share our layout before coding. Challenges we ran into One challenge we ran into was the different curriculum taught in the United States and Canada. Our team was split by location but we managed to contribute, do some research on subjects completely new to us and gathered resources. Our skill sets also varied, some of us with relatively more web development experience than others but because of this, we learned lots from each other over the cours"
      }
    ]
  },
  {
    "file_path": "./devposts/devnet-5p7alr.html",
    "project_id": "devnet-5p7alr",
    "title": "DevNet",
    "tagline": "DevPost is a revolutionary platform that connects students with professional developers in communities to facilitate project collaboration and mentorship connections.",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "firebase",
      "html5",
      "javascript",
      "json",
      "node.js",
      "react",
      "rest-api",
      "semantic-ui",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/864/526/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "DevNet DevNet 1 2 3 4 Inspiration In today's society, thanks to the creation of platforms such as Google and Stackoverflow, coders are able to find explanations to their bugs and problems within a few simple searches on the Internet. Other platforms such as Github have greatly facilitated online collaboration and the development of many open-source projects by the public. However, at a local level, there is no easy and efficient system for students to find local collaboration, guidance, and mentorship from other individuals. This is why we wanted to create a platform for students who are undertaking projects or seeking help to be able to easily connect locally with individuals that are a match for them. What it does DevNet is an online platform that allows its users to either register as students or as industry mentors and connect with other members of the platform. Users can fill a comprehensive profile of their skillsets, interests, experience, and projects which are shared with others. They then can then find others in their local communities based on their interests and expertise. For example, a student seeking advice for front-end development would be able to filter through industry mentors in order to find one of an appropriate fit. Another seeking to be involved in projects would be able to scroll through the project section and find one that is of interest. Once two individuals match with each other, they are able to message each other in order to set up a meeting in real life! How we built it We made a multiplatform application (browser and IOS) using ReactJS, NodeJS, Firebase, and Swift. Challenges we ran into We had a lot of issues with deploying Firebase Cloud functions. Choosing appropriate frameworks Integrating other features such as a messaging without affecting the rest of the system Accomplishments that we're proud of We have successfully used the Google API in order to create the platform Collaborative Skills Planning and organization of developme"
      }
    ]
  },
  {
    "file_path": "./devposts/deltahacks6.html",
    "project_id": "deltahacks6",
    "title": "Ignis Vigilante",
    "tagline": "Predict, Learn, React",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "flask",
      "html",
      "machine-learning",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/923/397/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The hardware with the database Home Page - Logo Density Graph - Standard Variable Deviation Correlation Map - Changes of Relative Variables The hardware with the database Home Page - Logo Density Graph - Standard Variable Deviation Correlation Map - Changes of Relative Variables The hardware with the database 1 2 3 4 Inspiration Forest fires have caused massive devastations during the last 5 years. Recently, Australia has been suffering from fires burning since October 2019. We wanted to create a hack that involves both the tool to collect the data and analyze it. What it does The sensors connected to the Arduino would send out statistical data using IoT protocols such as the MQTT. This data would be stored in our Firebase Cloud Firestore database which would be updated in realtime. We would then run our Machine Learning model to analyze the data and predict the likelihood of the area catching fire to prevent it. All this data would be tracked on our website for the citizens and the government of the country. How we built it Our hardware side uses an Arduino with a Grove shield. A Grove Temperature sensor v1.2 to track the temperature and a SparkFun Moisture sensor to track moisture content at a moderate depth. The collected data is read by server-side python code which adds all the collected data to our Firebase Cloud Firestore database. The collected data is then run through our Machine Learning model which is trained using the sci-learn kit. The model outputs the likelihood of a fire taking place in an area based on the temperature, wind, relative humidity, etc. All this data is displayed on our web application through charts and heatmaps. The web application is built using Python and the Flask web framework. Challenges we ran into Training the model was our biggest challenge, as we didn't have a big dataset set to work with. We had to tweak our calculations to get better prediction accuracy based on the dataset. Accomplishments that we're proud of What we learne"
      }
    ]
  },
  {
    "file_path": "./devposts/ddrive.html",
    "project_id": "ddrive",
    "title": "DDrive",
    "tagline": "Driving decentralized file storage to the next level",
    "hackathon": "",
    "built_with": [
      "axelar",
      "jackal-js",
      "javascript",
      "next.js",
      "solana",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/484/574/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sending a file --> Welcome to DDrive Login! Buy Jackal !!! Dashboard page :0 View your files :D Add a file <-- Sending a file --> Welcome to DDrive Login! Buy Jackal !!! Dashboard page :0 View your files :D Add a file <-- Sending a file --> 1 2 3 4 5 6 7 Inspiration Storing your files should be simple, seamless, and safe. However, the current platforms that do this are not as secure as we would like. Platforms like Github, Google Drive, and 1Password are all centralized storage, controlled by a third party that is able to overcharge or inhibit access to resources at any time. Control should be given to the user, not the corporations. \nAs such, we decided to create DDrive! What it does DDrive decentralizes conventional file storage and sharing using on chain protocols and methods. We support uploads up to 1 TB with Jackal Storage, and stores these files in an on-chain cloud storage system. A user is able to store anything from passwords, to API keys, to IAM access secrets, to code snippets. It uses the secure IPFS and GPG security protocol to encrypt and transfer/share files between users. To incentivize users, we allow the user to swap Solana and other types of cryptocurrency with Jackal coins using Axelar's general token passing ( callContract() method), in order to purchase more storage while using their interchain protocol. We also want to support the ability to mint the file on the blockchain in order to share certain secure files globally, in the case of open source use cases, which allows a decentralized and de-controlled protocol to share files (as compared to presigned URLs for example). We also want to support being able to upload all file types including images, and sending those securely without sacrificing latency, and possibly automate a way to create Jackal storage wallets. We also want to definitely support more interchain communication and types of transfers. Finally, we'd need to build our own interchain protocol token transfer in order to set up a "
      }
    ]
  },
  {
    "file_path": "./devposts/dotreadme.html",
    "project_id": "dotreadme",
    "title": "DotReadme",
    "tagline": "Deaf users no longer need to rely on individuals to make audio content accessible with captions: DotReadme provides operating system-wide live captioning and even translates sign language into speech!",
    "hackathon": "",
    "built_with": [
      "electron",
      "google",
      "javascript",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/486/916/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration When we think of Zoom, Twitch, and other live streaming platforms, we usually do not see live captioning for the users. Presenters tend to keep the live transcript off during most of their presentations. Another issue is that most streaming platforms—with live transcript features—will only have their live captioning for their own services. This makes things much more difficult for users who depend on live captioning as part of their daily usage. Also, those who are hard of hearing, and/or need ASL to communicate, do not have an effective way of presenting besides typing. What it does What .readme does is provide a universal live captioning service, where anyone on any device/system (Windows, Mac, Linux, etc.) will be able to have live captioning on their desktops, regardless of what application the user will need it for. So for example, when users log on to Zoom and join a meeting, live captions will be directly overlay based on the onboard output sound of their device. How we built it We built this application/service using React, Typescript, Electron, and Google Cloud services (Speech to Text). Challenges we ran into One of the biggest challenges our team faced was the limitations of API's and their compatibility with our web frameworks. For instance, Google's Speech to Text API had numerous package errors when running the service on Electron. When working with the ASL models, ASL detection was available; however, the models to actually interpret such signs were not preemptively trained. Accomplishments that we're proud of A big accomplishment that we're proud of, is our seamless user interface. We wanted to market this to users for easy access and easy use. Another accomplishment we're proud of was how we were able to workaround some of the Google API problems. We were able to redirect the speech to text transcripts from another site that we built and ship those transcripts directly into our live captioning. What we learned For most of us, Ele"
      }
    ]
  },
  {
    "file_path": "./devposts/docufiller-ai.html",
    "project_id": "docufiller-ai",
    "title": "Docufiller AI",
    "tagline": "Docufiller auto-fills out PDF forms using transcripts provided by the user. Our AI works through AI image recognition intelligence.",
    "hackathon": "",
    "built_with": [
      "openai",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/931/418/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Pdf is generated and filled out. Input the pdf, provide prompt, and add red boxes. Pdf is generated and filled out. Input the pdf, provide prompt, and add red boxes. Pdf is generated and filled out. 1 2 Inspiration\nThe inspiration behind DocuFiller AI stemmed from our previous experiences with transcription projects. Both Andrew and I noticed a recurring need among users, particularly in the medical field, to utilize transcriptions for filling out various forms. Doctors and dentists, for instance, often have to manually input information such as allergies from conversations with patients, which can be tedious and error-prone. This realization drove us to create an AI solution that could seamlessly transform natural conversations into structured data, thereby automating the form-filling process. What it Does\nDocuFiller AI allows users to automatically fill out PDF forms using transcriptions of natural conversations. By providing a PDF and marking the desired fields, our AI can accurately populate these fields based on the conversation transcript. This tool simplifies the data entry process for medical professionals and other users, reducing the need for manual input and minimizing errors. How We Built It\nWe leveraged OpenAI's image recognition software to develop DocuFiller AI. Initially, we experimented with various techniques, including the use of random placeholders on PDFs. The idea was to identify what content should replace these placeholders using image recognition and understanding. However, we soon realized that existing AI solutions couldn't pinpoint the exact pixel coordinates of form fields. Consequently, we designed a system where users specify the coordinates, allowing our AI to accurately fill in the required data. Challenges We Ran Into\nOne significant challenge was the absence of an AI capable of identifying and providing pixel coordinates for input form fields. This limitation required users to manually specify the coordinates, which added complexit"
      }
    ]
  },
  {
    "file_path": "./devposts/dclimate-api-visualizer.html",
    "project_id": "dclimate-api-visualizer",
    "title": "dClimate API Visualizer",
    "tagline": "The dClimate API Visualizer allows you to visualize all sorts of weather data from the dClimate API.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css3",
      "html5",
      "javascript",
      "postman"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Postman Student Summit Hackathon: Visualize for the Prize"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/611/035/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Minimum Temperature per Year Line Graph State -> RMA Code Table Dataset Information Thermometer and Datepicker Minimum Temperature per Year Line Graph State -> RMA Code Table Dataset Information Thermometer and Datepicker Minimum Temperature per Year Line Graph 1 2 3 4 5 Inspiration I was working on another application that uses the dClimate API to show a weather dashboard. I thought that it won't be a bad idea to show datasets in a Postman Visualizer. What it does Displays weather factors from datasets in a visualized method. It has two tabs, Overall and Hourly or Daily. The Overall tab contains a line graph of the averages for the whole year. The Hourly or Daily tab contains a datepicker for selecting the hour or day for when you want the data. As a bonus, it displays RMA Codes in a table format and lets you view the metadata on datasets in a more visualized format. How we built it I displayed the code in tabs using Bootstrap. Challenges we ran into Styling - It's not my best subject :)\nFinding Units - I had to run a bunch of 10 second API calls to get the units on different datasets in metric and imperial units Accomplishments that we're proud of Being able to actually create the web app properly :) Learning Postman Visualizer What we learned Using Postman Visualizer to visualize API data Using Bootstrap to style web applications What's next for dClimate API Visualizer Maybe adding support for more endpoints and making the data in the Hourly or Daily tab more visualized for more datasets. Built With bootstrap css3 html5 javascript postman Try it out www.postman.com Submitted to Postman Student Summit Hackathon: Visualize for the Prize Created by I worked on the dClimate API Visualizers Collection Yash Singh"
      }
    ]
  },
  {
    "file_path": "./devposts/datax-xntp8s.html",
    "project_id": "datax-xntp8s",
    "title": "DataX",
    "tagline": "Protecting IoT Data Privacy Using Blockchain",
    "hackathon": "",
    "built_with": [
      "arduino",
      "blockchain",
      "blockcypher",
      "google-cloud",
      "iot",
      "react-native",
      "sensors"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/348/348/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Main Page Hardware Blockchain Home Page Login Page Settings Page Registration Page Profile Page Main Page Hardware Blockchain Home Page Login Page Settings Page Registration Page Profile Page Main Page 1 2 3 4 5 6 7 8 9 Inspiration We drew inspiration for DataX from a variety of sources. Most notably the acclaimed documentary The Social Dilemma, which highlighted many of the dangers of social media and its capacity to reinforce addictive behaviours. This is no thanks to surveillance capitalism and the impacts of revenue models focused on big data, it is important for end users to be in control of how data mining directly affects them. The Facebook-Cambridge Analytica Scandal was also quite notorious for breaching the user privacy and obtaining the personal data of millions of users. We realised that transparency is absolutely essential. As such, we designed DataX with three principles in mind: autonomy, transparency, and connectivity. What it does In an age defined by rapid technological growth and the rise of big data, it is important to take a step back from the chaos and realize the reality of the modern human condition. Many of the technologies which supposedly empower us may in fact be ridding us of our autonomy. The power of big data is undeniable, and with the advent of the internet of things, even more so. But our information is a strictly personal thing. At DataX, we strongly believe in the human spirit and free will. We believe that we should not only have individual control over who our data is sent to, but also be rewarded for sharing such a valuable commodity. This is exactly what DataX has set out to accomplish. As opposed to a middle-man ominously collecting your data, you have full control over your IoT devices. Only you are in charge of who receives your data. Through DataX, big data is decentralized and can be sold directly to third parties via cryptocurrency microtransactions. Via our mobile app, you can view real time data statistics, manage who "
      }
    ]
  },
  {
    "file_path": "./devposts/diorama-infinity.html",
    "project_id": "diorama-infinity",
    "title": "DIORAMA INFINITY",
    "tagline": "See, Build and SHARE 3D AR dioramas on your Echo Show!",
    "hackathon": "",
    "built_with": [
      "3ds-max",
      "amazon-alexa",
      "amazon-web-services",
      "android",
      "areality3d",
      "augmented-reality",
      "echo-show",
      "ios",
      "lambda",
      "lamp",
      "photoshop",
      "realityscript",
      "s3",
      "unity",
      "vuforia"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/585/597/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "GIF This image is currently processing. Please be patient... GIF This image is currently processing. Please be patient... 1 2 3 4 5 6 7 Now with Google Poly support so you can load any 3D model! Note: Press the bottom left hand corner \"AR mode\" button if you are having trouble pointing your device camera at your Echo screen. This will force AR mode camera. By default, \"virtual mode\" happens so that interactivity continues even if you lose tracking. ***** Live on the iOS App Store! Grab it here! ***** If you don't have an Echo Show, feel free to use the Tester 3D \"virtual\" Echo Show (and environment) @ http://tester.diorama.space Diorama Infinity lets you create infinite worlds inside your Echo Show - by turning the Show into an augmented reality diorama creation platform. Every time you say \"Alexa, open DIORAMA INFINITY\", you get a random screen that a user created. Point your phone or tablet at the screen to \"see into this world\". Note that as you move your device, you can see so much more than just the plane of the screen - it's an entire infinite space! If you want to create your own diorama, simply summon a Grid. Say: Alexa, open DIORAMA INFINITY and load a grid. The creator menu shows up. You can now sign your name. The upload button also appears when you are ready to upload. There are a few books on the left side. If you can't see their titles, you can touch the red ribbon to rotate your camera in no virtual Echo Show mode. Each book represents a scene choice. Touch a book to change into that scene. There are 3D animals in front of the Echo Show diorama box, just like there would be if you were building your own diorama. Your job is to arrange them inside the Echo Show to turn it into your diorama! Echo currently times out after 8 seconds. You can load the grid as your Echo Show home screen image to keep building for as long as you want. The app also works without needing to point your phone at the Echo Show. Instead, you get a virtual desktop and virtualized "
      }
    ]
  },
  {
    "file_path": "./devposts/digidrop-u3jb6l.html",
    "project_id": "digidrop-u3jb6l",
    "title": "DigiDrop",
    "tagline": "A quick way to deploy dead drops on the web.",
    "hackathon": "",
    "built_with": [
      "bash",
      "flask",
      "linode",
      "nginx",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Undercover Hack Created by Mayank Jha #!lex Neel Adwani yeet",
      "Agent:HackerWinnerUndercover Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/728/969/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Sharing confidential information can be difficult for whistleblowers and if they're caught, they can be at a high risk for espionage. What it does A dead drop or dead letter box is a method of espionage tradecraft used to pass items or information between two individuals using a secret location. By avoiding direct meetings, individuals can maintain operational security. How we built it Linode - Server\nTwilio - SMS\nBack-end - Python, Flask Challenges we ran into Developing the Front-end, setting up auto-deployment. Accomplishments that we're proud of We're proud of developing two digital dead drops and learning about linode over the weekend. What we learned We learned about linode, auto-deployment, and dead drops. What's next for DigiDrop We can add more options to enable users to create their own dead drops. Built With bash flask linode nginx python sqlite Try it out GitHub Repo youcantseeme.co gonnahitstonkswith.tech Submitted to Agent:Hacker Winner Undercover Hack Created by Mayank Jha #!lex Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/destifind.html",
    "project_id": "destifind",
    "title": "DestiFind",
    "tagline": "Recommends travel destinations based on your selection of images that represent your ideal vacation.",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/527/925/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Recommended page Landing page Images to choose Recommended page Landing page Images to choose Recommended page 1 2 3 What it does The first part of any trip is to select your travel destination. It can be quite a challenging task to find a destination that would fit all your vacation expectations, and its also hard to describe your perfect holiday in words. That's where DestiFind comes in. Based on your selection of images that represents your ideal vacation, DestiFind will recommend travel locations that would meet all your holiday needs. Challenges we ran into The biggest challenge we ran into was figuring out what Artificial Intelligence model we would use to power the recommendation algorithm of DestiFind. What we learned We learned how to use Figma, Canva, as well as different Machine Learning Concepts such as vector embeddings. We also learned about similar image search engines. What's next for DestiFind The next step for DestiFind would be to implement and train the Artificial Intelligence model that powers DestiFind's recommendation algorithm. Built With figma Try it out www.figma.com www.canva.com Submitted to CSESoc's Flagship Hackathon 2023 Created by Harry . Xueyi Chee Watts Vanes"
      }
    ]
  },
  {
    "file_path": "./devposts/docuright.html",
    "project_id": "docuright",
    "title": "docuright",
    "tagline": "Writes docs that are right",
    "hackathon": "",
    "built_with": [
      "langchain",
      "openai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration DocuRight was inspired by the crucial need for up-to-date and comprehensive documentation in software development. Observing how often documentation lags behind during rapid development cycles, we sought to create a tool that could keep up with the pace of changes without adding to developers' burdens. By leveraging advanced AI technologies like OpenAI's GPT-3.5, we aimed to revolutionize how documentation is generated and maintained, ensuring it remains as dynamic and agile as the development process itself. What it does DocuRight integrates a powerful AI-driven GitHub bot with a VSCode extension to automate documentation tasks. When developers push new code, the GitHub bot, powered by OpenAI's GPT-3.5 and orchestrated by LangChain, analyzes the changes and automatically generates or updates documentation. This documentation is then crafted into pull requests that the VSCode extension fetches, allowing developers to review, adjust, and merge directly within their IDE, ensuring that documentation keeps pace with development without disrupting workflow. How we built it We built DocuRight using OpenAI's GPT-3.5 for generating the documentation text, relying on its advanced natural language understanding capabilities. LangChain was used to orchestrate the flow between the AI's output and our application's logic, facilitating seamless interaction with GitHub's API for code analysis and pull request management. The VSCode extension was developed with TypeScript, creating a user-friendly interface that connects directly with the GitHub bot for real-time updates. Challenges we ran into Integrating complex AI models like GPT-3.5 smoothly with GitHub's API presented a unique set of challenges, particularly in ensuring the AI accurately interprets code changes and generates useful documentation. Another significant challenge was maintaining the extension's performance and reliability, ensuring that it updates documentation in real-time without introducing lag or e"
      }
    ]
  },
  {
    "file_path": "./devposts/doct-ai.html",
    "project_id": "doct-ai",
    "title": "Doct.AI",
    "tagline": "The expertise of AI and medical professionals at your fingertips. Obtain medical diagnoses and next steps without the hassle (or the bill) of going into a clinic.",
    "hackathon": "",
    "built_with": [
      "azure",
      "node.js",
      "python",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/373/052/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In many countries around the world, healthcare institutions are crumbling due to the shortage of doctors, nurses and other healthcare professionals post pandemic. However, many of the people currently filling up these hospitals and ERs may not need to be there; my friend's brother had to wait a few months for a life saving procedure because the hospitals were filled with potential COVID patients at the time. A COVID test or an app such as Doct.AI could have remediated this issue much faster and have made better use of the doctors' time. So at CruzHacks, I decided to enact on the idea! What it does When you notice something irregular with your body, you type in some symptoms that you have been experiencing over the past few days. If words can't describe the symptom well, you can also upload an image which the backend will analyze. In either case the app sends back an analysis and possible theory of the disease / issue you may be experiencing and next steps to remediate it. Keep accessibility and UX in mind, users who may not be able to type or are visually impaired can also relay their symptoms via speech through a microphone on the app which will transcribe their words into the prompt box. If the app detects you may require a health professional, it suggests some around the area and can contact them on your behalf to get an appointment / consultation going faster. How we built it Azure Cognitive services for speech -> text Salesforce Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation (BLIP) model for image analysis Twilio to send texts to nearby doctors / specialists Node JS and Python for backend API calls to ML models React.js for frontend OpenAI's ChatGPT Challenges we ran into Some of the libraries I wanted to use were not fully functional with the latest ML models and sometimes couldn't even integrate with the Javascript code anyway. So I had to shell out to Python for some API calls and eventually had"
      }
    ]
  },
  {
    "file_path": "./devposts/disruptive.html",
    "project_id": "disruptive",
    "title": "Disruptive",
    "tagline": "A funding DAO platform for investors to seek out insights and connections from microaquisitions to portfolios",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "circle",
      "fastapi",
      "figma",
      "firebase",
      "flask",
      "graphql",
      "hedera",
      "jupyter",
      "kaggle",
      "next",
      "node.js",
      "openai",
      "python",
      "qlora",
      "tailwind",
      "taipy",
      "tensorflow",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH: Best Use of Hedera Created by Isabelle Huang Sophie Luo Jerry Zhu CS @UWaterloo | Retired | Fa",
      "Hack the 6ix 2023WinnerMLH: Best Use of Hedera",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/565/675/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Miscellaneous: Disruptive Logo Landing page Investor interest page: Selection of Pre/Post+ seed database Add company page: Typeform embedded Upload company pitches Miscellaneous: Disruptive Logo Landing page Investor interest page: Selection of Pre/Post+ seed database Add company page: Typeform embedded Upload company pitches Miscellaneous: Disruptive Logo 1 2 3 4 5 Inspiration Many investors looking to invest in startup companies are often overwhelmed by the sheer number of investment opportunities, worried that they will miss promising ventures without doing adequate due diligence. Likewise, since startups all present their data in a unique way, it is challenging for investors to directly compare companies and effectively evaluate potential investments.  On the other hand, thousands of startups with a lot of potential also lack visibility to the right investors. Thus, we came up with Disruptive as a way to bridge this gap and provide a database for investors to view important insights about startups tailored to specific criteria. What it does Disruptive scrapes information from various sources: company websites, LinkedIn, news, and social media platforms to generate the newest possible market insights. After homepage authentication, investors are prompted to indicate their interest in either Pre/Post+ seed companies to invest in. When an option is selected, the investor is directed to a database of company data with search capabilities, scraped from Kaggle. From the results table, a company can be selected and the investor will be able to view company insights, business analyst data (graphs), fund companies, and a Streamlit Chatbot interface. You are able to add more data through a DAO platform, by getting funded by companies looking for data. The investor also has the option of adding a company to the database with information about it. How we built it The frontend was built with Next.js, TypeScript, and Tailwind CSS. Firebase authentication was used to verify us"
      }
    ]
  },
  {
    "file_path": "./devposts/diet-helper.html",
    "project_id": "diet-helper",
    "title": "Diet Helper",
    "tagline": "On a Diet and want to find out what you can eat? Cook up the Recipe!",
    "hackathon": "",
    "built_with": [
      "css3",
      "edamam",
      "html5",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/336/022/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "results home page results home page results 1 2 3 Inspiration Our team knew before we started making the project that we wanted to create a web-app to practice front-end and back-end web development. Wracking our brains on issues we can tackle in the medical field brought us to the attention of diets. Most of us being fresh college students are experiencing cooking on our own for the first time and many of us rely on recipes to craft our fine dishes. We then thought it would be quite convenient to have one singular website for finding all recipe suggestions instead of going out recipe hunting on our own. What it does Diet Helper, as the name suggests, helps people when they are on a diet, regardless of it being medically-prescribed or for personal health reasons. This web-app allows the user to discover multiple recipes for certain diets, all in one place! They can restrict certain ingredients to their liking. How we built it It started with interviewing a range of people. This helped uncover a common user pain point when it came to cooking from a recipe: needing to figure out one unit of measurement to another for ingredients. A few possible web-app layouts were drafted in order to maximize the user experience. After the sketches and ideas were rounded out, we started on the coding stage. We decided to use Javascript and React as the front-end language as well as the good ole html and css. In the midst of coming up with a database for the recipes, we stumbled upon the Edamam API . The API contains millions of recipes along with dietary restriction tags as filters. Challenges we ran into The main challenges we ran into was linking the front-end and the back-end together. None of us has had much of a website development experience, so we were all struggling in figuring out how to connect the pieces to finish this project. For some of us, this was also our first time working with javascript. Accomplishments that we're proud of Making a working product with javascript "
      }
    ]
  },
  {
    "file_path": "./devposts/devmatch-2vglfb.html",
    "project_id": "devmatch-2vglfb",
    "title": "DevMatch",
    "tagline": "Devmatch helps you to get you a coding buddy/technical co-founder/remote job/hackathon teammate",
    "hackathon": "",
    "built_with": [
      "dynamicxyz",
      "express.js",
      "mongodb",
      "node.js",
      "pushprotocol",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "CodeDamn Award - Education projects Created by Satyam Singh",
      "CrackedDevs HackathonWinnerCodeDamn Award - Education projects",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/731/989/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Job listing section landing page match section My Profile Edit Profile Job listing section landing page match section My Profile Edit Profile Job listing section 1 2 3 4 5 6 Inspiration I have been to around 32 hackathons till now and in almost everyone of them I used to get this issue of finding a good technical teammate, it's hard to judge someone new just because they said they know something so I thought why not build a platform that can solve it so here it is! What it does Devmatch helps you to get you a coding buddy/technical co-founder/remote job/hackathon teammate.\nDevmatch is a decentralized platform with the smoothest onboarding ever, it scrapes user's public information with the help of their GitHub username, add interest as the languages that the user's use by going through their public repositories, recommends them users that have similar technical interests, they can like/dislike and communicate with those developers that they are matched with using a decentralized protocol powered by Push Protocol and users even get emails if they're matched with someone.\nUsers can even add their projects in the interested section so that other developers can look into it and contribute if they're interested.\nLast but not the least an automated job listing platform that recommends you remote jobs based on your GitHub profile which is powered by none other then CrackedDevs. How we built it I used DynamicXYZ to give users the smoothest onboarding possible on any dapp ever (they say it not me lol), I used ReactJS in the frontend, Push Protocol for the chat feature, MongoDB for the DB, NodeJS and ExpressJS in the backend, trycourier for mail notification when you're matched with someone Challenges we ran into I didn't had any teammates so it was difficult to get things done entirely by my own and to make things even complex I live streamed it for 25 hrs while building it. Accomplishments that we're proud of I am proud that I was able to pull everything together within tim"
      }
    ]
  },
  {
    "file_path": "./devposts/deb-ai-te.html",
    "project_id": "deb-ai-te",
    "title": "deb(AI)te",
    "tagline": "A better and smarter way to win your arguments with the power of artificial intelligence.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "cohere",
      "css",
      "html",
      "javascript",
      "next.js",
      "react",
      "tailwindcss",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/022/876/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Brian the Brain - A dorky and intelligent debater. deb(AI)te logo Home page of UI - User will enter debate topic here. Recording user's audio for the debate. Debate against Goose Goose Bot. Feedback against Goose Goose Bot. Socrates - Coming from a time long ago he shares his wisdom to his modern day students. Goose - *Hisses* Brian the Brain - A dorky and intelligent debater. deb(AI)te logo Home page of UI - User will enter debate topic here. Recording user's audio for the debate. Debate against Goose Goose Bot. Feedback against Goose Goose Bot. Socrates - Coming from a time long ago he shares his wisdom to his modern day students. Goose - *Hisses* Brian the Brain - A dorky and intelligent debater. 1 2 3 4 5 6 7 8 deb(AI)te Project for Hack the North 2024. 💡 Inspiration The idea for deb(AI)te was born from the desire to help people improve their presentation, critical thinking, and debating skills in a fun and interactive way. By integrating fun AI-driven characters with distinct personalities and expertise, users can engage in dynamic, real-time debates in a low-pressure environment. The aim is to make learning these essential skills more engaging and accessible for real-world purposes. ❓ What it does deb(AI)te allows users to participate in structured debates against AI opponents. Users choose a debate topic, and the AI, customized with different difficulty levels, responds as an expert in the field. The user gets 30 seconds to prepare an argument and then present using their speech. After the user is done, the AI will provide their argument as to why their stance is superior. Then, the system uses a rating mechanism to assess both performances and provides constructive feedback on their arguments, helping the user to improve over time. The application leverages speech-to-text functionality for seamless interaction and AWS Polly for high-quality text-to-speech responses from the AI characters. 🧰 How we built it We built deb(AI)te using JavaScript, React, and Tail"
      }
    ]
  },
  {
    "file_path": "./devposts/dartboard-s29big.html",
    "project_id": "dartboard-s29big",
    "title": "Dartboard",
    "tagline": "Generates random vacation ideas.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "css3",
      "django",
      "flask",
      "html5",
      "javascript",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "be the best use of our time and fit our needs"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/241/100/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "launch screen for secondary app preliminary ui dart logo launch screen for secondary app preliminary ui dart logo launch screen for secondary app 1 2 3 4 Inspiration Trying to plan the picture perfect vacation can be stressful. So we decided to help by randomizing part of that process. We all love the idea of having an adventurous spirit and embracing the unknown. What it does Dartboard is a website that helps you find your next adventure. We built a database with information from the top 200 travel destinations in the United States. Dartboard scrapes the web for hotel pricing, availability, local activities, and culture. If you’re feeling spontaneous, your next vacation could be one click away! We then made two proof-of-concepts frontends which displayed this information. The first takes the information from the scripts as JSON data to parse through and displays the information. The second calls the scripts directly, parses the information, and displays it. How we built it We built the scripts using the Selenium and Beautiful-Soup python libraries for web-scraping. These scripts parse popular travel related sites to return relevant information. For the two frontends we used JavaScript, HTML, and CSS. For the one that calls the scripts directly, however, we additionally used flask. Challenges we ran into We ran into the issue of integrating the backend and frontends. Selecting which frameworks and libraries would best be the best use of our time and fit our needs. Accomplishments that we're proud of Web Scraping - Some websites had extreme latency, other websites intentionally hide their data to make their API’s more attractive. Managing Data - The data that we scraped was a mess. The raw html data we started with was basically soup, hence the name. Sharing files - We had to modify our python scripts to output .json files to work in our javascript front end. Formatting - We had problems getting our animations to appear correctly. We also struggled with indestructibl"
      }
    ]
  },
  {
    "file_path": "./devposts/deso-ngs.html",
    "project_id": "deso-ngs",
    "title": "DeSo(ngs)",
    "tagline": "The decentralized music streaming platform that empowers artists and listeners alike.",
    "hackathon": "",
    "built_with": [
      "deso",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "7th - 13th Place Overall Do-Re-Mi Hacks II Winner Best Use of DeSo Created by Frontend Kanha Korgao",
      "category this weekend motivated him to finally learn about blockchain and web3, and not only get hi",
      "YPStem Hackathon 2022Winner7th - 13th Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/839/884/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 💡Inspiration We were inspired by the problems faced by the social media industry that can be solved with DeSo. We realized, that these problems are true even for the music streaming industry, and creating our own music streaming platform, with DeSo not only can we give more power to the artists/creators as well as the listeners or fans, but also build a highly secure streaming service that‘s ready for web3.0, thanks to DeSo Identity. ⚙️ What it does DeSo(ngs) lets anyone — even indie artists create and share or sell their music on the platform. It also lets fans buy a particular song as an NFT that can be MINTED to the DeSo Blockchain! Since it is expensive to play entire MP3 files, DeSo(ngs) also let users put their DeSo(ngs) as a spotify link, and be able to play them on the platform, just to show the proof of concept. Providing a platform like this for indie artists and empowering listeners to buy and support music while not using the outdated ad monetization method and using blockchain, makes us truly ready for the new web. 🏗 How we built it We used DeSo and ReactJS. Our code is also hosted in a public repo on GitHub! Use of DeSo We wanted to build an app that was bulletproof in terms of security. Which is why we used DeSo Identity. The amazing documentation on deso.org taught us about how blockchain authentication works and why it is THE choice for web3 apps using DeSo. We also used DeSo to mint NFTs using code on the DeSo blockchain. 🚧 Challenges we ran into One of our teammates left in the start of the project. We were hacking and studying simultaneously, because as I said before, both of us had exams coming up. For some reason any link we use will not properly show up on Diamond Appp 🏆 Accomplishments that we're proud of One of us was totally new to web3 and blockchain and he is really glad that the DeSo prize category this weekend motivated him to finally learn about blockchain and web3, and not only get his knowledge up to speed, but also successfull"
      }
    ]
  },
  {
    "file_path": "./devposts/double-deep.html",
    "project_id": "double-deep",
    "title": "Double Deep",
    "tagline": "Developing revolutionary techniques to optimize AI models.",
    "hackathon": "",
    "built_with": [
      "azure",
      "css",
      "flask",
      "html",
      "jupyter",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/687/721/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page. Double Deep: AI, for AI. Who we are. Watch our live demo for more information! Landing Page. Double Deep: AI, for AI. Who we are. Watch our live demo for more information! Landing Page. 1 2 3 Inspiration A.I. is like an iceberg. It can yield great results, yet demands a mounatin of computation and fine tuning to produce satisfying results. The problem is because some AI algorithms, notably neural networks, are black boxes. Little is known on why they perform so well. In addition, methods such as transfer learning that aim to use pretraiend neural networks to solve are limited, because a heavily trained model is refitted on a completely different data problem. Instead of relying on trial and error to solve data problems, we developed Double Deep, a web-based algorithm that can effectively and accurately craft a customized model that fits each unique problem. What it does AI, for AI. DoubleDeep crafts a custom neural network model for a specific problem. And this is possible with only a click of a button. How we built it We used Python's Scikit-Learn machine learning package to build a model that can takes as input quantitative values of the complexity of the problem and predicts the optimal architecture of a neural network. UsingKeras (with a Tensorflow backend), we recorded the architecture of a specific neural network and its associated loss. Having recorded several such neural networks, we trained our Scikit-Learn model to recognize patterns in the neural network topology. Challenges we ran into This project consisted of discovering a completely new method to optimize AI. We had to map out an algorithm that can measure the performance of a neural network and suggest ways to optimize its structure. We did not know if such an approach would yield significant results as no similar approach has ever been attempted . After gathering enough training data, the results positively showed that a Double Deep generated neural network had a lower loss than a base"
      }
    ]
  },
  {
    "file_path": "./devposts/distributed-cryptography.html",
    "project_id": "distributed-cryptography",
    "title": "Distributed Cryptography",
    "tagline": "Encrypting the future together, a bit at a time.",
    "hackathon": "",
    "built_with": [
      "css",
      "dcp",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of the DCP API Winner Top Overall 12 Teams Created by Jerry Zhu CS @UWaterloo | Retired | Fanat",
      "Best Use of the DCP API Winner Top Overall 12 Teams Created by Jerry Zhu CS @UWaterloo | Retired |",
      "SET.Hacks() 2021WinnerBest Use of the DCP APIWinnerTop Overall 12 Teams",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/627/644/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Distributed Cryptography Front Page Distributed Cryptography Persona Distributed Cryptography Front Page Distributed Cryptography Persona Distributed Cryptography Front Page 1 2 3 4 Inspiration Persona Bob is running a small business in 2040. He has many customers, all of which create accounts on his website. This means each of his user’s accounts has a lot of personal info on it. However, many malicious hackers want to steal his customers' data! How can he make sure his customers’ info is secure? Problem Bob tried many methods to solve his issue. He first tried to send a plaintext message, which was easily stolen. He also tried using a symmetric key encryption system to no avail, since the secret key was insecure, and could be simply brute forced! Solution Introducing my project, Distributed Cryptography! What it does Distributed cryptography uses the asymmetric secure RSA encryption system to regulate messages between Bob and his customers (e.g. a user named Alice), in order to pass information across users securely and effectively. It also uses the Distribute Compute Protocol API to speed up many embarrassingly parallel aspects of the RSA algorithm, and to run slices on a supercomputer, which is extremely useful especially for large inputs. \nIt leverages complex and efficient methods including Pollard Rho's algorithm and the Miller Rabin primality test to improve the time complexity and effectiveness of the RSA algorithm. \nBy encrypting messages using a secure ciphertext, it is very difficult for a hacker (e.g. Eve) to crack the text. This is due to the very fast time complexity encryption and decryption (modular exponentiation) compared to cracking a RSA code (factorization). Even if Eve used the DCP API and the fastest known factorization algorithm ( the general number field sieve ), it would still take infeasibly long for her to crack the ciphertext for even a relatively small key. \nThis is considering if she can even implement such an algorithm. Even the auth"
      }
    ]
  },
  {
    "file_path": "./devposts/dot-deck.html",
    "project_id": "dot-deck",
    "title": "Dot Deck",
    "tagline": "Visualization deriving crucial trading insights",
    "hackathon": "",
    "built_with": [
      "css",
      "dash",
      "html",
      "pandas",
      "plotly",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "National Bank of Canada - 4 x 500$ + office visit & interview Winner DRW - 4 x ​32 GB Oculus GO to",
      "ConUHacks VIIWinnerNational Bank of Canada - 4 x 500$ + office visit & interviewWinnerDRW - 4 x ​32 GB Oculus GO to each member",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/353/883/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 Inspiration Curious about the inner workings of equity markets and their intersection with technology, our team decided to build a hack targeting traders and financial exchanges. Exchange data is often volatile and unpredictable, making it hard to derive meaningful insight without the proper processing. What it does With Dot Deck, our team provides partners with a one-in-all dashboard, equipping the user with the ability to visualize critical underlying trends along with anomaly detection, while empowering the user with the ability to customize which data to show and how it is displayed. How we built it To build, scale, and deploy our dashboard, we used Plotly Dash and Python Graphs and data were generated using Pandas from JSON source data HTML/CSS was used to enhance the user experience by making the interface more user-friendly Challenges we ran into Understanding the data/parameters well enough to extract impactful insights for the partners Learning how to use the Plotly Dash API Performing statistical analysis to identify outliers and anomalies Unifying the dashboard to contain each of the relevant graphs in a logical manner Writing efficient data processing algorithms to minimize run and display time Accomplishments that we're proud of We all learned something new in the span of 24 hours We pushed ourselves to learn new technologies We dealt with real data, something that we don't interact with every day We performed anomaly detection using statistical analyses including standard deviation calculations and Tukey's fences We are really proud of what we created and learned together, we think that it came together quite well Built With css dash html pandas plotly python Try it out GitHub Repo www.canva.com Submitted to ConUHacks VII Winner National Bank of Canada - 4 x 500$ + office visit & interview Winner DRW - 4 x ​32 GB Oculus GO to each member Created by Jack Wang Rui Du Sacha Arseneault SWE @ uOttawa Joellyne Evaristo"
      }
    ]
  },
  {
    "file_path": "./devposts/data-tree-modeler.html",
    "project_id": "data-tree-modeler",
    "title": "Data Tree Modeler",
    "tagline": "A program to visualize large scale collaborative data",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/455/925/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Bonsai Data Tree 1 GIF Bonsai Data Tree 1 GIF 1 2 3 4 5 6 7 8 9 10 11 12 13 Our modeler takes coding data structures and visualizes it as a tree. By doing so we are eliminating the complexity and relating it to something we see everyday. The tree structure is something that we inherently understand because we have evolved to understand objects and structures in nature. Our modeler also interacts with the tree in a very meaningful way. Like the roots of a tree, some of which are filament like and some very thick and strong, the data structures are the same way. We have rendered that effect by changing the opacity of the trace code depending on the use. Similarly as a plant/leaves grows old, it slowly turns from green (young, new) to brown (old, dead), the user is able to see that in the tree modeler. Zooming in and out gives the depth of information that the person is looking obtain. Built With c# unity Try it out GitHub Repo Submitted to Reality, Virtually, Hackathon Created by I contributed to the ideation of the idea, and the scripting for the information into roots and branches. Adam Sauer I helped with the ideation process. I also worked on interaction in the 3d environment. Sarthak Giri I created the visual effects for our application including the 3D environment. I also contributed to the ideation of the application and it's functionality. Ethan Anderson Aravind Elangovan Tim Besard"
      }
    ]
  },
  {
    "file_path": "./devposts/dockerc.html",
    "project_id": "dockerc",
    "title": "dockerc",
    "tagline": "Software distribution solved.",
    "hackathon": "",
    "built_with": [
      "zig"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Technically Complex Hack (4x Mac Mini) Winner Bun: Best Use of Zig (4x iPad Pro + Interview wi",
      "TreeHacks 2024WinnerMost Technically Complex Hack (4x Mac Mini)WinnerBun: Best Use of Zig (4x iPad Pro + Interview with Bun Founder)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Distributing software is difficult. A lot of projects end up getting their users to run docker run to make things simpler. However relying on docker makes things complicated. Users need to have docker installed, users need to have the correct docker version. Installing docker is often a pain, you need to setup permissions correctly (docker needs to run as root). There are other ways of distributing software but they require a lot more investment. Writing Dockerfile s is just so easy! Dockerc solves this problem: Builders can continue writing Dockerfile s Users can just download a single executable and run it, no need to have 10 thousand setup steps What it does Dockerc takes existing docker images and a single executable file from them which can be distributed to your users. For 0 setup, you get the best possible form of software distribution: a single file to download. How we built it The compiler and runtime are written in zig. In order to have incredibly fast startup times no copying is done at runtime. The image is stored as a squashfs file and so the startup is near instant. (a squashfs file is a file that represents a file system and that can be mounted in the directory structure) Challenges we ran into Avoiding the copying of data was a difficult task. Most docker files are hundreds of megabytes large so we cannot afford to copy! The most difficult part was finding a way to mount the squashfs because it required identifying the offset of the squashfs file within a file that the squashfs-mounter could use. Things I tried: Using the /proc filesystem to identify how the executable was mapped into memory and to then deduce the location in the physical file based on that.  (/proc/self/maps) Using /proc/self/mem so that I can just directly use the pointer to the embedded file. Unfortunately, I didn't realize that processes couldn't access each other's memory until I implemented this... Overall the biggest challenge was using Zig. I had never used the la"
      }
    ]
  },
  {
    "file_path": "./devposts/duckduckgoose-site.html",
    "project_id": "duckduckgoose-site",
    "title": "DuckDuckGoose.site",
    "tagline": "A simple webapp to play duck duck goose and keep track of who wins. Created from One Shot Prompt on Bolt",
    "hackathon": "",
    "built_with": [
      "bolt",
      "netlify"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A simple webapp to play duck duck goose and keep track of who wins. Created from One Shot Prompt on Bolt"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/580/014/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 🦆 Duck Duck Goose Interactive - Digital Childhood Reimagined Live Demo: https://statuesque-manatee-6644b5.netlify.app Inspiration 🌟 Remember the joy of sitting in a circle during childhood, hearts racing as someone walked behind you chanting \"duck, duck, duck...\" and then suddenly \"GOOSE!\"? We wanted to bring that nostalgic magic into the digital world while making it accessible to everyone, anywhere, anytime. What it does 🎮 Duck Duck Goose Interactive is a beautifully crafted digital recreation of the classic playground game. Players sit in a virtual circle, and one player walks around tapping others as \"duck\" until they choose someone as the \"goose\" - triggering an exciting chase sequence! Key Features: 🎯 Interactive circular gameplay with smooth animations 🏆 Real-time scoring system tracking wins across multiple rounds 🎨 Beautiful, responsive design that works on all devices ⚡ Instant feedback with visual and animation cues 🔄 Multi-round tournaments for extended fun 🎭 Dynamic game states (setup, playing, chasing, finished) How we built it 🛠️ We leveraged modern web technologies to create a seamless, production-ready experience: React 18 with TypeScript for robust, type-safe component architecture Tailwind CSS for pixel-perfect, responsive styling Lucide React for crisp, scalable icons Vite for lightning-fast development and optimized builds Mathematical positioning for perfect circular player placement State management using React hooks for complex game logic CSS animations and transitions for delightful micro-interactions Design Philosophy 🎨 We prioritized creating an experience that feels both nostalgic and modern: Gradient backgrounds and soft shadows for depth Intuitive color coding (orange for \"it\", red for \"goose\", etc.) Smooth transitions that make every interaction feel responsive Clear visual hierarchy so players always know what's happening Accessible design with proper contrast and clear indicators Challenges we ran into 💪 Circular Positioning Ma"
      }
    ]
  },
  {
    "file_path": "./devposts/deez-7y01ae.html",
    "project_id": "deez-7y01ae",
    "title": "ICUthere",
    "tagline": "ICUthere uses empathetic voice AI to streamline hospital triage, cutting ER wait times, easing staff burnout, and improving care quality for patients.",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "shadcn",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/361/597/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 🏥 ICUthere ⚠️ Over 130 million people visit U.S. emergency rooms each year , yet many face critical delays due to manual triage and staff overload. ICUthere uses AI to streamline emergency care and prioritize patients faster. 🧠 Background ER teams juggle life-or-death decisions under intense pressure, often relying on outdated or manual triage processes. This leads to longer wait times, inconsistent prioritization, and staff burnout. ICUthere is an AI-assisted triage platform that analyzes patient inputs — like speech, facial expression, and symptoms — to recommend urgency levels and surface high-risk cases instantly. It empowers healthcare staff with faster decisions, improved care, and reduced legal exposure. 💡 What is ICUthere? ICUthere enhances ER triage through: 🧾 Video + Audio Patient Intake – Patients record symptoms via a friendly voice interface 📊 Triage Dashboard – View patients sorted by severity with AI-generated recommendations 🚨 Urgency Flags – Instantly highlights critical red-flag symptoms 👩‍⚕️ Staff Coordination Panel – Tracks who's on shift and current case assignments 🔁 Real-Time Queue – Dynamically updates as new cases come in ✨ Essential Features 🤖 AI Triage Engine – Combines voice tone, symptoms, and expressions to recommend care levels 🗣️ Empathetic Voice Assistant – Guides patients through check-in calmly and naturally 🔄 Live Patient Queue – Sorted by urgency and synced in real time 🧘 Burnout Reduction Tools – Automates repetitive intake questions for staff relief 🔌 EHR-Ready Integration – Built for compatibility with hospital systems 📚 Takeaways 🧠 What We Learned Designing AI for emergency care requires a deep balance between technical precision and emotional sensitivity. We explored how empathy-driven voice tech can ease patient anxiety while supporting medical staff under pressure. 🏆 Accomplishments Real-time triage powered by AI inputs Emotion-aware voice assistant built with Hume Seamless, intuitive dashboard for ER decision-ma"
      }
    ]
  },
  {
    "file_path": "./devposts/don-t-panic-rnoefi.html",
    "project_id": "don-t-panic-rnoefi",
    "title": "Don't Panic!",
    "tagline": "Our project will aid those affected by natural disasters and other emergency scenarios. It's an app that sends your location and a voice message to emergency contacts that have been selected before.",
    "hackathon": "",
    "built_with": [
      "gtts",
      "json",
      "pyqt5",
      "python",
      "requests"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Live location tracking, Map out an emergency via user input and modelling heat mapping of affected areas"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration c Over the course of the brainstorming session, we ended up deciding to work on a project that would aid those primarily affected by natural disasters with the possibility of endless applications in other emergency scenarios. The project revolves around improving connectivity between communities affected by these adverse conditions. What it does It's an app that sends your location and a voice message to emergency contacts that have been selected before. How I built it Main Features:-\nImplemented a graphical user interface to enhance the user experience\nUtilized the necessary HTTP python modules and Google Maps API framework to effectively retrieve GPS location of the concerned individual\nEstablished an automatic text message and email delivery system through existing SMTP and Twilio infrastructure\nEnacted text-to-speech conversion to yield an audio message attachment to be sent via email using the gTTS module Challenges I ran into The complexity with regards to mapping and API.\nEnsuring cohesive overlapping between the GUI, SMTP/Twilio infrastructure and HTTP mapping framework Accomplishments that I'm proud of The ability to provide the user with accurate data quickly and efficiently. The thought of being able give-back to society and people in need really makes me happy to have worked on this project. What I learned Gained hands-on technical experience working with modules and APIs that I wasn't familiar with What's next for Don't Panic! Live location tracking, Map out an emergency via user input and modelling heat mapping of affected areas Built With gtts json pyqt5 python requests Submitted to HackTX 2019 Created by Aryan Shetty Akash Gajendra Prajwal Iyer"
      }
    ]
  },
  {
    "file_path": "./devposts/donotfail.html",
    "project_id": "donotfail",
    "title": "DoNotFail",
    "tagline": "ever been unfairly marked? don't want to argue with a TA for hours? our agent can do it for you",
    "hackathon": "",
    "built_with": [
      "anthropic",
      "claude",
      "gpt4v",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best agent that makes use of Anthropics Claude 100k context Created by I re-hijacked GPT4V on Windo",
      "AI Agents HackathonWinnerBest agent that makes use of Anthropics Claude 100k context",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/641/403/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "My favorite email it sent Email chain showing the replies My favorite email it sent Email chain showing the replies My favorite email it sent 1 2 3 Inspiration We've all been there - feeling as though we've been unjustly marked down on a project or exam, wishing we could contest the grade but not knowing how to articulate our arguments. This feeling was particularly common during late-night study sessions when discussing with peers. This shared sentiment amongst students became the catalyst for creating \"DoNotFail,\" an AI agent that champions for academic fairness. What it does \"DoNotFail\" is an intelligent AI agent designed to review and analyze the feedback given on academic assignments. When a student feels they've been unfairly marked, they can turn to \"DoNotFail\" which will dissect the provided feedback, cross-reference with the student's answer or project, and then provide a structured argument detailing areas of potential oversight or misunderstanding by the TA. This ensures students have a well-informed perspective when approaching TAs or professors to discuss grades. How we built it Built on the Claude 2 chat model, we fine-tuned the model with a plethora of academic grading guidelines across various disciplines. Integrating with the popular file format called \"PDF\" it can read assignments, feedback and rubrics. We spoof being a user on ChatGPT to upload images of feedback from sites like CrowdMark which don't export PDFs properly and automatically extract the comments. All of this context is given to Claude 2, utilizing the 100k context length. The agent is tricked into thinking its acting in a play, pretending to be a student that was unfairly graded (to get around Claude's ethical concerns on arguing for marks) and then generates a plan. It will then infinitely email the TA following its plan. Challenges we ran into Using GPT4-V without API access. Ethan getting on to a bus half way through hackathon. Window's and Mac collaboration. Claude having strict "
      }
    ]
  },
  {
    "file_path": "./devposts/dynamic-pp-positional-pointer.html",
    "project_id": "dynamic-pp-positional-pointer",
    "title": "Dynamic PP (Positional Pointer)",
    "tagline": "The future of productivity is here. We're redefining human-computer interaction. Co-Released with F.A.R.T. (Fitness Analytics & Real-time Tracking), we bring you the mouse that moves with YOU.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "python",
      "react-native",
      "typescript",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "$tupidest Created by Julian BK Alexander Gu hackathons are fun",
      "Toronto Stupid Ideas HackathonWinner$tupidest",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/783/205/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "super fast mouse programming with protection super fast mouse programming with protection super fast mouse 1 2 3 4 5 PLEASE READ ME Inspiration We were inspired by a simple observation: humans have been letting mice control our computers for decades. Why are we taking orders from an inferior species? This inspired us to create a way for humans to directly control their cursors without relying on rodent-inspired technology. We worked incredibly hard at developing Dynamic Positional Pointer (PP), inspired by our belief that the most advanced species on Earth deserves a more advanced pointing system than plastic mouse replicas. What it does Dynamic PP replaces a traditional mouse with human movements, ensuring precision and accuracy. With our sleek design, our product can be used in small spaces or large fields, thanks to our sensitivity feature. Want to click a button in the top-right corner? Simply walk northeast until you reach the perfect pixel! Our innovative up-down coordinate system handles all clicking: lift your phone high above your head for a right-click, or crouch down low for a standard left-click (a minimum speed is required). Our F.A.R.T. (Fitness Analytics & Real-time Tracking) technology transforms every computing task into a cardio workout. As a bonus, Dynamic PP naturally promotes team collaboration. Imagine the synergy when your entire office is jumping and crouching together to complete a group project. How we built it We used the various sensors in our iPhone, such as the gyroscope and elevation data, to measure movement. We then integrated these into the React Native application that we built entirely ourselves. After that, we connected the app to our laptop through WebSockets to enable real-time communication between the mobile application and the MacBook. Challenges we ran into We built our project while using trackpads and mice (ew). This was an incredibly difficult challenge as they are just so impractical and limiting. How could we possibly "
      }
    ]
  },
  {
    "file_path": "./devposts/deia.html",
    "project_id": "deia",
    "title": "Deia",
    "tagline": "Encourage developers to build a diverse, equitable, inclusive and accessible internet.",
    "hackathon": "",
    "built_with": [
      "flask",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Inclusivity Hack Created by Chantal Pino Suven Pandey Renz Vital Asha Gadiraju",
      "Best Inclusivity Hack Created by Chantal Pino Suven Pandey Renz Vital Asha Gadiraju",
      "Support-a-thonWinnerBest Inclusivity Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/328/871/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 🎯 Inspiration 🎯 Deia is a platform for developers that aims to help them build an internet that is diverse, equitable, inclusive, and accessible. We were inspired to create Deia because we recognized that developers have the power to shape the internet and make it more accessible and inclusive for all users. We believe that by providing developers with the resources and support they need to create products that are accessible and inclusive, we can help them build a more diverse and equitable internet. Through Deia, we aim to empower developers to create digital products that are accessible and inclusive to people of all abilities and backgrounds, and to help create a more diverse and equitable tech industry overall. References: https://dev.to/flippedcoding/why-it-s-important-for-web-developers-to-focus-on-web-accessibility-37n3 ⚙ What it does ⚙ The app is designed to support developers in creating websites, applications, and other digital products that are inclusive and accessible to all users, regardless of their ability or background. One of the key features of Deia is its support for developers in creating inclusive user experiences. The platform provides guidance and resources on how to design and build products that are accessible to people with disabilities, such as those who are blind, deaf, or have mobility impairments. This includes support for designing websites and applications that are keyboard-navigable, have high contrast, and use clear and concise language. 🏗 How we built it 🏗 We looked for ways on to make websites more accessible. We learned how screen readers works and how to properly use semantic elements. 🛑 Challenges we ran into but didn't stop us 🛑 This is our first time using nextjs and auth0 which kind of took a lot of our time. Internet connection was a huge problem too. 🏁 Accomplishments that we're proud of 🏁 That, in some way, we are making an impact. \n\"You want to be the pebble in the pond that creates the ripple for change.\" Wha"
      }
    ]
  },
  {
    "file_path": "./devposts/diversifai.html",
    "project_id": "diversifai",
    "title": "DiversifAI",
    "tagline": "Eliminating Bias in hiring Medical Professionals 🩺✨",
    "hackathon": "",
    "built_with": [
      "docker",
      "e2e",
      "figma",
      "firebase",
      "google-cloud",
      "gpt4",
      "huggingface",
      "mongodb",
      "nextjs",
      "owasp",
      "prisma",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Targeted Track → Social Issues"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/659/800/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF 1 2 3 Targeted Track → Social Issues Note: We've preserved the main demo for the live judging and hence you're advised to watch till 0:55 of the YT video. Thanks! Inspiration 💡 One of the most significant challenges that all organizations face is the issue of unconscious bias in their hiring processes. Hiring managers may unconsciously allow their own beliefs and perceptions to influence their decisions in picking candidates. These biases, rooted in social conditioning and stereotypes, can act as a barrier to hiring qualified diverse candidates . Unintentional biases in applications can lead to a lack of diversity, which is especially problematic in fields like healthcare, where a diverse workforce can provide better patient care due to a deeper understanding and relatability to the patient's experience. To address this issue, we propose: the implementation of a blind recruitment strategy. It allows candidates to present themselves without the need to conceal their identities and enables companies to focus on the skills and qualifications that are directly relevant to the job. What it does 🤔 DiverisifAI is a mobile app that allows job seekers to apply for jobs anonymously while emphasizing more in their talent. Applicants upload their resume and our platform uses GPT-4 to tweaks signs of identity—race, age, gender, religion, etc—in their application. Applicants can then edit this new resume and use it to apply to different roles. This equalizes the playing field for applicants, and allows recruiters make fair and unbiased hiring decisions. Our second feature is an interview preparation feature for applicants. It includes an interview bot that is knowledgeable about the job description and provides feedback and practice questions to help applicants prepare for interviews. This is particularly useful for professions such as healthcare, where interviews often include complex scenario-based questions based on ethics and medical situations. UX Flow: Applicant"
      }
    ]
  },
  {
    "file_path": "./devposts/doro-study.html",
    "project_id": "doro-study",
    "title": "DORO.STUDY",
    "tagline": "Meet doro.study: the ultimate grade tracker for university students! Auto-import course weightings, track grades with sleek graphs, and stay on top of deliverables—all hassle-free. Study smarter!",
    "hackathon": "",
    "built_with": [
      "databases",
      "gemini",
      "nextjs",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/208/319/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 About Doro.study 🚀 At doro.study , we’re redefining how university students track their academic performance. No more clunky spreadsheets or timely overcomplicated apps like notion—just a sleek, modern, and stress-free solution. Why Doro.study? 🎯 We get it—school’s already tough enough and you want to see what you need to work on. That’s why we built a tool that simplifies your life. Using smart, Gemini web scraping, we auto-populated course weightings straight from online outlines. Just add your courses, input your grades when you get them, and let us handle the rest. What Makes Us Different? 🌟 Hassle-Free Setup : Skip the manual calculations and formatting nightmares. Stunning Visuals : Get deep insights into your progress with detailed, intuitive graphs. See where you’re crushing it and where you can level up. Stay Organized : Get a clear list of deliverables directly pulled from course outlines, so you’re always on top of your game. Built for Students, by Students 🎓 We know what you need because we’ve been there. Doro.study was designed to be as straightforward as it is powerful, combining utility with a modern, minimal design that feels right at home. Ready to Doro? 🔥 Take control of your academic journey with a grade tracker built for today’s students. Smart, simple, and seriously good-looking—because you deserve better than Excel. Check us out at doro.study and see the difference! Built With databases gemini nextjs react Try it out doro.study GitHub Repo Submitted to DeltaHacks XI Created by Julian BK archie shou Allen Lian"
      }
    ]
  },
  {
    "file_path": "./devposts/docusight.html",
    "project_id": "docusight",
    "title": "DocuSight",
    "tagline": "Upload and analyze your documents with ease through the power of AI.",
    "hackathon": "",
    "built_with": [
      "gpt",
      "nextjs",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/509/646/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Home Page Home Page Home Page 1 2 Inspiration:\nI was inspired to create DocuSight to address the time-consuming and tedious process of manually analyzing documents. I recognized the potential of AI to automate this task and provide users with valuable insights from their documents. My goal was to develop a user-friendly tool that would empower individuals and businesses to extract information quickly and efficiently. What it does:\nDocuSight is a cutting-edge document analysis tool that leverages AI to simplify the process of document analysis. Users can easily upload their documents through the intuitive interface. Once uploaded, DocuSight employs advanced machine learning models to extract relevant information. The extracted data is then presented to users in a structured format, enabling them to quickly analyze and make informed decisions based on the content of their documents. How we built it:\nI built DocuSight using a combination of technologies. The frontend of the application was developed using Next.js and React, which provided a responsive and interactive user interface. Users can easily navigate through the application, upload their documents, and view the analysis results. For the backend, I utilized Node.js, which handles the document processing tasks and interacts with the GPT API and includes chatting and making document embeddings. I also integrated Clerk, a robust user authentication and management service, to ensure secure access to the application. Challenges we ran into:\nDuring the development process, I faced several challenges. One major challenge was configuring the Clerk authentication. Additionally, handling large file uploads and optimizing the performance of the application to handle high volumes of document analysis proved to be another challenge. Accomplishments that we're proud of:\nI am proud of the accomplishments I achieved with DocuSight. I successfully created a user-friendly interface that simplifies the process of document uploadin"
      }
    ]
  },
  {
    "file_path": "./devposts/disco-de-match.html",
    "project_id": "disco-de-match",
    "title": "Disco Match",
    "tagline": "Find YOUR perfect hackathon team powered by AI! Live at https://girlhacks.vercel.app",
    "hackathon": "",
    "built_with": [
      "auth0",
      "mongodb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "disco vibes - our theme is groovier than a mirrorball! 🌈 Best diversity - because our dancefloor we",
      "use of MongoDB - storing data smoother than Barry White's voice! 🌐 Best Domain name from GoDaddy -",
      "in the hackathon! Time to pop the (virtual) champagne! 🕺 Best disco vibes - our theme is groovier t",
      "GirlHacks 2024WinnerThird Place",
      "🍾 First Place in the hackathon! Time to pop the (virtual) champagne!",
      "🕺 Best disco vibes - our theme is groovier than a mirrorball!",
      "🌈 Best diversity - because our dancefloor welcomes everyone!",
      "🏅 Best use of MongoDB - storing data smoother than Barry White's voice!",
      "🌐 Best Domain name from GoDaddy - we're spinning on the world wide web!",
      "🔐 Best use of Auth0 - keeping our disco secure and exclusive!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/050/449/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 💖✨ DiscoMatch: Where Hackers Shine Bright! 🕺💃 🌟 What it does AlgoRhythm is your groovy companion for hackathons! 🎉 It's like Tinder, but for finding your perfect hackathon dream team! 👯‍♀️👯‍♂️ Swipe right to connect with amazing hackers, and let the coding magic begin! ✨💻 🛠️ How we built it We put on our disco shoes and danced our way through the development process! 🕺💃 🎨 Frontend: NextJS, Tailwind, and Shadcn for that sleek, disco-ball shine! 🧠 Backend: Python Flask, grooving on AWS Lambda! 🗄️ Database: MongoDB for storing all those funky fresh profiles! 🔐 Auth: Auth0 keeping our dancers safe and sound! 🚀 Deployment: Vercel, because our app deserves a stage as big as Studio 54! 🤖 AI Magic: Gemini AI, adding some extraterrestrial flair to our matching! 🕳️ Challenges we boogied through 💃 Perfecting our matching algorithm was like learning the Hustle – tricky but so worth it! 🌈 Integrating all our tech was like choreographing the perfect dance routine – took practice! 🎶 Balancing fun and functionality was like mixing the perfect disco track – we think we nailed it! 🏆 Accomplishments that make us do the happy dance 🍾 First Place in the hackathon! Time to pop the (virtual) champagne! 🕺 Best disco vibes - our theme is groovier than a mirrorball! 🌈 Best diversity - because our dancefloor welcomes everyone! 🏅 Best use of MongoDB - storing data smoother than Barry White's voice! 🌐 Best Domain name from GoDaddy - we're spinning on the world wide web! 🔐 Best use of Auth0 - keeping our disco secure and exclusive! 🧠 What we learned 🤝 Teamwork makes the dream work (and the disco ball spin)! 🚀 How to scale our app faster than John Travolta's dance moves! 🎨 UX design is key – our app needs to look as good as platform shoes! 🔮 What's next for Disco(de)Match 💌 A groovy messaging system for our matched teams! 🌍 Expanding to more hackathons worldwide – let's turn this disco global! 🎓 Special features for beginners – everyone deserves a chance to shine! 🤖 Enhanced AI recommenda"
      }
    ]
  },
  {
    "file_path": "./devposts/disasterwatch-84f9jd.html",
    "project_id": "disasterwatch-84f9jd",
    "title": "DisasterWatch",
    "tagline": "DisasterWatch delivers real-time, local disaster alerts—by locals, for locals. From wildfires to blocked trails, stay informed by the people who care most: your neighbors.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "gmaps",
      "openai",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "By Jason Ly, My Nguyen, Henry Trinh, William Koh Inspiration In a time where natural disasters are occurring more often and becoming more prevalent and severe because of climate change, accurate real-time local updates are still scarce. So as a solution to that problem, we came up with DisasterWatch. Inspired by something more local, the California wildfire incident showcased the need for accurate real-time updates for locals in the area. Alerts are made for locals, by locals, ensuring fast and accurate information. Alerts can be something as simple as a hiking trail blocked off by a fallen tree, or something as big as a wildfire blocking off access to entire sections of a neighborhood. We wish this weren’t the case, but as climate change becomes more prevalent and as it affects more of our lives, DisasterWatch is a solution to fast and accurate information. The best part is that alerts will be made most likely by your neighbors, so by people who care. What it does The map that shows natural disaster incidents in a two-mile (or more, you can set this) radius from your location. You can also search by location.\nUsers have the ability to upload photos of a natural disaster and put a pin/location on the map. \nOther users will be alerted if they are close enough to the reported incident. \nTo filter out false reports, we wanted to use OpenAI’s image analyzing abilities along with a wildfire API that can detect wildfires in an image. To help reduce misinformation and spam, we integrated OpenAI's model into DisasterWatch. Whenever a user uploads an image and submits a description, our backend sends both to GPT-4. The model is prompted to verify whether the image matches the description and actually depicts a disaster. If the model detects a mismatch — for example, if someone tries to submit a meme or a non-disaster-related photo — the post is automatically blocked before it reaches the database. This ensures that only real, relevant reports are posted. How we built it Arch"
      }
    ]
  },
  {
    "file_path": "./devposts/diy-art-gallery.html",
    "project_id": "diy-art-gallery",
    "title": "SafeSpot",
    "tagline": "SafeSpot uses AR with hopes to save lives during natural disasters. Point your phone, see real-time safety guidance - 'GET UNDER' tables, 'STAY AWAY' from windows. Works offline when you need it most.",
    "hackathon": "",
    "built_with": [
      "ar/vr",
      "computer-vision",
      "graphics",
      "realitykit",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/489/040/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Learning Panel Selection Home Page Earthquake Fire Learning Panel Selection Home Page Earthquake Fire Learning Panel 1 2 3 4 5 6 7 8 💡 Inspiration 💡 We believe that every second counts in an emergency and that technology can bridge the gap between panic and survival. When disasters strike - earthquakes, fires, floods, tornados - people often make dangerous decisions due to lack of preparedness knowledge or visual impairments. We were inspired by the lack of AR applications addressing real emergency situations and wanted to create something that could genuinely save lives by providing instant, location-specific safety guidance when it matters most. References: https://www.ready.gov/earthquakes , https://www.redcross.org/get-help/how-to-prepare-for-emergencies ⚙️ What it does ⚙️ SafeSpot is an AR-powered emergency guidance app that transforms your phone or iPad into a life-saving safety assistant. Users select their emergency type (earthquake, fire, flood, or tornado) and point their device around their surroundings. The app instantly overlays color-coded safety instructions directly onto real-world objects in real-time. During an earthquake, SafeSpot might highlight a sturdy table with green bounding boxes and \"GET UNDER\" text, or warn about a bookshelf with red boxes and \"STAY AWAY.\" The app works entirely offline, ensuring it remains functional when networks fail during disasters - critical for disaster-prone regions where internet connectivity is unreliable. Each detection is powered by AI that understands hazard-specific safety protocols, providing personalized guidance based on your exact environment rather than generic safety tips. 🏗️ How we built it 🏗️ For the AR interface, we used RoomPlan API and RealityKit. For the backend safety logic, we implemented custom hazard detection algorithms and offline AI models. 🟣 RoomPlan API 🟣 We leveraged Apple's RoomPlan API to achieve real-time object detection without requiring pre-scanning. This allows users to immediate"
      }
    ]
  },
  {
    "file_path": "./devposts/dj-bestie.html",
    "project_id": "dj-bestie",
    "title": "DJ Bestie",
    "tagline": "Want a friend to vibe and listen to music with? DJ Bestie's got you! He will chat and keep you company while mixing up the best tunes!",
    "hackathon": "",
    "built_with": [
      "deepface",
      "keras",
      "mongodb",
      "next.js",
      "openai",
      "python",
      "pytorch",
      "react",
      "spotify",
      "tensorflow",
      "typescript",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Software Hack Created by Built the front end with React and Next",
      "TAMUhack 2025WinnerThird Overall Software Hack",
      "What's next for DJ Bestie",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/238/316/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Computer Vision Model in Action Personalized AI DJ Page Computer Vision Model in Action Personalized AI DJ Page Computer Vision Model in Action 1 2 3 Inspiration We all crave a music buddy who not only shares our tastes but also vibes with our moods and conversations. Imagine having a DJ and a friend in one! DJ Bestie was inspired by the desire to bridge music discovery with real-time interaction, creating a personalized and fun experience for people who want to listen to tunes while feeling connected. With hands-free interactions and an animated character that moves and talks like a friend in the same room, DJ Bestie brings a uniquely personal touch to music discovery. What it does DJ Bestie is an AI-powered virtual DJ and companion. It chats with you, analyzes your facial expressions and body language, and curates playlists tailored to your mood and energy level. The hands-free design lets you talk to it naturally, just like you would with a close friend. DJ Bestie responds with real-time conversation, plays music, introduces similar songs and artists, and even reacts with a lively animated character that moves and talks with you. Whether you're chilling, working out, or partying, DJ Bestie is your go-to vibe curator. How we built it Front end: React Next.js\nBackend: Javascript, python, Typescripts, MongoDB, WebSockets Challenges we ran into Cross-Platform Integration Recommendation System Optimization Data Privacy Concerns Real-Time Emotion Analysis UI/UX Cohesion Emotion Overlap Detection Accomplishments that we're proud of Innovative Multi-Modal Integration AI-Driven Song Recommendation System Seamless and responsive UI Emotion-Sensitive Analysis Mood-Based Playlists Real-Time Performance and Efficiency What we learned Optimize Real-Time Processing Overcoming AI model Limitations Collaboration Under Pressure User-Centric Design Principles Training Multi-Model Debugging Complex Systems Edge Case Management What's next for DJ Bestie Integration with Popular Music"
      }
    ]
  },
  {
    "file_path": "./devposts/echo-9pinuq.html",
    "project_id": "echo-9pinuq",
    "title": "Echo",
    "tagline": "Take a stroll down memory lane with Echo, your digital Rolodex of nostalgia. Echo transforms your memories into a 3D network.",
    "hackathon": "",
    "built_with": [
      "amazon-dynamodb",
      "amazon-web-services",
      "auth0",
      "cairo",
      "chakra-ui",
      "express.js",
      "figma",
      "ipfs",
      "react",
      "rekognition",
      "s3",
      "spline",
      "starknet",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/736/576/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Shared Echos Home Echos Selected Echo Shared Echos Home Echos Selected Echo Shared Echos 1 2 3 4 5 💡 Inspiration Echo was inspired by the traditional methods of storing contacts and memories: the rolodex and the photo album. The UI draws on some of these nostalgic details, like the polaroid-like image cards and the rotating contact card wheel. 🕸️ What it does Take a stroll down memory lane with Echo, your digital Rolodex of nostalgia. Echo transforms your memories into a connected network, sorting \"echoes\" by the people in them. Share your cherished moments and watch your personal Rolodex of memories unfold in harmony with others. 🧰 How we built it Front-end: The front-end was built with React.js and Chakra UI . The interactive 3D network of connections was developed and visualized with Three.js . The IPFS protocol was used to handle image uploads. Auth0 handled user authentication and management. Back-end: An Express.js server was used to stage API endpoints. Echo and user entities were created and stored in AWS DynamoDB tables, echo and user images were stored in AWS S3 buckets as buffers and encoded/decoded with base64, and AWS Rekognition was used for facial comparison, indexing, and searching. IPFS , Cairo , and Starknet were used to generate, store, and share NFTs of echoes. UX: Prototypes were designed and prototyped on Figma to create UI elements including buttons and pop-up overlays. Spline was used to prototype the 3D network, and then exported to Figma. 🧱 Challenges we ran into IMAGE FORMATS, TRANSFER, AND STORAGE DynamoDB is different from other NoSQL databases we've used in the past AWS Documentation is difficult to navigate and deeply nested AWS Rekognition has many limiting factors despite its powerful features Despite being very powerful, Three.js has a steep learning curve 🏆 Accomplishments that we're proud of Connecting a complex web of AWS services Publishing many composite API endpoints to enable full functionality of the app Designing and execut"
      }
    ]
  },
  {
    "file_path": "./devposts/dupedetector.html",
    "project_id": "dupedetector",
    "title": "DupeDetector",
    "tagline": "What are you reading?",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html",
      "javascript",
      "jupyternotebook",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "All Participants Winner Social Media Tract 10piHacks Winner 4th/5th Place Prize - Wolfram Alpha Sub",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/555/596/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The popular documentary, The Social Dilemma , was a major inspiration for this project. With the rising use of The Internet, misinformation is extremely easy to spread. The documentary outlined the mental health impacts of social media and its rise in fake news. According to a MIT study, fake news spread 6x faster than real news on Twitter. Additionally, according to the CIGI, 86% of the world’s population has fallen victim to fake news. With an abundance of social media posts intending to ‘spread awareness’, we must fact-check it. That is where DupeDetector comes along. We created a website and connected our ML model. We used fake news datasets from kaggle to create our model. What it does DupeDetector is a website that detects if the user is consuming fake news or not. It allows the user to input text from the article they are reading, or an image of an article, tweet, or instagram post. The website will then extract the text from the image, or take the text and determine its reliability. There is also an option to view your input to see if our code has extracted your inputted text correctly. How we built it We built the ML model using Python, our frontend using HTML, JS and CSS, and our backend with Python and Flask. Challenges we ran into We wanted to try something we haven't done before, and decided to create a project that utilized machine learning. We spent the first day just generally watching introduction to machine learning videos and the next day discussed what kind of project we could create. We also struggled with connecting our ML model to our flask and creating our ML model because it was our first time working with machine learning and Jupyter Notebook. We jumped a lot of hurdles when trying to debug our code because of the new functions we learned in our ML model. Accomplishments that we're proud of We are proud of creating a Jupyter Notebook Machine Learning project (with a 95% accuracy score!) for the first time and being able to conne"
      }
    ]
  },
  {
    "file_path": "./devposts/down-upside.html",
    "project_id": "down-upside",
    "title": "Down Upside",
    "tagline": "Platformer where gravity flips",
    "hackathon": "",
    "built_with": [
      "gdscript",
      "godot"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Themed Hack Winner Wolfram Alpha Created by It was my first time using Godot, and I wasn’t as knowl",
      "Best Themed Hack Winner Wolfram Alpha Created by It was my first time using Godot, and I wasn’t as",
      "LancerHacks VIWinnerBest Themed HackWinnerWolfram Alpha",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/378/831/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 Inspiration: We took inspiration from a variety of sources, from the aforementioned traditional platformers like Mario to newer games like Undertale. What it does: It’s a 2d platformer much like traditional arcade side-scrollers, with a unique twist. You are a mighty hero, tasked with saving the world from the big bad - but you’re guaranteed to fail. The hero will fall down a pit on the third level, victim to their own hubris.\nThe hero is transported to the Underworld, a state of limbo filled with strange sights and fallen enemies. As the formerly friendly text box goes from helpful advice to sarcastic lamentations, the player must make their way back to life. How we built it: We built this project with Godot, a game engine using GDscript. Challenges we ran into: Time management, synchronization, technical issues, and inexperience were our primary issues. We needed to coordinate out efforts a bit better, as we did not finish everything in time. Some people didn’t have computers or didn’t know well how to code, which was an obstacle in the beginning. Accomplishments that we're proud of: Learning an entirely new game engine and coding language that we barely knew the basics of. What we learned: We learned to not try and learn an entire language in less than 12 hours. WE also learned how to use a new game engine and its associated coding language. What's next for Down Upside: WE hope to make more levels or the main one longer depending on how we want to progress the game. WE also hope to make the textures nicer and make the controls feel better. Built With gdscript godot Try it out GitHub Repo Submitted to LancerHacks VI Winner Best Themed Hack Winner Wolfram Alpha Created by It was my first time using Godot, and I wasn’t as knowledgeable as the rest of the group. I did, however, make a text box system and come up with the idea for the project. Caleb Obico Krish Kalra Ashish Ramanan \"Python\" \"Java\" \"GDscrip"
      }
    ]
  },
  {
    "file_path": "./devposts/drive-sense.html",
    "project_id": "drive-sense",
    "title": "Drive Sense",
    "tagline": "Through CV models and LLMs, we are increasing road safety, and assessing a driver's safety rating, by correlating behavior with the road conditions.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "django",
      "opencv",
      "pytorch",
      "react",
      "replit",
      "streamlit",
      "yolo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2023 Finalist Created by i made it work Krish Modi Xin Lei Lin Vaishvi Shah Aly Shar",
      "Hack the North 2023WinnerHack the North 2023 Finalist",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/591/981/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "DriveSense DriveSense DriveSense 1 2 Inspiration: Our inspiration for this app comes from the critical need to improve road safety and assess driver competence, especially under various road conditions. The alarming statistics on road accidents and fatalities, including those caused by distracted driving and poor road conditions, highlight the urgency of addressing this issue. We were inspired to create a solution that leverages technology to enhance driver competence and reduce accidents. What it does Our app has a frontend, which connects to a GPS signal, which tracks the acceleration of a given car, as well as its speed. Such a React frontend also encompasses a Map, as well as a record feature, which, through the implementation of a LLM by Cohere, is capable of detecting alerting police, in the event of any speech that may be violent, or hateful, given road conditions.\nOn the backend, we have numerous algorithms and computer vision, that were fine-tuned upon YOLOv5 and YOLOv8. These models take in an image through a camera feed, surrounding cars,  the color of the surrounding traffic lights, and the size of the car plates in front of the drivers.\nBy detecting car plates, we are able to infer the acceleration of a car (based on the change in size of the car plates), and are able to asses the driver's habits. By checking for red lights, correlated with the GPS data, we are able to determine a driver's reaction time, and can give a rating for a driver's capacities.\nFinally, an eye-tracking model is able to determine a driver's concentration, and focus on the road.\nAll this paired with its interactive mobile app makes our app the ultimate replacement for any classic dashcam, and protects the driver from the road's hazards. Built With cohere django opencv pytorch react replit streamlit yolo Try it out GitHub Repo Submitted to Hack the North 2023 Winner Hack the North 2023 Finalist Created by i made it work Krish Modi Xin Lei Lin Vaishvi Shah Aly Shariff"
      }
    ]
  },
  {
    "file_path": "./devposts/drivepal.html",
    "project_id": "drivepal",
    "title": "DrivePal",
    "tagline": "DrivePal is an AI-powered driving assistant that uses locational data and image recognition to help new drivers prepare for their G2 test, delivering personalized training based on testing criteria.",
    "hackathon": "",
    "built_with": [
      "clarifai",
      "django",
      "hypertrack",
      "keras",
      "python",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hypertrack",
      "I worked on the Hypertrack integration, mainly detecting the vehicle's speeding status and geofence its surroundings."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/226/877/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Object Detection Demo App Demo Interface App Demo Interface Associated Hypertrack Framework Object Detection Demo App Demo Interface App Demo Interface Associated Hypertrack Framework Object Detection Demo 1 2 3 4 5 Inspiration 3 of our team members cannot operate an automobile. Driving is a crucial part of our daily lives. Bad driving habits, not following road rules or speeding are often the cause of car accidents that occur. Meanwhile, the G2 and G road tests ensure that the road is shared among drivers proven competent to drive to improve the overall safety of individuals. As a measure of driving safety, driving tests becomes more and more important; however, more than 40% of the increasingly growing drive test-taking population (~33,000/month) fail the G2 drive test, which indicates two major problems: 1) the lack of driving skills and 2) the inability to target what's on the test to pass the requirements. Therefore, our focus of this hackathon is to make driver's training more accessible, easy, and intuitive. What it does We delivers a smart driving assistant system that picks up traits often ignored by humans to improve driving quality and strictly judges the trainee's driving based on the testing criteria. The system has two integral parts: the image recognition feed based on a front-facing camera used to recognize road signs and a macro-monitor system that uses HyperTrack to track the car’s movements and parameters. The image recognition system ensures that the trainee obey all street rules and signs; in the case that they don’t – for example, if they don’t wait enough time at a stop sign or run a yellow light, the system will tally these feedback to the trainee and after a session of practicing. The macro-monitor system, on the other hand, uses HyperTrack’s system to track the position, pace, and parameters of the car, such as speed and acceleration, to detect bad driving habits like speeding or jerky driving. The system also gives audio cues to the traine"
      }
    ]
  },
  {
    "file_path": "./devposts/dessert.html",
    "project_id": "dessert",
    "title": "DeSsert",
    "tagline": "Find the perfect recipe while owning the rights to your content on the world's first decentralized recipe sharing site!",
    "hackathon": "",
    "built_with": [
      "css3",
      "deso",
      "figma",
      "html5",
      "next.js",
      "react.js",
      "tailwind-css"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of DeSo PrideHacks II Created by Stephen Ni Aritro Saha comp",
      "Best Use of DeSo PrideHacks II Created by Stephen Ni Aritro Saha comp",
      "FreyHacksWinnerBest Use of DeSo",
      "Find the perfect recipe while owning the rights to your content on the world's first decentralized recipe sharing site!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/017/261/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Details for the Recipe Landing Page About Us Page Login Page Browse Recent Recipes Compose a Recipe List of Composed Recipes Details for the Recipe Landing Page About Us Page Login Page Browse Recent Recipes Compose a Recipe List of Composed Recipes Details for the Recipe 1 2 3 4 5 6 7 8 Inspiration EVERYONE LOVES FOOD! We want to provide a platform for people to share their delicious pieces of heaven. However, there have been a multitude of cases a content creator has been unfairly kicked off their platform and robbed of their livelihoods. Creators are entrepreneurs, not products for a larger company. That is why we believe that creators should be able to own their content without the presence of a central authority. Hence, a decentralized recipe sharing site! What it does DeSsert is a decentralized recipe sharing site that allow users to browse through traditional to exotic recipes from cultures all over the world. Furthermore, users can friend other users who's recipe they love and compose their own recipes to share their trade secret to the rest of the world! All content is 100% owned by the user, and is stored permanently on the blockchain. How We built it The UI was designed through Figma. We then developed the front end with React and TailwindCSS. The pages were routed using Next.js's built-in router while the backend features such as creating and liking a post, and minting a recipe into a NFT was achieved through the DeSo protocol library. Challenges We ran into At first we had issues finding a way to coordinate our code. After setting on live share, we ran into a multitude of errors regarding React components. Furthermore, this was also the first time we dug deep into the DeSo protocol library, this was also the first time some of us used TailwindCSS so it took some time searching up every utility class. Finally, it was a great challenge implementing the many features we planned out in under 48 hours. Accomplishments that We're proud of We are proud of over"
      }
    ]
  },
  {
    "file_path": "./devposts/eataer-sfc02z.html",
    "project_id": "eataer-sfc02z",
    "title": "EatÆR",
    "tagline": "visualizing restaurant food with augmented reality capability with a click of a button.",
    "hackathon": "",
    "built_with": [
      "adalo",
      "databases",
      "echoar",
      "figma",
      "sketchfab"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/619/562/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Explore the food in AR with EatÆR Restaurant Analytics Explore the food in AR with EatÆR Restaurant Analytics 1 2 3 4 5 What it does Nowadays, people have become more health-conscious; they want to know what they are eating and how it will taste. EatÆR will help our customers to achieve this task, as well as reducing food and financial wastage. Our application has the capability to visualize the menu restaurant trends along with features to automatically update the restaurant menu database. Moreover, with our app, consumers now have the ability to set their own pick-up time for a particular dish from the restaurant. How we built it We built the application framework at adalo.com and imported 3D assets onto EchoAR. Challenges we ran into Connecting the live restaurant menu database with the EchoAR platform. Accomplishments that we're proud of Creating this startup application that can both improve customer experience and the restaurant transparency. What we learned Time management skills Handling of different relations among the databases Explored EchoAR capabilities App Building Designing How EatÆR can help Restaurants Improving visibility: Augmented reality restaurant menus can be customized to show information about each dish, such as 360-degree visualizations, details of ingredients used, portion sizes, calorie, and nutrition info, etc. Upsell: AR food menus can also help restaurants sell more items. Apps can be programmed to suggest ideal complements to selected dishes such as appetizers, beverages, dessert combos, etc. Improve customer engagement: Unlike traditional food menus, AR food apps can be customized to display a wealth of content on demand. What's next for EatÆR The limitation of the current version is that the restaurant owners may have to recruit a 3D artist or be proficient in Unity to have a 3D model of their dish, so we are considering creating an API between the application with a photogrammetry software. This would allow the restaurant owners to"
      }
    ]
  },
  {
    "file_path": "./devposts/dragonden.html",
    "project_id": "dragonden",
    "title": "Flock Stocks",
    "tagline": "Tinder but for Investing: Making inclusive, value-driven investing accessible to all!",
    "hackathon": "",
    "built_with": [
      "elevenlabs",
      "flask",
      "openai",
      "propelauth",
      "python",
      "react",
      "spline",
      "streamlit",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Winner Best Use of PropelAuth Created by Ana Lucia Franco Julia Ilioukhina Sophie Yang juli",
      "Best Overall Winner Best Use of PropelAuth Created by Ana Lucia Franco Julia Ilioukhina Sophie Yang",
      "TechNova 2024WinnerBest OverallWinnerBest Use of PropelAuth",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/054/138/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "💡Inspiration The inspiration for our project comes from recognizing how difficult it can be to make informed investment choices, especially for those from underrepresented communities. With so many options and differing financial philosophies, navigating the investment landscape can feel overwhelming. We wanted to create a platform that empowers users to understand these complexities and find a path that aligns with their values. By offering diverse perspectives on finance—sustainability, capitalism, and feminism—we aim to make financial literacy more accessible and engaging, ultimately helping people feel more confident in their investment decisions. 💻 What it does Inspired by the belief that financial opportunities should be accessible and inclusive for all, we’ve created a platform where advisors—each representing capitalism, female empowerment, and sustainability—engage in a real-time debate about the pros and cons of stocks. As you navigate through this interactive experience, you can match or reject stocks based on your own preferences, ultimately building a tailored profile that reflects your investment style. With a personalized dashboard tracking the performance of your matched stocks, you’re not just investing—you’re aligning your financial future with your values. Our vision is to empower users from all walks of life to take control of their financial journey, making inclusivity and sustainability cornerstones of modern investing. ⚙️ How we built it For the front end, we used React with Tailwind CSS for a responsive and customizable UI. To create the 3D bird models, we used Spline making the app more engaging. We use PropelAuth for user authentication. We also incorporated streamlit to create a stock dashboard that displays real-time data. \nWe used an Elegoo circuit for taking in user data via a toggle and buttons (toggle to select bird, buttons to accept/decline the stock). For the backend, we used Python with ElevenLabs for the text-to-speech multithrea"
      }
    ]
  },
  {
    "file_path": "./devposts/doodloor.html",
    "project_id": "doodloor",
    "title": "Doodloor",
    "tagline": "Turn your garbage drawings into something pleasing to look at",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "nextjs",
      "python",
      "supabase"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hackTAMS 2024WinnerDucky Keyboard",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/738/099/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Jawline Boi Landing Page lol Elon Musk with Long Hair \"Tim Cook with Long Hair\" Jawline Boi Landing Page lol Elon Musk with Long Hair \"Tim Cook with Long Hair\" Jawline Boi 1 2 3 4 5 Inspiration I was bad at drawing and wanted to get better without learning how to draw. What it does Turns your drawing and its according description into a cool/unstable image How I built it I built it using my blood, sweat, and tears as well as NextJS, Python, AWS, Supabase, HuggingFace. Challenges we ran into Deploying a model with concurrency, low-latency generations, and cheap with an Nvidia A10G Accomplishments that I am proud of Getting the website to work. What we learned I learned how to easily get Yeat instrumentals for my demo video. What's next for Doodloor Improve website. Built With amazon-web-services nextjs python supabase Try it out doodloor.arihanv.com GitHub Repo Submitted to hackTAMS 2024 Winner Ducky Keyboard Created by Arihan Varanasi Full-Stack ML Developer with a knack for design and creativity"
      }
    ]
  },
  {
    "file_path": "./devposts/dreamcatch.html",
    "project_id": "dreamcatch",
    "title": "DreamCatch",
    "tagline": "DreamCatch revolutionizes dream journaling with AI. Record dreams via voice or text, access anywhere, and use our tools for deep analysis.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "firebase",
      "hume",
      "nextjs",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/511/347/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Keywords Landing Page User Homepage Record and Add Dream Dream description Dream analysis Mood Keywords Landing Page User Homepage Record and Add Dream Dream description Dream analysis Mood Keywords 1 2 3 4 5 6 7 Inspiration For many, dreams remain a hidden mystery, an enigma that holds a lot of fascination, yet remains largely unexplored. We, at DreamCatcher , believe in the power and potential of dreams. Understanding that dreams can provide deeper insights into our subconscious minds and that interpreting them can help in personal growth and self-awareness, we felt the need to create an intuitive platform where users can record, analyze, and learn from their dreams. Goals Create an AI-based platform that allows users to record and analyze their dreams. Enable users to identify recurring themes and patterns in their dreams. Provide psychoanalytic insights into the dreams. Be open for future development and maintainable by the community. Enable users to share and discuss their dreams with a community of dream enthusiasts. Built With NextJS and TailwindCSS for front-end Advanced AI for transcribing voice recordings into text. Sentiment Analysis for mood identification. Keyword Extraction for identifying recurring themes and symbols. Psychoanalysis algorithms for deeper dream insights. Firebase for secure cloud-based storage. Challenges Ensuring seamless voice-to-text transcription. Accurately interpreting moods, themes, and symbols from dream descriptions. Building an intuitive and user-friendly interface. Ensuring secure and private data storage for users' dream records. Creating an engaging platform for dream discussion and feedback. Accomplishments We have developed DreamCatcher , an AI-driven platform that not only records and stores dreams but also provides deep, insightful analysis. It has an intuitive interface and leverages advanced technology to help users understand their subconscious mind better. The platform also offers community interaction, allowing us"
      }
    ]
  },
  {
    "file_path": "./devposts/ecarnomy.html",
    "project_id": "ecarnomy",
    "title": "Ecarnomy",
    "tagline": "The ecarnomical management pun just got real: view and track the cost of car ownership.",
    "hackathon": "",
    "built_with": [
      "api",
      "firebase",
      "flutter",
      "govdata",
      "rest"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The ecarnomical management pun just got real: view and track the cost of car ownership."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/815/342/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "add your car sign up see your garage add your car sign up see your garage add your car 1 2 3 4 Inspiration: While browsing the internet, I happen to stumble upon an article about how people in the United States overspend on their vehicles. Apparently many even borrow more on their cars than their college tuition. Knowing how much of a financial burden a vehicle may be, we were influenced to make an app that has the ability to manage this. What Ecarnomy does: Ecarnomy projects data regarding monthly operating costs of a vehicle. This helps users be aware of potential financial difficulties throughout their vehicle ownership. The app projects future maintenance, repair, fuel, and insurance costs. For auto investors/vehicle wholesalers, the depreciation rate is factored in to know if the car is economically viable enough to be stored/used. How we built it: We used governmental APIs to retrieve data about car expenses and utilized Firebase to manage user information. Moreover, we used TextFields to input several types of user data such as the vehicle identification numbers and the number of miles driven. Challenges we ran into: One of the main problems we ran into is extracting data from different APIs. The data had different formats, names, and capitalizations, so we devoted a considerable amount of time to revise the code. \nFor example, take how the vehicle identification number (VIN) was decoded by the API. If we tried to decode the VIN for a Mercedes-Benz S560, the decoder would output Mercedes-Benz S-Class instead of the specific model, which is incompatible with the other API that we were using. \nAnother challenge we ran into is that we got tired and started to misspell words when we are naming variables in the codebase. Accomplishments that we're proud of: One accomplishment that we are very proud of is that we not only managed to access governmental APIs that analyze vehicle costs from multiple aspects but also successfully manipulated data from the database to "
      }
    ]
  },
  {
    "file_path": "./devposts/easymed-y9so6w.html",
    "project_id": "easymed-y9so6w",
    "title": "EasyMed",
    "tagline": "EasyMed is a convenient and fun app to manage your prescriptions. It automatically adds medications when you upload an image of your prescription and is game-like to make taking medications fun.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "firebase",
      "flask",
      "javascript",
      "matplotlib",
      "python",
      "react-native",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH Sponsor Prize: Best Accessibility Hack sponsored by Fidelity Created by I mostly worked on the",
      "NewHacks 2022WinnerMLH Sponsor Prize: Best Accessibility Hack sponsored by Fidelity",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/283/728/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our incentivized pet game Login page for our app Main screen for medication reminders Our incentivized pet game Login page for our app Main screen for medication reminders Our incentivized pet game 1 2 3 Inspiration Most people don't like using prescription managers as it is tedious to manually input the medications into them. In addition, they do not add significant functionality apart from reminding users to take their medications at specified times. Thus, their effectiveness is not ideal. However, EasyMed solves both these problems by making it easy to add data about medications and adding a progress-based game to incentivize users. What it does EasyMed is more effective than other apps with the same purpose because of its ease of use and enjoyable features. To add medications to the app, all users have to do is upload an image of their prescription. In addition, users will actually want to take their medications as their virtual pet will then progress in the app's game. The app's home page can tell you info about the medications you've taken for the current week at a glance. Lastly, EasyMed also generates a visual report to summarize your past progress and illustrate potential concerns. How we built it For our backend we use Flask, Python and SQL. For our frontend, we created a mobile app using React Native and Expo. We deployed the Flask server to Heroku to turn it into anAPI, and the React Native mobile app can use it to send and receive data. We used an ML API to extract the text from the user's image, Javascript for the game, and Matplotlib for the graphs. Challenges we ran into We struggled the most with syncing our backend and frontend. Since Python/Flask is web based and React Native is mobile app based, connecting them was very difficult. There were many issues that came up with compatibility that we had to solve. We also struggled with extracting usable data from the ML-generated text as the formats of prescriptions vary widely. We had to look at a larg"
      }
    ]
  },
  {
    "file_path": "./devposts/eagle.html",
    "project_id": "eagle",
    "title": "EAGLE",
    "tagline": "BIM Web Management Platform for Prediction",
    "hackathon": "",
    "built_with": [
      "javascript",
      "keras",
      "python",
      "python-package-index",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/788/809/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "EAGLE Team Mission Control EAGLE Team Mission Control 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Inspiration 50th Apollo 11 Anniversary Mission Control What it does Mission Control - Project Eagle is about helping connect the data many firms already collect with a ML algorithm. The idea being proactive model maintenance ran off predictive analytics. Project Eagle has the goal to connect different open source project built in different hackathons. \nHox - Mission ControlAEC - Spectacles MissionControlAEC started with the AECHackathon at Facebook HQ from the work of the non-profit organization. (San Francisco Computational Design Users Group). Mission Control is an HOK product released open source at the begging of 2019 for the Apollo 11 50th Anniversary of the Moon Landing. Mission Control AEC is a web management tool that allows for better quality control of all our BIM Models without the need to open each model one by one, which saves an incredible amount of time, and assures the data integrity and performance stability in the environment. Furthermore, the tool can track the progression of every event and operation that happens in the Model. Thanks to the Forge and Design Automation API, Mission Control is also capable of performing the changes in the BIM environment. During the Hackathon, the EAGLE Team further developed Mission Control AEC to create a predictive model based on Time-Series that would help to not only forecast failures and corruptions, but also increase the liability of the models. The Proof of Concept developed during the weekend was strictly focused on monitoring views in relationship with the sheets. The goal was to integrate BIM Level 3 and Building Knowledge Modeling with Artificial Intelligence and Machine Learning so that they could quickly become part of the ecosystem and help the development of the project, forecasting and preventing errors and corruptions. How we built it Python \nJSON\nJavascript\nGrasshopper\nOwl Plugins Challenges we ran into Json"
      }
    ]
  },
  {
    "file_path": "./devposts/drawbot-ulof5z.html",
    "project_id": "drawbot-ulof5z",
    "title": "DrawBot",
    "tagline": "Love AI? Love drawings? Love robots? DrawBot is a robot to turn your ideas into original art on paper! Just say what you want and we'll draw it for you!",
    "hackathon": "",
    "built_with": [
      "ai",
      "arduino",
      "assembly-ai",
      "express.js",
      "motor",
      "servo",
      "stable-diffusion",
      "stepper-motors",
      "vector-magic"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A third motor is used for the activation of a drawing utensil, only drawing lines where it needs to"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/226/122/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Laser Cutting Logo DrawBot Main Webpage HBOT Frame Frame CAD Design Laser Cutting Logo DrawBot Main Webpage HBOT Frame Frame CAD Design Laser Cutting 1 2 3 4 5 6 Inspiration With the emergence of AI generation technology such as style-gan, mid-journey, and DALL-E, our team decided to focus on a project that would explore the possibilities of such technology in a cool and interactive way. Meet DrawBot, an AI-powered image generation robot that draws whatever masterpiece you have in mind onto physical paper. (This is also our team’s first hardware hack!) What it does Whenever you have a masterpiece in mind but don’t have the artistic talent for it, simply narrate your idea into our frontend app and we’ll create your artwork for you! This feat was accomplished by utilizing AssemblyAI for speech-to-text input, Stable Diffusion for image generation, and a gantry system to bring your ideas to life. How we built it Getting User Input: Speech-to-Text with AssemblyAI, Web App with Express.js\nDrawBot first creates a transcription of speech input using AssemblyAI’s real-time speech-to-text API. Our web app allows the user to record their desired image prompt, then automatically uploads and transcribes their speech using AssemblyAI. It then sends the final formatted image prompt to be used with Stable Diffusion, along with important keywords to ensure that the generated image would work well with the rest of our pipeline. Generating Custom Image: AI Image Generation with Stable Diffusion\nAfter receiving the prompt from the user, a customized masterpiece is generated using the AI image generation tool Stable Diffusion. Processing User Input: Cortex Image Processing\nAfter generating the image via Stable Diffusion, it is sent to our Raspberry Pi cortex for processing. The image is then resized into the proper format, cleaned, and processed using the Canny Edge Detection algorithm. Then, after translating the bitmap image into a vector format, the cortex interprets the Bezier Curve"
      }
    ]
  },
  {
    "file_path": "./devposts/dress-to-impress-c3ktua.html",
    "project_id": "dress-to-impress-c3ktua",
    "title": "StyleRise",
    "tagline": "StyleRise is your AI-powered morning stylist, offering personalized outfit recommendations to help you start each day with extra confidence and extra sleep.",
    "hackathon": "",
    "built_with": [
      "chromadb",
      "fetch.ai",
      "hyperbolic",
      "next.js",
      "ollama"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/090/127/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration The idea for StyleRise came from a common challenge many of us face—deciding what to wear for different occasions, whether it’s a job interview, a date, or even a casual outing. Hiring a traditional stylist can be both costly and time-consuming, making it inaccessible for most students and working professionals. Our goal was to create a simple, AI-driven solution that helps people make the most of the clothes they already own. Dress to Impress empowers users by allowing them to upload photos of their wardrobe and specify the occasion or style they’re dressing for. The app then uses AI to generate outfit suggestions, saving time and effort while boosting confidence without the need for a personal stylist or the purchase of new clothes. What it does Dress to Impress allows users to upload photos of their clothes, and the app prompts the user for the occasion of style they're dressing for. The app will then generate potential outfits. How we built it The frontend was developed using Next.js, providing a responsive and dynamic user interface. For data management, we utilized ChromaDB, a high-performance vector database, to efficiently store and retrieve clothing information. \nAt the heart of the system, we integrated two AI agents connected via Fetch.ai. The first agent leverages the capabilities of Hyperbolic and Llama-3.2-90B-Vision-Instruct to analyze images of clothing from the user's wardrobe, extracting key attributes and generating detailed descriptions. These data points are then stored in ChromaDB, alongside user-provided information about the occasion and preferences to deliver personalized outfit recommendations of the day.\nThe system also combines context relevant insights with other third-party APIs that to suggest additional items that would complement the user’s existing wardrobe. This tech-oriented cohesive architecture enables us to automate styling decisions, offering intelligent suggestions tailored to the user's needs and pref"
      }
    ]
  },
  {
    "file_path": "./devposts/easyquote.html",
    "project_id": "easyquote",
    "title": "EasyQuote",
    "tagline": "Your essay/project is filled with quotes but you forgot from which websites! Our citation tool will parse your essay, look for quotes and cite them automatically.",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "html5",
      "javascript",
      "milligram",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/413/265/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Has this ever happened to you? You are working on an essay or project with 50 tabs open. Your essay is filled with quotes from all these websites but there is one problem! You forgot from which websites you took the quotes. So now, you have to look at each quote then use Ctrl-F and stick each website you found into EasyBib. This is tedious work. What it does Our citation tool will parse your essay, look for quotes and cite them automatically. We parse your text for quotes and look at the top 50 google results that come up when searching for these quotes. Then, for each result, we look at the content of the page and check if any of it matches with a quote. If it does, we found a link! How we built it There are three main parts to this tool. 1 - Your text is parsed so we can get a nice list of strings which are your quotes. Nothing is saved on the server and the text is parsed on the client. 2 - The server takes these quotes and for each quote does a google search. 3 - If we detect a website that matches with the quote we send the URL and the title of the website back to the client. Challenges we ran into Coming up with a good idea for a project was very challenging. It seemed like everything we thought of has already been done. Relation to theme Using outside knowledge is great - it is what \"standing on the shoulders of giants\" is. However, it is vital to cite this outside knowledge. That's where our tool comes in. Accomplishments that we're proud of Overall the website is semi-functional. Although not all quotes can be found, it works fairly well! What we learned We learned a lot about HTTP methods such as POST and GET and how to utilize them. What's next for EasyQuote Next, we want to find a way to look at the \"snippets\" section of a google search and also create a proper citation generator. This generator would find the author of the website and the date it was created. Built With css express.js html5 javascript milligram node.js Try it out 76.103.186."
      }
    ]
  },
  {
    "file_path": "./devposts/ecaff.html",
    "project_id": "ecaff",
    "title": "ECaff",
    "tagline": "A wearable biomedical device that monitors heart rate, ensuring users don’t doze off in situations they wouldn’t want to.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "firebase",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/283/374/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "React app that shows the graph real time The hardware setup with Heart Rate sensor A graph of Heart Rate (bpm) vs Time (ms) of a person Another graph of Heart Rate (bpm) vs Time (ms) of a person Firebase to store the graph generated from the data collected through the sensor React app that shows the graph real time The hardware setup with Heart Rate sensor A graph of Heart Rate (bpm) vs Time (ms) of a person Another graph of Heart Rate (bpm) vs Time (ms) of a person Firebase to store the graph generated from the data collected through the sensor React app that shows the graph real time 1 2 3 4 5 Inspiration The first hour of the Hackathon, we all got together and asked the question “What’s the most annoying thing about everyday life?”. Two of us wittingly answered “Waking up” in unison. After a good laugh at our sleep schedule troubles as engineering students, we talked about how our late night work sessions during the week caused us to be tired during the day. We shared embarrassing stories of us dozing off during a lecture out of tiredness, or falling asleep on the Go Train and end up missing our stop by a large margin, or even from the morning of the event where one of our team members accidentally fell back asleep after waking up. “Imagine if your alarm clock could sense if you fell back asleep when you’re not supposed to, and then wake you up again” one of us said. And thus, out of our collective sleep struggles as commuters and engineering students, ECaff was born. What it does The E-Caffe is a non-invasive device which wakes up the user when they start to unintentionally doze off during the day. It consists of a Pulse Oximeter and Heart-Rate Sensor, which tracks the user’s pulse and sends the information to an Arduino Uno.  If the average heart rate over a 30 second period drops below 55 bpm (the average sleeping bpm of an adult) the Arduino turns on a buzzer which the user will wear, thus waking up. This device can be used during studying, driving, commuting"
      }
    ]
  },
  {
    "file_path": "./devposts/eduai-em0ud7.html",
    "project_id": "eduai-em0ud7",
    "title": "EduAI",
    "tagline": "Making homework help accessible to grade school students by providing and step-by-step solutions. EduAI user interface makes it easy for students of all ages to navigate and learn.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini",
      "openai",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/361/932/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Edu AI Edu AI 1 2 3 4 5 6 🌟 Inspiration We were inspired by the growing need for personalized and accessible educational tools that adapt to different learning styles. Traditional classrooms often fall short for students who benefit from interactive, step-by-step guidance or who have learning differences. We set out to build a platform that fuses the power of AI with gamified learning—making education not only more accessible, but also more engaging and adaptable. 🧠 What it does Our project has two main components: the Tutor section and the Gamification section. The Tutor section includes three AI-powered tutors: one for homework help, one for simplifying complex topics, and one tailored for accessibility and diverse learning needs. These tutors provide step-by-step guidance, encouraging critical thinking instead of just giving answers. The Gamification section includes interactive educational games: Charades , where users guess academic concepts using AI-generated clues. Detective Game , where players solve subject-related mysteries by answering questions. Together, these features offer an engaging and adaptive learning experience that makes education fun, effective, and inclusive. 🛠️ How we built it To build the Tutor section, we used the Gemini API for all three tutors, designing each one with targeted prompt engineering. We implemented start_chat from Gemini to maintain conversational context, allowing tutors to reference previous exchanges and provide coherent, step-by-step support. For the Charades game, we used prompt engineering with OpenAI to create an interactive AI game host, tracking progress with user_score and ai_score variables. The Detective Game also used prompt engineering with Gemini, carefully crafting prompts that guided the AI’s narrative and adjusted dynamically based on user input. The front-end was built using HTML, offering a clean, accessible interface that supports the platform’s interactive features. 🧩 Challenges we ran into One major ch"
      }
    ]
  },
  {
    "file_path": "./devposts/ecocard.html",
    "project_id": "ecocard",
    "title": "EcoCard",
    "tagline": "Building a sustainable future with EcoCard one SOL at a time",
    "hackathon": "",
    "built_with": [
      "express.js",
      "javascript",
      "next.js",
      "node.js",
      "opencv",
      "python",
      "react",
      "solana"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ChargerHacks 2023WinnerSolana Division",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/623/552/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our eco friendly score calculation Homepage of our app Sign up page Our eco friendly score calculation Homepage of our app Sign up page Our eco friendly score calculation 1 2 3 4 Inspiration Our inspiration for EcoCard was the lack of incentives for people to make eco-friendly choices. Currently, due to the cost of many eco-friendly products, people refrain from making choices that are eco-friendly in order to save money. Our app helps to solve this issue by leveling the playing field by adding incentives for customers to purchase eco-friendly items rather than non-eco-friendly items What it does EcoCard employs advanced receipt-scanning technology to assess the eco-friendliness of recent purchases, utilizing the OpenAI API. Following a rigorous evaluation, we generate an eco-friendliness score for these items and subsequently credit the user's account with the corresponding score as a measure of their sustainable shopping choices. How we built it EcoCard was built using the most cutting-edge tech stack, which includes Next.js for the UI and UX, Firebase for user authentication, Express.js for the node server, and Python to handle all the Solana logic. Challenges we ran into Our JavaScript Solana logic did not work initially, so we had to switch over the logic code to Python so that our Solana logic actually worked. Accomplishments that we're proud of This is one of our first applications where our team integrated web3 into the project. We are also proud of the fact that we are using our ability to develop web apps to promote a sustainable future for our community What we learned We learned that we should manage our time more wisely. We finished our project right on time but could have spent our time more efficiently and coordinated with our team members on when we were going to be away. We also learned about methods to communicate better and to enrich our team’s collaboration and spirit. What's next for EcoCard We have a lot of further improvements planned for EcoC"
      }
    ]
  },
  {
    "file_path": "./devposts/ecocommute.html",
    "project_id": "ecocommute",
    "title": "A",
    "tagline": "A",
    "hackathon": "",
    "built_with": [
      "py"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "A Built With py Submitted to TaroHacks Created by Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Vedant Garg Kosei Tsukamoto"
      }
    ]
  },
  {
    "file_path": "./devposts/e-co.html",
    "project_id": "e-co",
    "title": "E-co",
    "tagline": "Scan it. Learn it. Live it.",
    "hackathon": "",
    "built_with": [
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Second Place Created by Aravindkrishna Arivudainambi Kamronbek Ibatov Alex Liu",
      "East Bay HackathonWinnerSecond Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "print(\"hello world\") Built With javascript python Try it out drive.google.com GitHub Repo Submitted to East Bay Hackathon Winner Second Place Created by Aravindkrishna Arivudainambi Kamronbek Ibatov Alex Liu"
      }
    ]
  },
  {
    "file_path": "./devposts/eduquest-qvebwc.html",
    "project_id": "eduquest-qvebwc",
    "title": "EDUQuest",
    "tagline": "Tired of social media? Connect with real people with EDUQuest!",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "swift",
      "uikit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Social media apps like Instagram, SnapChat, and X promotes easy online interaction as an alternative to meeting and forming real relationships. We want to reverse this trend: what if there was an app that promoted people to meet in person while also promoting interest in STEM? Introducing EDUQuest! What it does EDUQuest promotes in-person social interactions by giving participants a game-like quest. To collect badges, you have to meet another player in-person and get close enough to share your badges. This is a great way for teachers to connect with students who may be interested in their work. When a teacher is looking for interested students, they can share their location in the app, and interested students can find and connect with them. How we built it We designed a mockup of the app using Figma and built the frontend with UIKit. The backend, which supports authentication and storing profile information, is built with Firebase Cloud Storage and Authentication. Challenges we ran into We had to learn how to use bluetooth to find the locations of nearby iPhones. Accomplishments that we're proud of What we learned What's next for EDUQuest Built With figma firebase swift uikit Try it out GitHub Repo Submitted to TAMUhack X Created by Kevin Zhang I am a sophomore studying CS and statistics at Texas A&M with an interest in web development. Soham Nagawanshi"
      }
    ]
  },
  {
    "file_path": "./devposts/ecorewards-t0qw26.html",
    "project_id": "ecorewards-t0qw26",
    "title": "EcoRewards",
    "tagline": "Earn and burn rewards points by making green choices 🔥",
    "hackathon": "",
    "built_with": [
      "agi",
      "express.js",
      "friendship",
      "jacklyn-biggin",
      "jeremysu",
      "kindness",
      "nfc",
      "node.js",
      "overheating-macbooks",
      "peace",
      "porter-robinson",
      "postgresql",
      "rbc-avion-api",
      "react",
      "remix",
      "shadcn",
      "sustainability",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2024WinnerRBC: RBC Avion Rewards – Making Your Point with Our Points",
      "🎯 Track daily streaks, unlock milestones, and compete with others on the leaderboard.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/022/686/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "gpt api spendings :sob: How to get points How to spend points Our mission Claiming points while taking public transport ERM triple skull emoji gpt api spendings :sob: How to get points How to spend points Our mission Claiming points while taking public transport ERM triple skull emoji gpt api spendings :sob: 1 2 3 4 5 6 7 8 9 🌱 Inspiration With the ongoing climate crisis, we recognized a major gap in the incentives for individuals to make greener choices in their day-to-day lives. People want to contribute to the solution, but without tangible rewards, it can be hard to motivate long-term change. That's where we come in! We wanted to create a fun, engaging, and rewarding way for users to reduce their carbon footprint and make eco-friendly decisions. 🌍 What it does Our web app is a point-based system that encourages users to make greener choices. Users can: 📸 Scan receipts using AI, which analyzes purchases and gives points for buying eco-friendly products from partner companies. 🚴‍♂️ Earn points by taking eco-friendly transportation (e.g., biking, public transit) by tapping their phone via NFC. 🌿 See real-time carbon emission savings and get rewarded for making sustainable choices. 🎯 Track daily streaks, unlock milestones, and compete with others on the leaderboard. 🎁 Browse a personalized rewards page with custom suggestions based on trends and current point total. 🛠️ How we built it We used a mix of technologies to bring this project to life: Frontend : Remix, React, ShadCN, Tailwind CSS for smooth, responsive UI. Backend : Express.js, Node.js for handling server-side logic. Database : PostgreSQL for storing user data and points. AI : GPT-4 for receipt scanning and product classification, helping to recognize eco-friendly products. NFC : We integrated NFC technology to detect when users make eco-friendly transportation choices. 🔧 Challenges we ran into One of the biggest challenges was figuring out how to fork the RBC points API, adapt it, and then code our own ad"
      }
    ]
  },
  {
    "file_path": "./devposts/educare-9vc6an.html",
    "project_id": "educare-9vc6an",
    "title": "EduCare",
    "tagline": "EduCare – Empowering Patients, Easing Doctors",
    "hackathon": "",
    "built_with": [
      "api",
      "custom",
      "deepgram",
      "firebase",
      "firestore",
      "flask",
      "language",
      "medical",
      "natural",
      "nltk",
      "openai",
      "parser",
      "pyaudio",
      "react.js",
      "sci",
      "scipy",
      "spacy",
      "toolkit",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/074/627/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration Healthcare is one of the most crucial and rapidly evolving industries, yet communication gaps between doctors and patients continue to pose a significant challenge. Often, post-appointment documentation is complex, medical jargon-heavy, and difficult for patients to fully understand. Studies reveal that 60-80% of medical information provided by healthcare professionals is forgotten by patients immediately after the consultation, with half of the remembered information recalled incorrectly (Journal of Royal Society of Medicine). Furthermore, the lack of clear, accessible medical records can leave patients confused about their diagnosis, treatment plans, and next steps. Current solutions available focus solely on the doctor’s convenience, automating voice-to-text to generate reports but leaving patients behind in the process. These reports often remain medical-centric and inaccessible, preventing patients from understanding their health journey effectively. EduCare was born from the need to address these gaps—creating a post-appointment reporting tool that is accurate, doctor-approved, and easily understandable for patients, while also providing concise summaries for doctors to review. What it does EduCare transforms post-appointment documentation into concise, doctor-approved summaries and digestible, patient-friendly reports. Here’s how it works: Voice Transcription: During the appointment, the doctor’s voice notes are transcribed into text in real-time using Deepgram API.\nMedical Parsing & Coding: The transcribed text is processed through NLTK and a custom parser to extract medical codes (CPT/ICD), symptoms, diagnostic procedures, and medications.\nDoctor Approval Stage: The summarized medical report is sent to the doctor for review and approval through the app interface, ensuring accuracy and mitigating hallucinations or errors from the AI-generated text.\nHumanized Patient Report: Once approved, the data is passed through OpenAI API to c"
      }
    ]
  },
  {
    "file_path": "./devposts/ecotransit-gqk7uf.html",
    "project_id": "ecotransit-gqk7uf",
    "title": "EcoNavigator",
    "tagline": "EcoNavigator reduces carbon emissions from motor vehicles by providing nearby transit routes and displaying how much emissions are reduced versus driving.",
    "hackathon": "",
    "built_with": [
      "carbon-interface",
      "mapbox",
      "shadcn",
      "svelte",
      "tailwind",
      "wolfram-technologies"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "BellHacks 24WinnerDrone",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/750/091/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Routes page Home page Mission statement Routes page Home page Mission statement Routes page 1 2 3 Inspiration We were inspired to build this project when we discovered how significant of an impact motor vehicles play on carbon emissions overall, and how much of this could be mitigated by taking advantage of public transit. What it does EcoNavigator provides a map interface where users will be able to see nearby transit routes as well as how much carbon emissions they will be reducing by taking transit versus driving. How we built it We used Svelte, Tailwind, and shadcn for the frontend, Mapbox for mapping, and WolframAlpha and Carbon interface for the backend calculations. Challenges we ran into We had trouble with implementing our map environment and carbon emission calculations, which was much harder than we anticipated. Accomplishments that we're proud of We are proud that we overcame our obstacles with the mapping to make our final product. We are also proud of the elegance and intuitiveness of our UI and its compatibility with multiple platforms. What we learned We learned how to leverage multiple new technologies with each other, like WolframAlpha's API, MapBox, and the Carbon Interface, to perform our backend calculations. What's next for EcoNavigator Next, we plan on expanding the range in which EcoNavigator will pull data, as well as adding data for other forms of transit like bikes. Built With carbon-interface mapbox shadcn svelte tailwind wolfram-technologies Try it out GitHub Repo bellhacks.vercel.app Submitted to BellHacks 24 Winner Drone Created by James Hughes Sam Jeffs Oliver Ma Ashish Ramanan \"Python\" \"Java\" \"GDscript\" \"Html\" \"CSS\" \"JavaScript\" \"React\" \"React Native\""
      }
    ]
  },
  {
    "file_path": "./devposts/ecoshopper-3v8xec.html",
    "project_id": "ecoshopper-3v8xec",
    "title": "EcoShopper",
    "tagline": "Shop without harming the environment",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "html",
      "javascript",
      "supabase"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/461/484/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "💡Inspiration 💡 We were inspired to do this project as since the pandemic a lot of people resorted to online shopping and because of sales tactics a lot of people make decisions on an impulse, especially when big corporations like Amazon offer next day delivery and nowadays even the same day delivery. This makes a lot of people buy products that they don't need and results in a big waste of money and a bigger waste for the environment. ❓What it does ❓ We made a chrome extension that allows the user to view the environmental impact of a product sold on Amazon which in theory would make the user think twice before buying a product. For example, if I am looking to buy a useless box (yes that's a real thing) I would think twice about before buying it if the environmental impact is negative. Another use case for this would be when I am looking to buy a new laptop per say, a new factor is introduced when buying a machine, environment sustainability. A laptop that cannot be recycled is less environmentally friendly compared to one that can be therefore I would be more lenient to the more environmentally friendly product for the sole purpose of helping the environment every way I can. 🛠️ How we built it 🛠️ We built this application by using basic Javascript, HTML, and CSS for the chrome extension. Although a chrome extension may not look very flashy compared to other applications (well, because it's an extension) but the code for it was complicated for us as we couldn't find a lot of helpful resources for a chrome extension and that alone took us around 12 hours of the hacking period. For determining whether a product is environmentally sustainable or not we wrote our own CUSTOM prompts. Now you may think we wrote 2 maybe 3 sentences instructing Co:here on what to do but no, we made prompts 2 pages long each that include prompt syntax rules, \"performance enhancers\" for the model (we had too much fun doing this), detailed instructions on what an environmentally sustainable pr"
      }
    ]
  },
  {
    "file_path": "./devposts/eco-goals.html",
    "project_id": "eco-goals",
    "title": "Can we hit 100 likes?",
    "tagline": "this is what happens when you try to win a community favorite track by memeing. Statistically the 97th most successful devpost of all time",
    "hackathon": "",
    "built_with": [
      "nothing-lol"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Built With nothing-lol Submitted to Hack the North 2020++ Created by I am never deleting this Micha",
      "force the creators of this hackathon to give us the community favorite award"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/344/566/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration nothing What it does yes How we built it good question Challenges we ran into thinking of the gif was kinda hard ngl Accomplishments that we're proud of lmao do you think im proud of this What we learned we learned nothing lol What's next for Can this hit 100 likes? force the creators of this hackathon to give us the community favorite award Built With nothing-lol Submitted to Hack the North 2020++ Created by I am never deleting this Michael Mohn High Schooler interested in CS. Member of CRHS Idea I wrote the backend, by far one of the most challenging projects of our time. Prasann Singhal AI Researcher | Full-stack Dev| Innovator ok Ian Kim Leonidas Varveropoulos"
      }
    ]
  },
  {
    "file_path": "./devposts/easytravel-iscyl0.html",
    "project_id": "easytravel-iscyl0",
    "title": "EasyTravel",
    "tagline": "The collaborative way to discover the world",
    "hackathon": "",
    "built_with": [
      "auth0",
      "coil",
      "fastapi",
      "google-maps",
      "linode",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Linode Cloud Winner Best Web Monetization Project Created by I worked on the entirety of the",
      "Third Overall Winner Best Use of Linode Cloud Winner Best Web Monetization Project Created by I wor",
      "Hack Around The WorldWinnerThird OverallWinnerBest Use of Linode CloudWinnerBest Web Monetization Project",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/708/040/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "StreetView support for pinned locations Landing page Log-in Cultural map StreetView support for pinned locations Landing page Log-in Cultural map StreetView support for pinned locations 1 2 3 4 5 💡Inspiration💡 We want to celebrate the culture and heritage of the world, the daily lives and lifestyles of people from all places and ethnicities around the world. That's why we created the platform where everyone can publish their culture on a global map and everyone can interact and travel the world without leaving home. ❓What it does❓ EasyTravel lets users explore the world in a collaborative way. Users can share their location, traditions, culture, and places to visit in that same location. This makes it for tourists to have more variety in their vacation planning, and lets locals share their own opinion for the tourists to both have the best experience in their vacation, and for the locals to promote the economy in the places to visit in their community, which lets locals share their own culture worldwide. 🏗️How we built it🏗️ We built EasyTravel with React, Auth0, FastAPI, Linode, Coil, GoDaddy, and Google Maps. 🟢 How we used Linode We utilized Linode for its hosting and storage. Linode is one of the top IaaS providers and is incredibly easy to use and the free Linode credit from MLH for us to learn and build on Linode was the cherry on the cake! Linode also has great documentation that really helped us implement EasyTravel’s backend. Linode is fast, flexible, and reliable, and we truly enjoyed using it. ⚫️ How we used Coil Monetized EasyTravel users get to publish markers to the map on the places they like for the whole world to discover, thanks to Coil. We realized that by giving only monetized users the option to add places, we can minimize spam on our website. Coil also lets EasyTravel donate micropayments to support non-profit organizations, such as freeCodeCamp.org directly with their wallet addresses. 🟡 How we used Google Cloud We utilized the Maps Platform by "
      }
    ]
  },
  {
    "file_path": "./devposts/dropbase-tcc.html",
    "project_id": "dropbase-tcc",
    "title": "Dropbase TCC",
    "tagline": "The Case for Profit and Growth: a Technical Case Competition",
    "hackathon": "",
    "built_with": [
      "research",
      "smiles"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The GoldenHack 3.0WinnerTechnical Case Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/679/280/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "12 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12 1 2 3 4 5 6 7 8 9 10 11 12 13 After much research, we recommend a three-pronged approach to maximize Dropbase’s success for the next 5 years as it relates to their technological products, sales, and operations. They include: Shifting sales and marketing team from technical-focused to business-focused outcomes Moving towards a centralized digital strategy for internal and external data sources to improve business operations Continuing to build a better product that: *** enables customers to save more money *** opens new channels for Dropbase to generate money *** lays the groundwork for generating insights and feedback *** saves Dropbase money operationally Built With research smiles Try it out www.canva.com drive.google.com Submitted to The GoldenHack 3.0 Winner Technical Case Challenge Created by Led brainstorming and strategy development and authored case study response in attached Google link Anita Yip Product owner, project manager, retired hackathon-er Ayush Kumar Pursuing B.Tech in CSE with a specialization in AI & ML (VITCC'23) Gamer in the morning and coder at night... Tan Zheng Bin Aaron"
      }
    ]
  },
  {
    "file_path": "./devposts/eataer.html",
    "project_id": "eataer",
    "title": "EatÆR",
    "tagline": "Visualizing restaurant food in a click of a button",
    "hackathon": "",
    "built_with": [
      "adalo",
      "databases",
      "echoar",
      "figma",
      "sketchfab"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/619/188/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Demo of actual application of the restaurant Explore the food in AR with EatÆR Restaurant Analytics Scan the QR code here to get immediate access Demo of actual application of the restaurant Explore the food in AR with EatÆR Restaurant Analytics Scan the QR code here to get immediate access Demo of actual application of the restaurant 1 2 3 4 5 6 What it does Nowadays, people have become more health-conscious; they want to know what they are eating and how it will taste. EatÆR will help our customers to achieve this task, as well as reducing food and financial wastage. Our application has the capability to visualize the menu restaurant trends along with features to automatically update the restaurant menu database. Moreover, with our app, consumers now have the ability to set their own pick-up time for a particular dish from the restaurant. How we built it We built the application framework at adalo.com and imported 3D assets onto EchoAR. Challenges we ran into Connecting the live restaurant menu database with the EchoAR platform. Accomplishments that we're proud of Creating this startup application that can both improve customer experience and the restaurant transparency. What we learned Time management skills Handling of different relations among the databases Explored EchoAR capabilities App Building Designing How EatÆR can help Restaurants Improving visibility: Augmented reality restaurant menus can be customized to show information about each dish, such as 360-degree visualizations, details of ingredients used, portion sizes, calorie, and nutrition info, etc. Upsell: AR food menus can also help restaurants sell more items. Apps can be programmed to suggest ideal complements to selected dishes such as appetizers, beverages, dessert combos, etc. Improve customer engagement: Unlike traditional food menus, AR food apps can be customized to display a wealth of content on demand. What's next for EatÆR The limitation of the current version is that the restaurant owner"
      }
    ]
  },
  {
    "file_path": "./devposts/eeg-placeholder.html",
    "project_id": "eeg-placeholder",
    "title": "MindScape: Neural Odyssey",
    "tagline": "Because peace of mind is not a destination, it's a journey.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "eeg",
      "hume",
      "intel-developer-cloud",
      "pandas",
      "python",
      "reflex",
      "scipy",
      "ssh",
      "tensorflow",
      "together-ai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Intel Developer Cloud Created by Mishty Dhekial Contact me @ mishty",
      "Cal Hacks 10.0WinnerBest Use of Intel Developer Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/644/463/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "(Local Program for data in + hardware firmware) https://github.com/assasin2gamer/CalHacks (Website with Reflex) https://github.com/mishcoder/calhacks (Intel integration) https://github.com/AKUMAR0019/calhacks Inspiration Our project draws inspiration from the challenge of classifying emotions, a complex task. We aim to provide a reliable and cost-effective solution for training EEGs (Electroencephalograms), which can contribute to better understanding and analysis of emotions. We used a research grade EEG headset to get reliable data and do accurate sentiment analysis. What it does Our project leverages machine learning to train on vast datasets of EEG data and Hume's audio analysis. We use this training to develop a sentiment analysis model specifically tailored to EEGs. EEGs capture brainwaves resulting from the neuro-physiological interactions in the brain. By employing techniques like Fast Fourier Transform (FFT) and random tree (RT) modeling of time series data, we can identify EEG characteristics associated with different emotions. Our model allows us to generate visually appealing images using TogetherAI's image generation service based on the emotion classification and even further! How we built it We built our product using three main components:\n1) Hume for sentiment data labelling\n2) CockroachDB serves as our database for storing EEG data.\n3) Intel Cloud Compute to compute our model\n4) TogetherAI to generate images based on the emotion classification.\n5) Reflex to host our website which combines the multiple data streams into one websocket. Challenges we ran into We ran into a few challenges:\n1) We could not figure out why, but when we pinged spesifically the CockroachDB from the Intel Compute instance, the instance would freeze.\n2) Our concept of using the model to be input sources for a VR game fell through when we realized the computer we brought could not handle the processing required. Accomplishments that we're proud of We take pride in successfully"
      }
    ]
  },
  {
    "file_path": "./devposts/ecoalchemy.html",
    "project_id": "ecoalchemy",
    "title": "EcoAlchemy",
    "tagline": "We use simple alchemy mechanics to encourages curiosity for sustainability. A simple but addictive game. Start with a few basic elements and combine them to make more sophisticated creations!",
    "hackathon": "",
    "built_with": [
      "html5",
      "react",
      "three.js",
      "visionos",
      "vr"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/770/017/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "NFT credential sent to user via email after completing game (crossmint) Welcome screen A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of one of the rendered 3d maps A screen capture of one of the rendered 3d maps NFT credential sent to user via email after completing game (crossmint) Welcome screen A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of gameplay in Eco-Alchemy A screen capture of one of the rendered 3d maps A screen capture of one of the rendered 3d maps NFT credential sent to user via email after completing game (crossmint) 1 2 3 4 5 6 7 8 9 10 11 12 TRY IT ON YOUR OWN DEVICE! https://ecoalchemy.vercel.app/ Inspiration 🌍 We built EcoAlchemy to be the ultimate educational game on ecology and sustainability that is friendly to all age groups. EcoAlchemy is inspired by the urgent need for environmental awareness 🌱 and the captivating power of gaming 🎮. It's our answer to engaging a wider audience in the critical conversation about sustainability and ecological balance. We want to gamify our approach to spreading awareness on carbon footprints and the permanence of pollution. What it Does 🚀 The game educates players on the interconnectedness of nature 🌳, the impact of human activities 🏭, and the importance of sustainable living through fun, interactive gameplay. Eco-Alchemy is a puzzle game where players combine basic elements like air, fire, earth, and water to create new items, substances, and concepts. The game mechanics involve experimentation and disc"
      }
    ]
  },
  {
    "file_path": "./devposts/eco-recipy.html",
    "project_id": "eco-recipy",
    "title": "Eco-Recipy",
    "tagline": "We believe that Eco-Recipy would allow you to achieve and maintain a healthy lifestyle, reduce climate change, and make sure that animals are living under the best well-being.",
    "hackathon": "",
    "built_with": [
      "cssmodules",
      "json-server",
      "react",
      "reacthooks",
      "reactrouter",
      "spoonacularapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Animal-Wellbeing Hack Created by Vikas Shukla Dark the Eyezor Nethara De Silva Tina Xu Software Eng",
      "Best Animal-Wellbeing Hack Created by Vikas Shukla Dark the Eyezor Nethara De Silva Tina Xu Softwar",
      "Hack the EarthWinnerBest Animal-Wellbeing Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/096/729/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Calendar Fridge Component Calculated Recipe In Season Produce Calendar Fridge Component Calculated Recipe In Season Produce Calendar 1 2 3 4 5 Inspiration During quarantine, many of us haven't been eating healthy. So we wanted to take this opportunity to change that. Also, we wanted to make a big change to help nature, and one way we thought of that was to make a recipe generator for non-veg dishes using vegan ingredients. What it does This app suggests recipes based on the ingredients you have left in your fridge, which saves you so much time and energy from searching up recipes, and helps save animals by providing healthy and delicious vegan recipes. How we built it We made this app using React JS with a database called json-server. Through making API calls, we were able to store our fridge items in that database and use them to query when using the Spoonacular API for recipes and instructions. Challenges we ran into For a lot of us, this was the first time ever we worked with React, and it was challenging! Also, creating a user-friendly API and suggesting relevant recipes was another hurdle. Accomplishments that I'm proud of It works!! And it helps with so many food dilemmas. What we learned How to code with react JS and how to work in a team, despite being in different time zones. What's next for Eco-Recipy Making the interface more interactive, suggest more recipes, and possibly include suggestions on eco-friendly ways to change our homes for the better, such as suggestions to save water and veggie parts for later use in cooking, and more. Built With cssmodules json-server react reacthooks reactrouter spoonacularapi Try it out GitHub Repo Submitted to Hack the Earth Winner Best Animal-Wellbeing Hack Created by Vikas Shukla Dark the Eyezor Nethara De Silva Tina Xu Software Engineering and Business at Western University"
      }
    ]
  },
  {
    "file_path": "./devposts/endesk.html",
    "project_id": "endesk",
    "title": "Endesk",
    "tagline": "Development of a platform to facilitate connections between handymen and residents by using opposite reciprocation.",
    "hackathon": "",
    "built_with": [
      "mongodb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Development of a platform to facilitate the residents for availing handyman's services and handyman's to get the business leads. What it does When one of the taps in my kitchen broke, I contacted quite a few plumbers by making phone calls to get it fixed. However I realized that only one of them was competent to fix it and he confirmed his availablity for the next day. As the water was overflowing and it was difficult for me to wait, I somehow managed to fix it with the help from my friend. This was the day when I realized that if there is a platform available to request handymen services without the need to flag down each and every handyman individually and wait for THEIR response, the solution to my situation would have been significantly easier. How we built it I built the app from the ground up using the MERN tech stack- MongoDB, Express JS, Node JS and React Native Challenges we ran into This was my first time ever dabbling with backend services, and this already daunting challenge of learning 3 entirely new technologies was amplified even more by the fact that I decided (stupidly) to go solo. Accomplishments that we're proud of As aforementioned, despite being solo and having zero experience with many of the MERN backend technologies and frameworks, I was able to execute my vision with a high degree of accuracy, which is something I'm very proud of. What we learned Team work is key - I often felt highly unmotivated due to being completely alone in my struggles. What's next for Endesk Currently I am in the process of implementing more functionalities including MIS Reports covering aspects like\nHow many leads were shared with the service provider, how many attended, etc At a later stage, I plan to develop a Mobile App for the same so that it is easier for handy man to submit the proposal even when he is at work. Subscription model to establish premium quality platform and generate revenue. Built With mongodb Submitted to hack::peel Created by Worked "
      }
    ]
  },
  {
    "file_path": "./devposts/ecotrack-dtn732.html",
    "project_id": "ecotrack-dtn732",
    "title": "EcoTrack",
    "tagline": "EcoTrack is a  revolutionary web application that helps individuals reduce their carbon footprint and embrace sustainable practices.",
    "hackathon": "",
    "built_with": [
      "clerk",
      "express.js",
      "nextjs",
      "node.js",
      "sass",
      "survey.js",
      "tailwind",
      "tidb",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "What's next for EcoTrack",
      "ecotrack.vercel.app"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/547/355/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Badge Page EcoTrack Carbon Footprint Calculator AI Analytics Blog Zone Badge Page EcoTrack Carbon Footprint Calculator AI Analytics Blog Zone Badge Page 1 2 3 4 5 6 Our Team We are the Ecotrack team, consisting of four passionate students: Akshay, Ariv, Mike, and Riya. Through effective organization and strategic planning, we successfully completed the project within the allotted timeframe. Akshay led the development of the blog zone and database, while Ariv focused on creating the Analytics and Homepage sections. Mike took charge of the backend and carbon footprint calculations, and Riya played a pivotal role in designing and developing various pages. Our team name, Ecotrack, reflects our mission of tracking and promoting eco-friendly actions. Our project EcoTrack was inspired by our shared commitment to protecting the planet and combating climate change. We envisioned a platform that fosters a community of eco-conscious individuals sharing sustainable practices and ideas. With the power of AI tips, we empower users to reduce their carbon footprint and create a collective impact for a greener future. Together, let's make a positive difference for our planet. EcoTrack is a user-friendly web application empowering individuals to reduce their carbon footprint and embrace sustainable practices. Leveraging AI, users receive personalized tips and calculate their carbon emissions, making eco-friendly choices easier in various aspects of life. The platform also includes a dedicated blog zone where users can track their progress, share ideas, and exchange experiences with like-minded individuals. This blog zone fosters a sense of community and collaboration, inspiring collective action toward a greener future for our planet. Using TiDB We utilized TiDB for storing userData, blogs, and carbon footprint data. Leveraging TiDB dataservice, we created data app endpoints that allowed seamless data retrieval. TiDB's efficiency and developer experience were superior to other databa"
      }
    ]
  },
  {
    "file_path": "./devposts/edu-hub-ectuon.html",
    "project_id": "edu-hub-ectuon",
    "title": "Edu  Hub",
    "tagline": "Your one stop shop to a more personalized education",
    "hackathon": "",
    "built_with": [
      "firebase",
      "javascript",
      "nextjs",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by the prompt to re-use a currently existing application for better use for society. We decided to refurbish Discord as most of us used it in our daily lives and we felt it could be used for the better. For that reason, we created an excellent application: Edu Hub short for The Education Hub for You. What it does Edu Hub allows users to participate in various school-related activities. Our system facilitates a better education for students in many ways, mainly due to its resemblance to a familiar and fun platform called Discord. Our platform allows students to keep track of assignments in order to make sure that they complete their assignments before the due date. In addition, students can take note of different lectures allowing them to save important information for later use, memorization, and overall for to help them understand the concepts they are being taught. Last but not least, our platform allows users to chat in various ways such as through conversations regarding various homework assignments or talks with teachers and other administrators in a less formal way How we built it We built the project using mainly frontend technologies such as NextJS and React with a styling system called TailwindCSS as well as other useful technologies Challenges we ran into We ran into many challenges with a cloud system called Firebase and our styling system of choice was TailwindCSS. Accomplishments that we are proud of We are proud of creating the wonderful application that is named Edu Hub What I learned We learned how to work together as a team in order to collaborate when we had major bugs and how to use the various technologies that we did in increasing depth. We learned many concepts such as image rendering and how to use python in Firebase What's next for Edu  Hub Better UI styling Grading schedules Reminders Pins Built With firebase javascript nextjs react Try it out GitHub Repo Created by Rohan Fernandes A full-stack programmer who mai"
      }
    ]
  },
  {
    "file_path": "./devposts/electron-green-it-up.html",
    "project_id": "electron-green-it-up",
    "title": "Electron: Green it up!",
    "tagline": "Saving megawatts saves megabucks",
    "hackathon": "",
    "built_with": [
      "flask",
      "jupyternotebook",
      "pandas",
      "python",
      "sklearn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Created by I trained the Model, connected and integrated it Satyam Singh I worked for",
      "SustainHacksWinnerThird Overall",
      "We are proud that on our first attempt as a complete beginner we were able to train our own model",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/317/460/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration we waste about two-thirds of the roughly 100 quads (quadrillion Btu) of energy we consume each year, whereas 940 million (13% of the world) do not have access to electricity and this is a major concern as because of high amount of electricity we get there is a large amount of it that gets wasted every year that's why to save environment for our future generation we thought about this amazing project i.e. * Electron: Green it up! * which predicts the amount of electricity that is needed ! What it does Electron is a machine learning model that predicts the amount of energy that is need so that we can save it. How we built it We used Jupyter notebook to train the model and kaggle to get the dataset Challenges we ran into This was our first time working on a machine learning project, it was tough to get the data cleaned after a lot of effort we were able to train our model but unfortunately because of lack of experience and knowledge we were not able to add it with out website. Accomplishments that we're proud of We are proud that on our first attempt as a complete beginner we were able to train our own model What we learned we learned how to get the correct data, steps to train a model, data cleaning. What's next for Electron: Green it up! we will be looking forward to add in a website and make it even more accurate in future! Built With flask jupyternotebook pandas python sklearn Try it out GitHub Repo Submitted to SustainHacks Winner Third Overall Created by I trained the Model, connected and integrated it Satyam Singh I worked for Backend for frontend, connected the database and Machine learning to the front end pages using Flask, python. It was my first time learning Flask and implementing it. There were amany difficulties that we ran into, but it taught us alot. Om Dalwadi I worked for the front-end and helped gathering the data. Shivam Soni Kartik Patel Nothing much..!"
      }
    ]
  },
  {
    "file_path": "./devposts/ecocycle-mtser2.html",
    "project_id": "ecocycle-mtser2",
    "title": "Reusify",
    "tagline": "Reuse Gamified.",
    "hackathon": "",
    "built_with": [
      "android",
      "android-studio",
      "dart",
      "firebase",
      "flutter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "of the best and possibly show off how high up you are! (or not) :) This encourages people to create"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/030/985/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Profile, Rating & Upload Pages Login, Gallery & Leader-board Pages Profile, Rating & Upload Pages Login, Gallery & Leader-board Pages Profile, Rating & Upload Pages 1 2 3 Inspiration The sheer lack of resourcefulness in our community was put on full display when our school district subtly decided they would no longer encourage recycling, and instead will be sending all of the garbage straight to landfills. As crazy as it sounds, if you don't believe us, you can believe our teachers who broke the news to us. You can imagine how shocked we were when you consider how much recyclable material was thrown away throughout the year across our various high schools. According to the recycling coordinator at our very own district, we sent away nearly 41 million pounds of garbage to landfills last year alone. This idea flowed naturally from our past climate change projects. What it does It's fun and simple! Join in by creating a new account, and start showing off how much you can recycle. Once you log in you get the choice to upload images of your recycling accomplishments, or by rating other people's jobs to see who's the best. Basically, all you do is go out and photograph proof of your reuse, and once you've done so, post it on Reusify and allow others to rate (be in awe) of your work. The more you recycle, the more posts you submit, the more stars you get. The more stars you get, the higher you rise on the global leaderboard, where you can see the best of the best and possibly show off how high up you are! (or not) :) This encourages people to create less waste, inspired both by projects others have made and the app's gamification system. How We built it The Flutter SDK This SDK makes it quick and easy to deploy new tests and create beautiful UI. Firebase Cloud storage, Realtime Database, Authentication Challenges We Ran Into I wish we could say we were perfect... and we truly impressed ourselves with how well the development process went. But in the end, we did have our fa"
      }
    ]
  },
  {
    "file_path": "./devposts/editly-3ud79g.html",
    "project_id": "editly-3ud79g",
    "title": "Editly",
    "tagline": "AI-powered video editing that follows the latest social media trends, helping you boost your personal brand effortlessly.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "flask",
      "lambda",
      "nextjs",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/038/825/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration 💡 Online personal branding is a daunting science for many beginner content creators. Thankfully, existing media trends tell us how to make simple videos go viral. What it does 🧑‍💻 The user simply uploads a raw video and selects existing videos as inspiration. Then the app outputs an AI-edited video infused with viral video formats. How we built it 🛠️ Front: NextJS, TailwindCSS\nBack: AWS Lambda, Docker\nDev: Vercel Challenges we ran into ⚠️ Fetching video data (title, caption, video, etc.) from Instagram Business API Operating AWS Lambda functions across several local machines Integrating multiple ML model layers for video processing (Hugging Face, OpenAI Whisper) Accomplishments that we're proud of 🏆 Learning and integrating an extremely complex tech stack in 24 hours Extracting sound/visual effects from Instagram videos Implementing AI video editing with raw user clips What we learned 📚 Our biggest lesson was choosing too many open ended and ambitious MVP features. We should've relied way less on AI processing. What's next for Editly 💭 We want to provide a wider range of editing options for video format infusion. This can include plot points, color effects, and more. We also want to allow users to share inspiration boards via a community tab. Users would be able to create boards that contain video and/or creators that inspired individual video edits. Built With amazon-web-services flask lambda nextjs python Try it out penn-apps2024-1.vercel.app GitHub Repo Submitted to PennApps XXV Created by Legasse Remon Rian Corcino i code stuff for fun Ethan Santos"
      }
    ]
  },
  {
    "file_path": "./devposts/edyfai.html",
    "project_id": "edyfai",
    "title": "EdyfAI",
    "tagline": "Makes Learning a bit more HUMAN 👨‍🏫",
    "hackathon": "",
    "built_with": [
      "affectiva-api",
      "ai",
      "bootstrap",
      "heartbeat.js",
      "html",
      "javascript",
      "opencv",
      "plotly.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackUPC 2n Prize Winner IThinkUPC Challenge Created by Pratyay Banerjee Trying to learn how to lear",
      "Winner IThinkUPC Challenge Created by Pratyay Banerjee Trying to learn how to learn ;) Private user",
      "HackUPC 2021WinnerHackUPC 2n PrizeWinnerIThinkUPC Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/511/061/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Background With the advent of the 𝐂𝐨𝐯𝐢𝐝-𝟏𝟗 online education or simply E-Learning has become the new norm . With the onset of remote learning, some of the most popular video-conferencing platforms like Google Meet or Zoom have become part & parcel of every teacher's life. But there is a sharp line of difference between physical & online-based teaching. Improper tackling of so many students online has created new loopholes in the current education system. Facial expressions communicate a lot about a student, more than they care to admit. Whether a student is interested or not in a class, if he’s looking towards what the teacher is teaching - these informations are extremely valuable to the teachers as well as the school/college they are enrolled in. According to NYT , because of the feeble face-to-face traditional interaction between lecturers and students, the interest in online education has drastically reduced in the last few months for students, globally! And this is actually a two-way process. Poor response from the bored students does exhaust teachers which overall degrades the overall experience, keeping the future of these young minds at great stake. Upon performing extensive research, we couldn't find any platform/app where this censorious issue is effectively tackled. We believe that with the power of AI, this can be solved if proceeded creatively. Thus we made EdyfAI ! What is EdyfAI? EdyFAI is a mobile solution in the form of a web extension. It is a revolutionary tool that helps teachers and students improve the online learning experience for the better. By looking at the expressions of the student throughout the duration of the course, EdyfAI can help you figure out which points of the course were interesting, or which parts confused students the most. It shows which topics made students uninterested and diverted attention to other activities. This in turn can help turn online learning into a fun, interesting & productive experience. A further explan"
      }
    ]
  },
  {
    "file_path": "./devposts/ecotracker-9qzfwk.html",
    "project_id": "ecotracker-9qzfwk",
    "title": "EcoTracker",
    "tagline": "EcoTracker: Paving the Way to a Greener Tomorrow.",
    "hackathon": "",
    "built_with": [
      "node.js",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack4EarthWinnerHonorable Mention",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/605/264/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Hmmm....what is this? Home page of EcoTracker Chatbot! Did you pick up garbage today at Cuesta Park? Map of top 10 parks in your area! Profile Page! Good job! You earned 6 points! Hmmm....what is this? Home page of EcoTracker Chatbot! Did you pick up garbage today at Cuesta Park? Map of top 10 parks in your area! Profile Page! Good job! You earned 6 points! Hmmm....what is this? 1 2 3 4 5 6 7 8 Inspiration: EcoTracker was inspired by our passion for environmental conservation and our desire to make sustainable living accessible and engaging for everyone. We wanted to create an app that not only helps users track their recycling efforts but also educates and motivates them to make a positive impact on the planet. What it does: EcoTracker is a multifunctional app that tracks your recycling habits, offers eco-themed quizzes, and rewards you with points for your eco-friendly actions. It's designed to make sustainability a part of your daily life while making the journey enjoyable and rewarding. Impact By creating an app that allows users to easily track their eco-friendly efforts, we hope to encourage them to take more action to help create a more sustainable planet.  The interactive map provides users with an easy way to track their actions in nearby parks in the click of a few buttons and the quiz invokes users to think more critically and deeply about topics like pollution and how they affect our planet.  Furthermore, the chatbot page provides easily accessible help to understand what the web app is meant to do and what features it has, and, finally, the home page allows users to see their hard work reflected in point values and a growing tree so they can feel more encouraged to keep going. The profile page available via the home page also allows the user to feel more attached to the app, as they are able to personalize it with their own username and personal information. How we built it: We built EcoTracker using React Native. We used an API for the map and many rea"
      }
    ]
  },
  {
    "file_path": "./devposts/drawing-app.html",
    "project_id": "drawing-app",
    "title": "Web3 Canvas",
    "tagline": "Doodle and draw anything you would like — using Web3 on the blockchain network!",
    "hackathon": "",
    "built_with": [
      "art",
      "blockchain",
      "crypto",
      "node.js",
      "react",
      "stacks",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "2nd Place Open Innovation Track Created by I worked on the connection between Stacks and the fronte",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/860/832/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Code Snippet Homepage + Login Screenshots The Different Webs Technology Stacks Usability Code Snippet Code Snippet Homepage + Login Screenshots The Different Webs Technology Stacks Usability Code Snippet Code Snippet 1 2 3 4 5 6 7 8 ☁️ Inspiration The inspiration from our app was the world of Web3. In the world, all information is centered in global corporations such as Google and Apple. With Web 3, it centralizes data in the blockchain and thus ownership of data is given back to users, which increases privacy. 👷 How We Built It Stacks : Backend for decentralized blockchain-based database Typescript : Compiled language used for typing React : Frontend framework 🎈 Accomplishments That We're Proud Of We actually finished it...yay! Other than that, we are very happy on how the finally UI turned out. Almost all the APIs work. The canvas and text were fully implemented, and we believe we succeeded! 📙 What We Learned We learned a lot of things in this. Firstly, none of us connected to the blockchain network before. This was a major challenge, as the API was very confusing. We used a wrapper called Hiro Wallet for blockchain user addition. In addition to that, connecting React/NodeJS with the crypto was hard. We didn't add all the features we wanted to, but we succeeded in many aspects. 🔜 What's Next For Web3 Canvas We will add a better UI and more functions. 🎨 Main Functionality To use this, you need to download the Hiro Wallet extension. Create an account by signing up with google, and you are good! A login window will pop up with the extension when you are on our website, and once you log in, you can draw or write anything! Everything is on the blockchain network, so it is cryptographically impossible to break into. Built With art blockchain crypto node.js react stacks typescript Try it out GitHub Repo docs.google.com Submitted to LancerHacks V HackMerced VII Winner 2nd Place Open Innovation Track Created by I worked on the connection between Stacks and the frontend and"
      }
    ]
  },
  {
    "file_path": "./devposts/edwiz.html",
    "project_id": "edwiz",
    "title": "EDwiz",
    "tagline": "Gestures  ➠  Visualizations ✨",
    "hackathon": "",
    "built_with": [
      "machine-learning",
      "mongodb",
      "nextjs",
      "prisma",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack sponsored by Fidelity ♿ We were delighted to know that this was a category",
      "Fidelity ♿ We were delighted to know that this was a category",
      "Best Use of MongoDB Atlas Created by The magician was worried about his garden after the summer",
      "HackED 2023WinnerBest Use of MongoDB Atlas",
      "Best Domain Name from Domain.com ⭐",
      "Best Accessibility Hack sponsored by Fidelity ♿",
      "Best Use of MongoDB Atlas 💚",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/357/663/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration 💡 Boring PowerPoint slides and drab Zoom webcams. This is the “cutting edge” technology being used to teach classes remotely today. However, as the topics and concepts taught in schools become increasingly abstract, these tools may not be sufficient to engage and support student learning. According to a survey of Canadian schools, only 37% students feeling invested in learning. Statistics show that 25% of students of students who drop out of school cite low self-efficacy and disengagement as reasons for leaving. Disengagement with school can begin as early as age 9 and may worsen as students get older. To address this issue, some methods have been developed to help students enjoy learning. Given that 40% of students are visual learners, visualizations can be particularly effective for retention. However, incorporating visualizations into lessons can be challenging, as it often requires teachers to spend time learning complex software. We believe that visualizations should be summoned magically with simple gestures. We went ahead and built just that. What it does 🤔 EDwiz is a browser based visualization tool that allows educators to better prepare for their lessons by mapping Gestures --> Visualizations. After logging in, teachers can view a Canvas where they can preset three unique gestures to visualizations of their choice. We have recognized the value of Generative image AI applications such as Dall-E 2 and Stable Diffusion and have offered teachers a way to map their gestures to Generative Images based on their prompt or lesson requirements. Moreover, we enable teachers to map their gestures to GIFS because GIFs are often liked by students and convey the concept in an interactive manner EDwiz also provides a history dashboard where teacher can view images they have previously configured so that they can reuse them for future lessons. After the gestures to visualizations mapping has been completed, teachers can share their screen showing th"
      }
    ]
  },
  {
    "file_path": "./devposts/examly-7st2g4.html",
    "project_id": "examly-7st2g4",
    "title": "Examly",
    "tagline": "We eliminate the chaos of exam scheduling, every semester.",
    "hackathon": "",
    "built_with": [
      "genetic-algorithms",
      "next-js",
      "sagemaker"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Project for Smart Exam Scheduling Category Created by Olivia Wong Juliana Zhang Phoebe Chuang Ryan",
      "Best Project for Smart Exam Scheduling Category Created by Olivia Wong Juliana Zhang Phoebe Chuang",
      "Hack the Student Life 2024WinnerBest Project for Smart Exam Scheduling Category",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/160/284/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Examly - Redefining Exam Scheduling with Genetic Algorithms 💡 Inspiration Exam weeks are notorious for causing unnecessary stress for students and faculty alike. Overlapping schedules, back-to-back exams, and de-centralized planning result in a frustrating experience for everyone. Inspired by the need for a smarter and fairer system, we built Examly—a platform that leverages AWS Sagemaker, S3, and genetic algorithms to optimize exam scheduling for both students and institutions. What it does Examly is an innovative scheduling tool that: Eliminates Exam Conflicts: Our genetic algorithm ensures conflict-free schedules by analyzing course enrollments, room availability, and time slots. Balances Workloads: Students enjoy fair and manageable exam schedules with fewer back-to-back tests and reduced stress. Simplifies Coordination: Professors can book time slots and rooms collaboratively, with real-time conflict detection to streamline the process. How we built it Examly combines cutting-edge genetic algorithms with a sleek, user-friendly interface to deliver a robust solution. Backend: Our genetic algorithm iterates through thousands of scheduling possibilities, optimizing for minimal conflicts, balanced workloads, and institutional constraints. AWS Sagemaker Frontend: Built with React, the interface allows professors and students to interact seamlessly, providing real-time insights and conflict detection. Data Integration: Using real-world course enrollment data, we tested and refined the system to ensure it meets the needs of complex scheduling scenarios. Challenges we ran into Handling multiple constraints while ensuring fairness for all stakeholders was a complex algorithmic challenge.\nDesigning a platform that serves both faculty and students required careful UX/UI considerations.\nScaling the algorithm to handle large datasets while maintaining efficiency took extensive optimization. Accomplishments that we're proud of Achieving perfect conflict reduction in initial "
      }
    ]
  },
  {
    "file_path": "./devposts/ecobc.html",
    "project_id": "ecobc",
    "title": "EcoBC",
    "tagline": "Save Nature By Educating the world about Ecofriendly Nature!",
    "hackathon": "",
    "built_with": [
      "django",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Since there is alot of plastic wastage and Non Biodegradable waste on our land, We came up with an idea to educate people about how to reuse the materials and in how many ways we can reuse by just clicking a photo of that material. So we introduce EcoBC an app that can click on a photo and tells you in how many ways it can be reused, As well as connect people nearby their location who promotes eco friendly nature What it does An user can click on a picture and our app will recognize what the item is based on ML model and displays in how many ways it can be reused, as well as points will also be awarded for each click of picture. These points are given to encourage the users. How we built it We used React, Django, Tensorflow to build frontend, Backend and ML Models Challenges we ran into We found it hard to integrate all 3 of them. Accomplishments that we're proud of We were able to integrate backend with ML Model. What we learned We learnt more about frontend and Backend Frameworks What's next for EcoBC We would like to upgrade our app to next version which is selling eco-friendly products to the users and promote more eco friendly nature. Built With django react tensorflow Try it out GitHub Repo GitHub Repo Submitted to BC Hacks 2022 Created by I worked on the frontend together with Rhea. We were able to build and design pages for the application using React Js. EMEKA ⚡️ Creative Software Engineer, bodybuilder. Daehyung Kwak Manisimha Varma Manthena Private user"
      }
    ]
  },
  {
    "file_path": "./devposts/edurender.html",
    "project_id": "edurender",
    "title": "SmartSwipe",
    "tagline": "Ditch the doomscroll. Scroll more, learn more ✨",
    "hackathon": "",
    "built_with": [
      "appwrite-(database-+-auth)",
      "dall?e",
      "ffmpeg",
      "flask",
      "gemini-api",
      "manim",
      "openai-gpt-4o",
      "pillow",
      "playwright",
      "pymupdf",
      "pysrt",
      "python",
      "quart",
      "swift",
      "swiftui",
      "tavily-api",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Open Source Submission (by Appwrite) + Best Crawler Agent (by Tavily) 👥 Team Name: SmartSwipe Team",
      "+ Best Open Source Submission (by Appwrite) + Best Crawler Agent (by Tavily) 👥 Team Name: SmartSwip",
      "📢 Targeted Tracks → Jury Winner + Best Open Source Submission (by Appwrite) + Best Crawler Agent (by Tavily)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/550/071/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Auto-Generated Educational Shorts: Watch AI-generated videos complete with narration and visuals crafted from academic content in seconds Flexible Content Input: Choose a subject, upload a PDF, or paste an article URL SmartSwipe adapts to your learning preferences and sources Topic Selection Screen: resume learning with \"Recently Viewed\" topics and explore what’s trending across subjects Agent-Powered Web Search: Enter any topic and fetch high quality, relevant articles you can instantly convert into short form videos Auto-Generated Educational Shorts: Watch AI-generated videos complete with narration and visuals crafted from academic content in seconds Flexible Content Input: Choose a subject, upload a PDF, or paste an article URL SmartSwipe adapts to your learning preferences and sources Topic Selection Screen: resume learning with \"Recently Viewed\" topics and explore what’s trending across subjects Agent-Powered Web Search: Enter any topic and fetch high quality, relevant articles you can instantly convert into short form videos Auto-Generated Educational Shorts: Watch AI-generated videos complete with narration and visuals crafted from academic content in seconds 1 2 3 4 5 📢 Targeted Tracks →  Jury Winner + Best Open Source Submission (by Appwrite) + Best Crawler Agent (by Tavily) 👥 Team Name: SmartSwipe Team Profiles: Pratyay Banerjee , Brayton Lordianto Inspiration 💡 In today's fast-paced digital world, students often struggle to stay engaged with dense academic content spread across textbooks, PDFs, and scattered online articles. Traditional learning resources can be overwhelming, time-consuming, and unmotivating especially when compared to the short form, visually engaging content dominating social media platforms. We wanted to reimagine education through the lens of agentic AI. Inspired by the idea that autonomous systems could bridge the gap between serious learning and addictive media formats, we built SmartSwipe : an agent-powered educational platform th"
      }
    ]
  },
  {
    "file_path": "./devposts/eco-future.html",
    "project_id": "eco-future",
    "title": "Eco Future",
    "tagline": "We are a group of teens who are deeply passionate about creating software solutions that aim to bridge the gap between tech and social issues by driving people to recycle through friendly competition.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "css3",
      "flask",
      "html5",
      "jinja",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/005/550/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration ⭐ Our group was trying to come up with ideas, we were jumping in between many because we wanted to do something we were all passionate about and felt needed fixing. That was when we had the idea of climate change and what can we do to maybe help slow it down or potentially stop it in the future. Since climate change littering and etc have been a huge problem for the world that has been an increase especially now of all times. And it’s been treated like a trend. So we decided to dedicate a website to people can you to learn what goes where. And be able to track their eco-friendly growth so hopefully everyone can have a brighter future. And makes sure everyone knows this is not à trend but an actual issue that won’t go away even if we ignore it. Source: https://jamaica-gleaner.com/article/lead-stories/20220611/holness-calls-action-climate-change-mitigation-policies-summit https://www.theweathernetwork.com/ca/news/article/pairing-youths-with-nature-can-form-future-conservation-leaders-group-canada What it does ⚙️ Our website is meant to educate anyone on where to throw stuff out I.E. TRASH, RECYCLE, and COMPOST. Not only that but if you were to make an account on our website you could be able to track how much you did and how that helped the environment. And keep you wanting to grow your eco-skills by seeing how much good you're doing. This will lead to cleaner communities and individually help people lead a better and more eco-friendly lifestyle. And most importantly make people feel more confident in their eco-skills, It will also make them feel like they are making a larger impact. Since the community will have seen a difference and want to participate. How we built it  🔧 We built the backend using flask and python while using cockroachDB as a way to query our data. We used vanilla javascript, html and css for the frontend. Challenges we ran into  🧐 We ran into a lot of challenges because we weren't super familiar with the tech stacks we used, "
      }
    ]
  },
  {
    "file_path": "./devposts/elon-stock-bot.html",
    "project_id": "elon-stock-bot",
    "title": "Elon Stock Bot",
    "tagline": "Using Natural Language Processing and real-time twitter scraping to purchase stocks Elon Musk tweets about!",
    "hackathon": "",
    "built_with": [
      "natural-language-processing",
      "nltk",
      "python",
      "tkinter",
      "twint",
      "yahoo-fin"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/395/672/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Trade made on Investopedia Tweets from our fake Elon Musk Account to test scraper functionality Resulting terminal display and ticker graph from our program Basic component diagram GME jump after tweet (\"The Elon Effect\" from Bloomberg article) Clubhouse jump after tweet (\"The Elon Effect\" from Bloomberg article) Trade made on Investopedia Tweets from our fake Elon Musk Account to test scraper functionality Resulting terminal display and ticker graph from our program Basic component diagram GME jump after tweet (\"The Elon Effect\" from Bloomberg article) Clubhouse jump after tweet (\"The Elon Effect\" from Bloomberg article) Trade made on Investopedia 1 2 3 4 5 6 7 Inspiration Our project's inspiration was driven by the massive stock market influence that is Elon Musk. The idea came to us when Elon Musk tweeted about an coming messaging platform Signal. Immediately the share price for Signal Advance Inc. skyrocketed and the kicker, Signal and Signal Advance aren't the same company. We realized Elon Musk tweeting about certain stocks can generate or destroy millions of dollars - this is our attempt to harness this to power a stock purchasing bot. What it does This application uses Twint to scrape any chosen twitter account every 5 seconds - we then use Natural Language Processing to examine the tweet for companies. then it will compile a list of possible company names. We execute HTTP queries to Yahoo Finance to check for any valid company tickers, and use those to purchase a user-set amount of shares in Investopedia's paper trading stock market. How we built it Included in the images is a component diagram that  displays the structure of our software Challenges we ran into Initially, we wanted to use Tkinter to display most of our information. However, our application needs 2 separate threads to operate - the twitter-scraping, stock-buying thread and the matplotlib data visualization thread There are no open libraries or API's that integrate with Investopedia's paper t"
      }
    ]
  },
  {
    "file_path": "./devposts/elevate-pklvrh.html",
    "project_id": "elevate-pklvrh",
    "title": "Elevate",
    "tagline": "Empowering Homelessness Through Community Crowdfunding and Prioritisation",
    "hackathon": "",
    "built_with": [
      "gemini",
      "google-maps",
      "groq",
      "humeai",
      "nextjs",
      "singlestore",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/090/232/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "System Architecture Landing Page Problem Statement Solution | Features System Architecture Landing Page Problem Statement Solution | Features System Architecture 1 2 3 4 5 Inspiration 🌟 Homelessness remains a growing and complex challenge across U.S. cities, with over 7,200 individuals experiencing homelessness in San Francisco alone in 2024. Family homelessness has risen by a staggering 94% since 2022. This pressing issue inspired us to create Elevate, a platform that goes beyond traditional solutions, offering a direct, transparent, and human-centered approach to addressing homelessness. What it does 💡 Elevate is a crowdfunding platform that connects donors with homeless individuals through personalized profiles and storytelling. Sponsors advocate for individuals, raise funds for essential needs, and provide ongoing updates to ensure transparency and accountability, empowering both donors and homeless individuals to create meaningful, lasting change. How we built it 🔧 Frontend: NextJS, Tailwind CSS, Shadcn Backend: Typescript API Integrations: Gemini (case creation), Hume AI (user communication), Singlestore (data storage), Groq (real-time image descriptions), Google Maps (location services) Challenges we ran into 🚧 One of the biggest challenges we faced was ensuring transparency and accountability for sponsors managing funds. We had to build a robust system for tracking donations, spending, and progress updates, while also balancing the privacy and dignity of the homeless individuals featured on the platform. Additionally, integrating various APIs seamlessly into the platform posed technical difficulties, particularly in handling real-time updates efficiently. Accomplishments that we’re proud of 🏆 We’re incredibly proud of creating a platform that personalizes the homelessness experience, giving a voice to individuals through their stories and enabling real-time impact updates. Our integration of AI technologies for storytelling and real-time image descriptions a"
      }
    ]
  },
  {
    "file_path": "./devposts/edupal-nzu65w.html",
    "project_id": "edupal-nzu65w",
    "title": "EduPal",
    "tagline": "Enabling cross-cultural interaction across the world",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "html5",
      "javascript",
      "node.js",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/241/597/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Chat from Kevin Nguyen's perspective Login page. Server handles successful/failed login attempts. Chat from James Bond's perspective Chat from Kevin Nguyen's perspective Login page. Server handles successful/failed login attempts. Chat from James Bond's perspective Chat from Kevin Nguyen's perspective 1 2 3 Inspiration The first pen pal program began in 1936, as a way for students from different parts of the world to connect and learn about each other’s cultures. The almost century-old program has surprisingly gone through no major changes. This is what led us to create EduPal. What it does EduPal utilizes modern design concepts and habit formation methods to provide a fun and engaging experience to today’s students. Our goal is to promote global interconnectedness and diversify learning modes in today’s educational climate. The first iteration uses a chatbox interface to facilitate communication. Users can send messages to their \"partners\" and learn about each other. Each day a new message will be sent to each user prompting them to talk about the topic of the day. How we built it We built it using HTML, CSS, JavaScript, and node.js (express + socket.io). The user loads up the HTML page, which uses socket.io to communicate with the server to login. Challenges we ran into We had to decide whether to save separate message logs for each user or to share one log between two students. We opted for the separate approach because it allows personalized instructor feedback. We had trouble formatting our message log chat bubbles, especially with regards to left-right alignment. Because we used chat bubbles as opposed to a terminal style chat, we had to store the chat as an array of messages instead of just a string. Accomplishments that we're proud of We created a user interface that connects people across the world. What we learned Three members of our group were unfamiliar with javascript prior to the project. By the end, everyone had a grasp of how javascript was used to "
      }
    ]
  },
  {
    "file_path": "./devposts/emomi.html",
    "project_id": "emomi",
    "title": "emomi",
    "tagline": "Help nonverbal children express their emotions through music!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "keras",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Rock-n-Roll Hack Created by Christian Mina Renz Vital Chantal Pino",
      "Do-Re-Mi Hacks 3WinnerMost Rock-n-Roll Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/291/438/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration We wanted to create an application that helped nonverbal children or children with autism communicate their emotions through music. It acts as a kind of music therapy and helps us show our support and solidarity to children who want to express themselves but cannot. What it does Emomi is an application that helps nonverbal children express their emotions through music. We chose the piano to represent specific emotions and a blob-like friend shows up to help children specify the emotion. Every time a child clicks on a note/emotion, their input is stored under the hood so that parents can track their child's emotions.  There's also a speech-to-text feature where the child is able to verbalize their emotion through limited sentences and is easily visualized for parents to see. How we built it We built our UI using vanilla JS, HTML, and CSS in order to create our UI, flask, and python for the skeleton of the app and Keras and TensorFlow for the text-to-speech feature. Challenges we ran into We had never used TensorFlow and Keras before to create both a sentiment analysis model and a text-to-speech model for our app. It took a lot time and trial and error Accomplishments that we're proud of We're proud of making the music and illustration ourselves What we learned How to convert speech-to-text and make programming enjoyable while making a good impact to others. What's next for emomi Better ui and mobile responsiveness. Built With css flask html keras python tensorflow Try it out GitHub Repo Submitted to Do-Re-Mi Hacks 3 Winner Most Rock-n-Roll Hack Created by Christian Mina Renz Vital Chantal Pino"
      }
    ]
  },
  {
    "file_path": "./devposts/dsv.html",
    "project_id": "dsv",
    "title": "ReLive – Revolutionizing Your Memories into NFTs!",
    "tagline": "Transform photos into exclusive NFTs! Upload any image, add details, and own a digital piece of your past. Embrace the future of memories with blockchain authenticity. #ReLiveNFTs 🌐🖼️💎",
    "hackathon": "",
    "built_with": [
      "1inch",
      "avalanch",
      "avalanche",
      "caldera",
      "css",
      "css3",
      "docker",
      "html5",
      "javascript",
      "keras",
      "next.js",
      "node.js",
      "python",
      "react",
      "solidity",
      "tailwind",
      "tensorflow",
      "together.ai",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/776/043/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Problem Statement Background:\nIn our increasingly digital world, the desire for meaningful connections and learning from past generations has never been stronger. Despite the wealth of information available online, individuals often feel disconnected from history, cultural heritage, and, most poignantly, loved ones who have passed away. Studies show that about 43% of adults suffer from loneliness, which is compounded by the loss of meaningful interactions with those who have inspired or influenced them, whether family members or historical figures (source: Cigna U.S. Loneliness Index). Furthermore, the digital age has brought about a resurgence in interest in personal history and learning from the lives of those who have shaped our world. However, traditional methods of engagement and learning lack the interactivity and personal connection that modern audiences seek. Additionally, there's a growing demand for secure and respectful ways to connect with the past, with 78% of internet users expressing concern over the security and privacy of their online interactions (source: Pew Research Center). The Need for Innovation:\nCurrent digital platforms and social media offer limited opportunities for meaningful and educational interactions with the personas of historical figures, celebrities, or deceased loved ones. There's a significant gap in the market for a platform that allows for deeply personalized, interactive, and secure connections with these figures. The ability to \"speak\" to a representation of Albert Einstein, for example, and receive tailored advice or insights, or to have a conversation with a digital persona of a deceased relative, could revolutionize the way we learn from and remember influential figures in our lives. Security and Ethical Concerns:\nEngaging with the personas of those who have passed away or public figures raises significant security and ethical considerations. Ensuring the privacy, accuracy, and respectful representation of "
      }
    ]
  },
  {
    "file_path": "./devposts/edutracker-kfpj0v.html",
    "project_id": "edutracker-kfpj0v",
    "title": "EduTracker",
    "tagline": "Fast tracking your education to success",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "fastapi",
      "scikit-learn",
      "typescript",
      "uvicorn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Participation Prize Created by I worked on the front-end using the Angular Framework",
      "Fast tracking your education to success",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/194/406/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Mark Predictor Landing Page Resource Hub Mark Predictor Landing Page Resource Hub Mark Predictor 1 2 3 4 Inspiration: As students that spend most of our day at school and study whenever we get a chance, we depend on good grades in order to judge our academic success. However, unlike a physical manifestation, our future grades are very difficult to predict. With no guarantees as to what our future marks may be, we are left with stress and anxiety until we wait until long after the exam or test is completed to receive our marks. After being left in the dark for so long, this built up stress can lead to mental health issues. We wanted to solve this issue by giving a way for students to not have to worry about their test scores round the clock, and be able to study more effectively. In order to ease the burden of students and help improve their in person learning experience by helping them study, we created EduTracker. What it does EduTracker is a real time prediction and cheat sheet to mitigating the stress involved in schoolwork and fast tracking your way to success with in-person learning. Our real time prediction tool uses state of the art machine learning models, trained with a dataset with hundreds of thousands of student grades, to help students accurately predict their next grades. EduTracker also doubles as a resource hub, providing collaborative and note-taking learning tools to augment the in person learning experience. We also provide tutoring support for students in need of guidance for studying. How we built it For our front-end, we used the Angular framework (wrapped in HTML/CSS) along with a few libraries such as Angular Flex-Layout and Angular Material. For the back-end, we used typescript to relay messages across the full stack, and to communicate with the machine learning API, a fastAPI endpoint deployed using Uvicorn. The API allows simple requests with just a single line of code. Both the web application and the API endpoint were deployed on an Azur"
      }
    ]
  },
  {
    "file_path": "./devposts/eve-k65nsa.html",
    "project_id": "eve-k65nsa",
    "title": "Eve: Autonomous Navigation for Environmental Sustainability",
    "tagline": "Your on-demand environmental inspector, delivering real-time data for a cleaner world.",
    "hackathon": "",
    "built_with": [
      "docker",
      "ev3",
      "flask",
      "gcloud",
      "gemini",
      "next.js",
      "python",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Environmental Hack Created by Prashanth Reddy Shyamala Kashish Mittal sarvaSanjay Sanjay Aina Merch",
      "Hack the 6ix: Best Environmental Hack Created by Prashanth Reddy Shyamala Kashish Mittal sarvaSanja",
      "Hack the 6ix 2024WinnerHack the 6ix: Best Environmental Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/975/677/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "EVE Robot EVE Robot EVE Robot 1 2 Inspiration Inspired by the vision of Eve from WALL-E, EVE is our answer to a world demanding sustainable spaces. We imagined a robot that could meticulously assess building health, just as Eve analyzed Earth's viability. What it does Eve is a cutting-edge robot that assesses your building's environmental performance based off of LEED , BREEAM , and ISO 14001 standards. The robot enabled with IR-motion detection navigates throughout your urban-building and captures image data which is processed using generative-ai to provide a comprehensive report of your building's sustainability. How we built it We started with a LEGO Mindstorms EV3 robot, interfacing it with an NVIDIA Jetson for advanced computational capabilities. To enable autonomous navigation, we integrated a Luxonis AI camera that captures high-definition images, which are then sent to a hub using async sockets for fast real-time data transmission. These images are analyzed using Google Gemini to generate a comprehensive environmental report. Throughout the process, we focused on developing robust concurrency, efficient socket communication, and precise localization and mapping techniques. Challenges we ran into Building EVE came with its set of challenges. Integrating different hardware components and ensuring seamless communication between them required extensive debugging. Implementing real-time data processing while maintaining accuracy was another hurdle. Additionally, perfecting the robot's navigation and localization within various building environments demanded meticulous calibration and algorithm refinement. We also planned to integrate audio and speech onto the robot but the speaker/microphone turned out to be incompatible with our microcontroller. Accomplishments that we're proud of We successfully created a fully autonomous robot capable of navigating complex indoor environments while collecting and analyzing environmental data in real time. Our integration of hi"
      }
    ]
  },
  {
    "file_path": "./devposts/en-ft.html",
    "project_id": "en-ft",
    "title": "EN-FT",
    "tagline": "NFTs to incentivize environmental action.",
    "hackathon": "",
    "built_with": [
      "deso-protocol-library",
      "domain.com",
      "figma",
      "javascript",
      "velo",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Top 5 Business Solutions Winner Technical Demo Winner Best Domain Name from Domain",
      "Best Use of Velo by Wix Created by Edison Qu rule the world Stephen Ni Diana L Sarah Kwak",
      "The GoldenHack 4.0WinnerTop 5 Business SolutionsWinnerTechnical DemoWinnerBest Domain Name from Domain.comWinnerBest Use of Velo by Wix",
      "🌐 Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/240/252/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Composing Page (Compose your own opportunity!) Logo Hero Page Implementation with DeSo Opportunities Page (Browse available opportunities) Opportunities Info Page (More detailed profile on opportunity) DeSo Login Collections Page (Collection of owned EN-FT's) Composing Page (Compose your own opportunity!) Logo Hero Page Implementation with DeSo Opportunities Page (Browse available opportunities) Opportunities Info Page (More detailed profile on opportunity) DeSo Login Collections Page (Collection of owned EN-FT's) Composing Page (Compose your own opportunity!) 1 2 3 4 5 6 7 8 9 💡 Inspiration We can all agree that people who go out of their way to care for the environment are good people. However, none of them are truly rewarded for their actions, which are soon forgotten. We believe that these small actions should be remembered and praised. This is why we created EN-FT. Though not much, we wanted to offer an NFT as a sort of novelty to these amazing individuals. After a while, the user would be able to look back at all of the good deeds they’ve done and feel great about it! Additionally, we want to encourage others to become environmentally friendly by gamifying their experience by adding collectables.## What it does 🔍 What it does Our program allows users seeking to help the environment effectively find volunteering opportunities to do so. We also preserve the action through EN-FT's so good deeds are never forgotten! First, we used DeSo Login to implement the authentication. After the user has signed in, they are brought to the dashboard where they can browse through various volunteering opportunities posted by individuals and organizations. Once a user has completed the task, they will be awarded an EN-FT. The user can then recall their accomplishments by looking at their collection of EN-FT’s. Additionally, users can also post their own volunteering opportunities to find passionate volunteers enthusiastic to help save the world! ⚙️ Tech Stack We prototyped on Fig"
      }
    ]
  },
  {
    "file_path": "./devposts/evmelectric.html",
    "project_id": "evmelectric",
    "title": "EVMElectric",
    "tagline": "Electrifying simple DAO for crowdsourcing charging stations",
    "hackathon": "",
    "built_with": [
      "fastify",
      "flow",
      "hedera",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Flow Created by Jerry Zhu CS @UWaterloo | Retired | Fanatic Organizer",
      "Hack The ClassroomWinnerBest Use of Flow",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/576/419/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Electric vehicles are a common argument in the sustainability world. Although they are more environmentally conscious than gasoline vehicles, finding a charging station is often very difficult, and may offset the cost of actually having one in the first place. With our app, we hope to foster the next generation of electric vehicles. What it does Introducing ElectricEVM, a web application that allows users to crowdsource charging stations using a DAO in order to complete purchases. Users are able to add charging stations, view existing stations on a map or web view, and view charging stations. They're able to perform wallet based activities, like view wallet balances, mint NFTs, or run smart contracts with emulation. This done through our Fastify APi, and emulators like Flow emulator, Hardhat, and Hedera Testnet. They can also interact with a Voiceflow LLM, which will answer any questions about our app, or sustainability/blockchain related questions. \nWe used blockchain principles with Hedera, Flow, and Verbwire in our application. We used the Hedera Consensus Service to log payments, the Hedera HBAR wallet using the SDK to validate balances and create crypto payments, and the Hedera File Service (HFS) to upload and download files (from the Fastify API). \nWe used Flow's emulator and playground to mint and deploy NFTs (translated from Solidity to Cadence) to the Flow blockchain, using flow wallets, as well as a service to help new users onboard and mint NFTs. Next, Verbwire is used to take this metadata and send it cross chain to other chains, so it can be viewed on Opensea. How we built it We used Streamlit & Matplotlib for our frontend application, and Node.JS & Typescript for the backend. We used the Verbwire API, Hedera SDK, and Flow Emulator, as well as Hardhat and Alchemy to deploy Solidity scripts. We used Fastify and Flask for the backend endpoints, connecting it together with Axios and requests . We used Voiceflow and GPT-4 to train a Q&"
      }
    ]
  },
  {
    "file_path": "./devposts/empower-us-y1dcxw.html",
    "project_id": "empower-us-y1dcxw",
    "title": "Empower Us",
    "tagline": "Create events, meet up, play games, and do much more on Empower Us!",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "firebase",
      "node.js",
      "python",
      "react",
      "replit",
      "tailwind",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Google Cloud Global Hack Week: INIT 2023 Day 7 Created by Sarvesh Madullapalli Full Stack De",
      "Best Use of Google Cloud Global Hack Week: INIT 2023 Day 7 Created by Sarvesh Madullapalli Full Sta",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/882/154/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Event Page Sign Up Page Event Page Sign Up Page Event Page 1 2 3 ☁️ Inspiration Everyone needs a place to interact and connect. So many people try to find good places, but get even more put down. Our website aims to empower people by spreading positive events and providing all the necessary software. 🚧 What It Does Our website provides meeting software for people to gather. The UI is very simple to use. In addition to that, you can create events. Events have various pieces of information to help people learn more. They can even like and share it! 🛠️ How We Built It We used many technologies to build it. For sponsor specific things, check the sponsors section below. For the backend, python/flask was used. All of it was hosted on replit. Node.js was used for the frontend, specifically tailwind, react, and next.js. 👨🏾‍💻 Challenges We Ran Into We ran into numerous issues. Our react components were not working, and we ran into many compilation issues. In the backend, flask (python) kept returning a untraceable error. In addition to code, one of our team members was in India, so communicating with him was hard. In the end, everything was solved. 📝 Accomplishments That We're Proud Of We actually finished the project...yay! We fixed both the frontend and backend, though they were causing a lot of errors. The final styles of the website were simple to use, which we wanted them to be. 📙 What We Learned We learned many things. We expanded our knowledge in react and tailwind. In flask, we ran into many errors which we had to solve. Finally, we used the sponsor's services well. 🔜 What's Next For Empower Us There was a lot we could improve on. The mobile styles were not good, and the navbar needed fixing. Some react components had weird placement. In all, we can fix the project, which we will in the future. 🏢 Sponsors Google Cloud - We used google cloud for 2 main things. The first was authentication. We used firebase for the authentication, using google auth via a pop up window."
      }
    ]
  },
  {
    "file_path": "./devposts/environmentgo-bka48z.html",
    "project_id": "environmentgo-bka48z",
    "title": "EnvironmentGo",
    "tagline": "A competitive, environmental treasure hunt app  prompting users to discover local plants and win prizes.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "jinja",
      "python",
      "sqlite",
      "tailwind",
      "urllib"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A competitive, environmental treasure hunt app prompting users to discover local plants and win prizes."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/254/167/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Main Page Challenges Identified Species Logo Main Page Challenges Identified Species Logo 1 2 3 4 💡 Inspiration 💡 Nature photography is one of the most effective ways that the beauty of nature is shown to the public - and we were inspired by how nature photography contests both encourage the photographers to capture the diversity of the world, and provide people with a glimpse of it. A big problem, however, is the cost of entry: while photos can look deceivingly simple, it can be discouraging to the average person who can't afford expensive cameras, or spend weeks taking the perfect photo. With a little bit of help from technology, we can gamify hiking and exploring and help create our own competitions! By encouraging our users to go out, explore, and capture the flora of their surroundings with their own natural beauty contests, we can help them learn more about their local wildlife, developing a greater appreciation for nature! ❓ What it does ❓ Environmental Go strives to serve the ecosystem and environment by encouraging its users to go outside and explore a variety of species. Through weekly challenges, it encourages its users to take and upload pictures of plant species from the challenges, which are then checked for accuracy and counted towards the user's scores. At the end of each week, the top users on the leaderboard receive incentives as a form of reward. 🏗️ How we built it 🏗️ The project was built mainly using HTML/JS/CSS. The backend of the web application was made using Flask, Jinja and SQL. The frontend was made using Tailwind.css. User authentication was implemented by cross referencing from our data base, then storing user data such as images, scores, leaderboard standings and image data. The application was displayed as webpages with Jinja templating language and lastly the species classification was done through API calls handled with Flask. 🚧 Challenges we ran into 🚧 The biggest challenge that we ran into during development was communication:"
      }
    ]
  },
  {
    "file_path": "./devposts/eyeballin.html",
    "project_id": "eyeballin",
    "title": "EYEBalliN",
    "tagline": "Slam Dunk 🏀 in the blink of an 👁️",
    "hackathon": "",
    "built_with": [
      "ai",
      "chart.js",
      "facemesh-api",
      "javascript",
      "numpy",
      "opencv",
      "qoom",
      "spotify",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Judges' Prize hACCESS 2021 Slam Dunk Hacks Winner First Overall Winner Best Domain Name from GoDadd",
      "hACCESS 2021 Slam Dunk Hacks Winner First Overall Winner Best Domain Name from GoDaddy Registry [AP",
      "PeddieHacks 2021WinnerJudges' Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/631/557/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 Inspiration 💡 The Coronavirus outbreak has caused major disruptions to our daily lives. Currently, the fear of the third wave has imposed lockdown in several countries. Changes in social dynamics due to local restrictions immensely impacted human behavior and are making humans lethargic. According to nimh.nih.gov , the same has resulted in an over 50% increase in the number of people affected by Attention Deficient Hyperactivity Disorder (ADHD) which is a matter of great concern! The most affected ones are specially-abled people as well as children. The current scenario in fact acts as a catalyst & results in low-esteem , lethargy , limited attention span , hyperactivity , and even can cause paralysis . We believe that with the power of AI, this can be solved if proceeded creatively. Thus we made EYEBalliN ! What it does 🤔 EYEBalliN' is a single-player TPF (Third person View) game based on Tensorflow.js, where users can aim and shoot the basketball into the hoops with the blink of an eye! Using cutting-edge technologies, we are bringing the fun of playing basketball 🏀 to your doorstep. You just need to wait and target a hit at the proper angle and wink! Boom, you will get the shot! Also, for people who just want to play the game for fun, there is an option to hit spacebar , and the ball shoots. 🎯  And also not to mention, we also added some Easter Eggs inside this game! 😉 Just visit keep-balling-with.us on your PC 💻 & slam! How we built it ⚙️ EYEBalliN' is crafted with ❤️. EYEBalliN' is primarily a Javascript-based Webapp, running on Tensorflow.js which segments the eyes from the face under the hood and tracks the user's face to detect winks and log the current session segmented upon various factors. In the beginning, the video-feed is processed via TFjs's face-API for facial detection. Then we sample the stream into distinct frames to extract few metadatas like — Facial Landmarks & Expressions. Furthermore, on those sampled frames, we apply OpenCV.js "
      }
    ]
  },
  {
    "file_path": "./devposts/emergency-for-merge-2021.html",
    "project_id": "emergency-for-merge-2021",
    "title": "Emergency! for MERGE 2021",
    "tagline": "Emergency! is an app which provides interactive step-by-step instructions for a variety of emergency situations. With this app in your back pocket, you will always know what to do when trouble arises.",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/451/208/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We would like to ask you a question: can you remember all of the steps for what to do if somebody suffers a sudden cardiac arrest right next to you? Emergency! was inspired by the worrying prevalence of negative outcomes in emergency situations within our society. Even in the personal lives of our team members, we hear about people who suffer injury or even death because the people surrounding an emergency situation do not know how to act when a threat suddenly appears. This unfortunate norm has been created by societal and socio-economic barriers to First Aid and Emergency education. We firmly believe that all members of society should have access to a tool which easily guides them through an emergency situation—so we built it. What it does Emergency! is a mobile Android app which serves interactive, step-by-step instructions on what to do in an emergency situation. If a person believes that they have found a Cardiac Arrest victim for example, they can select the Cardiac Arrest option in our app. This will provide them with comprehensive yet easy to understand instructions on what to do. In the case of Cardiac Arrest, the app will instruct the user to check the safety of the area before approaching the victim. From there, it instructs the person on how to help, even if they lack previous formal training. Our app features additional innovative features such as 3D modelling and animation to show the first responder exactly how to act or help. For example, if the user doesn't know how to locate the correct place to apply chest compressions during CPR, the app can display a 3D animation on where to place your hands and fingers to landmark a victim's chest. Virtual features like these are missing from any sort of application available today, and we believe that educational and concise demonstrations using modelling can truly impact the outcomes of emergency situations. Users can also call for emergency services from the app, or access a metronome"
      }
    ]
  },
  {
    "file_path": "./devposts/evee-qexm4b.html",
    "project_id": "evee-qexm4b",
    "title": "EVEE",
    "tagline": "We are a realtime browser web application that grabs live diagnostic data from a connected vehicle and provides information on charging stations and efficiency through a beautiful interface.",
    "hackathon": "",
    "built_with": [
      "daisyui",
      "python",
      "react",
      "samsara",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Auth0 Created by vatsalananthula Ananthula Sreya Muppalla Jess Edmund Fan Fiorina Chau",
      "LA Hacks 2023WinnerBest Use of Auth0",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The market for electric vehicles is one of the fastest growing global market segments, with commercial and personal viability of using them growing rapidly. However, despite significant investments in infrastructure and improving technologies underpinning electric vehicles, drivers both new and old remain hesitant adopt this new drivetrain full-time due to some looming questions whenever they hit the road.\nSome of these questions include:\nWhere should I stop and charge to reach my destination in the least time possible?\nWill I have enough range to reach a charger based on how I’m currently driving?\nWill the charger(s) be working when I get to it?\nAre there enough free charging handles at the charger / are the chargers full?\nIf the chargers are full and there is a line, how many people are in front of me?\nIs it worthwhile to leave?\nIs my vehicle ready to accept a charge at its maximum speed?\nIs the battery below a certain threshold to maximize charging efficiency?\nIs the battery temperature between 70f and 80f?\nIs the charger’s rated speed above the rated speed of the vehicle? What it does Our project is a browser-based web application that captures vehicle diagnostic data from commonly available hardware devices. We track key metrics about the vehicle and display this information in a seamless frontend while tracking the vehicles efficiency and how much CO2 it saves among other useful data points. Most significantly, we also predict the optimal route for a vehicle to take from one destination to another to ensure it finds chargers at the optimal times. How we built it We used React for the frontend and Flask for the backend. Challenges we ran into We had issues working with APIs to integrate the data. The geopy library was very slow. Endpoints were also quite messy to work with. As our software is composed of multiple intricate parts it was challenging to do integrations in a production environment. Accomplishments that we're proud of We are proud of bui"
      }
    ]
  },
  {
    "file_path": "./devposts/expresso-9inhuw.html",
    "project_id": "expresso-9inhuw",
    "title": "Expresso",
    "tagline": "Automating your Adobe Express workflow",
    "hackathon": "",
    "built_with": [
      "adobe-creative-sdk",
      "flask",
      "pytorch",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the 6ix 2024WinnerHack the 6ix: 3rd Place",
      "Develop advanced analytics to track post performance and refine optimization strategies",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/976/744/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration In today's fast-paced digital world, creating engaging social media content can be time-consuming and challenging. We developed Expresso to empower content creators, marketers, and businesses to streamline their social media workflow without compromising on quality or creativity. What it does Expresso is an Adobe Express plugin that revolutionizes the process of creating and optimizing social media posts. It offers: Intuitive Workflow System: Simplifies the content creation process from ideation to publication. AI-Powered Attention Optimization: Utilizes a human attention (saliency) model (SUM) to provide feedback on maximizing post engagement. Customizable Feedback Loop: Allows users to configure iterative feedback based on their specific needs and audience. Task Automation: Streamlines common tasks like post captioning and scheduling. How we built it We leveraged a powerful tech stack to bring Expresso to life: React: For building a responsive and interactive user interface PyTorch: To implement our AI-driven attention optimization model Flask: To create a robust backend API Challenges we ran into Some of the key challenges we faced included: Integrating the SUM model seamlessly into the Adobe Express environment Optimizing the AI feedback loop for real-time performance Ensuring cross-platform compatibility and responsiveness Accomplishments that we're proud of Successfully implementing a state-of-the-art human attention model Creating an intuitive user interface that simplifies complex workflows Developing a system that provides actionable, AI-driven insights for content optimization What we learned Throughout this project, we gained valuable insights into: Adobe Express plugin development Integrating AI models into practical applications Balancing automation with user control in creative processes What's next for Expresso We're excited about the future of Expresso and plan to: Expand our AI capabilities to include trend analysis and content rec"
      }
    ]
  },
  {
    "file_path": "./devposts/example-yjtxbk.html",
    "project_id": "example-yjtxbk",
    "title": "Example",
    "tagline": "This is for testing",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Test What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Example Built With python Created by David Wang"
      }
    ]
  },
  {
    "file_path": "./devposts/environment-hero-can-you-save-the-world.html",
    "project_id": "environment-hero-can-you-save-the-world",
    "title": "Environment Hero | Can you save the world?",
    "tagline": "A Game that is set in a dystopian future which shows the possible effects of Global Warming,Water Pollution etc!",
    "hackathon": "",
    "built_with": [
      "alexa-skills-kit",
      "ask",
      "html",
      "node.js",
      "twine"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/679/996/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration We were inspired to create this game to show the effects of Global Warming,Water Pollution and Air Pollution along with other less aware environment damaging factors. With all of these factors we created a story that really highlights what could happen if we continue to damage the earth at the current rate. What it does It is a interactive story game where the user (You!) Navigate trough a dystopian future where the world we know of has broken down. You have to try find Food , Water and essential resources to survive, Trough your exploration - You will learn new facts about our environment and Mini Games to make a (small but important) impact to the environment you live in - It could be a quick task as recycling some stuff instead of sending it to the landfill but it could also be a longer term task of 'banishing' plastics from your daily routine. Our idea is for you to eventually reduce your impact to the environment thus Improving it (a Marginal reduction has a large impact!) How we built it We built it using JavaScript and Alexa Developer Templates, We heavily modified a base template by adding features such as Checkpoints , Adding Arrays for our statistics and then calling them and then adding saving features along with the story , We also modified the code extensively with some Minor feature adds which overall adds to a unique and innovative experience unique to Environment Hero. We also integrated DB's to manage data from our users which involved us learning how dynamoDB works! (Our First ever time using dynamoDB!!) Challenges we ran into Coming up with a story was difficult - The paths we made were very separate and merging them to other parts of the story was exceptionally difficult. In the end we decided to have the story path multiple different ways with Different endings. Debugging - Consistently through development we encountered errors either from Lambda or the ASK Simulator. Through lots of Googling and scavenging trough our code, We ma"
      }
    ]
  },
  {
    "file_path": "./devposts/everything-calendar.html",
    "project_id": "everything-calendar",
    "title": "Everything Calendar",
    "tagline": "Like the everything bagel, but for your day :)",
    "hackathon": "",
    "built_with": [
      "certbot",
      "cloudflare",
      "docker",
      "kubernetes",
      "next.js",
      "nginx",
      "oracle",
      "python",
      "react",
      "resend",
      "supabase",
      "tailwind",
      "terraform",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/148/053/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "landing page overview of personalized calendar pop up to sync platforms to calendar pop up to add events landing page overview of personalized calendar pop up to sync platforms to calendar pop up to add events landing page 1 2 3 4 Inspiration As university students, we have noticed that too many people spend hours manually inputting their courses, appointments, and events into calendars (including ourselves). While some software can generate calendars for specific platforms, they often don’t support integration across multiple sources like D2L, Google Calendar, Instagram etc. So, how can we save everyone time? By creating a calendar website that syncs events from various platforms automatically! What it does The website has a login system that allows users to make their own personalized calendar, giving the option to sync club events from instagram, courses on d2l, hackathons from devpost, and ics calendar files. Like all calendars, there are also options to add and delete your own events to your personalized calendar. How we built it The frontend is hosted on Vercel and written using React and Next.js. We used typescript for the react components and a mixture of css and tailwind to style the different components/pages. For the database, we used Supabase to store information regarding the user’s username, password, and events in their personalized calendar. Backend is hosted on oracle as a virtual machine. We purchased a .org domain and used CloudFare and NGINX to open and route between ports/IP addresses. When changes are pushed to the database, the real time function will detect these changes and send them to the backend. The backend will then use this information to determine what information should be updated in the database and subsequently sent to the frontend. We also wrote our own APIs with python to scrape devpost, instagram, d2l, and ics files to sync the information obtained from these pages to the calendar. Challenges we ran into One challenge we ran int"
      }
    ]
  },
  {
    "file_path": "./devposts/echoo.html",
    "project_id": "echoo",
    "title": "Echoo",
    "tagline": "Over 285 million people suffer from blindness worldwide unable to navigate. Echoo provides the visually impaired with affordable echolocation to navigate their surroundings easily and effectively.",
    "hackathon": "",
    "built_with": [
      "battery",
      "battery-circuit",
      "buzzer",
      "esp8266",
      "ibm-cloud",
      "motor-driver",
      "node-red",
      "node.js",
      "python",
      "ultra-sonic-sensors",
      "wires"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/915/340/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration Our goal was to impact a community of people in the world in a big and positive way. We found a problem missing a proper solution, the visually impaired community. The visually impaired community did not have proper access to emerging assistant technology that is both affordable and accessible. What it does The greatest inventions throughout humanity's history have always been based on the adaptation that animals have around us. Example: Birds and Planes. Whales, dolphins and bats all use Ultrasonic waves to navigate and communicate. Unfortunately, thus far no major efforts have been made to replicate these concepts until now. Echoo is a light weight stick-device equipped with ultrasonic sensors and vibration motors that will assist visually impaired individuals to navigate, avoid obstacles, and perform everyday tasks with a sense of what is around them. The Echoo device acts like a personal radar, always alerting the user of what is around them in real-time. How we built it There are both hardware and software components equipped to the Echoo device. Hardware: consists of a ESP8266 microcontroller, one ultrasonic sensor, a vibration motor, battery, and charging circuit. With all these components, the ultrasonic sensor is commanded by the microcontroller through Python code to repeatedly sense the surroundings. If an object is within the sensitivity range, the microcontroller will command the vibration motors to vibrate at varying intensities. Software: using IBM Cloud, and a Node-Red server, runs a web-based application that controls the sensor sensitivity. The web-based application and microcontroller communicate through MQTT protocol. Syntax for sensory of object in range (in Micro-Python): from hcsr04 import HCSR04\nfrom machine import Pin\nimport time sensor1 = HCSR04(trigger_pin=16, echo_pin=5) front = Pin(14, Pin.OUT) while True: distance1 = sensor1.distance_cm()\n\n    print('Distance Front:', distance1, 'cm')\n\n    if distance1 == -0.0171"
      }
    ]
  },
  {
    "file_path": "./devposts/ecolink-wkyuco.html",
    "project_id": "ecolink-wkyuco",
    "title": "EcoLink",
    "tagline": "What if all local/expert in every city worked on improving your projects? We provide a platform for city projects that address climate challenges.",
    "hackathon": "",
    "built_with": [
      "django",
      "openaiapi",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/455/516/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We all want to make our world a better place, and assisting one another is the key to making a difference. The idea for EcoLink arose from seeing the world's present climate state with a great deal of awareness but nothing in a tangible method that could really start taking steps and acting at least a little bit towards a better world. And this is where Our website comes in, assisting you in taking the initial step, in which locals and expert work hand in hand with businesses to reach the climate target. What it does A platform where companies post the problems that act as a hindrance to achieving climate goals with the current industry's resources in the marketplace of our website, and the locals and experts of that city will be involved and help in teams to propose the solutions and figure the resources, after the assessment the result will be visualized by the company's jury in terms of achievability with their resources and the best project with the most climate impact will be picked, with the goal check supplied for others to witness the execution. This will also assist the corporation retain transparency in terms of its role in climate challenges, allowing them to achieve more efficiently.\nWe have also implemented the feature of AI judge report generator, which offers a summarized report to the company's jury providing with feasibility, Advantages and disadvantages on implementing the suggest feature. Our application acts as a bridge to connect citizens who are experts in local issues but not in project planning to produce and plan project ideas for local city development that are directly linked to the industries/companies where the ideas are executed. We will charge a little fee from the company's registered to make the project planning operate successfully. And they'll be pleased to register since it will help them become more visible in their response to climate change. How we built it frontend: React\nbackend: Django Challenges we ran into It w"
      }
    ]
  },
  {
    "file_path": "./devposts/eyec-6egat2.html",
    "project_id": "eyec-6egat2",
    "title": "EyeMAP",
    "tagline": "Help people with visual impairment navigate through the interiors of buildings.",
    "hackathon": "",
    "built_with": [
      "css3",
      "fastapi",
      "gcp",
      "gcp-tts",
      "html5",
      "javscript",
      "nextjs",
      "opencv",
      "python",
      "voicerecognition"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/024/726/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Tech Tree Hacker wearing eyemap headgear for surrounding detection Hacker wearing eyemap headgear for surrounding detection Eyemap identifying objects in surroundings Eyemap route #1 with MappedIn Eyemap route #2 with MappedIn Eyemap route information Eyemap code Tech Tree Hacker wearing eyemap headgear for surrounding detection Hacker wearing eyemap headgear for surrounding detection Eyemap identifying objects in surroundings Eyemap route #1 with MappedIn Eyemap route #2 with MappedIn Eyemap route information Eyemap code Tech Tree 1 2 3 4 5 6 7 8 9 ⁉️ Why? In 2020, there were 43.3 million blind individuals and 295 million people with Moderate or Severe Visual Impairment (MSVI) worldwide. Navigating large, complex buildings can be overwhelming for those with visual impairments, limiting their independence. Existing tools like canes or guide dogs are helpful but can't provide detailed, real-time navigation in indoor spaces. EyeMap was created to address this gap, offering a tech-driven solution that empowers visually impaired users to navigate confidently and independently through voice guidance and object recognition. 🌟 Inspiration We often get lost in large, complex buildings like E7 🏢, and it made us wonder 🤔 how visually impaired individuals handle such situations without assistance. This challenge inspired us to create a solution that empowers them to navigate independently, providing real-time guidance and object recognition to simplify their experience in unfamiliar environments. 🧭 What it does EyeMap is an accessory that \"sees\" 👁️ the world around you. We created the AI agent \"Joe,\" which provides voice-guided navigation 🗣️, helping users move through complex buildings by detecting obstacles 🚧 and describing what's in front of them. It is also able to accurately detect people. Whether it’s understanding the space around them or navigating to hard to find areas, EyeMap offers a seamless experience for users to navigate independently. 🛠️ How we built it We deve"
      }
    ]
  },
  {
    "file_path": "./devposts/evbuddy.html",
    "project_id": "evbuddy",
    "title": "EV Buddy",
    "tagline": "Most Reliable EV Charging Station Finder with Rewards on the Go",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "google-cloud-apis",
      "javascript",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/208/281/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Workflow Map of Stations Submit Updates for Station Route Stations Loyalty Page Workflow Map of Stations Submit Updates for Station Route Stations Loyalty Page Workflow 1 2 3 4 5 Inspiration Zach took a wee road trip to America in the deep Everglades of Florida using an EV, but he, unfortunately, experienced nothing but headaches :( . Current apps were often outdated, and stations that were reported alive were either degraded or out of service. Our team wanted to save little ol' Zach from range anxiety and general fear of EVs, so we created EV Buddy. What it does EV Buddy is inspired by Gas Buddy to crowdsource the most recent data about charging stations. We automatically get info about charging stations and let users report their conditions. By gathering data about the reliability and accuracy of charger conditions, consumers can be confident about their charging situations. We provide manufacturers and station owners with data about outages and degradation so they can improve reliability and uptime. Through our rewards system, we will partner with loyalty programs (like Air Miles) and provide users incentives to continue contributing to EV Buddy. How we built it We used Flo to gather our initial data. All our data is stored in MongoDB, with a time series database and a regular one. The regular database stores the most recent updates while the time series has the history. All backend processing is done with FastAPI. Our frontend utilizes React to display the charging stations on maps. We use the Google Maps API to generate routes, addresses, and the UX for users to interact. Challenges we ran into Merge conflicts Environments breaking Accomplishments that we're proud of Fetches real time data and lets users see latest reports What we learned Google Maps routing EV charging standards What's next for EVBuddy Refining UI Improving efficiency of requests Built With fastapi google-cloud-apis javascript python react Try it out GitHub Repo Submitted to DeltaHacks XI Crea"
      }
    ]
  },
  {
    "file_path": "./devposts/enviromoney.html",
    "project_id": "enviromoney",
    "title": "Enviromoney",
    "tagline": "Be the change with your spare change",
    "hackathon": "",
    "built_with": [
      "figma",
      "javascript",
      "mongodb",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/366/642/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Profile Page Enviromoney Home Organizations Profile Page Enviromoney Home Organizations Profile Page 1 2 3 4 5 Inspiration During Covid-19, public grants to environmental organizations were taken back to prioritize investments in masks and sanitizers. At the same time, the number of online transactions in the private sector has drastically increased. Observing this trend, we were motivated to create a solution that enables people to donate spare change, generated in online transactions, to these environmental organizations. What it does The Enviromoney mobile app provides a simple and seamless way for users to donate to sustainable causes. The app takes users’ spare change (by rounding up to the nearest dollar on purchases) and puts it toward the organization of each user’s choice. Whether they are grabbing a snack after school or shopping online, Enviromoney provides a way to support sustainability wherever a user goes. The app also includes social and gamification aspects, such as special badges, to push users to further support causes they care about, engage with our partner sustainable organizations, and have fun doing it. On top of this, Enviromoney motivates its users to maintain participation by having a feed to show the causes their friends to.\nA notification system periodically updates the user on the real life impact of the donations. How we built it We designed the Enviromoney app using Figma to visualize the different UI/UX features that are required to make this app as easy and accessible to use as possible. After finalizing the design on Figma, we used the React Native framework to develop the front-end mobile application. We attempted to use MongoDB to process user authentication and Plaid API to link bank accounts to Enviromoney accounts for easy expenditure tracking. Challenges we ran into Implementing a secure User Authentication and the Plaid API proved to be extremely challenging given the short timeframe of the hackathon. Despite our attempts, w"
      }
    ]
  },
  {
    "file_path": "./devposts/fablely.html",
    "project_id": "fablely",
    "title": "Fablely",
    "tagline": "We're creating a future where no language has to disappear!",
    "hackathon": "",
    "built_with": [
      "computer-vision",
      "deep-learning",
      "gemini",
      "llm",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/273/919/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Introduction We’re Fablely - an storytelling platform that preserves indigenous languages and cultures by using interactive fables and conversations to teach them to children, with the power of AI. Why is this important? There are over 7,000 languages worldwide, but only a few are actively taught. Children in indigenous communities lack engaging language tools and as elders pass, cultural knowledge is lost forever. Most apps, like Duolingo, rely on memorization, using flashcards and drills. But language is learned through real conversation, where the meaning comes from cultural context. Indigenous languages thrive in oral traditions, not textbooks - Duolingo misses that. Fablely doesn’t just teach a language—it tells a story. Our AI speaks authentically, detects when a child loses focus, and adapts—rephrasing, and simplifying vocabulary to keep them engaged. Tech Stack We use a combination of LLMs, deep learning, and computer vision at the core of our full stack platform. We leverage Gemini AI models to ensure context-aware storytelling in multiple languages, and integrated a deep learning computer vision (CV) model using OpenCV to analyze a child’s facial expressions in real-time. If the AI detects disengagement, it adjusts its storytelling style, by rephrasing and using simpler vocabular, making learning more natural and effective. On the frontend, we used a React fronted typescript application to host our stories. This communicates with our backend service which hosts the deep learning model, and connects to Microsoft Azure Speech for our narrational functionality. What we accomplished Right now, we can support Swahili, Chinese and English. In the future, we hope to support even more languages around the world, such as aboriginal languages from Canada or Yoruba! With Fablely, we’re creating a future where no language has to disappear - one fable at a time. Built With computer-vision deep-learning gemini llm python react Try it out GitHub Repo Submitted to"
      }
    ]
  },
  {
    "file_path": "./devposts/facelock-xgdar1.html",
    "project_id": "facelock-xgdar1",
    "title": "FaceLock",
    "tagline": "Embrace the Next-Gen Password Authentication with FaceLock. Discover the strength of open innovation with FaceLock, simplifying secure access to profiles via facial recognition!",
    "hackathon": "",
    "built_with": [
      "express.js",
      "flask",
      "mongodb",
      "node.js",
      "opencv",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/540/916/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "homepage homepage 1 2 3 4 5 6 7 Inspiration Our inspiration stemmed from our fascination with the expansive security industry and the intriguing concept of facial recognition technology. This project provided a great opportunity to delve into and learn about the next generation of face-authentication with AI. What it does Our application leverages OpenCV to access the webcam and capture individual frames from the user. During this process, the user is prompted to exhibit various facial expressions to enhance recognition. We used a machine learning model that uses these frames to recognize faces from our image database. Based on the model's assessment, a Boolean value is returned to the JavaScript interface indicating the likelihood of a successful facial match. If the match exceeds 75%, the user proceeds from the login page; otherwise, they are prompted to retry or adjust their sign-in credentials. Our frontend provides a straightforward interface featuring login and signup buttons. The signup process enables users to capture images, enter their names, and provide their email addresses. For logging in, users input the same parameters and have their faces scanned for comparison with the database images. The backend of our system efficiently manages images, names, and other relevant data to streamline database navigation. How we built it Our project started with a bare-bones idea, from which we developed a website that included placeholders for different components using React. These placeholders were gradually replaced with the intended features as we progressed. We used a Flask server to host the facial recognition technology and had a MongoDB database for storing the saved profiles and authentication data. Challenges we ran into We found it difficult to use OpenCV with the application for tracking and storing it to match to the database. Accomplishments that we're proud of Learning how to integrate OpenCV in realtime with the camera in the site was really fun! Hope"
      }
    ]
  },
  {
    "file_path": "./devposts/evo-cadujv.html",
    "project_id": "evo-cadujv",
    "title": "Eve",
    "tagline": "Your personal safety network on campus through real-time alerts on incidents!",
    "hackathon": "",
    "built_with": [
      "framer-motion",
      "neon",
      "next.js",
      "postgresql",
      "pwa",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for a Social Cause Created by Araf A Uhhhhhhhhh Idk Naman Sonawane Tech enthusiast ✨ Jerry Zhu",
      "Best Hack for a Social Cause Created by Araf A Uhhhhhhhhh Idk Naman Sonawane Tech enthusiast ✨ Jerr",
      "Hack404WinnerBest Hack for a Social Cause",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/607/671/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Signup / Login Dashboard Buddies Map Landing Page Signup / Login Dashboard Buddies Map 1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration The origin for \"Eve\" initiated from a critical gap in personal safety technology. While walking at night, particularly in urban environments, a state of heightened awareness often precedes any actual incident. This period of suspicion, the feeling of being followed or entering an unsafe area, is a valid and stressful experience, yet it falls short of the legal threshold required for an emergency services call. Existing solutions are often reactive, designed for use only after a threat has escalated. Our inspiration was to develop a proactive, preventative tool that empowers individuals in this intermediate \"gray area.\" We aimed to create a system that provides a sense of security and a tangible deterrent without prematurely involving law enforcement, leveraging trusted social networks and technology as a first line of defense. What it does Eve is a Progressive Web App (PWA) engineered to enhance personal safety for individuals walking alone. Its core functionality provides a multi-faceted safety net, beginning with an Emergency Alert System that allows a user to instantly notify a pre-selected list of \"buddies\" with an alert and their precise, real-time GPS coordinates via a single button press. This is complemented by an AI Chatbot Deterrent, an integrated, voice-enabled AI powered by ElevenLabs, which allows a user to appear engaged in a phone call—a proven tactic for deterring unwanted approaches. Furthermore, Eve incorporates Community-Sourced Incident Reporting, a map-based feature where users can anonymously drop a pin to report unsafe incidents, populating a collective, real-time map of potential danger zones. Users can manage their trusted contacts through a dedicated Buddy Management & Tracking interface, which also includes a \"Find My Buddy\" feature to display the live location of all connected buddies on a map, subj"
      }
    ]
  },
  {
    "file_path": "./devposts/eyes-3v10zg.html",
    "project_id": "eyes-3v10zg",
    "title": "Memor.i.eye",
    "tagline": "We built memor.i.eye glasses, a memory collector device that records the users best memories implicitly and hands-free. AdHawk Mindlink was used to identify these moments and then processed using ML.",
    "hackathon": "",
    "built_with": [
      "ad-hawk",
      "cockroachdb",
      "cohere",
      "flask",
      "machine-learning",
      "nextjs",
      "opencv",
      "python",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/224/692/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "memor.i.eye Backend + Frontend Architecture memor.i.eye Backend + Frontend Architecture memor.i.eye Backend + Frontend Architecture 1 2 Inspiration Memories are special to us but in often situations we are faced with the dilemma to record the moments that are special vs fully enjoying them. This gave us the inspiration to build memor.i.eye glasses which capture the moments that are special and are worth re-visiting at some point in the future. What it does In contrast to automatic cameras or smartphones, we unobtrustively capture and curate photos of the moments in which you first meet new people after placing your gaze on them and when they evoke positive emotions. These are stored on a personal website account where the user can see a catalog of all their essential memories. How we built it We use signal processing techniques to monitor how eye gaze varies over time through the variance of the running timesteps' eye gaze coordinates. We classify a moment as a \"fixation\" when one is paying significant attention to a new human face with positive emotions. Challenges we ran into Determining an appropriate and meaningful custom measure of gaze \"fixation\", which we defined to be a moment in which the variance of the gaze position is sufficiently small. Accomplishments that we're proud of It was a lot of fun researching perceptual models and how we could use the glasses to capture the correct memories as they happened Building a functional MVP to capture pictures by gaze duration and fixation alongside emotion tracking to further use ML Algorithms to classify these images What we learned ML embeddings Adhawk device + the initial learning curve to exhaust opportunities and ideas Using API to connect the frontend(NextJS and the website) and the backend(Python: flask, openCV, ad-hawk, cockroachDB, co.here) of the project Thinking in the perspective of the consumer Teamwork and effective communication Planning and structuring our tasks that ultimately created this big web a"
      }
    ]
  },
  {
    "file_path": "./devposts/facebook_phishing_website.html",
    "project_id": "facebook_phishing_website",
    "title": "Facebook_Phishing_Website",
    "tagline": "Renders the facebook login page on the local browser and stores login credentials of user",
    "hackathon": "",
    "built_with": [
      "flask",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Introduction It is a Facebook phishing website where the user is tricked into believing that the website they are using is the official Facebook login page.\nIt only works on a local computer. \nI did not host the phishing website online to not promote any phishing scams.\nThe project is made for educational purposes only. Setup Download facebook_phishing_website.py and retrieve_info.py pip install -r requirements.txt Create a data.txt file in the same directory as the facebook_phishing_website.py Make sure to have the templates folder in the same directory as the facebook_phishing_website.py How to use it Run the facebook_phishing_website.py Go to http://127.0.0.1:3000 on your browser Type in the credentials into the website Run retrieve_info.py Type in the email you want see the password of Built With flask python Try it out GitHub Repo Created by she11fish she11fish"
      }
    ]
  },
  {
    "file_path": "./devposts/edpop.html",
    "project_id": "edpop",
    "title": "EdPop",
    "tagline": "Accessible in-person learning through direct-to-consumer location-based classes",
    "hackathon": "",
    "built_with": [
      "airtable",
      "classroom",
      "cloudapi",
      "ecomposor",
      "locationsmadesuper",
      "make.com",
      "mapbox",
      "shopify",
      "softr"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/624/565/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Automated Application for Becoming an Instructor THE FUTURE IS IN PERSON Checkout Page Make over $50+ to teach! Stop TAing! Soon to be stats - GO READ OUR STORY Accessible In-person learning Purchase Page Available Classes for an Instructor Locational based search Our Innovations page with all technologies used Instructors List Payments and Payouts Systems Student Course Management System AI-Powered Speech Recongition Search Backend Dashboard for Managing Classes Automated Application for Becoming an Instructor THE FUTURE IS IN PERSON Checkout Page Make over $50+ to teach! Stop TAing! Soon to be stats - GO READ OUR STORY Accessible In-person learning Purchase Page Available Classes for an Instructor Locational based search Our Innovations page with all technologies used Instructors List Payments and Payouts Systems Student Course Management System AI-Powered Speech Recongition Search Backend Dashboard for Managing Classes Automated Application for Becoming an Instructor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 THIS IS AN INTERACTIVE PROJECT: TRY IT OUT!! edpop.us EDPOP: THE FUTURE IS IN-PERSON If there's one thing we learned about COVID... It’s that virtual learning does not work. Students found themselves unable to focus, struggling to build meaningful connections, and had trouble learning at the same rate as before. Engagement dropped, and ultimately, so did test scores. Ever since the pandemic, standardized testing scores such as the ACT have been at an all-time low. Parents know about this issue... When given the option between an online class and an in-person teacher, parents are willing to pay significantly more for the in-person experience even if it meant having to drive children back and forth. So I started my own in-person class... A handful of students, gathered in my living room everyday just to learn about computer science. That summer, I made $40,000. Both students and parents loved it and were willing to pay a significant premium for the in-person atten"
      }
    ]
  },
  {
    "file_path": "./devposts/fantastic-feast.html",
    "project_id": "fantastic-feast",
    "title": "Dine_Bot_",
    "tagline": "Between allergies, fad diets, and cultural restrictions, it is a miracle if a catered meal satisfies anyone. Our webpage allows you to RSVP your guest's preferences, then we find the perfect meal.🦃🎄",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "matlab",
      "node.js",
      "sql",
      "twilio",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/280/140/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Empowerment (Education, Health) Web Inspiration If you’ve ever catered an event, you know how stressful it can be to meet everyone’s constantly changing needs. Whether preparing for Thanksgiving, Hanukkah, or Easter, were ready to make your life a little easier by finding the optimal recipes to accommodate the pickiest guest. What it does Just give us the phone number, and our chat will not do the rest. Once your attendees respond, we will send you tailored catering and recipe choices that everyone will be happy with. ( The no risky links, No hassle. ) Q0. Do you have any of the following health concerns that require dietary accommodation? Text back the appropriate letters one at a time, if any, then type NEXT\n  a. General Health\n  b. Brain\n  c. Cardiovascular\n  d. Digestive\n  e. Infection\n  f.  Female Health Q1. Do you have any allergies? Text back the appropriate letters one at a time, if any, then type NEXT\n  a. Shellfish \n  b. Gluten\n  c. Tree nut\n  d. Egg\n  e. Soy\n  f. Sesame\n  g. Fish Q2. What are your other dietary restrictions? Text back the appropriate letters one at a time, if any, then type NEXT\n  a. Vegetarian \n  b. Vegan\n  c. Kosher\n  d. Keto\n  e. Low Carb\n  f. Halal Q3. It is a post-meal survey. Q3. (1-10) How we built it Every project starts with research, and we read two books, 183 articles, and 65 studies and conducted customer discovery by interviewing people who follow the diets in question. Our team is diverse, so our collective lifetime culinary knowledge has much to pull from. Herbs and Spices have been long-standing home remedies to cure sickness, not only complementary treatments for the symptoms of chronic conditions like menopause: arthritis, bone density loss, hot flashes, and anxiety. So food of interest with nutritional content can act not only as the optimal nutrition for recovery but for preventative medicine. We chose to focus on chronic illnesses because other conditions are, by nature, random, thus producing too sparse of a "
      }
    ]
  },
  {
    "file_path": "./devposts/equill.html",
    "project_id": "equill",
    "title": "Equill",
    "tagline": "Non-Inclusive Workplaces Cost U.S. Companies $1 Trillion. To solve this problem we created Equill, a chrome extension that analyzes documents to create inclusive and culturally appropriate language.",
    "hackathon": "",
    "built_with": [
      "bun",
      "chrome",
      "chrome-extension-api",
      "cohere",
      "css",
      "javascript",
      "lstm",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "] Best Hack for Diversity & Inclusion Winner Honorable Mention: Use of AI Winner Honorable Mention:",
      "Hack for Diversity & Inclusion Winner Honorable Mention: Use of AI Winner Honorable Mention: UI/UX",
      "[TRACK] Best Hack for Diversity & Inclusion Winner Honorable Mention: Use of AI Winner Honorable Me",
      "WaffleHacks 2024Winner[TRACK] Best Hack for Diversity & InclusionWinnerHonorable Mention: Use of AIWinnerHonorable Mention: UI/UX",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/930/898/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Settings feature Company Logo Landing page Real-time application Settings feature Company Logo Landing page Real-time application Settings feature 1 2 3 4 5 Inspiration: Gen z is creating a cultural revolution where diversity and inclusivity is becoming a more prominent focus; in contrast to this shift in culture, inclusive communication is still a grey area ignored by businesses, perpetuating a non inclusive workplace that is costing US companies over $1 Trillion ( https://chief.com/articles/non-inclusive-workplaces-cost-us-companies-1-trillion-heres-how-to-change-that ).  According to the American Psychology association, Generation Z is on track to become the most diverse generation in history. Nearly half (48%) identify as people of colour and over one in five (20.8%) identify as LGBTQ+. Furthermore, according to witty works  79% also believe that the language we use has an impact on workplace inclusion. A survey conducted by Lingoda stated that, In Germany and France only 44% and 49%, respectively said that they are familiar with gender-inclusive language. Inclusive language is becoming more prominent for workplaces as more workers and clients are susceptible to harmful non inclusive language, and isnpired with this growing need for an inclusive environment we created, What It does Equill, a chrome extension that can instantly recognize text for sources of non-inclusive or discriminatory language and replace it with more welcoming vocabulary. Aiming to subconsciously implement the idea of inclusive language, Equill can allow companies to mould an environment where everyone is accepted. Technology: To incorporate the project, we utilized the Cohere language model, and we implemented this in the format of a Google Extension. The state of the art LSTM, machine learning model that is popular for Natural Language Processing, from Cohere was used to process the input text and made it more inclusive through prompt engineering. Since we were on a time-crunch we decided "
      }
    ]
  },
  {
    "file_path": "./devposts/finding-demographics-for-small-businesses.html",
    "project_id": "finding-demographics-for-small-businesses",
    "title": "Predemo (Prediction Demographics)",
    "tagline": "We predict if a small business is undergoing financial instability by using linear regression over their historical transaction data as well as product popularity",
    "hackathon": "",
    "built_with": [
      "data",
      "linear-regression",
      "numpy",
      "pandas",
      "python",
      "scikit-learn",
      "visualization"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/254/157/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration There is a lot of data related to several stores available in the NCR API. The data consists of details regarding the store's transactions through which we can obtain the details for each transaction. We plan on using this data in order to identify particular trends for any particular store. What it does We plan on developing a visualization tool that can identify the details of a particular store's state by using touchpoint ID as well as location as a parameter for scraping the data. Based on a particular touch-point ID which we obtain for a given machine at a particular store or using the location ID of the store. We find out the timeline of purchases made at the store. Using this information we fit a linear regression model which predicts if the shop is undergoing losses or profit (if the slope of the regression plot is negative - loss, if it is positive - profit).\nApart from this, we also identify whether if the number of purchases was affected by any discounts being made to the customers over a given time duration identifying whether if frequent discounts or discounts at a particular time of the year give more purchases at the given store. Lastly, we identify the frequency of sales of individual products at the store so that we can identify which products hold higher value at a particular region so the supply could be increased or decreased based on the statistics. All of these things can be done for all stores that are available in the API using a simple GUI for identification of the store touchpoint ID or the store location ID. Using these methods, we can optimize each store as per their demographics predicting their statistics and finding optimal solutions for solving them. How we built it We used the NCR API as well as streamlit for the dataset generation and GUI. We use scikit-learn to fit the linear regression model and pandas as numpy for carrying out the data processing and parsing. Challenges we ran into Accessing the NCR API was one of the"
      }
    ]
  },
  {
    "file_path": "./devposts/face2xrp.html",
    "project_id": "face2xrp",
    "title": "Face2XRP",
    "tagline": "Send XRP to anyone with an image of one's face! View account balance, past transactions, and send XRP all through face recognition!",
    "hackathon": "",
    "built_with": [
      "discord",
      "dlib",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "BlockHack 2023WinnerXRP Ledger",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/629/704/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Face2XRP Face2XRP is an innovative project that combines computer vision and blockchain technology to enable secure and user-friendly XRP transactions through facial recognition. With Face2XRP, you can send XRP to anyone using just an image of their face. Additionally, you can view your account balance, past transactions, and perform various XRP-related actions with ease. Inspiration The inspiration behind Face2XRP was to create a seamless and secure method for conducting XRP transactions. We wanted to harness the power of facial recognition technology to simplify the process and provide users with a novel, convenient, and secure way to interact with the XRP Ledger. What it does Face2XRP offers the following key features: Facial Recognition: Face2XRP employs computer vision technology with OpenCV and the Dlib C++ library to encode and recognize faces. This biometric security ensures that XRP transactions are initiated securely. XRPL Integration: We leverage the XRPL ledger HTTP API and the Python SDK to access account balances, transaction history, account information, and perform transaction operations. XRP Transactions: With Face2XRP, you can send XRP to anyone by simply providing an image of their face. The recipient's face is recognized, and the transaction is executed securely. Account Management: Easily check your XRP account balance and view past transactions through the intuitive interface. How we built it We built Face2XRP by integrating computer vision and blockchain technologies: Computer Vision: We used OpenCV and the Dlib C++ library to implement AI-based facial biometric encoding and recognition, ensuring secure and user-friendly transactions. XRPL Integration: We integrated the XRPL ledger HTTP API and the Python SDK to interact with the XRP Ledger, enabling account management and secure transactions. Challenges we ran into While developing Face2XRP, we faced several challenges, including: Complex Integration: Combining computer vision with blockchain"
      }
    ]
  },
  {
    "file_path": "./devposts/farming_app.html",
    "project_id": "farming_app",
    "title": "Cultivate",
    "tagline": "Taking \"farmer's market\" to a virtual and accessible level",
    "hackathon": "",
    "built_with": [
      "api",
      "beautiful-soup",
      "firebase",
      "flask",
      "flutter-sdk"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/070/597/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Each member on our team had some connection to gardening, whether they had a passion for growing crops themselves or an issue related to farming that they wanted to solve. Many of use have backyard gardens, but keep it modest and grow crops only for ourselves. We wanted to create an app that created not only a virtual marketplace for fresh produce but also an app that would let others get into the gardening hobby as well. We were also greatly inspired by the book _ Hungry for Disruption _ by Shen Ming Lee, a holistic review of how technology can address problems like food sustainability and climate change in agriculture. We learned through this book how important the decentralization and urbanization of small-scale agriculture can do. By creating an app that promotes local transport, we wanted to do a lot for solving problems like long-distance food transportation (pollution), and the perils associated with it. What it does Cultivate encourages people to farm with their own food and helps them so that they can grow their own food. This app also does not need any special materials. All you need is a backyard to farm, some basic material, and the instructions. Our app centers around providing everything users need to participate in the online market.\nCultivate facilitates the entire process of farming,  from the purchase of the seeds to the harvest and sale of the crops. After the produce is grown, you can sell the plants to create an e-commerce of produce operated by individual people transported through local distances. How we built it Cultivate is the product of a medley of cool technology. We use a combo of a flask server and a flutter application that work hand-in-hand to retrieve necessary data from the internet. For our storage system, we use Firebase Firestore, which enables us to get real-time updates and quick data uploading and downloading. We use firebase for authentication and storage of image data as well. For our web-scraping algor"
      }
    ]
  },
  {
    "file_path": "./devposts/farm-your-finances.html",
    "project_id": "farm-your-finances",
    "title": "Farm Your Finances",
    "tagline": "Understanding How to Run a Farm Business",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Created by Anita Yip Product owner, project manager, retired hackathon-er",
      "1st Place - Financial Wellness Track Created by Anita Yip Product owner, project manager, retired h",
      "PickHacks 2022Winner1st Place - Financial Wellness Track",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Despite the culture, romantic notions and hard work surrounding farming, managing a farm boils down to managing a business. For example, farmers cultivate corn to create income to market seed-stock. Farmers must also cultivate their farm’s financial records in order to make sound financial management decisions. Running a farm is basically running a business. While farmers know a ton about the production side of their business, they need more help with the financial side. Simply filing a schedule F does not constitute financial literacy nor business management. It's only when farmers understand financial reports that they can devise ways to operate better. I'm aIso a city kid at heart Iooking to expand my horizons. What it does Play a game with the goal of earning money while running a farm! How we built it Unity / C# Challenges we ran into Working with object layers for visuals, figuring out how to code a game, making the visuals happen as expected (should selecting one object mean deselecting current object? generally yes!), recording using Zoom while Unity is running is tricky because clicks sometimes speeds up the recorded video so that whatever I said was no longer understandable, creating and uploading video! Also, Unity has a lot of files - some of which are huge - and I could not upload using traditional git (or the way I was doing it). As such, I uploaded the most important pieces, showcasing the assets and scripts I used within the hack! Accomplishments that we're proud of Made a game - on my own!!! I've always wanted to learn, and I can only learn by really just doing it (as opposed to delegating or looking to someone more expert). What we learned I learned to create a nifty farming game (for this city kid - this is definitely a new one!), animate based on delays, learned more C#, and use scriptable objects so that I don't have to manually add so many Unity components! Built With c# unity Submitted to PickHacks 2022 Winner 1st Place - Financial"
      }
    ]
  },
  {
    "file_path": "./devposts/fairfi.html",
    "project_id": "fairfi",
    "title": "FairFi - A tool to reduce bias in financial services",
    "tagline": "A full-stack tool to reduce bias among employees in financial services",
    "hackathon": "",
    "built_with": [
      "cohere",
      "css3",
      "express.js",
      "git",
      "github",
      "html5",
      "javascript",
      "next",
      "node.js",
      "react",
      "tailwind",
      "trailscale",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DeltaHacks XIWinnerNSBE X P&G Equity Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/212/463/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "dashboard dashboard dashboard 1 2 Inspiration Our inspiration stems from the alarming disparities in unemployment and poverty rates within African American communities. These inequities are deeply rooted in the racial bias of financial institutions. Studies show that African Americans are often subjected to discriminatory treatment when seeking financial assistance, such as loans, mortgages, and credit approvals. This bias results in fewer opportunities for wealth accumulation and financial stability, perpetuating a cycle of economic hardship. Our mission is to bring attention to and address the pervasive racial biases that hinder financial inclusion and economic justice for marginalized communities. We aim to empower companies to test and identify racial biases in their everyday operations, enabling them to address these disparities so that they may continue fulfilling their mission of serving and uplifting the communities they were created to support. What it does We have developed a website allowing companies to analyze their employees' biases by simulating a customer call. They may change the gender and accent of the AI-generated voice, and an AI-generated call will be made to the company using Twilio. The AI follows a script allowing pitch and tone to act as independent variables when the actual content is not. While generating the AI human-sounding voice, Twilio also transcribes the audio received from the employee into text. We then used Cohere’s Command R+ to generate two outputs from the text. One is the sentiment of the employee and the other offers a general overview of the contents of the phone call. ... How we built it In the beginning, we brainstormed several ambitious ideas, but we ultimately chose FairFi because it struck the perfect balance between innovation and practicality, especially given our short timeframe. We started by establishing a clear workflow and designing the app architecture. For the front end, we utilized Next.js and Tailwind CSS. "
      }
    ]
  },
  {
    "file_path": "./devposts/feelthewave.html",
    "project_id": "feelthewave",
    "title": "FeelTheWave",
    "tagline": "A Free Alternative To Paid Music Streaming. All You Need Is A URL.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Right now, there not many good free music applications - Spotify, iTunes and Soundcloud all require you to pay for better service. We solve that by downloading the music from Youtube instead of the user buying the music from our servers. What it does Streams youtube videos via their URLs for personal enjoyment. How we built it We built this app using node, react and firebase as well as github for version control. Challenges we ran into We ran into many bugs which were mostly due to lack of experience and bad practice e.g. not indenting properly, not commenting and not committing often. Another challenge we faced was using firebase - this was our first time using databases of any kind, so we had to ask the mentors and refer to the documentation quite a bit. Accomplishments that we're proud of We're all very proud that we were able to learn a lot of tools (node, react, firebase) in such a short time (24 hours). While the app isn't very functional, it's the first step in learning. What we learned We learned many fundamental react.js concepts, such as components and constructors, as well as learning about how good practice can help benefit our code. We also learned how to read documentation, even when the documentation wasn't very clear. Another thing we learned was how to work effectively as team and resolve conflicts between team members. Last, we also learned how to debug errors using the developer console. What's next for FeelTheWave Right now, there's a lot of bugs for FeelTheWave which should definitely be fixed. In addition we should improve the UI to make using FeelTheWave easier. Long-term, we would like to transport this to a desktop app, perhaps using the Electron framework. Built With firebase node.js react Try it out GitHub Repo Submitted to Hack the Hammer Created by Raiyan Sayeed Marcus Chong hi Amman Waheed"
      }
    ]
  },
  {
    "file_path": "./devposts/fabulous-5.html",
    "project_id": "fabulous-5",
    "title": "Youtube Thumbnail Generator",
    "tagline": "Generate Thumbnails Automatically based on only a picture and text!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/747/153/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We all loved Python and wanted to make a sick project that would genuinely help people! What it does Automatically generates YouTube thumbnails to help YouTubers avoid a busy life! How we built it Many packages and APIs were used to help construct the program, including Pillow for image manipulation, Clarifai for facial recognition, and background removers for, well, background removal! Challenges we ran into Getting our program to accurately detect faces across all mediums (humans, cartoons, video games, etc) Accomplishments that we're proud of Staying up every hour of the event and making friends What we learned Project Management, coding (duh), teamwork, and collaboration skills What's next for Fabulous 4 Bringing the Thumbnail Generator to YouTubers all over the world! Built With css flask html5 javascript python Try it out GitHub Repo Submitted to HackPrinceton Spring 2023 Created by Aaron Ang Matthew Pena Christy Lau Jason  Alba Shiho Sugiyama"
      }
    ]
  },
  {
    "file_path": "./devposts/ethnosphere.html",
    "project_id": "ethnosphere",
    "title": "EthnoSphere",
    "tagline": "Providing a space for minority communities to thrive",
    "hackathon": "",
    "built_with": [
      "css3",
      "firebase",
      "flask",
      "html5",
      "nextjs",
      "python",
      "react",
      "sqlite",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/713/054/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We noticed that many voices of minorities were silenced as majority groups dominated conservation. In addition, many minorities were afraid of being themselves due to comments by majority groups. This inspired us to design a community for people in minority groups to thrive and have a place to connect with people from their groups. As such, showing that they are not alone in being minorities. What it does Our project facilitates the building of communities. We allow people to message each other, which helps develop a sense of community among minority groups. In addition, we have a feed where people can talk with each other, another source of community for our users. We built a blog feed for people to talk about their experiences as minorities, allowing them to share their experiences, aspects of their culture and find similarities between one and another. How we built it We did this using CSS, NextJS and react. We used GitHub, Visual Studio Code, and MySQL Workbench. Challenges we ran into We ran into challenges with linking the programs and with a common time for meeting and working on this project. Accomplishments that we're proud of Creating a social media platform using Flask (a Python web framework) for the backend and Next.js (a React framework) for the frontend is a significant accomplishment.  It enables ease of communication of diverse commiunities from different time zones. What we learned We learned how to communicate between different timezones. 3 of our teammates are in the timezone PST, but one of us as around in the world, with the timezone of EAT. As such, we learned skills in communication. We also learned about new frameworks such as NextJS and Flask. Helping us develop this project What's next for EthnoSphere We could add a few features to EthnoSphere in the future. First, improving our styling throughout the application. Second, adding additional pages to enhance the user's experience within the web page and to further enc"
      }
    ]
  },
  {
    "file_path": "./devposts/eighteye.html",
    "project_id": "eighteye",
    "title": "EightEye",
    "tagline": "Dynamic insight timelines, enabling real-time and retrospective analysis of security-related events through interactive assessment of social media and geospatial data.",
    "hackathon": "",
    "built_with": [
      "anthropic",
      "fastapi",
      "huggingface",
      "javascript",
      "langchain",
      "mongodb",
      "next.js",
      "ntlk",
      "openai",
      "pandas",
      "python",
      "telegram",
      "twitter",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/881/998/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Insights Example Logo Landing Page and User Prompt Timeline Example Event Example Insights Example Logo Landing Page and User Prompt Timeline Example Event Example Insights Example 1 2 3 4 5 Video Demo: https://www.loom.com/share/257d280d9da343dabf69603aae3f0966?sid=e1cc388e-f448-49f5-b714-080bd0402850 Inspiration Our inspiration for EightEye emerges from the complex landscape of national security, where professionals often struggle to quickly and accurately synthesize vast amounts of unstructured social media and geospatial data into actionable intelligence. This challenge hinders timely decision-making and effective response strategies during critical security events, such as public disturbances or tactical operations. Our team---with experience and interest in defense technology, OSINT, and cybersecurity---is committed to resolving this issue; thus, EightEye was born. What it does EightEye is a dynamic insight timeline tool that enables real-time and retrospective analysis of security-related events. The user can provide a query or prompt about a certain event or occasion that they seek to gather information or intelligence on; our tool then intelligently parses through social media datasets (e.g. Telegram) and geospatial data (e.g. SkyFi) with the use of semantic searching and NLP to construct a chronological timeline that details various important aspects of the incident, either in hindsight or in real time. By presenting a concise summary of the time, location, and key descriptors and images of the event of interest in a streamlined visual format, users can easily put together key pieces of intelligence and accurately determine next-steps. In addition to the events timeline, there are two other features that further aid the user in intelligence gathering and decision-making. Our tool has an AI chat interface that allows the user to ask questions, clarify understanding, and identify connections about the event of interest, as well as similar interests that the "
      }
    ]
  },
  {
    "file_path": "./devposts/fastpass-v24txh.html",
    "project_id": "fastpass-v24txh",
    "title": "fastpass",
    "tagline": "Quick and easy app managers can use to securily share sensitive secrets, tokens, and keys with new coops/interns/hires in general.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "amplify",
      "graphql",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/592/281/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Our inspiration for \"fastpass\" came from the need to securely share sensitive information such as secrets, tokens, and keys with new team members, especially interns and coops. During many of our coops, the managers would just send vital .env files and passwords through slack (at that point, you might as well write it on a piece of paper and stick it on the office bulletin board). We recognized that many organizations face challenges in ensuring the secure transfer of such data while onboarding new hires. This inspired us to create a solution, using Syro , that simplifies and secures this process. What it does \"fastpass\" is a platform designed to streamline and secure the sharing of sensitive information within organizations. It provides a user-friendly interface for managers to upload and securely transmit secrets, tokens, and keys to new team members. The platform employs Syro 's robust encryption and access control mechanisms to ensure that only authorized individuals can access and use the shared data. Additionally, it logs all interactions for auditing purposes. How we built it We built \"fastpass\" using a modern tech stack that includes Syro , web development technologies, secure authentication mechanisms, and encryption protocols. The frontend of the platform was developed using React.js to provide a responsive and intuitive user interface. The backend, powered by Node.js and Express, handles user authentication, data storage, and encryption. For security, we implemented industry-standard encryption techniques to protect sensitive data both in transit and at rest. We also conducted rigorous testing to identify and address vulnerabilities. Challenges we ran into During the development of \"fastpass,\" we encountered several challenges. One significant challenge was implementing robust encryption without compromising performance. Balancing security with user experience required careful consideration and optimization. Additionally, ensuring seamle"
      }
    ]
  },
  {
    "file_path": "./devposts/fastaid-8kbgjr.html",
    "project_id": "fastaid-8kbgjr",
    "title": "FastAid",
    "tagline": "Coronavirus has hospitals all over the world over capacity. We sought to make a web app wherein users could come into contact with medical professionals in their vicinity thus not risking infection.",
    "hackathon": "",
    "built_with": [
      "ajax",
      "bootstrap",
      "firebase",
      "jquery",
      "maps",
      "node.js",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/162/387/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Currently, the urban centers of India are inundated with patients due to the ongoing coronavirus pandemic. This also causes people to not visit hospitals and clinics in the fear of contracting the virus, even when it would be in their better interests to do so. What it does FastAid is a web app where patients can request help and people can sign up to be volunteers. Patients in need of care can use the website to put out a call for help. They enter their contact information and their ailment. The web app then collects their location and notifies volunteers within a 500-meter radius. The volunteer and patient can then communicate on the best course of action, which can range from a call to a visitation. How I built it The backend along with the database was set up on Firebase. It provided real-time database access enhancing the user experience on our website. Javascript was mainly used to iterate through the database and store information back into the tables. HTML pages were created for the front end service along with streaming using CSS. The pages were bootstrapped to make it mobile user friendly. Ajax, a jQuery library, was used to make the website asynchronous with its data. The Google Maps API was used to track the current location of the user and to send help without any hassle to the volunteer. The Twilio API send texts messages to the volunteer to notify the volunteer of the patient's distress call. These pages were served on Node JS in order to integrate the API's and Javascript pages. Challenges I ran into The first issue was the restricted functionality of the web app since the Google map API was not compatible with Mozilla Firefox. Secondly, there were cross-platform issues, resulting in the program being unable to run on Mac OS, which we solved. We solved this by. Lastly a last minute issue that we could not resolve was upon hosting the site onto Heroku via git, our Twilio account details were rotated - this was because posting account c"
      }
    ]
  },
  {
    "file_path": "./devposts/fintruist.html",
    "project_id": "fintruist",
    "title": "Fintruist",
    "tagline": "Decentralized, Deliverable based charitable crowdfunding 🌏💸",
    "hackathon": "",
    "built_with": [
      "auth0",
      "botdoc",
      "dasha",
      "ganache",
      "javascript",
      "metamask",
      "moralis",
      "react",
      "solidity",
      "tailwind",
      "truffle",
      "twilio",
      "web3.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackPrinceton Spring 2022WinnerMost Creative Use of Twilio",
      "Best Use of Dasha AI 👂",
      "Best Domain Name from Domain.com 🌐",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/889/601/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration 💡 Let us start with a story. About one year ago, one of our teammates got a text message about a charitable crowdfunding campaign seeking donations that promised that all the money raised would go towards planting trees. Our teammate scrolled through their Facebook page and was impressed by their previous work greenifying areas in India. So he made a sizable donation to the campaign. However, he later learned that the pictures posted were scraped off the internet and he, along with several other people, was scammed by this fraudulent crowdfunding campaign. Reflecting on that experience, we decided that we will only make donations to charitable campaigns if and only if they show us deliverables for the cause they support. However, current crowdfunding platforms focus on raising money before the campaign takes actions. By compelling campaigns to deliver on certain milestones, we can effectively prevent fraud because donations do not take place until evidence is provided. We were willing to donate only after certain milestones were achieved by the campaign. To facilitate a transparent deliverables-based transaction between donors and charitable crowdfunding campaigns, we created Fintruist ✨ What it does 🤔 Fintruist is a decentralized crowdfunding application that uses bleeding edge-technologies to fight against Scams and Frauds in the name of Fundraising and Crowdcampaigns. On Fintruist , charitable organizations can create campaigns that allow users to donate fixed amounts . But donations will only be executed after the donors verify the deliverables that were promised by the organization . How we built it 🦾 Frontend: ReactJs, Tailwind CSS Backend: Solidity, Truffle, IPFS, Web3.js Tools: Auth0, Botdoc.io, Dasha, Moralis Design: Figma, Illustrator, Photoshop, After Effects For Blockchain Network, we went ahead with ETH & Wei. And several other 3rd party services & testing tools & obviously GitHub as VCS. Team Discord Usernames chief_of_mischief#80"
      }
    ]
  },
  {
    "file_path": "./devposts/flash-t5a89q.html",
    "project_id": "flash-t5a89q",
    "title": "Flash",
    "tagline": "Changing how people study. Forever.",
    "hackathon": "",
    "built_with": [
      "flask",
      "html5",
      "nextjs",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/505/576/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "⚡️ Flash ⚡️ 📔 Revolutizing the way students study 📔 ☁️ Inspiration Nowdays, Everyone is so busy. Everyone has different class. Even as a highschool, everyone is busy as a bee, and time management is crucial. Its unusual to waste time. With Flash, you can summarize and practice a weeks worth of notes in a ⚡️Flash⚡️ 🚧 What It Does ⚡️Flash⚡️ uses state of the art machine learning technology to  recognize text and help you better learn your class content. Flash is able to generate Quizzes, Flashcards, Chats and so much more. 👨🏾‍💻 Our Tech Stack NextJS was used for our Frontend Flask was used to build our API backend Pytorch / HF OCR was used for Text recognition OpenAI's GPT 4.0 is used for summarization and generation of quizzes and flashcards.\n## 👷 Challenges We Ran Into\nThe main challenges we ran into includes the amount of time it took find a good OCR model, after scowering online for hours, we ended up using Microsoft's TROCR. Not only this, we spent almost all the time working on the Frontend.\n## 🎉 Accomplishments That We're Proud Of Full Implimentation of NextJS Full Usage & Implimentation of OpenAI's GPT 4.0 Usage of Microsoft's TROCR text recognition 📙 What We Learned 🔜 What's Next For Flash For flash, in the future. we plan to use our own Chat model instead of using Open Ai's. Bilingual AI, be able to use different languages.\n### 🌎 How This App Changes The World And Correlates To Education Technology\nEveryone's life is so packed that everything has to be effcient and quality. with Flash, instead of reading pages of books, we slim it down to almost 1-2 Paragraphs. Additionally we are able to generate flashcards,quizzes and much more. Built With flask html5 nextjs python pytorch Try it out docs.google.com Submitted to HackaKhan Created by :) Edward He mid Developer TBH, average at coding ig. Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Kosei Tsukamoto"
      }
    ]
  },
  {
    "file_path": "./devposts/facestylr.html",
    "project_id": "facestylr",
    "title": "faceStylr",
    "tagline": "Polyvore meets Augmented Reality for styling your face. Make meaningful product connections with your customers!",
    "hackathon": "",
    "built_with": [
      "android",
      "asm.js",
      "dlib",
      "ios",
      "lamp",
      "linux",
      "mac",
      "opencv",
      "realityscript",
      "s3",
      "shopify",
      "tensorflow",
      "unity",
      "visa",
      "webgl",
      "windows"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "in Show Winner Semi-Final Prize Created by Caramel Corgi Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3",
      "Best in Show Winner Semi-Final Prize Created by Caramel Corgi Yosun Chang EPIC HACKATHON JUNKIE (XR",
      "Created by Caramel Corgi Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)",
      "Disrupt SF Hackathon 2018WinnerBest in ShowWinnerSemi-Final Prize",
      "I could swap in a better tracking SDK, but…",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/666/298/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Please show your face to help us thumbnail the looks! Try out a new look designed by the community Apply some filters! Snapshot your look! Save your Look Please show your face to help us thumbnail the looks! Try out a new look designed by the community Apply some filters! Snapshot your look! Save your Look Please show your face to help us thumbnail the looks! 1 2 3 4 5 6 Inspiration My mother was a former beauty queen, from another country, who had become completely forsaken to beauty. Though she was once even an Avon lady, she would not teach me anything about makeup. Once, when we were watching a late night beauty pageant, and I looked wistfully at the contestants, my mother told me, “No, you’ll never qualify.” I was not raised in a competitive family, but I had always personally believed in winning contests and at age 12, being told I had no chance meant this wasn’t worth the time investment at all. I learned early on, from my mother, the beauty expert, that I was not pretty. 18 years later, in the streets of NYC and Paris, on my own, I would discover the world of expert fashion stylists, who are able to make anyone look glamorous — they can even make an ugly girl look pretty. For anyone in this modern world, seeing yourself look amazing is transformative. It fosters hope and makes you believe in your dreams again. I want to help spread this magic. My goal in ShopFace is to build an AR product that lets anyone show off the look they want, and even share it so that others can, quite literally, instantly try it out. My aim is to create an innovative yet  universal platform to lets anyone express their beauty creativity by becoming a stylist, and by helping them discover and virtually try-on products they did not know could transform their looks. What it does FaceStylr is Polyvore meets augmented reality for styling your face. Users can browse different styles, mix and create their own look sets from a selection of products—and try any of them on virtually! The plat"
      }
    ]
  },
  {
    "file_path": "./devposts/fair-exchange.html",
    "project_id": "fair-exchange",
    "title": "Fair Exchange",
    "tagline": "An app where people can exchange their time/abilities for business services through a work-exchange job board. Income no longer has to be a barrier to entry for art, exercise, travel, & more!",
    "hackathon": "",
    "built_with": [
      "figma",
      "mongodb",
      "mui",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/372/649/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Summary of intended flow, features, and codebase Sign In Page User Profile (Where user can edit their profile) Job Posting Job Form (Where businesses to post jobs) If job is posted successfully Wireframe of MVP Summary of intended flow, features, and codebase Sign In Page User Profile (Where user can edit their profile) Job Posting Job Form (Where businesses to post jobs) If job is posted successfully Wireframe of MVP Summary of intended flow, features, and codebase 1 2 3 4 5 6 7 8 Inspiration We took inspiration from one of our team member's personal stories. As a student, she wanted to take dance classes, but couldn't afford the high cost of admission for the advanced classes she was interested in.  After talking to the studio, they offered up a novel arrangement: a work-exchange program. In exchange for a few hours a week working their front desk, she could take the classes she wanted. It was genius; she got the classes she wanted and the business could fill extra shifts their receptionist couldn't cover. After that, she realized work-exchange programs were secretly everywhere; in dance studios, art classes, gyms, and more.  Coming from a low economic background didn't have to mean that you couldn't take the trendy new pilates class, take up a new hobby, or take care of your physical health. Many kind-hearted businesses had word-of-mouth programs or arrangements they publicized through their newsletter, but there wasn't a centralized location for those in need to find them. That's where Fair Exchange comes in. What it does Fair Exchange is a novel job board where the goal is to connect businesses with job seekers.  Users can create personalized profiles on their experience, skills, location, and interests. Businesses can also create job postings for a job board where they can specify their location, necessary skills, and the \"exchange currency\", or what time/abilities the user needs to put in to redeem the business' services. How we built it This was built using "
      }
    ]
  },
  {
    "file_path": "./devposts/farmdirect.html",
    "project_id": "farmdirect",
    "title": "FarmDirect",
    "tagline": "Fresh Produce, Fair Futures!",
    "hackathon": "",
    "built_with": [
      "d3.js",
      "etherium",
      "lightgbm",
      "metamask",
      "react",
      "sepolia",
      "solidity",
      "speedometer",
      "styled-with-tailwind-css",
      "tailwindcss",
      "the-sepolia-test-network",
      "vite.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Grand Prize ($6K USD for Top 3 Teams) Winner Taskade Starter Plans Winner Art of Problem Solving Gi",
      "AlphaStar Academy Course Discounts Winner",
      "s Winner Grand Prize ($6K USD for Top 3 Teams) Winner Taskade Starter Plans Winner Art of Problem So",
      "($6K USD for Top 3 Teams) Winner Taskade Starter Plans Winner Art of Problem Solving Gift Cards Win",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/867/166/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Exploring pricing strategies to maximize value for users Market Place App Screen: \"Explore local farms and products with ease on our Market Place screen Dashboard: Real-time data and insights at your fingertips Key features and hypothesis driving our innovative approach Our roadmap: Key milestones planned over the next year Insightful market analysis guiding our strategic decisions Exploring pricing strategies to maximize value for users Exploring pricing strategies to maximize value for users Market Place App Screen: \"Explore local farms and products with ease on our Market Place screen Dashboard: Real-time data and insights at your fingertips Key features and hypothesis driving our innovative approach Our roadmap: Key milestones planned over the next year Insightful market analysis guiding our strategic decisions Exploring pricing strategies to maximize value for users Exploring pricing strategies to maximize value for users 1 2 3 4 5 6 7 8 Inspiration FarmDirect: Empowering Farmers through Technology Our global team of five (Indonesia, Kenya, Singapore, India, United States) was united by a desire to create a meaningful impact on the world. Inspired by the pressing issue of hunger and the belief that no one should suffer from it, we explored numerous ideas, from nutrition education to the gamification of farming. We settled on supporting farmers globally, starting with Indonesia, a decision driven by the country's diverse agriculture and our connection through a team member residing there. Our goal was to make existing technologies more accessible to farmers to help them improve their practices and market reach. What it does: Our key features We developed FarmDirect (our temporary code name), a platform that integrates AI, IoT, and blockchain to empower farmers with advanced yet easy-to-use tools for better crop management and market access. We also provided login-free access to the marketplace to explore farms and products. AI-Powered Dashboard Offers real-time "
      }
    ]
  },
  {
    "file_path": "./devposts/ezdb.html",
    "project_id": "ezdb",
    "title": "ezDB",
    "tagline": "Streamline development with our full-fledged cloud storage solution. A document-based database along with a slick developer dashboard and a customized AI assistant. What more is there to ask for?",
    "hackathon": "",
    "built_with": [
      "chatgpt(api)",
      "cockroachdb",
      "deno",
      "fresh",
      "http",
      "oauth",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/644/375/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration We love using document-based databases such as MongoDB. We just wish they were better. \nMore often than not, they aren't built with serverless in mind, have a terrible developer experience, and are unreliable. What it does ezDB is full full-fledged cloud storage solution, providing a database built on top of CockroachDB and a developer dashboard bundled with a smart AI assistant. The database includes an HTTP-API layer and a Schema system, and the dashboard contains an items explorer and UI for editing tables/databases. As a developer, in one click, you can create your database, in another, your table, and with one line of code, you can begin adding items right away. Stuck? The AI assistant customized to your database's data will help you! How we built it ezDB uses CockroachDB as its \"engine\", with all documents stored there. Deno KV is used as a temporary cache to keep track of user metadata and document references. The website front-end is written with Typescript and React. The AI assistant is built on top of ChatGPT. GitHub OAuth is used for login. Challenges we ran into The sheer size of the project was quite a bit. ezDB aims to be a full cloud solution, providing not just the database but also all the tooling to explore the data within it, create tables, and a generally seamless UI. The caffeine definitely helped... Accomplishments that we're proud of Not only does our solution work, we think it looks great as well. Design is paramount when creating any product, and the website we created is both slick and informative. It feels easy to use ezDB, which was our goal. What we learned We learned a lot about SQL querying (something we were all a lot less familiar with), performance challenges behind databases, and CockroachDB in general. What's next for ezDB There is a lot of polishing left to do before ezDB can go into production. Security needs to be analyzed, proper error handling must be installed, and further features integrated into the dev"
      }
    ]
  },
  {
    "file_path": "./devposts/firecast.html",
    "project_id": "firecast",
    "title": "FIREcast",
    "tagline": "Leveraging AI to forecast fire risks in geographical regions. FIREcast empowers communities with actionable insights to allocate resources and implement proactive strategies for wildfire prevention.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "node.js",
      "openai",
      "weatherapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/565/469/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Our inspiration for creating FIREcast stemmed from the heartbreaking impact of the devastating wildfires that have been ravaging Canadian provinces, territories and notably, Maui. Witnessing the destruction caused by these fires served as a catalyst for our team's commitment to curate a solution that addresses these pressing environmental challenges head-on. What it does FIREcast integrates geo-coding and weather data APIs to predict regions with elevated wildfire risks. FIREcast uses mathematical formulas to calculate the Fire Weather Index (FWI), resulting in a efficient algorithm that can display the risk of a wildfire. Recognizing the inherent challenges in fully averting these natural and human-induced disasters, our tool enables global users to participate in resource allocation for vulnerable areas, while aiding experts in identifying high-risk zones. How we built it The frontend was developed using HTML, CSS, and JS .  Some libraries used in the frontend include \"Animate On Scroll\". We used asynchronous functions and onClick buttons to call the GeoLocation API which gave longitude/latitude coordinates. Then, we used those coordinates to call the Weather API to get the weather, humidity, wind speed, etc. Using this information, we performed the algorithm to find the FWI. Challenges we ran into Creating a full-stack website, as this was all of our first times. It was difficult to update the website due to DOM manipulation. Calling APIs without Node or Express. Fixating on a specific issue that we could realistically address using the technology we have on hand. Accomplishments that we're proud of and what we learned Since none of us were seasoned coders, we collectively embraced the opportunity to acquire new skills, with some focusing on frontend development and others delving into the intricacies of implementing various APIs. Regardless, we all endured restless hours of research to create a final product that tackles the world's most pressing"
      }
    ]
  },
  {
    "file_path": "./devposts/firesight.html",
    "project_id": "firesight",
    "title": "FireSight",
    "tagline": "Firesight is an interactive fire risk prediction app.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "flask",
      "javascript",
      "python",
      "sklearn",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/908/980/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration With an ever-growing concern of climate change and global warming, it is becoming more important for human beings to keep track of natural disasters that impact them close to home. We built Firesight to prepare for a future where wildfires are becoming more common than ever. What it does Firesight predicts the likelihood of fire in any location in the US using our custom trained machine learning model. How we built it We trained the machine learning model on historical fire and weather data using Sklearn's random forest regression.\nWe created several internal APIs using python/Flask for the model data API and node/express for the weather and python middleman APIs to get real-time weather data based on location to feed to our model in order to get a prediction and communicate with our front end based on vue.js! Challenges we ran into Finding good training data was the toughest challenge we encountered. We attempted to create our own dataset by matching existing fire data with their historical weather data but ran into API query limits. In the interest of time we used a smaller UCI machine learning dataset that contained both fire and weather data, the resulting model's accuracy suffered but still demonstrates the overall goal of the project. Accomplishments that we're proud of This project included many moving parts, interaction with external weather APIs, and two internal API servers in python and node, orchestrating the interactions between all these parts with the front end and then hosting everything on Heroku was definitely something we were proud of. What we learned We learned a lot about various things:\nIn the backend, we learned about how to interact with external APIs, create a Flask server to host the python model, and connect our python and node servers together to seamlessly serve prediction data to our front end. We also learned how to use the javascript environment \"Node\" as the intermediate layer to communicate with the backend flas"
      }
    ]
  },
  {
    "file_path": "./devposts/fight-companion.html",
    "project_id": "fight-companion",
    "title": "Fight Night",
    "tagline": "Helping MMA fans bet confidently using AI to determine the likelihood of the outcome; while formulating a more compelling approach to MMA rankings that disregard the hype and rewards objectively.",
    "hackathon": "",
    "built_with": [
      "flask",
      "pandas",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/378/754/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "UFC Predictions UFC Predictions UFC Predictions 1 2 💸Inspiration MMA has quickly become the fastest-growing sport in the world, yet the big war and one of the oldest organizations, the UFC, have been misusing the rankings and are unilaterally giving special consideration to more popular fighters; this becomes problematic when the company uses the list to determine fighter compensation and used by managers to secure individual sponsorships. This leads to fighter pay inequity, where results are a secondary consideration. Even top MMA commenters have spoken out about how the ranking seems to defy logic in the promotion's favor. 📊What it does We trained a model using random foresting to return a likelihood of each fighter winning when the user enters two names. In addition, we can score each fighter's skills by applying an Elo rating system which is popular in zero sum games like chess. In Elo, each player starts at 1000 as they win or lose, gain or lose points, respectively, proportional to their opponent's skill. Post fight Elo for fighter A is equal to the inverse of one pulse ten to the power of the difference of current fighter B Elo and fighter A Elo divided by four hundred. Post fight Elo for fighter B is equal to the inverse of one pulse ten to the power of the difference of current fighter A Elo and fighter B Elo divided by four hundred. Over time this becomes an overall reflection of skill. 💻How we built it We use two data sets containing fight statistics to predict the outcome. We used binary classifications. Build a graph using c born. Random foresting. 🧑‍🤝‍🧑Challenges we ran into Deciding what kind of data to collect from UFC players and building an Elo prediction system was challenging. There was a wealth of information available, but determining which data was relevant and important for creating accurate predictions was difficult. Each player's physical condition and winning experiences in UFC are distinct and must be considered when building an Elo predi"
      }
    ]
  },
  {
    "file_path": "./devposts/flamefury.html",
    "project_id": "flamefury",
    "title": "[U30] - Elemental Clash",
    "tagline": "Elemental Clash is an electrifying, fire-and-water-flinging showdown where you race against time to protect your room from being consumed by the unstoppable fury of the opposing element!",
    "hackathon": "",
    "built_with": [
      "metapresenceplatform",
      "quest3",
      "questionpro"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "handtracking (to eliminate the controllers learning curve)",
      "We have really progressed a lot from our first day and relished the opportunity to learn and implement our new skills."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/989/259/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Elemental Clash - Game Poster Elemental Clash - Head to Head Elemental Clash - Game Poster Elemental Clash - Head to Head 1 2 3 4 5 Inspiration We started with the idea of creating a very simple, fun, easy to play table-top game to introduce to new people to the Meta Quest 3: A game for non-gamers. To ease them in, we wanted our game to include: passthrough (to reduce overwhelm of VR) handtracking (to eliminate the controllers learning curve) multiplayer (to have the reassurance of another person being there) very simple actions and game rules (so it’s easy to get started and into a natural flow) From here we ideated and settled on a casual and social, picking and throwing action game involving 2 elements - fire and water. What it does 2 players enter: 1 is water. 1 is fire. In a fire-and-water-flinging showdown, each player picks up their element ball and throws it into the opposing element’s pool. As many as they can, as fast as they can…before the pool shrinks and disappears. The winner with the most successful throws, is revealed by the whole room filling up with their winning element. How we built it Our game was built in Unity with the Meta Presence Platform. \nIn game assets were made in Unity. Challenges we ran into The multiplayer presented the most challenges for us with shared spatial anchors. Accomplishments that we're proud of We have really progressed a lot from our first day and relished the opportunity to learn and implement our new skills. What we learned We learnt a lot of new Unity skills and really benefited from the support of the mentors - the Meta, Photon and Unity mentors really helped us in developing our project and learning new skills. What's next for Elemental Clash We would like to bring in additional levels and storytelling and introduce other elements, like wind, too. Built With metapresenceplatform quest3 questionpro Try it out drive.google.com Submitted to XR Hack - London Created by shammi seth Pallavi Davé Jiachen Zeng www.jiax2.com"
      }
    ]
  },
  {
    "file_path": "./devposts/fire-away.html",
    "project_id": "fire-away",
    "title": "Fire away",
    "tagline": "The world's first hands-free, multi-functional DL/AI drone",
    "hackathon": "",
    "built_with": [
      "arduino",
      "assemblyai",
      "azure",
      "deep-learning",
      "dji",
      "fastapi",
      "html",
      "kaggle",
      "python",
      "rest",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/225/255/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration: As a group of 4 people who met each other for the first time, we saw this event as an inspiring opportunity to learn new technology and face challenges that we were wholly unfamiliar with. Although intuitive when combined, every feature of this project was a distant puzzle piece of our  minds that has been collaboratively brought together to create the puzzle you see today over the past three days. Our inspiration was not solely based upon relying on the minimum viable product; we strived to work on any creative idea sitting in the corner of our minds, anticipating its time to shine. As a result of this incredible yet elusive strategy, we were able to bring this idea to action and customize countless features in the most innovative and enabling ways possible. Purpose: This project involves almost every technology we could possibly work with - and even not work with! Per the previous work experience of Laurance and Ian in the drone sector, both from a commercial and a developer standpoint, our project’s principal axis revolved around drones and their limitations. We improved and implemented features that previously seemed to be the limitations of drones. Gesture control and speech recognition were the main features created, designed to empower users with the ability to seamlessly control the drone. Due to the high threshold commonly found within controllers, many people struggle to control drones properly in tight areas. This can result in physical, mental, material, and environmental damages which are harmful to the development of humans. Laurence was handling all the events at the back end by using web sockets, implementing gesture controllers, and adding speech-to-text commands. As another aspect of the project, we tried to add value to the drone by designing 3D-printed payload mounts using SolidWorks and paying increased attention to detail. It was essential for our measurements to be as exact as possible to reduce errors when 3D printing. The servo "
      }
    ]
  },
  {
    "file_path": "./devposts/findayota.html",
    "project_id": "findayota",
    "title": "FindAYota",
    "tagline": "Welcome to FindAYota! A website that will help guide you to the Toyota vehicle of your dreams! We hope that our work will help many customers find Toyota vehicles that matches their lifestyle needs.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "github",
      "html",
      "json",
      "python",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/235/747/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Catalogue Home Page #1 Home Page #2 Form #1 Form #2 Form #3 Results Financing Catalogue Home Page #1 Home Page #2 Form #1 Form #2 Form #3 Results Financing Catalogue 1 2 3 4 5 6 7 8 9 Inspiration Brought together by our mutual ownership of Toyota cars, we took inspiration from the beloved vehicle brand's front facing website and from TrueCar's Find Your Fit website. We wanted to find a way for potential customers to get familiar with Toyota's products by taking into account their personal preferences and calculating the Toyota vehicle that best fit each person. We also wanted this website easily accessible through Toyota's very own website which we took inspiration from for our UI/UX design. We hope that in the future, Toyota will be able to incorporate this helpful feature into their websites! What it does FindAYota has many features that make it unique, namely: An interactive UI/UX design Intuitive form design Smart calculation of car compatability Customizable financial planning for each car How we built it FindAYota was built as a Flask web application using Tailwind, HTML, CSS and Python for frontend and backend, and json files to handle Toyota car information.\nThe calculation of car compatability was done by compiling the user's inputs on the form, and putting \"weights\" on certain question inputs. For example, body style of the car was given the most weight in determining the compatability of cars with the user's preferences. In the results page after submitting the form, the top 3 cars with the highest compatability points were displayed. The financial aspect of FindAYota is built on a Python file that calculates the total amount of money someone would need to finance a car. The python file then uses credit score information to roughly estimate APR. The APR, total financed amount, and months financed are used to calculate the estimated monthly pay required. These numbers provided an accurate estimate close to those on the Toyota website. Challenges we ran int"
      }
    ]
  },
  {
    "file_path": "./devposts/feel-track.html",
    "project_id": "feel-track",
    "title": "Feel-Track",
    "tagline": "Complete feel-track surveys to earn NFTs and view illness prediction on symptoms. Also view the rates of the most recent illness outbreak for each state and make conscious decision for vacation plans!",
    "hackathon": "",
    "built_with": [
      "flask",
      "foliu",
      "framer",
      "heroku",
      "html5",
      "kaggle",
      "machine-learning",
      "python",
      "typdream"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Typedream Winner Best Use of Framer Created by I parsed CDC data using pandas, implemen",
      "FreyHacksWinnerBest Use of TypedreamWinnerBest Use of Framer",
      "What's next for Feel-Track",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/018/269/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Summer vacations are just around the corner, and the hottest thing to do is travel. Ever since the advent of the coronavirus, however, the prevalence of safety from infectious diseases is at its highest. While travel borders have opened up and vaccines have arrived, our fear of infectious diseases (beyond just the coronavirus) will not depart easily. Our team aims to give a user-friendly one-stop-shop for people to see the rates of illnesses in different areas so that they can make conscious, and hopefully safe, choices on where to travel. What it does Feel-Track shows two types of interactive maps. The first is the most recent rate of infectious outbreaks through an interactive choropleth map. The second is another interactive map showing how other users are feeling wherever they are, and the potential illness they may have. The users’ data is collected through a survey of symptoms, which our AI model can use to identify as potential illnesses. Users can gain points by completing these surveys, which can be used to redeem NFTs; these NFTs come from data companies who will buy our data. How we built it Our team chose to use Framer and Typdream to design our summer-themed frontend to maximize frontend efficiency. We parsed data from the cdc website and showed it in an interactive map using Folium/Leaflet. We used for Our backend was deployed with Heroku. Challenges we ran into One of the challenges was the building of the choropleth. The data provided by the CDC were not all consistent so it required some manual work to gather the data we wanted to collect. Some of the website building tool did not provide html export so it was hard to connect with the backend Accomplishments that we're proud of We are especially proud of our web app’s design. It was our team’s first time using Framer and Typdream, and we are proud to creating a program that looks good with these tools. What we learned We learned about current outbreaks by reading documentations at CD"
      }
    ]
  },
  {
    "file_path": "./devposts/farm-to-table-5wmdaj.html",
    "project_id": "farm-to-table-5wmdaj",
    "title": "Farm to Table",
    "tagline": "Farm to table - A collaboration platform connecting canadian farmers and volunteers to food banks",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-cloud",
      "google-distance-matrix",
      "google-geocoding",
      "google-maps",
      "mysql",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/195/511/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration Introducing Farm to Table - A collaboration platform connecting canadian farmers and volunteers to food banks What's the problem? Throughout canada, farmers are dumping large amounts of crop due to the lower demand from the food industry. \nFarms are forced to continue to grow crops: If demand goes back to normal, they can't risk getting caught behind a crop cycle. \nThis means that as farmers harvest, they are forced to dump their crops, as they're too expensive to ship and there's no demand for them. Where we fit in We know farms who's sails are mainly retail are suffering because of the low demand in the food industry. \nCrops are very expensive to transport for the already struggling farming sector. And we have many people currently sitting at home with nothing to do! Our Solution Participating farmers could give this extra produce to food banks accepting fresh produce, or food banks could work to buy shipments directly from farms, but transporting produce is expensive: The farming industry is already in trouble due to low sales, and food banks are struggling with the current covid response. This is where we step in, offering a service to connect participating farmers, volunteers, and local food banks. What it does Farm to Table has 2 use-cases: the Volunteer and Farmer perspectives. Farmers can sign up through the registration system and enter available times into a calendar. Volunteers can then browse through the available times of various farms, sorted by distance from the volunteer's location. After selecting a time, the farmer is notified, a google calendar event is generated for the volunteer and a google maps route is generated and attached to the calendar invite. How we built it Backend - Python, Flask Front End - JavaScript,  React APIs - Google Calendar, Google Maps Geocoding, Google Maps Distance Matrix, Google Maps URL Schemes Challenges we ran into So, as with any project, there are always unforeseen challenges. For us, one of"
      }
    ]
  },
  {
    "file_path": "./devposts/farsight-fyi.html",
    "project_id": "farsight-fyi",
    "title": "Farsight.fyi",
    "tagline": "AI-powered layoff risk analysis",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "claude",
      "fastapi",
      "python",
      "react",
      "selenium",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/500/919/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Analysis Page Landing Page Company Input Analysis Page Landing Page Company Input Analysis Page 1 2 3 Inspiration Mass layoffs always feel like lightning bolts devastating but “out-of-the-blue.” We wanted to give employees, recruiters, and policymakers foresight instead of hindsight. With WARN filings, news rumors, and tiny LLMs all in the open, we realized we could surface an objective layoff-risk score weeks or months before the pink-slips hit. That vision became Farsight.fyi. What it does Farsight.fyi is a hybrid AI-system web application that assesses the potential layoff risk of a company. Users enter a company name, and our system performs a multi-stage analysis in real-time: Data Aggregation: It scours the web for recent news articles and public data related to the company. AI-Powered Feature Extraction: An LLM reads through the unstructured text of the articles to extract key risk factors. Predictive Modeling: These extracted features are fed into a CatBoost machine learning model, which calculates a quantitative risk score. Insightful Reporting: The application presents the user with a final risk level, a detailed explanation of the contributing factors, and a summary of the key data points that influenced the score, all delivered through a clean and intuitive user interface. How we built it Frontend: Built using React and TypeScript, using Vite for local dev, Tailwind for styling and various components from shadcn/ui Backend: Python and FastAPI Real-time Communication: Socket.IO Web Scraping: Beautiful Soup and Selenium AI & Machine Learning: Claude 4 and a CatBoost model Database: Simple SQLite database Challenges we ran into Prompt Engineering: Designing prompts that could consistently and accurately extract specific, structured features from the diverse and noisy text of news articles required extensive iteration and refinement. Managing Asynchronous Tasks: Building a non-blocking, real-time user experience was complex. We had to carefully manage long-r"
      }
    ]
  },
  {
    "file_path": "./devposts/fluffy-friends.html",
    "project_id": "fluffy-friends",
    "title": "Fluffy Friends",
    "tagline": "A gallery of the fluffiest friends for the roughest of times.",
    "hackathon": "",
    "built_with": [
      "css",
      "gatsby",
      "git",
      "graphql",
      "html",
      "javascript",
      "netlify",
      "sass"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/614/019/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "The advanced deep nueral network algorithm at play Inspiration Every time I get frustrated with my homework I like to look at pictures of my dog. Not only does she take my mind off the work, but I'm allowed to reminisce on our history... Nah I'm lying she's just really cute. So that's why I made Fluffy Friends!! Granted, my dog isn't fluffy by any means, but her cuteness is something I like to look at. But, why would I only limit myself to her? There are millioooons of other cute animals on the internet too. Boom . That's where Fluffy Friends comes in: cute animals for your luxury. MY fluffy friend What it does Users are able to scroll through my collection of cute animals (that I did not steal off of google). Just keep tapping the next button under the search tab! The website is guaranteed to pull you in with its appeal to cuteness. How I built it I built the website using a react-based framework, Gatsby. The styling was done with SASS, a CSS extension. I chose Gatsby because of its preloading of pages, ultimately making it one of the faster options. Also, I believed it was a great gateway to frameworks for me. I used Visual Studio Code with the appropriate plug-ins for my work environment. The website is deployed through Netlify cloud computing my github repository. Challenges I ran into I ran into many challenges. This was my first time touching javascript, so learning the semantics on top of the framework proved to be very difficult for me. These issues didn't make debugging any easier, as it was inarguably my greatest weakness. I spent upwards to 2 hours on bugs. My motivation hit record lows during those hours. I gave thought to scrapping the project in its entirety. The only thing that prevented me from doing so was the image of an inflated bunny staring at me on the screen. I didn't want the guilt of erasing it on my hands. Accomplishments that I'm proud of I'm glad I decided to make a website. This is the first one that I've deployed. What I'm most proud of"
      }
    ]
  },
  {
    "file_path": "./devposts/fable-m1d4bq.html",
    "project_id": "fable-m1d4bq",
    "title": "Fable",
    "tagline": "Bringing stories to life with immersive, accessible reading",
    "hackathon": "",
    "built_with": [
      "audiocraft",
      "css",
      "fastapi",
      "gemini",
      "langchain",
      "mediapipe",
      "motion",
      "opencv",
      "react",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Hack Winner Best Accessibility Hack Created by sheng Zhi Sheng menamerai Duong Daniel Venne",
      "Best Overall Hack Winner Best Accessibility Hack Created by sheng Zhi Sheng menamerai Duong Daniel",
      "HackDuke: Code for Good 2025WinnerBest Overall HackWinnerBest Accessibility Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/262/916/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "fable cover image Fable – Hackathon Submission Inspiration For over 30 years, both of my parents have been dedicated educators. My mother, in particular, has spent much of her career fighting to make learning more accessible for all students-- from students with learning disabilities to those who have English as their second language. She has earned multiple grants from the state of Ohio for her work on using music as a tool to break down educational barriers, especially for students with learning disabilities and those learning English as a second language. Growing up, I watched her dedicate herself to making sure no student was left behind, no matter their challenges. She showed me firsthand how learning isn’t one-size-fits-all—some students struggle with reading, others with comprehension, and sometimes, all it takes is the right sensory experience to unlock a whole new way of understanding. Her work has deeply shaped my values. I believe technology should be used to make education more inclusive, more engaging, and more human. That’s exactly what inspired us to build Fable—a reading experience that adapts to the reader, not the other way around. By integrating AI-generated ambience, music, and accessibility features, we’re bringing stories to life while ensuring that reading is an experience that everyone can enjoy, no matter their background or ability. What it does Fable enhances the reading experience with: AI-generated ambience & music that adapts to the mood of the text. Customizable UI for font styles, background colors, and text formatting. Hand gesture scrolling for a seamless, touch-free reading experience. Dyslexia-friendly rewording with a simple double-click to improve readability. How we built it FastAPI – Powered the backend for real-time text processing and AI-driven rewording. AudioCraft– Generated dynamic ambience and sound effects, balancing quality with efficiency. LangChain & Gemini Flash 2.0 – Handled AI-driven readability improvements and t"
      }
    ]
  },
  {
    "file_path": "./devposts/exteriscan.html",
    "project_id": "exteriscan",
    "title": "ExteriScan",
    "tagline": "A performant scanning software, made to detect surface anomalies on both micro scale (microscopic pictures) and macro scale (satellite pictures)",
    "hackathon": "",
    "built_with": [
      "azure",
      "classification",
      "coco",
      "docker",
      "jupyter",
      "keras",
      "labelimg",
      "machine-learning",
      "opencv",
      "python",
      "rtc",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Developed a first binary classifier; created, modified and enlarged dataset."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/894/252/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Detection of cracks on streets Microscopical fractures Position of all cracks Labeling every image and marking all the cracks Detection of cracks on streets Microscopical fractures Position of all cracks Labeling every image and marking all the cracks Detection of cracks on streets 1 2 3 4 Inspiration Noticing a microscopical fracture on a wing of a plane before it's too late, could mean the difference between someone's honeymoon and funeral. Whether today, or in the future years of technology - the stability of our enormous metal constructions, will remain as relevant as never before.\nWe're a team of three students, who are interested in shaping a safer future for everyone, and plan on doing so in the most efficient way possible. What does it do The core of the project is data analysis. Multiple classification and object detection algorithms are mixed together to analyze visual data and provide insigts with minimal computing power. A picture of a solid, fed through our scanning software will be analyzed whether it contains any surface anomalies, and if any of them are present, the software will determine the approximate position and the count of all damage points. Due to the sheer volume of data, generated by in-depth scans, we knew that the software had to be as efficient as possible - crunching through gigabytes of data in a matter of minutes, it would be able to deal with heavier datasets in a reasonable amount of time already. We have been able to achieve our own-set speed goal and proof test it by performaing crack detection with a live camera footage - the speed of image analysis can easily keep up with lower framerate video streams. Speed however, while impressive on it's own, is not all that matters. Since the data that has to be analyzed could vary heavily, the software has to be able to adapt to different types of datasets. We believe that we have managed to achieve precisely that - going from micro to macro, analysing camera footage of roads, our softwar"
      }
    ]
  },
  {
    "file_path": "./devposts/facemelody.html",
    "project_id": "facemelody",
    "title": "FaceMelody",
    "tagline": "Let Your Face Speak, Let the Music Guide",
    "hackathon": "",
    "built_with": [
      "computer-vision",
      "css",
      "gcp",
      "html",
      "javascript",
      "machine-learning",
      "replit",
      "youtubeapiv3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "collegiate hack Created by Chose the name, chose the slogan, chose the brand colors, chose the bran",
      "Best collegiate hack Created by Chose the name, chose the slogan, chose the brand colors, chose the",
      "Citro Hacks 2023WinnerBest collegiate hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/536/579/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were considering people with disabilities and saw how it may be hard for them to use or even interact with technology depending on how severe the situation is. This may affect their mood since they may not be able to do much. Music has the ability to uplift and heal and would be of help to them, since it can lift their mood or help them control it. However, they may not be able to switch or even play music by themselves, and if they have a caretaker it they may not be able to constantly monitor the person's states and expressions to change the music. This inspired us to create FaceMelody to help automate the music. What it does FaceMelody is a website application that uses a machine learning model to read the facial expressions of the user and play music based off of their expression. It will observe the user and switch the music at certain intervals to meet the needs of the user. How we built it FaceMelody is built using Javascript, HTML, and CSS for the user interface and is connected to an MTCNN and VGG-Face Mode trained machine learning model to recognize facial expressions in real time. We used some simple Javascript to integrate everything and create the final product. Challenges we ran into This project posed some unique challenges. We had to deal with real life problems, such as how the user would even interact or use the product. We discussed the issue and came to the solution to have minimal physical interaction from the user after the web application has been started, most likely from the caretaker. Accomplishments we are proud of This was a daunting task that we did not have much experience in, and we are proud to have completed the project that will help better the lives of those around us. What's next for FaceMelody Moving forward, FaceMelody would extend to more than just improving playing the right music. We would like to use the facial expression AI to extend to activating other features, such as notifying caretakers. Resources https:"
      }
    ]
  },
  {
    "file_path": "./devposts/financing4food.html",
    "project_id": "financing4food",
    "title": "Financing4Food",
    "tagline": "Financing4Food is an interactive quiz site where users boost financial literacy and win local business coupons, helping people learn while supporting small businesses to succeed in today’s economy.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/129/452/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration After years of visiting farmers' markets and seeing local small businesses struggle, we were inspired to take action. Financing4Food was born from our desire to make a positive impact—helping individuals improve their financial literacy while driving more traffic to small businesses. We aim to provide both valuable education and tangible support, creating a sustainable ecosystem where people can gain knowledge and local businesses can thrive. What it does Financing4Food is an interactive quiz platform that promotes financial literacy while supporting local businesses. Users participate in engaging quizzes on key financial topics, from budgeting basics to smart investing. As they score well, they earn coupons redeemable at local small businesses, giving them practical rewards while boosting community businesses' visibility and customer flow. It’s a win-win for financial education and local economic support. How we built it We began by developing a robust backend for the quiz using Python, focusing on educational content and a reward system to motivate learning. Our team dedicated extensive time to mastering frontend skills in HTML, CSS, and JavaScript, building a visually appealing and user-friendly interface. From designing the quiz flow to creating an intuitive reward system, we balanced functionality with an engaging experience to make financial learning both fun and impactful. Github: https://github.com/VedSoni-dev/CapitalOneChallenge Challenges we ran into Our biggest challenge was navigating frontend development, as it was our first time working with HTML, CSS, and JavaScript. Learning the intricacies of building a responsive, appealing website in a short timeframe was intense but rewarding. Being new to hackathons also added an extra layer of excitement and pressure, as we worked hard to complete a project from concept to execution within the set timeframe. Accomplishments that we're proud of We’re incredibly proud of building a functional, vis"
      }
    ]
  },
  {
    "file_path": "./devposts/flightspace.html",
    "project_id": "flightspace",
    "title": "FlightSpace",
    "tagline": "Revolutionize your flight experience with FlightSpace - A touch-ready app for in-flight information, engagement and entertainment. All without internet access.",
    "hackathon": "",
    "built_with": [
      "actix-web",
      "canvas",
      "css",
      "html5",
      "javascript",
      "regexlib",
      "rust"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/478/991/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "FlightSpace landing page Inspiration When Vueling presented their challenge, the whole team's eyes lit up. The interesting challenge and the creative freedom caught our attention. We unanimously agreed on doing that project without sharing a single word.  Each with our own perspective, we came up with many ideas on how to handle our area of expertise. But that wouldn't be without challenge - We all ventured out to the unknown and went above and beyond to provide the best user experience. What it does FlightSpace provides an infotainment system for planes (or any sort of mass transit) without the need of a connection to the internet. But it does so with a twist - Users can interact with each other.\nOn our demo, we made a trivia game where users can see each other making decisions in real time. How we built it We built the backend, which is a REST API in Rust. The backend handles player stats and other API calls. The game mechanics and player interactions are made with JavaScript and HTML5 canvas. The stunning UI was built with vanilla HTML and CSS. Challenges we ran into Working on and with a REST API was a first for all of us. Handling the multi-threaded web server was a huge challenge, one we learnt a lot with solving. Working with this kind of interactive platform and with HTML5 canvases was also a first for the members working on the frontend. There were loads of hard-to-find bugs (but fairly to fix): things that didn't work and left no error trail, things that did work after not working for hours (and not chaning anything), code doing things we didn't ask it to do... Integrating the frontend and the backend has been a hard job, as transferring some of the objects between languages lead to problems due to differences in object types. Regardless on what part we worked on, there's a challenge we all faced: Staying organized on a team. \nBuilding a UI without having an API to support it yet and building an API without having a direct feel of how it's going to be used"
      }
    ]
  },
  {
    "file_path": "./devposts/eyetrain.html",
    "project_id": "eyetrain",
    "title": "eyeTrain",
    "tagline": "An eye exercise game to combat the increase of online activities.",
    "hackathon": "",
    "built_with": [
      "dlib",
      "gaze-tracker",
      "opencv",
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMUhack 2021 Second Place Prize Created by I made video, did eye research, and coded eye tracking",
      "TAMUhack 2021WinnerTAMUhack 2021 Second Place Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/378/245/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Gameplay Screen Start screen Tutorial Screen Gameplay Screen Start screen Tutorial Screen Gameplay Screen 1 2 3 4 Inspiration Due to Covid, almost all aspects of school and work alike have shifted to the computer. While it might be nice to work from home, it is also very straining on your eyes to be staring at a computer screen for the entire day. The symptoms for eye strain include headaches and eye pain, among others. To combat this, we have decided to produce a game that exercises your eye as you play through different eye movements and blinking. Our team got the idea to address this topic through the combination of the Dell and HPE challenges. What it does Our game is a spin on the classic rhythm game, with the player using their eyes rather than using their keyboard or mouse to interact with the game. Arrows fall from the top of the screen at certain time intervals, and when the arrow reaches the bottom of the screen you must either blink or look to the side of the screen that matches with the arrow direction. Eye exercises have been proven to reduce eye fatigue, and by playing the game your eyes should feel less fatigued than before. How we built it With Python, we used the gaze_tracking library for our eye tracking (which included the use of openCV and dlib), as well as making the actual game through Pygame. For the music we used \"Slow Motion\" by Bensound to create a peaceful backdrop to our gameplay. Challenges we ran into Three of us were new to hackathons so we had to spend a bunch of time at first deciding how we wanted to go about things. At first we wasted multiple hours trying to figure out a project and then once we decided on this idea we started to look for libraries. The problem we ran into is we started using a library that didn't support webcams at first and required more expensive hardware we did not have access to. After figuring out things we wanted to implement things went more smoothly. The gaze_tracker module only had no up and down capabil"
      }
    ]
  },
  {
    "file_path": "./devposts/forecastfanatics.html",
    "project_id": "forecastfanatics",
    "title": "ForecastFanatics",
    "tagline": "We are really passionate about forecast so the ifo Business Climate Index is our favourite weather channel!",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Overall Prize, ifoHack Created by I worked on the back-end",
      ", ifoHack Created by I worked on the back-end",
      "ifoHack 2023Winner1st Overall Prize, ifoHack",
      "Winner",
      "I worked on the back-end. It was my first time using Python and I learned a lot about creating web apps in Streamlit"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/467/156/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration ifo\nBuzzfeed What it does Predicts the given three target variables (state of business, business expectation, price expectation for 2022) of the ifo Business Climate Index How we built it Python, streamlit, sklearn Challenges we ran into Working with the virtual machine, chasing time Accomplishments that we're proud of 0.56 accuracy :')\nAnd most importantly our fun little quiz What we learned Power of energy drinks/coffee\nA LOT OF DATA MANIPULATION/CLEANING\nCombining our strengths What's next for ForecastFanatics SLEEP\nThen bring on ifoHack 2024!! Link to Gitea:\n10.0.0.6:3000/user91-ifohack2023/ifoHack2023-ForecastFanatics Built With python Submitted to ifoHack 2023 Winner 1st Overall Prize, ifoHack Created by I worked on the back-end. It was my first time using Python and I learned a lot about creating web apps in Streamlit Elena Boni Lucia Nafziger Julius Hege Merve Ogretmek Furkan Yigit Kavak"
      }
    ]
  },
  {
    "file_path": "./devposts/flostem.html",
    "project_id": "flostem",
    "title": "FloSTEM",
    "tagline": "From the Stem and Up, Discover and Blossom your Future",
    "hackathon": "",
    "built_with": [
      ".net",
      "css",
      "html",
      "javascript",
      "sql",
      "ssms"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/740/644/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home Screen House of Math House of Engineering House of Technology House of Science Home Screen House of Math House of Engineering House of Technology House of Science Home Screen 1 2 3 4 5 6 Inspiration What inspired us to create FloSTEM is the idea of impacting younger generations to have the passion and intellectual drive to develop solutions that will benefit our future through STEM innovation and discovery. What it does FloSTEM, a web application, sprouts students' curiosity and excitement in STEM through a pixelated fantasy-themed assessment. In this assessment, the user answers various questions. Each answer choice contains specific attributes that will determine which STEM category best fits the student. How we built it For the front-end development, we utilized HTML/CSS and Javascript. We used SQL, SSMS, and .NET for the back-end development. Our designs were created in Aseprite. Challenges we ran into We initially had several creative ideas we wanted to implement into our project. However, we had to narrow them down due to the lack of hackathon experience and time constraints. Accomplishments that we're proud of We managed to adapt and work under pressure in a time constraint. What we learned Through this event, we organized our project attentively, which led us to discover how to apply the Database First Approach, reverse engineer a database, and intertwine an algorithm to front-end development. What's next for FloSTEM We will improve the user experience and design of the project, creating an interactive story that will draw an adventurous experience for the user. Built With .net css html javascript sql ssms Submitted to TAMUhack X Created by Summer Wong Jonathan Gao Salina Teng Claire Wang"
      }
    ]
  },
  {
    "file_path": "./devposts/foodify-rdfi2b.html",
    "project_id": "foodify-rdfi2b",
    "title": "Foodify",
    "tagline": "An innovative Shopify app that helps restaurant or other food service owners host their online food shops with speed and ease!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "google-cloud",
      "google-vision",
      "html",
      "java",
      "javascript",
      "npm",
      "ocr",
      "proto",
      "python",
      "shopify",
      "webrtc"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/229/353/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Shopify shop can also be managed and configured from the Foodify platform itself. Our logo for Foodify Registration page, where company owners can register their restaurants or other food providal servers Menu scan - one of the features that makes the creation of a virtual shop an extremely simple process Delivery services - once the complete Menu is uploaded, the next big step is delivering the dishes to people ordering thgem remotely. Scheduled pickup - a rather less popular feature that almost all modern restaurant's have - it's like preordering food that you can pick up! Table reservation tool - something that is a must have on an official restaurant e-commerce shop. An inbuilt picture taing application that stores the menu pictures in the Foodify gallery. Gallery - this is where the pictures can be reviewed and where the Google Vision can give a short summary on what it sees in the pictures. A confirmation screen for a created online shop. From here on now everything can be managed from Shopify platform normally. The Shopify shop can also be managed and configured from the Foodify platform itself. Our logo for Foodify Registration page, where company owners can register their restaurants or other food providal servers Menu scan - one of the features that makes the creation of a virtual shop an extremely simple process Delivery services - once the complete Menu is uploaded, the next big step is delivering the dishes to people ordering thgem remotely. Scheduled pickup - a rather less popular feature that almost all modern restaurant's have - it's like preordering food that you can pick up! Table reservation tool - something that is a must have on an official restaurant e-commerce shop. An inbuilt picture taing application that stores the menu pictures in the Foodify gallery. Gallery - this is where the pictures can be reviewed and where the Google Vision can give a short summary on what it sees in the pictures. A confirmation screen for a created online shop."
      }
    ]
  },
  {
    "file_path": "./devposts/fanum-diddler-horse-tax.html",
    "project_id": "fanum-diddler-horse-tax",
    "title": "Fanum Diddler - Horse Tax",
    "tagline": "Yo, you ever seen a horse snatch a glizzy and yeet like baby gronk? In this game, it’s all about chomping correct snacks with a sigma grindset and dodging the Fanum Hay Tax while keeping that rizz.",
    "hackathon": "",
    "built_with": [
      "framer-motion",
      "react",
      "react-three-fiber",
      "shadcn",
      "three.js",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "worst project ($5) Winner (TPIA) this project is awesome Winner top 5 community votes prizes (SURPR",
      "s Winner worst project ($5) Winner (TPIA) this project is awesome Winner top 5 community votes prize",
      "brainrot jia.seed hackathon ($5,772) in prizesWinnerworst project ($5)Winner(TPIA) this project is awesomeWinnertop 5 community votes prizes (SURPRISE GIFTS)",
      "Brainrot hackathons are the best",
      "Winner",
      "created the first W rizz moment at Waterloo University"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/165/377/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "back to ohio's mom in-game rizzly sigma screenshot mewmaxxing interaction page beta horse yeet back to ohio back to ohio's mom in-game rizzly sigma screenshot mewmaxxing interaction page beta horse yeet back to ohio back to ohio's mom 1 2 3 4 5 6 ⚠️WARNING⚠️\nThis project includes a lot of sound effects, headphones and low volume is recommended. Inspiration The internet is full of chaos, and we wanted to channel that into something fun, absurd, and uniquely entertaining. The idea of a 3D horse food serving simulator—complete with brainrot soundtracks and over-the-top animations—felt like the perfect way to bring together our love for memes, creative coding, and questionable humor. What it does The game is a 3D horse food serving simulator where players take on the role of serving “questionable” food items to horses in a chaotic and surreal environment. The game features food items like “Grimance Nuts” and “Skibidi Pie”, brainrot soundtracks, and absurb reactions to food items. Ong kizzy no cap this shit be bussin fr fr only those who know appreciate the true culinary delight. Here we like our cheese drippy How we built it The project was developed using: React-Three-Fiber for building and rendering the 3D environment. Blender for adjusting horse models and food items with wacky textures and effects. Shadcn and framer for UI animations Challenges we ran into Our IQ significantly dropped during the creation of this project Accomplishments that we're proud of The simulator is functional (somehow) and three.js works correctly. What we learned Brainrot hackathons are the best What's next for Fanum Diddler - Horse Tax Multiplayer mode: brain rot togeether More Food Items: even more cursed items. Enhanced Animations: Adding new horse reactions like rage-quits and victory dances. Better mobile support Built With framer-motion react react-three-fiber shadcn three.js vite Try it out GitHub Repo fanum-diddler-horse-tax.vercel.app Submitted to brainrot jia.seed hackathon ($5,772"
      }
    ]
  },
  {
    "file_path": "./devposts/festivall.html",
    "project_id": "festivall",
    "title": "F3STIVAL",
    "tagline": "Conduct concerts in the metaverse, powered by DeSo and Gather.town",
    "hackathon": "",
    "built_with": [
      "css3",
      "deso-protocol",
      "emotion",
      "gather",
      "html5",
      "javascript",
      "materialui",
      "react",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "HackerlandWinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/023/515/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 💡Inspiration We wanted to build something that turns listners from being passive consumers of songs and albums to music fans who could directly engage with their favorite artists and participate in the upside of their musical careers. Forward-thinking artists are experimenting with Web3 tools to engage with their communities and build loyalty amongst their fans. Whereas existing PFP NFT collections are static images that can be displayed as a badge of affiliation with a particular online community, artists’ NFT collections are dynamic membership clubs that confer certain access rights and benefits for tokenholders. These privileges could include exclusive access to sales of merchandise and concert tickets, invitations to private Discord channels to interact with other fans and/or the artist, meet and greets, airdrops and giveaways, and even admission to “roped off” sections of metaverse virtual worlds (such as Decentraland or Sandbox). https://www.forbes.com/sites/leeorshimron/2022/02/28/how-musicians-are-using-nfts-to-revolutionize-fan-engagement/?sh=217032901fed ⚙️ What it does F3STIVAL lets artists host and organize concerts virtually with gather.town, and also monetize these concerts with the power of NFTs on the DeSo blockchain. Artists and musicians can create a space for their concert on gather.town, mint NFTs on the DeSo blockchain and display their minted NFTs for fans to buy within their concert venue with F3STIVAL. 🏗 How we built it We built F3STIVAL's toolkit with React, Vite, Javascript, HTML and CSS. We also used Material UI and Emotion for the UI. Here's how we used technology from MLH Sponsors this weekend: 💙Use of DeSo We used DeSo to enable artists to mint NFTs, because we learnt that it was built ground up for the purpose of social media and thus, is capable of handling large picture and audio files without costing a lot, unlike blockchains built for fintech. We used the deso-protocol package to fetch NFTs and display them in a car"
      }
    ]
  },
  {
    "file_path": "./devposts/foodfriends.html",
    "project_id": "foodfriends",
    "title": "FoodFriends",
    "tagline": "Web app that allows volunteers and restaurants to communicate to each other about food recycling needs.",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "google-maps",
      "html",
      "javascript",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/703/626/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Whether it be your local Tims or even upbeat restaurants, it is no secret that almost all food places have food waste, a lot of which could be eaten by people who want and need it. However, due to lack of infrastructure in most restaurants for such an operation, most of that food is still thrown out at the end of the day. But what  if... What it does Foodfriends is a web app created to link any place with food waste to local organizations so that volunteers can go pick up the food and deliver them to \"food waste centres\", where that food would then be redistributed to people who need it. How we built it We used React Native, Javascript, Html and CSS for the front end, and for the backend we used Flask and Google Cloud. We also used the Google Maps API (a part of google cloud) to build our map system functionality. Challenges we ran into The biggest challenge we ran into was the difference in timezones between members of our team, which posed a huge obstacle in terms of communication and lead to several people leaving and several new people being recruited over the course of the hackathon. Accomplishments that we're proud of We were able to get this app built despite all of the various changes in team members! What we learned The backend devs on our team were forced to work with a bit of frontend and vice-versa, which lead to all of us discovering how truly little we know in the world of software development! Overall, I personally learnt a completely new workflow to work with my teammates, and I'm sure they did the same too! What's next for FoodFriends The next step for FoodFriends is finding some food places and some \"friends\" (volunteer organizations) that want the food! (i.e expanding our userbase) Built With css3 flask google-maps html javascript react-native Try it out hscd3.csb.app Submitted to Hack the Valley V Created by I built the majority of the frontend and worked on integrating it with the backend. Arihan Sharma I worked on integratin"
      }
    ]
  },
  {
    "file_path": "./devposts/flock-9yb8iq.html",
    "project_id": "flock-9yb8iq",
    "title": "Flock",
    "tagline": "Flock is the world's first airport networking app, a one stop shop to find activities to do and chat with people on your flight, and share your flight details: all at the convenience of your hands!",
    "hackathon": "",
    "built_with": [
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Airlines Hack Created by I built the forum section of the app! It’s my first project in React, and",
      "AA Challenge: Best Airlines Hack Created by I built the forum section of the app! It’s my first pro",
      "TAMUhack 2023WinnerAA Challenge: Best Airlines Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our team is well acquinted with air travel, and noticed that one unspoken aspect of it can be loneliness. Airports can be a strange phenomena when travelling alone, where regardless of being surrounded by thousands of people, if one is without friends and family they can feel alone and closed off. Combined with the sheer amount of time it takes in air travel, this can become mentally draining. Even at airports, there are often tons of things to do which are overlooked due to lacking media presence. What it does Thus, we created an app to solve the problem of air travel loneliness: a one stop air travel social media app! The name \"Flock\" accurately represents our motivation behind the app: flock travellers together! The app firstly gives a user the opportunity to explore the airport and surrounding area. We did this by adding a forum section where users can view posts by fellow travellers. The feed of these posts is personalizable, where the user can sort by duration, price, inside or outside security, and type of activity. These posts are rated by other users using upvotes and downvotes.\nNext, the app gives people on the same flight the ability to chat with each other. This feature was made with more freedom to the users, where they can use this chat to do what they find suitable!\nFinally, since it is an airport we have a feature to view the status and details of your flight in the same app for your convenience. How we built it We built it using the MERN Stack: MongoDB, Express.js, React, and Node.js. Git and Github was used for collaboration. Additionally, we also used a flight api to pull flight data in real time. Challenges we ran into The api we had access to was unreliable and would often deliver inconsistent data: which we had to work around. Accomplishments that we're proud of It was the first hackathon of 3/4 of our teammates, and all three of those teammates had no experience with development in any of the technologies of the MERN stack: hence i"
      }
    ]
  },
  {
    "file_path": "./devposts/financeflex.html",
    "project_id": "financeflex",
    "title": "FinanceFlex",
    "tagline": "All Your Finance Needs In One Place",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Place: Mechanical keyboards for all team members Created by Ashish Ramanan \"Python\" \"Java\" \"G",
      "Milpitas HacksWinnerThird Place: Mechanical keyboards for all team members",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Need for finance tools that don't take up much space or tabs What it does Stores all tools for finance in 1 place How we built it We use react HTML CSS py flask java script Challenges we ran into hard time using Flask but we eventually got it, our chatbot was buggy and it wouldn't work some times Accomplishments that we're proud of We accomplished all of what we planned to do What we learned Learned Flask chat gpt API, react What's next for FinanceFlex Add more tools like incorporating the articles to predict stocks Built With css flask html javascript python Submitted to Milpitas Hacks Winner Third Place: Mechanical keyboards for all team members Created by Ashish Ramanan \"Python\" \"Java\" \"GDscript\" \"Html\" \"CSS\" \"JavaScript\" \"React\" \"React Native\""
      }
    ]
  },
  {
    "file_path": "./devposts/fireworksim-org.html",
    "project_id": "fireworksim-org",
    "title": "fireworksim.org",
    "tagline": "click anywhere to launch a firework there! celebrate online anywhere you are - a one shot app",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/595/439/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Interactive Fireworks Display 🎆 Inspiration We wanted to create a digital experience that captures the wonder and excitement of real fireworks shows, making it accessible anytime, anywhere. The goal was to build something that would bring joy and provide a satisfying interactive experience through beautiful visual effects. What it does Our Interactive Fireworks Display is a web application that creates stunning firework explosions wherever you click or tap. Each firework launches with realistic physics, travels to its target height, and explodes into vibrant bursts of colorful particles with trailing effects. The application features: Realistic Physics : Fireworks launch with proper trajectory, gravity, and air resistance Particle Systems : Each explosion generates 25-50 particles with individual physics properties Dynamic Color Palettes : Six carefully curated color schemes for visually appealing combinations Trail Effects : Both fireworks and particles leave glowing trails as they move Mobile Responsive : Full touch support for mobile and tablet devices Smooth Animation : 60fps canvas-based rendering for fluid motion How we built it The application is built using modern web technologies: React with TypeScript for component structure and type safety HTML5 Canvas for high-performance rendering and animation Tailwind CSS for responsive styling Custom Physics Engine implementing gravity, velocity, and particle lifecycle management Optimized Animation Loop using requestAnimationFrame for smooth 60fps performance The core challenge was creating realistic particle physics while maintaining smooth performance across devices. We implemented custom algorithms for: Firework trajectory calculation Particle explosion patterns with radial distribution Trail rendering with fade effects Memory-efficient particle lifecycle management Challenges we ran into Performance Optimization : Rendering hundreds of particles simultaneously while maintaining 60fps required careful opt"
      }
    ]
  },
  {
    "file_path": "./devposts/flover.html",
    "project_id": "flover",
    "title": "Flover",
    "tagline": "A voice recorder and playback website that generates a unique flower pattern by analyzing your personal audio waves.",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/814/345/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Our team members have been sharing our sleep quality from our smart watches for the past few months (Yes, these past two days have been quite poor in terms of sleep quality). We have fun waking up every morning just to compete with each other about how well we slept. Since we enjoyed sharing our sleep data, we wanted to make something that would allow us and everyone else to share interesting data/information to one another. \nWe have found voice notes to be a fast and straightforward means to record memories. Our goal is to enhance the voice notes experience by generating unique floral patterns based upon our speech, with future plans to introduce a social aspect through URL sharing for existing voice recordings. What it does A main menu introduces users to Flover, a website that accepts audio recordings from a user. There are two buttons- one for recording, and one for playback. How is this different from a voice notes app?  We analyze the data of the sound recording. Using that data, we generate a pattern of flowers unique to that voice recording. How we built it Throughout the process of creating a website for the first time, we learned about the structures of HTML, as well as its tight knit embedding of CSS and javascript to enhance it. Since we started our project in Python, we also used Flask to connect the two. Challenges we ran into Our team decided to challenge ourselves and all got out of our comfort zones to take on the tasks that were not our strong suit. We had to scratch everything and restart four times as we jumped from framework to framework, library to library. Ultimately, we settled on building a website so that it was in the most accessible form possible and can allow easy sharing. Our original vision was very ambitious and we needed to continuously scale it down as the clock ticked closer and closer to the 24th hour. Lastly, simply the technicality of building a working product in an environment that none of us have ever touc"
      }
    ]
  },
  {
    "file_path": "./devposts/fleetcontrol.html",
    "project_id": "fleetcontrol",
    "title": "CabCab",
    "tagline": "CabCab. Your electric friend! \nCabCab uses novel algorithms to deploy autonomously driving cabs most efficiently. Precise mathematical optimization elevates Munich to the next level!",
    "hackathon": "",
    "built_with": [
      "linearoptimizer",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/152/679/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Linear Optimization Programme CabCab Dashboard Connection map across Munich First decision cycle of the algorithm. Efficiency metric is used as reference Linear Optimization Programme CabCab Dashboard Connection map across Munich First decision cycle of the algorithm. Efficiency metric is used as reference Linear Optimization Programme 1 2 3 4 Inspiration Autonomous driving is the future of transportation, and planning for these systems is essential. In Munich, we envisioned a smarter way to manage autonomous electric robot taxis to minimize waiting times, optimize routes, and operate sustainably. What it does Our project introduces a dynamic fleet control system for autonomous taxis. By using K-means clustering, the system prevents taxis from competing for the same customers and optimizes zones for better fleet coordination. Through constrained linear optimization, it ensures efficient and sustainable route assignments. The algorithm adapts to real-time changes, reducing waiting times while maintaining operational efficiency. A visual dashboard offers fleet managers a clear overview of all operations, including live updates on vehicle locations and performance. How we built it The system is powered by a backend built with Python and Java for the core algorithm and a frontend developed with React and CSS to provide a user-friendly dashboard. Docker was used to containerize the application, ensuring scalability and smooth integration with real-time APIs. The heart of the system is the dynamic algorithm, which balances clustering and optimization to achieve global efficiency. Challenges we ran into We faced challenges in integrating APIs to handle real-time data and building a stable Docker architecture for scalable deployment. Developing a real-time clustering and optimization algorithm added complexity, but through collaboration and problem-solving, we overcame these obstacles. Accomplishments that we're proud of We are proud of successfully implementing a globally "
      }
    ]
  },
  {
    "file_path": "./devposts/fishin-impossible.html",
    "project_id": "fishin-impossible",
    "title": "Fishin' Impossible",
    "tagline": "Fishin’ Impossible is a multiplayer fish hunt in dangerous waters. Eat fish to grow and score points. But the sharks are hungry — don’t get caught.",
    "hackathon": "",
    "built_with": [
      "blender",
      "horizon",
      "meta",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/615/554/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "On top of the mountain Lots of danger U-Boat Discover Golden Starfish Clamp Photo Booth On top of the mountain Lots of danger U-Boat Discover Golden Starfish Clamp Photo Booth On top of the mountain 1 2 3 4 5 6 7 Inspiration We were inspired by the vast and lively ecosystem that is the ocean and the various sea creatures that inhabit it. \nIn our original game idea, you are a fish, navigating in three dimensions and eating other, smaller fish. Bigger fish can eat you, including players that are bigger than you, comparable to games like agar.io, but in 3d. When we decided to develop for Horizon Worlds, we noticed that this idea does not fit into that framework, where players remain humans and join as themselves. \nSo we went back to the drawing board and reinvented the idea to work with human avatars. We decided to change the game into a somewhat more relaxed game (although still high stakes with sharks chasing you) that enables both cooperation and sabotage between players, fitting the narrative-driven social experience of a horizon world. Once our game environment started taking shape and we noticed how fun it was just to explore it, we also implemented challenges that give the players more reason to roam the environment and search for secrets. What it does Fishin’ Impossible is an underwater exploration and survival game where players take on the role of a diver who collects fish to earn points. As the diver goes deeper, the fish become more valuable, but the dangers increase. Players must avoid threats and return to the home base alive to secure their score, competing for high scores. Achievements can be completed by exploring the world and engaging with the game systems. How we built it We were eager to try the new Horizon World Editor out and decided to use it to create our fish game idea. After finishing the basic tutorials to get an idea for the development environment, we jumped directly into creating the shark movement and fish-eating functionality. Managing "
      }
    ]
  },
  {
    "file_path": "./devposts/flamecast.html",
    "project_id": "flamecast",
    "title": "Flamecast",
    "tagline": "With accelerating climate change, the risk of wildfires has been growing every year as well. ML-based wild-fire forecasting can help communities around the world prepare and reduce risks and losses.",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "html",
      "javascript",
      "keras",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/355/609/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Title Title Title 1 2 3 4 Inspiration Climate change is one of the most concerning problems around the world these years. It causes wildfires which will put human life, properties, and wild resources in danger. There are more than two thousand wildfires per year just in California. So, we have already had a huge amount of data records on it. Big data is extremely helpful in making machine learning models and making predictions about future events. As a result, based on the weather data from NASA and the wildfire data from the Forest Service Research Data Archive, we started this project predicting the wildfire patterns to give local governments and people forecast about the wildfire to help them make better decisions. By this project, we can better address the UN SDGs in climate action(#13) and life on land(#15) What it does Flamecast is a machine-learning powered tool for local governments to use for a 14-day prediction of the probability of wildfires. It works by using weather data over 14 days before targeted data like wind, temperature, humidity, etc. to identify what is the probability of the fire. How we built it Front-end As the UI designer, I first started with wireframing after determining what our web app needed. My wireframe is already colored because our team decided early that it would be incredibly useful to have colors for each day to signify the severity of the fire risk, as it’s a great way to quickly scan the data. From there, I created the mockup and chose a clean, minimalist style that focuses on the most important part of the site, the prediction model. After the mockup was finished, Shalini developed the site with HTML, CSS, and Javascript. Back-end To build the network we started with gathering the data on wildfires and weather conditions. To begin, we decided to focus on CA. We gathered climate data from NASA Power dataset and used Kaggle 1.88 million US Wildfires dataset . After gathering all the data, we subset the wildfires and weather dat"
      }
    ]
  },
  {
    "file_path": "./devposts/fora-2fr8sv.html",
    "project_id": "fora-2fr8sv",
    "title": "Fora",
    "tagline": "Fora more mindful meal",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "javascript",
      "jupyternotebook",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/567/991/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Knowing that nutritional value of the foods we eat can help encourage individuals all over the world to make healthier choices when it comes to eating. We decided that we wanted to make a web application that would allow users to check the nutritionals facts of the foods they'd eat all through the quick click of a few buttons. What it does Fora allows users to upload an image of a fruit or vegetable which is then compared to our machine learning model. The machine learning model then detects what fruit or vegetable is in the picture against 131 different fruits and vegetables and outputs the nutritional information for the detected fruit or vegetable. How we built it The machine learning model was built and trained using Jupyter Notebook and PyTorch. The model was trained using the Fruits 360 dataset on Kaggle: https://www.kaggle.com/moltean/fruits . The Edamam Nutrition API was integrated into our backend using Python. The values were passed to our frontend built with HTML, CSS, and JavaScript with the framework Flask. Challenges we ran into This was our first time creating a machine learning model so there were lots of challenges. One of the biggest ones was the wait time. The first cycle of our training took 5 hours and during that time, our team wasn't even sure if it was working or not. The dataset contained over 90,000 images and unfortunately since we've never created a machine learning model, we didn't know how long it would take. We initialized our model to train over 3 cycles so that was 3x5 hours - 15 hours. Training it alone took a considerable amount of time since our deadline was June 20 at 12am, about 30 hours to create our project. Aside from training, we also had to spend some hours testing it, making sure the Edamam Nutrition API worked, and that our website took in an image and outputted accurate information. Other challenges included working with Visual Studio Code and their LiveShare extension. Allowing all of our teammates to access"
      }
    ]
  },
  {
    "file_path": "./devposts/food-finder-y0lrxp.html",
    "project_id": "food-finder-y0lrxp",
    "title": "Food Finder",
    "tagline": "Our service allows you to quickly find food in your neighborhood, and find good food nearby. You can filter through multliple categories, including radius, calorie count, and food type.",
    "hackathon": "",
    "built_with": [
      "css",
      "eslint",
      "gps",
      "html",
      "next",
      "nutritionix",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We felt that we needed to be able to find food more easily and have more information about its nutrition (e.g. calories, sugars, proteins, etc.). What it does Our app looks for food in your local area and displays its nutrition facts, which can be filtered to have more healthy options. How we built it We used Next.js, Typescript, and React. Challenges we ran into We were rate limited by Nutritionix because we accidentally spammed their API a bit too much. What we learned We learned more about network requests and testing API requests with Insomina. What's next for Food Finder We hope to expand to include more options within our app, such as more sorting and filtering options, tracking nutrition within the app, improving the UI, and improving network request efficiency. Built With css eslint gps html next nutritionix typescript Try it out GitHub Repo Submitted to MSET health hackathon Created by Redger Xu Adithya Prem Kevin Fang"
      }
    ]
  },
  {
    "file_path": "./devposts/flowpilot-zoom-agent-that-automates-your-workflows.html",
    "project_id": "flowpilot-zoom-agent-that-automates-your-workflows",
    "title": "FlowPilot: Your Agentic Co-Pilot",
    "tagline": "FlowPilot listens, understands, and executes, transforming Zoom meetings into Slide decks and Notion workflows. No more lost action items - just approve and watch it execute.",
    "hackathon": "",
    "built_with": [
      "dain",
      "docker",
      "express.js",
      "node.js",
      "rtms",
      "websockets",
      "zoom"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DAIN Labs: AI Agent Excellence & Innovation Awards ($5k Cash [1st] & $2",
      "Zoom: Best Use of Zoom APIs ($250 Git Card + Herschel Duffle Bags [1st] & $100 Git Card + Hoodies [",
      "Perplexity: Hacking With Perplexity Award ($50 Gift Card per team member) Created by I built out th",
      "Maintains contextual awareness across multiple meetings to track long-term projects and commitments",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/270/129/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration FlowPilot listens, understands, and executes, transforming Zoom meetings into Slide decks and Notion workflows. No more lost action items - just approve and watch it execute. FlowPilot provides amazing collaboration opportunities for sales, engineering, and product teams alike. Having been apart of workflows at fast-growing startups and large corporations, our team grew increasingly frustrated with the significant friction caused by meetings. This includes the amount of action items discussed in meetings that often get forgotten, tediously written, or executed. We noticed that while tools like Notion excel at documentation and Google Workspace handles scheduling, there wasn't a seamless way to transform meeting conversations into automated workflows. FlowPilot bridges this gap by creating an intelligent layer that turns verbal commitments into automated actions. What it does FlowPilot transforms Zoom meetings into an autonomous productivity engine. By leveraging DAIN's advanced agent framework, our system: Creates comprehensive Notion documentation including meeting notes, workflow templates, and task assignments Automatically generates follow-up slide decks for educational sessions and team presentations Handles calendar scheduling and email communications through Google Workspace Maintains contextual awareness across multiple meetings to track long-term projects and commitments Technical Architecture 1. Meeting Intelligence Layer Zoom RTMS Integration : Implements WebSocket connections for real-time audio stream processing Verifies local server client for the Zoom application via Ngrok 2. DAIN Agent Framework Implementation Agent Orchestration : Custom-built context router that manages state between multiple specialized agents Implements DAIN's memory system for maintaining conversation context and user preferences Uses structured JSON formats for inter-agent communication and task delegation Specialized Agents : Documentation Agent: Hand"
      }
    ]
  },
  {
    "file_path": "./devposts/food-bank-ai.html",
    "project_id": "food-bank-ai",
    "title": "Food Bank AI",
    "tagline": "An efficient solution to the lessening supply of food in food banks due to COVID-19 using AI",
    "hackathon": "",
    "built_with": [
      "c++",
      "css3",
      "express.js",
      "firebase",
      "flask.py",
      "html5",
      "javascript",
      "node.js",
      "python",
      "qt",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Wolfram|One Personal Edition + 1 year subscribtion to Wolfram|Alpha Pro Winner Paccurate API projec",
      "Geom HacksWinnerWolfram|One Personal Edition + 1 year subscribtion to Wolfram|Alpha ProWinnerPaccurate API project 3rd place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/125/032/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "process process process 1 2 Food-Bank-AI a more efficient way to deal with the lessening food supply in food banks due to COVID-19 using AI (a project for GeomsHacks) Problem Due to the mass demand for food due to the lockdown and COVID-19, a lot of food shelters have been running out of food. Solution Rather than trying to convince a lot of people to donate which never really works, we can create a more efficient way to manage food in the food banks so that we don’t run out as quick What it does The website is to be used by the government and food bank chains to see the amount of food in each bank, gather inventory, see how food should be transported on trucks, and the AI handles all of the code concerning to which food shelters food should be sent, how buses should be packed and their routes, while taking into account the needs of the clients The app is to be used by homeless people or anyone else who needs food from food banks to select a well balanced meal from what is in the closest bank as well as track whether they’re getting the proper amount of calories and nutrients or not.\n# How it works Website made with HTML, JS, CSS, Node.js, and Socket.io, and uses Paccurate API to find percentage of space used by food shelters, how food should fit in the trucks, and which food shelters the food should be sent to App made with QT, C++ and gets client info and suggestions and sends requests to server AI Written in python and figures out which food shelters food should be transported to based on distance to near homeless shelters and how filled up they are, routes for buses, and much more\n# Languages, Libraries and APIs used Python JavaScript C++ HTML CSS Node.js Socket.io Flask.py QT Paccurate API Built With c++ css3 express.js firebase flask.py html5 javascript node.js python qt socket.io Try it out GitHub Repo Submitted to Geom Hacks Winner Wolfram|One Personal Edition + 1 year subscribtion to Wolfram|Alpha Pro Winner Paccurate API project 3rd place Created by I work"
      }
    ]
  },
  {
    "file_path": "./devposts/foodshake.html",
    "project_id": "foodshake",
    "title": "FridgeShake",
    "tagline": "This application allows users to cook right from their home. Users can connect with and follow other chefs to teach them how to cook. Java frontend Ruby backend",
    "hackathon": "",
    "built_with": [
      "java",
      "ruby"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/010/808/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Prototype! Prototype! Prototype! 1 2 Inspiration Providing people with connection to chefs who can teach them about food\nand also providing accessible food options for college students who have limited amount of time. What it does Connects regular people with chefs that teach them how to cook.\nAllows to browse through different recipes based on the ingredients they have in the fridge ( by typing in all the ingredients they want to use). It also filters out recipes based on the time available. How we built it We built the backend using Ruby, and the frontend using Java. Challenges we ran into We ran into many challenges trying to build out the backend and connect it to the frontend. Accomplishments that we're proud of We are proud that we were able to make a fully functional scaling backend What we learned We learned new languages that none of us have even been exposed to before. What's next for FridgeShake Hopefully we can test this with real users to connect individuals to each other.\nWe can connect to larger recipe API to have more options for filtering! \nWe need smoother user interface:) (we beginners) Below is the link to the final prototype we are hoping to accomplish! VIEW PROTOTYPE! Built With java ruby Try it out GitHub Repo Submitted to WaffleHacks 2022 Created by Front and editing code also recoding video sherry Yu Jacob Rosen Javier Guerra Michelle Minsol Kim"
      }
    ]
  },
  {
    "file_path": "./devposts/foundair.html",
    "project_id": "foundair",
    "title": "foundAIr",
    "tagline": "Become a startup founder in minutes!",
    "hackathon": "",
    "built_with": [
      "ai/ml",
      "amazon-web-services",
      "apis",
      "css",
      "ipfs",
      "lambda",
      "openai",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Business Hack: Airpods Created by Edison Qu rule the world Ian Korovinsky Stephen Ni Anna Wei",
      "Best Business Hack: Airpods Created by Edison Qu rule the world Ian Korovinsky Stephen Ni Anna Wei",
      "MacHacks 3WinnerBest Business Hack: Airpods",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/370/156/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Completion Page Landing Page Input Page Summary Page The title page of our AI-generated business plans! The table of contents for our AI-generated business plans! This is how an executive summary for our AI-generated business plans looks like! Completion Page Landing Page Input Page Summary Page The title page of our AI-generated business plans! The table of contents for our AI-generated business plans! This is how an executive summary for our AI-generated business plans looks like! Completion Page 1 2 3 4 5 6 7 8 Inspiration Imagine you have a great idea for a startup (as we're sure you probably don't even need to imagine). You've got a vision, you've got your dream, but when it comes time to execute, suddenly, you feel lost, and you don't know where to even start. Lucky for you, we created foundAIr - an AI-powered business plan writer that will take care of the logistics for you! We felt that uncertainty when we started our own ventures, but after overcoming this challenge, we've put our minds together to help other founders tackle this obstacle and take their ventures to the moon! What it does Introducing the future of business planning: an AI-powered business plan generator! Say goodbye to the stress and frustration of writing a business plan from scratch. All you need is your business idea and a few clicks of a button. Simply enter your idea into the webpage, as well as your name, your budget, and your proposed business name, and the AI will take care of the rest. In no time, you'll have a comprehensive and customized business PDF plan, tailored to your specific needs. Say hello to more time, less stress, and a clearer path to success with foundAIr - the world’s first AI-powered business plan generator. How we built it Starting off with the front end, we used Tailwind CSS and React to create a webpage, consisting of a landing page and a Typeform, to create an interactive and founder-friendly UI. To integrate this with the back end, we used an AWS Lambda functio"
      }
    ]
  },
  {
    "file_path": "./devposts/flow-state-1s5qxk.html",
    "project_id": "flow-state-1s5qxk",
    "title": "Flow~State",
    "tagline": "Flow~State is the cheat code for stress optimization. Using your biometric and activity data, it delivers personalized workout plans and schedules designed to help you achieve peak performance.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini",
      "pandas",
      "perplexity",
      "python",
      "pytorch",
      "swiftui",
      "terraapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/274/059/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Example of full schedule home page health score tech stack example of workout plan generated Example of full schedule home page health score tech stack example of workout plan generated Example of full schedule 1 2 3 4 5 6 Inspiration Every morning, millions of people wake up to check their sleep scores, monitor their heart rates, and track their daily steps. We've become a generation obsessed with quantifying our well-being, wearing devices that capture every heartbeat and movement. Yet beneath this endless stream of metrics lies a deeper human truth: we're not just seeking numbers – we're searching for balance, energy, and a genuine sense of wellness in our increasingly demanding lives. We created FlowState because we believe technology should work in harmony with our bodies, not just monitor them. Our breakthrough came from a simple insight: true wellness isn't about collecting more data—it's about understanding the unique patterns of your body and lifestyle, then turning those insights into meaningful change. By combining advanced biometric analysis with real-world behavioral data, FlowState creates a personalized path to optimal physical and mental performance. This isn't just another wellness app. It's your intelligent companion for achieving that elusive state of flow, where stress melts away and everything just clicks. Welcome to the future of personalized wellness. What it does Flow~State is a personalized wellness platform that helps users improve their health and manage stress through tailored recommendations. It creates customized workout plans and stress-relief activities by analyzing the user's biometric data, such as heart rate and activity levels, alongside their heart health history. Automatically plots out events for you on Google Calendar Displays heart disease risk and cardiovascular health score trained on 3k PPG data from regular and irregular heartbeats The platform identifies the user's strengths and weaknesses to provide personalized suggest"
      }
    ]
  },
  {
    "file_path": "./devposts/foods-3z06qa.html",
    "project_id": "foods-3z06qa",
    "title": "RR Recommender",
    "tagline": "Our website gives users multiple options for recipes based on ingredients they input and recommends restaurants.",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of John Snow Labs Dataset Created by Minjeong/Christine Kim Sreya Muppalla Apoorva Chiluku",
      "PioneerHacksWinnerBest Use of John Snow Labs Dataset",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/616/052/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired the number of food borne illnesses caused by restaurants, which are more then double the number cases at a private house. We were also inspired by, how many of us are unable to think of recipes at the top of our heads when we cook. What it does Our website has two main functions. First, the user can input what ingredients they have and get a recommendation of what recipes they can make in a particular cuisine. Our second feature is takes in a violation description and an inspection score and outputs whether or not it is a good restaurant. How I built it We built the website using HTML, Java and Python. Challenges I ran into Halfway through building our website, we doubted the usefulness of our website. However, we realized that the refrigerator dilemma is a widespread, everyday issue and that the restaurants' ratings could provide potential businesspeople valuable information on where they should build their startups based on the popularity - a factor affected by the ratings of buildings nearby - of each area. We also ran into several problems trying to learn new languages and APIs but, with the support of the mentors, persevered and created a product. Accomplishments that I'm proud of We are satistfied that we managed to expand our knowledge on building websites with HTML and CSS. We also dabbled in Python while trying to use Machine Learning and R while creating our heat map. What I learned We learned much of the information we listed above on-the-spot today. For instance, some of us had no idea how to use APIs; others had no idea what APIs were! What's next for Foods We want to broaden our views by offering more recipes to users and supplying them with more options for restaurants. We also want to be able to utilize all the data we were offered by the John Snow Labs spreadsheets by using Machine Learning, and we want to we able to add a scanning feature to use image detection for the inside of the refrigerator. Try it out GitHub Repo "
      }
    ]
  },
  {
    "file_path": "./devposts/finnacle-16vxg2.html",
    "project_id": "finnacle-16vxg2",
    "title": "Finnacle",
    "tagline": "Your financial friend.",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/737/813/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "logo logo 1 2 3 4 5 6 Inspiration Finnacle is inspired by the lack of an older adult friendly financial application. Current banking applications have impersonal user interface and disregard the need for simplicity and clarity.  With age comes the susceptibility of cognitive impairment and fraud. Cognitive impairments, such as dementia, can cause older adults to feel helpless out of control. This feel leaves them susceptible to money scams. 36.5 billion dollars is lost annually due to money scams against seniors. Finnacle is designed to give older adults back financial control and financial security. Why Finnacle? Finnacle promotes collective decision-making and shared accountability Finnacle's has Simplified Settings: Perceptibility: Color-coded icons Readability: Adjustable font size Inclusive: Change interface language Finnacle's Dementia-friendly Settings Finnacle Cares: Fraud Protection Alerts How we built it We did research on UI/UX on elder people and applied the following conclusions to our designs:\n     - Simple and intuitive UI.\n     - Color-coded sections and categories, that highlight important information.\n     - Suitable fonts and font-size for better legibility.\n     - Auditory and visual guidelines to support and aid those with audio and visual needs. Challenges we ran into There is not a lot of older adult friendly applications on the market. We had to do a deep dive into what are the visual and cognitive needs of these individuals when it come to mobile applications. Accomplishments that we're proud of We are proud that we were able to take a step back and put ourselves into the shoes of our targeted audience. Additionally we able proud of out ability to work seamlessly together as we built an app that grows with the user. What we learned We learned a significant amount about UI research specifically targeted for the older population. Additionally, we learned how to use Figma and create and an interactive app What's next for Finnacle Moving forward"
      }
    ]
  },
  {
    "file_path": "./devposts/floodify.html",
    "project_id": "floodify",
    "title": "FloodML",
    "tagline": "Helping people and governments prepare for and reallocate resources for floods using machine learning.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "css3",
      "flask",
      "heroku",
      "html5",
      "javascript",
      "machine-learning",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HarmonyHacks 2WinnerHonorable Mention",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/174/510/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Damage heatmap Prediction page Satellite image analysis Damage heatmap Prediction page Satellite image analysis Damage heatmap 1 2 3 4 UPDATE AUG 3 2020: As a proof of concept, our web app currently deems Mumbai as \"Unsafe\" and at risk for a flood, and if you search up Mumbai weather, there are multiple reports from sources such as NDTV proclaiming that Mumbai is facing intensely heavy rain and flooding. Check out the link below. Link - https://www.ndtv.com/mumbai-news/mumbai-rain-heavy-rain-floods-parts-of-mumbai-city-on-red-alert-for-2-days-2273668 What makes FloodML Unique? / Originality Due to the large amounts of flood-related data available for the US, creating a model to predict and determine future floods in the US is a relatively unpretentious task. However, given the extremely limited data available regarding floods in India, we chose to challenge ourself to innovate a method to create a prediction model for the Indian Subcontinent. Thus, instead of using the more natural satellite image analysis, we opted for a new and innovative method. We chose to analyze and mine flood reports from local news sources in India, from which we extracted the location and time frame of the flood. We then extracted weather conditions – temperature, max temperature, wind speed, cloud cover, humidity, precipitation – at the time and location of the floods, which allowed us to create a robust dataset for effective predictions. This unique approach is what sets FloodML apart. Inspiration Floods are one of the most dangerous and frequent natural disasters in the world. According to the World Resources Institute, over 80% of India's population, that is, 1.08 billion people, are at risk due to floods. In the recent Kerala flood tragedy, over 100 people lost their lives, and over 15,000 houses and buildings were swept away in the torrential rains. These kinds of floods happen almost every single year in many prone areas, and cause major damage to life and property. The major cause o"
      }
    ]
  },
  {
    "file_path": "./devposts/flashify-o48guw.html",
    "project_id": "flashify-o48guw",
    "title": "Flashify",
    "tagline": "Become an academic weapon! Seamlessly transform handwritten notes into interactive flashcards for efficient learning. Reuse your deck of personalized flashcards whenever wherever.",
    "hackathon": "",
    "built_with": [
      "flask",
      "mysql",
      "openai",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Top 3 Overall - sponsored by Wolfram & Roku Winner Best Use of AI in Education Created by Flask, Re",
      "The GoldenHackWinnerTop 3 Overall - sponsored by Wolfram & RokuWinnerBest Use of AI in Education",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/613/126/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Demo Thumbnail Demo Thumbnail Demo Thumbnail 1 2 Inspiration The inspiration behind \"Flashify\" sprouted from our collective desire to optimize our study habits. We recognized the effectiveness of active recall in retaining information, and we wanted to bridge the gap between traditional handwritten notes and modern digital learning tools. Our goal was to develop a solution that would convert handwritten notes into digital flashcards, making it easier for students and learners to test themselves on the material. What it does \"Flashify\" is a web application designed to streamline the process of converting handwritten notes into interactive flashcards. Users can upload images of their handwritten notes, and our AI-powered system will convert the text into digital flashcards. These flashcards are not just static; they come alive with the integration of OpenAI API, which generates challenging questions based on the content and formats them into flashcards. Users can then study and test themselves on these flashcards, promoting active recall and enhancing their learning experience. How we built it Authentication and Security: We prioritized user security by implementing a fully authenticated login system with password hashing to protect user data. AI Handwriting Recognition: We utilized advanced AI techniques with the apilayer to convert handwritten text into digital text, ensuring accuracy and reliability. OpenAI Integration: Our application integrates seamlessly with the OpenAI API to generate challenging questions and format them into flashcards, adding an element of interactivity to the learning process. Backend: We used Flask to develop a robust REST API in the backend, ensuring smooth communication between the frontend and the database. Database: MySQL was our choice for the database, enabling us to efficiently store user data, notes, and flashcard information. Frontend: For the frontend, we employed React for its flexibility and responsiveness, along with Tailwind "
      }
    ]
  },
  {
    "file_path": "./devposts/fleurish.html",
    "project_id": "fleurish",
    "title": "Fleurish",
    "tagline": "Imagine turning any image into a dynamic animation in just seconds—no design or animation skills needed. With Fleurish, static visuals come to life with a flourish at the press of a button.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "convex",
      "next.js",
      "python",
      "replicate",
      "websocket"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/025/917/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sample AI generation #3 Fleurish Landing Page Sample AI generation #2 Sample AI generation #1 Sample AI generation #3 Fleurish Landing Page Sample AI generation #2 Sample AI generation #1 Sample AI generation #3 1 2 3 4 5 Inspiration There are a lot of text-to-image, image-to-text AI generators, only a few image-to-video AI generators, but from our research, we couldn't find an AI generator that converted live images to video (.gif). We wanted to fill this void, since it has a few useful applications, and so we created Fleurish! What it does When the user inputs an image, selects a theme and clicks the \"Imagine\" button, an AI-generated gif based on the inputted image will be generated after a few seconds. Alternatively, if the user connects their phone to their computer, they can also use the \"live image\" option to get the application to read images from the phone camera video in real time. How we built it We used a Convex template with a built-in Replicate integration as our backend, and then added on a Replicate https://replicate.com/lucataco/dreamshaper7-img2img-lcm in order to convert images to AI-generated images. For the live image option, we used RTC peer connections to send camera feed to a Python backend, which then compresses the image (to optimize the AI generation) and feeds to the front-end, built in Next.js with the WebSocket API. Challenges we ran into We spent a lot of time testing and searching for a model that gave us satisfactory results, and even then, it took us time to learn how to integrate that with our application. Also, we did not have previous experience with a lot of the technologies used, namely generative AI (with images), WebSocket API, and using the RTC peer connection to allow the communication between a phone and our application. Accomplishments that we're proud of Our application is highly optimized and generates the gif within 1-2 seconds. Also, the themes and the gifs produced give very accurate results. What we learned We learne"
      }
    ]
  },
  {
    "file_path": "./devposts/foodprint-fun.html",
    "project_id": "foodprint-fun",
    "title": "Foodprint Fun",
    "tagline": "Eating our way out of climate change - are you up for the challenge?",
    "hackathon": "",
    "built_with": [
      "chakra-ui",
      "formik",
      "google-cloud",
      "python",
      "react",
      "twilio",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "3rd Place - 3rd Choice Pick Winner Wolfram Award Winner Digital Ocean Award Winner Best Domain Name",
      "Winner Digital Ocean Award Winner Best Domain Name from Domain",
      "DragonHacks 2022Winner3rd Place - 3rd Choice PickWinnerWolfram AwardWinnerDigital Ocean AwardWinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/922/407/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Twilio Landing Home Results Subcribe twilio Twilio Landing Home Results Subcribe twilio Twilio 1 2 3 4 5 6 Inspiration Lead reviewer for the Intergovernmental Panel on Climate Change Durwood Zaelke said, \"Cutting methane is the biggest opportunity to slow warming between now and 2040.\" That's not surprising, since about a third of human-caused methane emissions come from livestock, and more specifically, cows and other farm animals produce about 14% of human-induced climate emissions. What's implied here is that collectively we can make a dent in the fight against climate change if we were more environmentally conscious in deciding what we make to eat. While moving away from animal-based diets would probably help a lot, it's not feasible for everyone like a growing child in need of protein. So how do we engage people who want to do as much as they can for the environment but can't give up meat, or people who might otherwise not be engaged in the fight against climate change based on logical arguments? What it does Introducing Foodprint Fun, where Your every meal counts. Using our app, you can find a holistic view of the environmental  impact you're making with every meal. At its core, you can submit a link to recipe you're thinking of making, and we let you know how much greenhouse gas emissions, land use, and water use is for the ingredients you're using to make this recipe. We also allow you to subscribe to daily updates on your phone for delightful green recipes to try out. How we built it We used React, Chakra UI, and Typescript for the front end, Formik for forms, Python for backend processing and analysis and to clean up data, and Twilio to tweet our recipes. We used Google Cloud Run to host our FastAPI backend. The data for the food carbon emission, land use, and water use was from a study titled \"Reducing food’s environmental impacts through producers and consumers\" and from OurWorldInData.org Challenges we ran into Finding and cleaning a dataset with a more"
      }
    ]
  },
  {
    "file_path": "./devposts/fourfit-pu2yj5.html",
    "project_id": "fourfit-pu2yj5",
    "title": "Fourfit",
    "tagline": "Make your stylist forfeit with Fourfit",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "css",
      "flask",
      "html",
      "javascript",
      "mongodb",
      "openai",
      "python",
      "react",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/062/606/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Feedback on user upload Main menu page Products page Liking a product Store website page Upload a photo for feedback page Feedback on user upload Main menu page Products page Liking a product Store website page Upload a photo for feedback page Feedback on user upload 1 2 3 4 5 6 7 Fourfit Project for Hack the Valley 2024. 💡 Inspiration The idea for Fourfit originated from the need to help individuals discover and enhance their fashion sense by offering personalized clothing suggestions based on their uploaded images. We aimed to create an engaging and user-friendly platform that utilizes AI technology to analyze outfits and provide tailored recommendations, helping users feel more confident in their fashion choices. ❓ What it does Fourfit allows users to upload images of their outfits and receive instant feedback and fashion suggestions. The AI analyzes the uploaded image, identifying clothing items and their styles, and offers complementary items or fashion tips to enhance the overall look. By providing a personalized experience, Fourfit helps users make informed fashion choices, elevating their style effortlessly. 🧰 How we built it We built Fourfit using Python for the backend and JavaScript with React for the frontend. The application integrates AWS services for image storage and processing. Using TensorFlow, we developed machine learning models that analyze clothing items in the uploaded images and generate fashion suggestions. We also utilized various APIs to enhance user experience and ensure quick response times for outfit evaluations. 🤔 Challenges we ran into One significant challenge was ensuring the accuracy of clothing item recognition and suggestions. Fine-tuning the machine learning models to deliver precise recommendations required extensive testing and iteration. Additionally, managing the image processing and storage efficiently was crucial to maintain performance. 🏆 Accomplishments that we're proud of We are proud of the seamless integration of AI t"
      }
    ]
  },
  {
    "file_path": "./devposts/fridgeful.html",
    "project_id": "fridgeful",
    "title": "Fridgeful",
    "tagline": "An app to help reduce food waste",
    "hackathon": "",
    "built_with": [
      "next.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We looked for issues that the new advances in machine learning could tackle. We browsed through countless statistics and analyzed data in order to find out an issue that has not yet been tackled by others. How We Built It For the front end, we used Next.js and React to improve the user experience and make their interactions with data interactive. Additionally, through the usage of TailwindCSS, we drastically improved the user experience by styling the app beautifully. Finally, we used Clerk to authenticate the user into the marketplace and recipe generator. A full demo of the frontend is displayed in the demo video above. Challenges We Ran Into While developing the app, there were countless minor issues that we had to solve, but here are the major issues: Overfitting of the machine learning model: When training our machine learning model using TensorFlow, we had to be extremely careful about overfitting. Therefore, we had to carefully watch our accuracy and the number of parameters that our model had in order to mitigate it while using techniques such as splitting our data and reducing model complexity layers. Accomplishments That We're Proud Of We accomplished everything that we planned and brainstormed with the short amount of time we had. Our execution when integrating Machine Learning and AI while having an interactive user interface was almost perfect: the user experience along with the accuracy of the model boosted the performance of our app. We are proud to have an app that works and works extremely well, and it is an enormous leap for tackling food waste. Built With next.js react Submitted to Random Forest Hackathon Created by Kosei Tsukamoto Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly"
      }
    ]
  },
  {
    "file_path": "./devposts/fourfit.html",
    "project_id": "fourfit",
    "title": "Fourfit",
    "tagline": "Make your stylist forfeit using Fourfit!",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "css",
      "flask",
      "html",
      "mongodb",
      "openai",
      "python",
      "react",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Fourfit Project for Hack the Valley 2024. 💡 Inspiration The idea for Fourfit originated from the need to help individuals discover and enhance their fashion sense by offering personalized clothing suggestions based on their uploaded images. We aimed to create an engaging and user-friendly platform that utilizes AI technology to analyze outfits and provide tailored recommendations, helping users feel more confident in their fashion choices. ❓ What it does Fourfit allows users to upload images of their outfits and receive instant feedback and fashion suggestions. The AI analyzes the uploaded image, identifying clothing items and their styles, and offers complementary items or fashion tips to enhance the overall look. By providing a personalized experience, Fourfit helps users make informed fashion choices, elevating their style effortlessly. 🧰 How we built it We built Fourfit using Python for the backend and JavaScript with React for the frontend. The application integrates AWS services for image storage and processing. Using TensorFlow, we developed machine learning models that analyze clothing items in the uploaded images and generate fashion suggestions. We also utilized various APIs to enhance user experience and ensure quick response times for outfit evaluations. 🤔 Challenges we ran into One significant challenge was ensuring the accuracy of clothing item recognition and suggestions. Fine-tuning the machine learning models to deliver precise recommendations required extensive testing and iteration. Additionally, managing the image processing and storage efficiently was crucial to maintain performance. 🏆 Accomplishments that we're proud of We are proud of the seamless integration of AI technology in providing personalized fashion recommendations. Creating a responsive and visually appealing user interface was another achievement, along with building a robust backend that efficiently processes user-uploaded images. We’re excited about the potential impact Fourfit c"
      }
    ]
  },
  {
    "file_path": "./devposts/freebites.html",
    "project_id": "freebites",
    "title": "FreeBites",
    "tagline": "Reducing food waste and food cost",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "firebase",
      "javascript",
      "mongodb",
      "react-native",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/238/480/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 FreeBites: The Free Food Whisperer Inspiration Hungry college students on a budget + free pizza flyers = the ultimate epiphany. Why should anyone have to hunt for free food when free food can hunt for you? What it does What if you never missed out on free food that matched your preferences and was close to your location? FreeBites acts like your personal food finder: it sniffs out free food events that match your distance limits. How we built it We built FreeBites using Expo and React Native for the front end, allowing us to achieve cross-platform compatibility. The back end uses Firebase for authentication, and database management, ensuring fast and reliable performance. To implement location-based services, we integrated Google Maps API , enabling users to filter food options by proximity. Challenges we ran into Offering Cross-Platform Compatibility : Offering cross-platform compatibility was one of the most difficult challenge we faced. This was also the first some of the people on our team worked with mobile, and it was one of those ex Accomplishments that we're proud of Seamless cross-platform functionality: Successfully developed an app that performs equally well on Android and iOS devices, thanks to Expo and React Native. What we learned Handling Real-Time Data What's next for FreeBites Adding a “Hunger SOS” button that alerts your friends when free food is running out. Adding dietary restrictions and preferences Built With expo.io firebase javascript mongodb react-native typescript Submitted to TAMUhack 2025 Created by Nihar Shah Tim Cai Ethan Luo"
      }
    ]
  },
  {
    "file_path": "./devposts/foodwise-3wgviq.html",
    "project_id": "foodwise-3wgviq",
    "title": "Foodwise",
    "tagline": "Eat wise, save the cries.",
    "hackathon": "",
    "built_with": [
      "azure",
      "css",
      "flask",
      "html5",
      "javascript",
      "nginx",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Division Delta Winners TOConnect 2021 Created by I mostly contributed with front end, which include",
      "Ignition Hacks 2021WinnerDivision Delta Winners",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/632/182/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Results Main Page Features Results Main Page Features Results 1 2 3 4 Foodwise Inspiration As high school students, we are always busy, hungry, and typically not very experienced in the culinary arts. Our team was motivated to create a solution that can help us find good healthy recipes while not sacrificing study time. The ultimate goal is to improve both our mental and physical health, by relieving the stress generated from the indecision of what to eat. Other benefits of using the app include encouraging home-cooking, being more conscious of meals, and learning the skills of cooking. With Foodwise, there will be no more of opening the fridge and spending time staring blankly at the items inside that could be used for learning instead. What it does Welcome to Foodwise; an interactive adventure where we suggest meals based on your personal needs, preferences, and available ingredients! Save yourself the hassle of buying expensive food components and looking through frustrating recipe lists using our reliable, easy to use software (with exact, simplified measurements and instructions). Our website offers 3 methods to input some of your current ingredients: photo detection, manual input, paragraph input. Photo detection allows users to upload an image of their fridge and our program will identify 5 ingredients in the image. Manual input submits a form of the ingredients entered by the users while paragraph input identifies ingredients based on key terms from the input. After processing the given ingredients, Foodwise returns a number of meals with information such as recipes, calories count and serving size. Features It helps you stay healthy with it's recipe suggestions, and gives you an incentive to cook at home. It relieves stress with simple and easy to use recipes, and gives tips about healthy eating. It helps you make conscious decisions about what you eat, and teaches you about culinary arts and famous recipes to easily cook at home. It helps save energy, sinc"
      }
    ]
  },
  {
    "file_path": "./devposts/freshfridge-zd4na7.html",
    "project_id": "freshfridge-zd4na7",
    "title": "FreshFridge",
    "tagline": "Decrease Food Waste Using AI",
    "hackathon": "",
    "built_with": [
      "ai",
      "airtable",
      "clerk",
      "next.js",
      "python",
      "quart",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "PioneerHacks VWinner3rd Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our inspiration for this project was the issue of food waste in our community. There's a lot of food waste in our city, but not many people think of giving away or selling this food for budget prices to serve the community as well as decrease food waste. We did some research on this issue, and discovered that worldwide, 1.3 billion tons of food are wasted every year! Thus, we created FreshFridge. How we built it We used a lot of different technologies to build this app. In the frontend, we used Next.js as our main driver of the user interface, as well as Radix UI and Tailwind CSS to make it easy for us to import beautiful components like forms and textboxes into our application. We used Clerk as an authenticator, ensuring safety by checking whether the user is signed in or not. In the backend, we used Quart.py to handle routing, the OpenAI API to generate recipes based on food input, a TensorFlow model to analyze the picture of the users' fridge, and Airtable to manage and receive data. Challenges we ran into A major challenge that we ran into was making the design of the marketplace, as we needed to ensure that it could display many products while still being simple. We decided to opt for a grid of \"cards\", or small informational rectangles on each one of our products, similar to browsing through YouTube or Amazon. We also decided to make a separate page for checking out items from the marketplace. Our smart design is similar to Gmail, where we have a list of checked-out items and ways to interact with these items (such as removing them from the cart). Accomplishments that we're proud of One accomplishment that we're proud of is using a new UI library, Radix UI. It was quite different than what we were used to, but it was a pretty big upgrade and its components were simple and easy to modify. Another accomplishment that we're proud of is successfully making a very fast TensorFlow model to process our images and process them with our OpenAI API interacti"
      }
    ]
  },
  {
    "file_path": "./devposts/food-for-thought-rjfym0.html",
    "project_id": "food-for-thought-rjfym0",
    "title": "Food for Thought",
    "tagline": "A 21st century solution to an age old problem.Settle the never ending debate of where you will go out to eat with Food for Thought. This app that will recommend the best spots based on your thoughts!",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "google-maps",
      "java",
      "xml"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/821/346/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Our inspiration was an attempt to solve problems that we have personally run into. We wanted to solve the problem of deciding where to eat in a simple way that was more personal then the current offerings like Google maps, Uber Eats, or Door dash. What it does Food for Thought takes in several parameters on your eating preferences and searches the web for restaurants that are have similarities to your profile. Then it proceeds to send the user to a restaurant through Google Maps. How we built it We built this using Java in Android studio Challenges we ran into There were major challenges every step of the way. Most of the team were relatively new to coding and had limited experience which made it difficult to gain an initial foothold. None of us had any significant front end or UI experience and that was a huge hurdle as we had no idea where to start. We attempted using Figma but found out that it doesn't work very well when transferring to code. David also had not used GitHub before and accidentally overwrote his entire project the night before the submission date. learning how to use the Google API was also a difficult challenge. We also ran into an issue regarding constraints, or more specifically we didn't realize they were a thing. We found this out after completing our UI so we had to do some work-around. Accomplishments that we're proud of The thing we are most proud of is that we were able to get past the first part and build something from nothing. 37 hours ago there was nothing, not even an idea and now we have an actual product that we worked together to build. What we learned We learned many different concepts related to android programming, google api and UI design. Being apart of the lifecycle of software creation was allowed us to have a good understanding of how the software team in the industry could function. What's next for Food for Thought Silicon Valley here we come. Built With android-studio google-maps java xml Try it out"
      }
    ]
  },
  {
    "file_path": "./devposts/garden-in-the-sky.html",
    "project_id": "garden-in-the-sky",
    "title": "Garden in The Sky",
    "tagline": "Empowering individuals to grow their own food, foster sustainability, and cultivate a greener future.",
    "hackathon": "",
    "built_with": [
      "cloudflare",
      "css",
      "fetch",
      "google-gemini",
      "html",
      "javascript",
      "jest",
      "plantid",
      "react",
      "surveyjs",
      "typescript",
      "zod"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/830/409/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Plant Health Analysis Carrot-kun Dashboard Generated Garden Daily Plant Checklist Plant Health Analysis Carrot-kun Dashboard Generated Garden Daily Plant Checklist Plant Health Analysis 1 2 3 4 5 Inspiration The inspiration for Garden in The Sky comes from the desire to promote sustainable agriculture practices, support food self-sufficiency, and contribute to the goal of eliminating hunger (SDGs: Zero Hunger, Good Health and Well-Being, Sustainable Cities and Communities, Climate Action), especially as many suffer from malnutrition, lack nutritious, diverse, and culturally appropriate diets, and local food availability is decreasing due to climate change. The app aims to empower individuals to grow their crops and provide personalized guidance and recommendations using generative AI. What it does The gardening app uses generative AI to provide personalized guidance and recommendations for cultivating healthy crops. The app uses AI to identify plants and crops based on user images, providing real-time insights and recommendations for adjusting growing conditions. The app also detects pests, diseases, and nutrient deficiencies in plants based on user images, providing personalized recommendations for pest management strategies. The app offers gardening tips and tutorials, including articles, tutorials, and instructional videos on seed starting, transplanting, pruning, and harvesting. The app has potential impacts on food self-sufficiency, supporting sustainable agriculture practices, improving food access and nutrition, and fostering community building. By promoting healthy eating habits and a diverse range of fruits, vegetables, and herbs, the app contributes to sustainable agriculture while reducing carbon emissions and creating a better environment. Overall, the gardening app aims to empower individuals and communities to grow their own food, reducing reliance on store-bought produce, while protecting the environment. How we built it We built the frontend aspect o"
      }
    ]
  },
  {
    "file_path": "./devposts/foci-9gkdc7.html",
    "project_id": "foci-9gkdc7",
    "title": "FOCI",
    "tagline": "Upload raw footage & a prompt, and our AI-powered platform using AWS, OpenSearch, FastAPI, and Editly will create a polished video that brings your vision to life effortlessly.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "bedrock",
      "editly",
      "fastapi",
      "ffmpeg",
      "python",
      "s3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/902/297/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Finished Video Video Upload + Prompt Page Finished Video Video Upload + Prompt Page Finished Video 1 2 3 Inspiration In today's digital landscape, small businesses often struggle to create compelling marketing assets due to limited resources and expertise. We were inspired to leverage the power of generative AI to provide an affordable and accessible solution for contractors and small businesses to promote their services online. By automating the video editing process and transforming raw footage into polished marketing videos, we aim to empower these businesses to showcase their work and attract new customers effectively. What it does Our platform revolutionizes the way small businesses create marketing videos. It takes raw video footage and images provided by contractors, along with a description of their work, and utilizes advanced AI technologies to generate professional-grade videos. These videos are optimized for social media platforms, allowing contractors to effortlessly publish and share them on their own pages. By simplifying the video creation process, we enable small businesses to produce high-quality marketing assets without the need for extensive technical knowledge or expensive equipment. How we built it We built our platform by leveraging a range of cutting-edge technologies. We utilized AWS Bedrock Titan for generating sophisticated video embeddings, capturing the essence of the raw footage. OpenSearch was employed to efficiently store and retrieve relevant video clips, ensuring quick access to the most impactful moments. AWS S3 provided secure and scalable storage for the raw footage, allowing seamless management of the content. LaunchDarkly was integrated to handle project credentials and configuration, enabling a personalized experience for each user. The backend was powered by Python and FastAPI, ensuring fast and efficient processing of video editing requests. The Claude API played a crucial role in generating JSON-formatted objects based on th"
      }
    ]
  },
  {
    "file_path": "./devposts/frugal-foodie-zm7q23.html",
    "project_id": "frugal-foodie-zm7q23",
    "title": "Frugal Foodie",
    "tagline": "Frugal Foodie is a modern meal planning app that works for your wallet. Simply enter your budget and let Frugal Foodie's AI driven recommendations plan tasty meals that keep your bank account happy.",
    "hackathon": "",
    "built_with": [
      "apis",
      "cloud-services",
      "databases",
      "frameworks",
      "languages",
      "platforms"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Socially Beneficial Hacks Created by I am a web developer with experience in front end design and d",
      "Best Socially Beneficial Hacks Created by I am a web developer with experience in front end design",
      "hackUMBC Fall 2022WinnerBest Socially Beneficial Hacks",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/240/370/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "dark mode (showcased on an ipad) GIF Pitch / Story Deck responsive design our app mobile view dark mode (showcased on an ipad) GIF Pitch / Story Deck responsive design our app mobile view dark mode (showcased on an ipad) 1 2 3 4 5 Inspiration I am a college student on a tight budget, so I understand how difficult it is to eat healthily and save money at the same time. Our team created this app to help other college students do exactly that. What it does The app allows users to input their weekly food budget and then provides them with recipes and grocery lists that fit their budget. The app has a built-in calculator that lets users easily see how much each recipe will cost. If the user has a lot of leftovers in the fridge, our app leverages one of the world's most powerful AIs to generate a novel recipe for them to try! How we built it We started the hackathon with a very structured brainstorming session, where we wrote down all of our ideas. We then narrowed several down until we had a single problem and solution that we thought we could develop. We identified key application functions and focused on building them out by assigning roles to complete tasks. The app was built using react.js, GPT-3, and several APIs to collect and generate useful data for the users of the app. Challenges we ran into The main challenge we had to overcome was effectively managing data from a cutting-edge AI and trying to provide recipes that people would actually want to eat, without breaking the bank. Our team met the day of, so we had to learn each other's strengths and work styles quickly in order to be as efficient as possible Accomplishments that we're proud of We are VERY proud of the level of polish we were able to get on our app within such a short timeframe. We may be biased, but we think the app looks super clean and modern, and we were able to achieve this without sacrificing usefulness or practicality. What we learned We learned how to communicate and collaborate more efficie"
      }
    ]
  },
  {
    "file_path": "./devposts/gethealthy.html",
    "project_id": "gethealthy",
    "title": "getHealthy",
    "tagline": "Pay lazy people to do sport",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css3",
      "flask",
      "git",
      "github",
      "html",
      "javascript",
      "jquery",
      "markdown",
      "opencv",
      "posenet",
      "python",
      "sqlite",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/223/160/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "survey homepage dashboard bunty survey homepage dashboard bunty survey 1 2 3 4 5 Inspiration In Switzerland, 1 adult on 4 doesn't do enough weekly sport, according to the Federal Office of Statistics[1]. Sadly, it has also been shown that there is a clear correlation between one's education/socio-economic level, with the amount of sport one does. People that are already marginalized or from a lower socio-economic level are shown to do less sport. [1] 1. What it does It connects people who wish to motivate less sporty people, with couch-potatoes. With the money incentive, everyone can earn money by doing sport. As shown in the demo images: user is welcomed by the homepage with sign-in promotion if not completed already. dashboard lists all the possible exercises with user activity data. bounty page, as the name suggests, shows 2. How we built it The GetHealthy web app is powered by the Flask framework and is implemented with posnet, opencv and tensorflow.js for motion detection. .\n├── README.md\n├── benchmark.py\n├── flaskr                  // main Flask project\n│   ├── __init__.py\n│   ├── __pycache__\n│   ├── db.py\n│   ├── posenet.  // posnet for motion detection\n│   ├── static       // static files \n│   ├── templates   // web pages\n├── get_test_images.py\n├── main.py\n├── setup.py\n└── venv    // virtual env 3. Challenges we ran into 3.1. How to provide smooth-less UX One of the major problems we ran into is how to render the exercise videos without any hindering. Because to ensure a great user experience, the exercise video must be presented in real time with motion detection enabled. Due to the natural computing power constraint of the web application, after the investigation of possible solutions, we chose to go with posenet, a pure Python implementation of Google's tensorflow.js because it is relatively light-weighted, easy to implement, and are more compatible with Flask framework. 3.2. How to optimize the performance This part is closely tied to eliminating redunda"
      }
    ]
  },
  {
    "file_path": "./devposts/food-drive-dg8mtc.html",
    "project_id": "food-drive-dg8mtc",
    "title": "Food Drive",
    "tagline": "Reduce waste and give food :)",
    "hackathon": "",
    "built_with": [
      "css",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We are inspired by the amount of food that goes to waste in grocery stores, restaurants, and even school dining halls every day. So we wanted to create something that put that food to good use. What it does We connect local restaurants and grocery stores who have extra produce or food at the end of the day, charities like meals on wheels and local homeless shelters, and users to pick up and deliver it to those in need. How we built it We used react, css, and java to create our website Challenges we ran into As beginners, we faced a lot of difficulties such as design that didnt look right, or crashing the entire website. Many challenges we were able to overcome by collaborating and building off eachothers strong suits . Accomplishments that we're proud of We're proud of being able to overcome these challenges and learn from them, as well as creating a functioning website What we learned We learned how to create a website, how to use design elements, how to make pop-ups, etc. What's next for Food Drive Maybe we can be the next uber eats :) Built With css javascript react Try it out GitHub Repo Submitted to Longhorn Hack for Humanity 2022 Created by adorawu Wu"
      }
    ]
  },
  {
    "file_path": "./devposts/gazy.html",
    "project_id": "gazy",
    "title": "Gazy",
    "tagline": "Navigate the internet effortlessly using simple gestures like blinking, head tilting, and more.",
    "hackathon": "",
    "built_with": [
      "google-cloud-speech",
      "media-pipe",
      "opencv",
      "playsound",
      "pyaudio",
      "pygui",
      "python",
      "react",
      "tailwind-css",
      "wave"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "🌐 Best Domain Name from Domain.com"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/683/502/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 💡 Inspiration 🌍 Our inspiration stems from a deep commitment to inclusivity. Recognizing the challenges faced by disabled individuals in accessing the internet, our team set out to create a solution that empowers users to browse effortlessly using only one’s face. Our goal is to break down barriers and provide a seamless online experience for everyone. 🎙️ What Gazy does 🚀 Gazy revolutionizes web browsing by allowing users to navigate entirely with their face. Whether it's blinking to click, tilting to scroll, or even talking to type, Gazy provides a comprehensive and intuitive interface that caters specifically to the needs of disabled individuals. It opens up a world of possibilities, ensuring that browsing the internet becomes a more accessible and enjoyable experience. 💬 How we built Gazy 🛠️ The front-end was developed on React and the user authentication was built on Firebase. The backend was developed on Python, we harnessed the power of MediaPipe to implement real-time face detection and landmark recognition. To play audio, we utilized PyAudio, and we leveraged Google Cloud’s Speech to Text to convert voice commands to text. Lastly, PyGUI was used to craft the actual mouse movement, scrolling, clicking, and typing! 🚧 Challenges we ran into 🚧 Throughout this hackathon, we ran into a plethora of challenges. The main challenge proved to be iris tracking. The intricacies required to accurately track the movement of the iris and projecting that movement onto the 2D screen as mouse movement proved to be difficult. Additionally, identifying a dependable reference point for facial gestures presented its own set of challenges. Our team iteratively tested different scaling factors and points in order to optimize the result. Finally, during the development process, some of our teammates fell ill. However, overcoming these health challenges highlighted the resilience of our team members. 🌟 Accomplishments that we're proud of 🎉 We are proud of developing a fu"
      }
    ]
  },
  {
    "file_path": "./devposts/freezy-a-web-application-to-post-your-leftover-food.html",
    "project_id": "freezy-a-web-application-to-post-your-leftover-food",
    "title": "Freezy: A web application to post your leftover food",
    "tagline": "It's ridiculous spending 3.50 for 10Timbiebs when they threw it out anyway. You know what's more ridiculous? Global hunger, plummeting economics and pollution. This project aims to aids those issues",
    "hackathon": "",
    "built_with": [
      "css3",
      "django",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Honourable Mentions Winner Best Design Created by Jay Phan",
      "Hack Your TomorrowWinnerHonourable MentionsWinnerBest Design",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "N/A Built With css3 django html5 javascript python Try it out GitHub Repo Submitted to Hack Your Tomorrow Winner Honourable Mentions Winner Best Design Created by Jay Phan"
      }
    ]
  },
  {
    "file_path": "./devposts/genbridge.html",
    "project_id": "genbridge",
    "title": "GenBridge",
    "tagline": "Leveraging technology to foster meaningful intergenerational connections, enriching lives across ages with shared wisdom and experiences.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "heroku",
      "javascript",
      "postgresql",
      "python",
      "react",
      "vercel",
      "webspeechapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/773/771/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration GENBRIDGE was sparked by a blend of observation and empathy towards the growing isolation experienced by the older generation—a situation only exacerbated by the rapid pace of technological advancements. Recognizing the untapped wealth of wisdom and experience residing within these individuals, we sought to create a platform that not only addresses their loneliness but also enriches the younger generation. Our inspiration was further fueled by the realization that while technology often serves as a barrier, it also holds the potential to be a powerful connector. Thus, GENBRIDGE was conceived to bridge this gap, leveraging technology to foster meaningful, intergenerational connections. What it does GENBRIDGE is a unique platform that enables senior citizens to offer advice and share life experiences with younger individuals seeking guidance. Through a user-friendly app, we facilitate one-on-one interactions that are both meaningful and mutually beneficial. Seniors can impart their wisdom on a range of topics, from career advice to life’s big questions, while young adults gain invaluable insights. Our platform uses a sophisticated matching algorithm to ensure that connections are relevant and enriching for both parties. Furthermore, each interaction has the potential to be transformed into a digital keepsake, capturing the essence of the exchange for posterity. How we built it Our journey in creating GENBRIDGE involved an interdisciplinary approach, combining elements of psychology, technology, and design thinking. We developed the platform with a focus on accessibility, ensuring that it is senior-friendly simple navigation and an engaging interface. The matching algorithm was crafted using advanced AI techniques to analyze user profiles and preferences, facilitating meaningful connections. The tech stack includes React for the frontend, Python, FastAPI, and PostgreSQL for the backend, and Web Speech API for speech to text. Challenges we ran into One of th"
      }
    ]
  },
  {
    "file_path": "./devposts/geotrainer.html",
    "project_id": "geotrainer",
    "title": "GeoTrainer",
    "tagline": "GeoTrainer is an AI-powered geography game that enhances user retention with interactive hints.",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "flask",
      "google-maps",
      "html",
      "nextjs",
      "openai",
      "python",
      "react.js",
      "ux/ui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/249/225/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Preview of GeoTrainer Preview of GeoTrainer Preview of GeoTrainer Preview of GeoTrainer Preview of GeoTrainer Preview of GeoTrainer Preview of GeoTrainer 1 2 3 🌍 Inspiration GeoGuessr, a geography game, challenges players to identify Google Street locations using visual clues, but they often rely on prior knowledge rather than deep learning insight. We noticed a lack of resources online to help beginner players, so we built GeoTrainer —an AI-powered geography game that not only tests players' knowledge but also explains why an image belongs to a specific country. 🔍 What it does Players analyze Google Street View images and guess the country. Our AI provides feedback based on: Road signs, languages, and text Architecture and infrastructure Vegetation, terrain, and climate Street markings and traffic patterns Unlike the existing GeoGuessr game, GeoTrainer teaches players how to improve over time through AI-driven explanations. 🛠️ How we built it Node.js server handles requests and processes data. Python Flask server sends images to OpenAI’s API for analysis. OpenAI API extracts meaningful location-based hints from images. Figma UI → React & CSS for a seamless and intuitive front-end experience. 🚧 Challenges we ran into Matching GeoGuessr’s UI to replicate a familiar player experience. Parsing AI-generated responses into relevant and understandable hints. Making the game intuitive and accessible for both GeoGuessr veterans & new players. 🎉 Accomplishments that we're proud of Effective UI/UX throughout the prototype. Real-time AI feedback makes geographic learning more engaging. 🔮 What's next for GeoTrainer Multiplayer challenges—compete with friends in realtime using WebSockets! Multimedia hints like native language enunciation Built With css figma flask google-maps html nextjs openai python react.js ux/ui Try it out GitHub Repo Submitted to SpartaHack X Created by Rian Corcino i code stuff for fun Lisa Chai Experience Architecture & Comp Sci student at MSU Jack Bajcz "
      }
    ]
  },
  {
    "file_path": "./devposts/foodness.html",
    "project_id": "foodness",
    "title": "foodness",
    "tagline": "An all-in-one app to achieve your fitness goals",
    "hackathon": "",
    "built_with": [
      "express.js",
      "mongodb",
      "node.js",
      "react",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/712/701/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Generating recipe from the items in inventory with nutrients information entire exercise done for the day Health Card Inventory after user uploads the receipt Goals when exercise is not done for the day with streak exercise set completed exercise started exercise in motion Generating recipe from the items in inventory with nutrients information entire exercise done for the day Health Card Inventory after user uploads the receipt Goals when exercise is not done for the day with streak exercise set completed exercise started exercise in motion Generating recipe from the items in inventory with nutrients information 1 2 3 4 5 6 7 8 9 Inspiration 💡 As college students, we understand firsthand how difficult it is to eat healthy when you do not have many options. Most students also do not have the budget to afford a fitness program or a personal trainer, and therefore work out using bad form which causes slow progress and bad habits that can potentially lead to injuries. We created foodness to help tackle this problem and ease the process of students getting closer to their dream physique. What it does ⚙️ foodness is a web service that fosters healthy eating habits alongside efficient workout programs. Users can track their food items and meal recipes are automatically generated using what is available. The app also enables users to update their inventory using a receipt scanner. On the fitness side, foodness recommends workout plans for you based on your physique goals. As a bonus, you can track your form live while working out using foodness and it informs you right on the live stream using client-side machine learning i.e. TensorflowJS whenever you deviate from the perfect form for the exercise. How we built it 🔨 We built foodness using React and TailwindCSS on the frontend, and Firebase for the authentication. We use MongoDB to store the user data and inventory and expose API endpoints to the client using Express . On the server, we extracted the receipt text using Te"
      }
    ]
  },
  {
    "file_path": "./devposts/foot-patrol.html",
    "project_id": "foot-patrol",
    "title": "Foot Patrol 2.0",
    "tagline": "Connecting students with university volunteers to walk them home after dark.",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "google-directions",
      "google-maps",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ElleHacks 2022WinnerGMWinner(MLH) Best use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/831/482/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Foot Patrol 2.0 app. Home page when opening app. Page to choose the university the user is attending. Student and patroller sign-in page. User has entered pick-up drop-off points. User is awaiting patroller's arrival. Safety feature to call campus police while walking. Patroller and user have reached destination. List view of tasks available for patrollers. Detailed task view for patrollers. Foot Patrol 2.0 app. Home page when opening app. Page to choose the university the user is attending. Student and patroller sign-in page. User has entered pick-up drop-off points. User is awaiting patroller's arrival. Safety feature to call campus police while walking. Patroller and user have reached destination. List view of tasks available for patrollers. Detailed task view for patrollers. Foot Patrol 2.0 app. 1 2 3 4 5 6 7 8 9 10 11 💡 Inspiration Foot Patrol 2.0 was inspired by a program called Foot Patrol which many Canadian universities have implemented to promote and ensure safety on college campuses. Foot Patrol is a service for undergraduates that provides safe escorts for students walking alone at night. These programs can be extremely useful for reducing the number of dangerous situations occurring on and around campus after dark. However, from our personal experiences, our group was able to identify a few major issues with these programs. Firstly, students need to call these campus organizations directly and arrange to meet with volunteers at a specific location. The overall process is time-consuming resulting in students choosing the shorter option of walking back alone. The act of picking up a phone to call someone can also be stressful to certain students — influencing their decision to not utilize the safety program. The largest shock to our group members is that this type of program is not accessible at all universities. As young women, we believe having a form of these safety programs at every university is extremely important. That is why we decided to build Fo"
      }
    ]
  },
  {
    "file_path": "./devposts/fresh-choices.html",
    "project_id": "fresh-choices",
    "title": "Fresh Choices",
    "tagline": "An app to help you make healthier choices when eating",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "flask",
      "google-cloud-vision",
      "javascript",
      "jinja",
      "python",
      "react",
      "react-native",
      "sqlalchemy",
      "sqlite",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This is our first full-stack react native app that we have ever built"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/594/741/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Pitch website(built with react) App preview(built with react native) Web preview(built with flask) Pitch website(built with react) App preview(built with react native) Web preview(built with flask) Pitch website(built with react) 1 2 3 4 Inspiration Kids were very stressed during the pandemic(including me) and started eating junk food, which took a toll on our health. Fresh Choices aims to reduce the consumption of junk food to lead to a healthier lifestyle and more happiness What it does The user uploads an image(or takes a photo of their food) and our backend processes that image and gives the user a star rating out of 5 How we built it We used react native with typescript for the frontend, we used flask and HTML for the web app and the backend, and we used react to make the pitch website Challenges we ran into We did not know how to send form data through axios, so with hours of debugging, we figured out how to. We also realized the importance of teamwork as in the middle, we had an argument and were mad at each other. this decreased our productivity, so as a result, we said sorry to each other and started working as a team again(much more productive this time) Accomplishments that we're proud of This is our first full-stack react native app that we have ever built What we learned We learned how important teamwork is and more ways to optimize our code to run it faster What's next for Fresh Choices We plan on publishing it to the app store and getting companies that promote fresh and healthy foods to run ads on it Built With expo.io flask google-cloud-vision javascript jinja python react react-native sqlalchemy sqlite typescript Try it out GitHub Repo confident-bell-e52dfc.netlify.app GitHub Repo GitHub Repo Submitted to AtlasHacks II Created by I did most of the frontend work and most of the backend work. I basically hard carried lmao Veerrohit Veeravadivel I worked on the front end and styling and design of the app. I helped build the react website as well Aravi"
      }
    ]
  },
  {
    "file_path": "./devposts/gitaway.html",
    "project_id": "gitaway",
    "title": "Gitaway",
    "tagline": "Gitaway is a simple travel site to explore cities, rate places, and RSVP for events.\n\nBut this is no regular travel site. By abstracting GitHub in innovative ways, Gitaway uses GitHub as a backend!",
    "hackathon": "",
    "built_with": [
      "fontawesome",
      "github",
      "picocss",
      "sveltekit",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "WaffleHacks 2023WinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/516/742/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "activity page home screen destination page github backend activity page home screen destination page github backend activity page 1 2 3 4 5 Our site: gitaway.tech Gitaway is An open-source, free-for-all, data-free adventure coordinator The world's first GHaaB app (GitHub-as-a-Backend) Also, quite possibly the biggest abuse of git/GitHub in existence A fun experiment to play around with! Inspiration Using GitHub today is like building a Lego set with half the pieces missing! You clone a project to learn from it, or to be inspired by it, or to enhance it... but you can't! Half of it is missing. The problem is clear: Github may store the full front-end, but rebuilding the back-end and databases requires access to the original developer's Firebase, MongoDB, or some other third-party database platform. Replicating this infrastructure can be a Herculean effort unless you have the original developer looking over your shoulder. What if we told you there was another way? What it does Gitaway is a simple travel site to explore cities, rate places, and RSVP for events. It's perfect for a getaway weekend! But this is no regular travel site. This is the first ever platform that uses GitHub as a Backend! By abstracting GitHub in innovative ways, we can leverage it to store, manage, and distribute data. Gitaway is a forum for tourists but because everything is centralized on GitHub, enterprising developers can easily fork the repo and start up a forum for anything. And it just works, no strings attached. Hell, it doesn't even need to be a forum. The possibilities are endless. Throughout the site we included links to the corresponding GitHub components so you can get a look under the hood! Future Plans Trip itineraries (front-end) Destination and activity image attachments Networking Friending other users Creating \"friends only\" activities Creating \"invite only\" activities Technical Information Codebase Our project's code is separated into three separate parts--- app, bot, and depl"
      }
    ]
  },
  {
    "file_path": "./devposts/gobot.html",
    "project_id": "gobot",
    "title": "Context Sensitive Advertising",
    "tagline": "What you need, on the go !",
    "hackathon": "",
    "built_with": [
      "intel-joule",
      "java",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How I built it Challenges I ran into Accomplishments that I'm proud of What I learned What's next for GoBotdsf Built With intel-joule java javascript node.js Created by Shreyasvi Natraj Heyo"
      }
    ]
  },
  {
    "file_path": "./devposts/github-ranked.html",
    "project_id": "github-ranked",
    "title": "DevDuels",
    "tagline": "Want a fun version of GitHub? DevDuels is a GitHub based game that connects entertainment and education together to provide an innovative experience of learning, improving, and competing with code.",
    "hackathon": "",
    "built_with": [
      "figma",
      "githubapi",
      "html",
      "javascript",
      "langchainapi",
      "mongodb",
      "next.js",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the Valley 8Winner(MLH) Most Creative Use of Github",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/623/290/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration: Millions of active software developers use GitHub for managing their software development, however, our team believes that there is a lack of incentive and engagement factor within the platform. As users on GitHub, we are aware of this problem and want to apply a twist that can open doors to a new innovative experience. In addition, we were having thoughts on how we could make GitHub more accessible such as looking into language barriers which we ultimately believed wouldn't be that useful and creative. Our offical final project was inspired by how we would apply something to GitHub but instead llooking into youth going into CS. Combining these ideas together, our team ended up coming up with the idea of DevDuels. What It Does: Introducing DevDuels! A video game located on a website that's goal is making GitHub more entertaining to users. One of our target audiences is the rising younger generation that may struggle with learning to code or enter the coding world due to complications such as lack of motivation or lack of resources found. Keeping in mind the high rate of video gamers in the youth, we created a game that hopes to introduce users to the world of coding (how to improve, open sources, troubleshooting) with a competitive aspect leaving users wanting to use our website beyond the first time. We've applied this to our 3 major features which include our immediate AI feedback to code, Duo Battles, and leaderboard. In more depth about our features, our AI feedback looks at the given code and analyses it. Very shortly after, it provides a rating out of 10 and comments on what it's good and bad about the code such as the code syntax and conventions. How We Built It: The web app is built using Next.js as the framework. HTML, Tailwind CSS, and JS were the main languages used in the project’s production. We used MongoDB in order to store information such as the user account info, scores, and commits which were pulled from the Github API using octok"
      }
    ]
  },
  {
    "file_path": "./devposts/global-cmd-k.html",
    "project_id": "global-cmd-k",
    "title": "global-cmd-k",
    "tagline": "cursor's cmd+k everywhere",
    "hackathon": "",
    "built_with": [
      "cocoa",
      "ns",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/805/356/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Just something I wanted tbh, I love the UX of cursor's cmd + k and just wanted the same ux Built With cocoa ns swift Submitted to Arcadia FISI Created by Rahul Tarak"
      }
    ]
  },
  {
    "file_path": "./devposts/gennet.html",
    "project_id": "gennet",
    "title": "GenNet",
    "tagline": "A way to connect with the generations before and after you in a meaningful way",
    "hackathon": "",
    "built_with": [
      "django",
      "firebase",
      "flask",
      "mongodb",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/663/886/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Homepage Homepage Homepage 1 2 Inspiration We were inspired by the movie Coco to learn more about our ancestry. What it does It allows you to connect with other members of your family through family trees. How we built it We built it using MongoDB, React Native, Django and Flask. Challenges we ran into We had a very hard time coordinating work online. Accomplishments that we're proud of The end product is much closer to the desired result than we had imagined at the start. As well as that, a lot of the work we did on the project was in a language or framework we had never touched before. What we learned We learned teamwork, and every member of our team learnt a new framework to hone the workflows they use (such as the MERN stack). What's next for GenNet We plan on developing this into a fully-fledged application in the future. Built With django firebase flask mongodb react Try it out GitHub Repo Submitted to Hack the North 2021 Created by I worked on building out the frontend for the app and integrating it with the backend. I'm very proud of what I accomplished given that this was my first time working with React. Arihan Sharma I mainly worked on the backend, which was written in Flask. I'm proud of what I did because it was my first time working with both Twilio and MongoDB. Anthony Chen Worked on the backend with MongoDB and Django. Divyansh B Abdul-Baseet Shabi"
      }
    ]
  },
  {
    "file_path": "./devposts/freshteams.html",
    "project_id": "freshteams",
    "title": "freshteams",
    "tagline": "Fresh partners for your hackathon experience!",
    "hackathon": "",
    "built_with": [
      "css3",
      "firebase",
      "firestorm",
      "flutter",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/877/577/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "FreshTeams' messaging platform, which includes text/img chat. Marie Johnson, a user of FreshTeams looking for a hackathon partner. FreshTeams' messaging platform, which demonstrates user experience. FreshTeams' messaging platform, which includes text/img chat. Marie Johnson, a user of FreshTeams looking for a hackathon partner. FreshTeams' messaging platform, which demonstrates user experience. FreshTeams' messaging platform, which includes text/img chat. 1 2 3 Inspiration Hackathons are a great way to learn, make connections, and have fun. Unfortunately, many people are put off by hackathons because not being able to form a team can be anxiety-inducing, demoralizing, and overall not fun. What it does Our platform streamlines the team formation process. Each person's profile displays pertinent information such as skillset and interests. With our tinder-like swipe model, making a hackathon team is easy and fun. When people are matched with each other, they can start chatting.  In addition, we are able to recommend people that are closer to your social network(degrees of separation) so the user meets people they are likely to know or have mutual friends with. We are also able to recommend people further away to for a more exciting and dynamic experience. Lang/Frameworks Flutter HTML CSS Javascript Challenges we Faced 3 of our team members had no experience in Flutter, making the app development extremely difficult. Objectives/Accomplishments We are proud of our UI design as well as our algorithm to recommend people. What we learned We researched lots about graph theory algorithms as well as Flutter development. What's next? We believe that there are many other bonus features we could add, such as grouping people based on interests/contrasting skillsets. Built With css3 firebase firestorm flutter html5 javascript Try it out freshteams.ml GitHub Repo Submitted to Electric City Hacks IV Created by Created flutter app. Synced with Firebase. Raiyan Sayeed Marcus Chong hi M"
      }
    ]
  },
  {
    "file_path": "./devposts/gagggle.html",
    "project_id": "gagggle",
    "title": "Gagggle",
    "tagline": "Brainstorming, but powered by AI. Type a prompt, and instantly get a gaggle of ideas that you can expand, combine, or build on — all while collaborating with your team in real time.",
    "hackathon": "",
    "built_with": [
      "claude",
      "cohere",
      "cursor",
      "express.js",
      "figma",
      "graphite",
      "graphstore",
      "groq",
      "langchain",
      "next.js",
      "node.js",
      "react",
      "typescript",
      "warp",
      "windsurf"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/739/028/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Collaborate with others on your ideation. Brainstorm with AI through a mind map. Quickly switch between LLMs. Branch off of or merge your ideas. Collaborate with others on your ideation. Brainstorm with AI through a mind map. Quickly switch between LLMs. Branch off of or merge your ideas. Collaborate with others on your ideation. 1 2 3 4 5 Gagggle Inspiration Brainstorming on Miro or FigJam is powerful but still manual. Teams often hit creative blocks, waste time organizing sticky notes, and lose momentum. We wanted that same collaborative flow, but with AI supercharging ideation and helping ideas evolve without friction. What it does Generates ideas with AI → Type a prompt and get sticky-note ideas instantly with blazing inference or structured outputs with top LLMs Expands and combines thoughts → Branch from a note to generate sub-ideas or merge two into a synthesized concept Collaborative whiteboarding → Add your own notes, edit with teammates, and see live cursors in real time Boosts brainstorming → Helps individuals and groups push past creative stalls and rapidly explore directions How we built it Backend – TypeScript + Node.js + Express, with a GraphStore managing nodes and edges in memory. APIs handle generation, merging, and categorization via Groq and Cohere, and export sessions as markdown. Frontend – Next.js + React, with ReactFlow for the whiteboard, custom components for prompts and nodes, and Socket.io for real-time sync and cursor sharing. State is managed with React Context. Stack – TypeScript, Node.js, Express, React/Next.js, Tailwind, Socket.io, Zod validation, Groq/Cohere APIs. Challenges we ran into Designing a graph-based structure flexible enough for AI operations and user edits Managing real-time collaboration smoothly with sockets and multiple users Getting AI outputs to feel natural inside a visual whiteboard instead of just plain text Dealing with context window limits for larger sessions Accomplishments that we’re proud of Built an end-to"
      }
    ]
  },
  {
    "file_path": "./devposts/givehub-xpd6b7.html",
    "project_id": "givehub-xpd6b7",
    "title": "GiveHub",
    "tagline": "GiveHub provides an easy way to sell and exchange old items with other members of your local community, in a way reminiscent of yard sales.",
    "hackathon": "",
    "built_with": [
      "android",
      "firebase",
      "firestore",
      "react",
      "react-native",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Cornucodia ($17k+ in prizes, internship opportunities)"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration GiveHub was inspired by a combination of the Nextdoor app (social media for local communities) and eBay. What it does GiveHub creates an easy and intuitive way to sell unwanted items to other in your local community while encouraging building bonds between others in your community. How we built it This project was created using React Native for Android with Typescript and Firebase for storage and authentication. Challenges we ran into It took a while to setup the project due to installing emulators and needing to setup the development environment. In addition, the project is currently not functional due to dependency issues. Accomplishments that we're proud of I am proud of being able to mostly work out the project, as this was my first project for mobile devices using React Native. What we learned I learned to use React Native with my typical web development technologies to create a mobile application. What's next for GiveHub I plan to fix the launching issues and implement more sophisticated features like in-app transactions and in-app messaging. Built With android firebase firestore react react-native typescript Try it out GitHub Repo Submitted to Cornucodia ($17k+ in prizes, internship opportunities) Created by Redger Xu"
      }
    ]
  },
  {
    "file_path": "./devposts/gitgud-etyh65.html",
    "project_id": "gitgud-etyh65",
    "title": "GitGud",
    "tagline": "Master DSA one morning at a time — because greatness starts before coffee.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "gemini",
      "github-api",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/376/864/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 💡 Inspiration As CS majors, we realized two things: 1️⃣ We need to get better at DSA. 2️⃣ We also need to wake up before 2 PM to do that. Tech interviews are brutal, and let’s be honest — practicing LeetCode is the gym of coding. So we thought: what if we turned our morning alarm into a coding dojo? GitGud is our way of combining ✨productivity✨ with panic — solving DSA questions first thing in the morning so we can finally pass a tech screen (and maybe stop being “currently seeking opportunities” on LinkedIn 🙃). 🚨 What it does GitGud is an alarm clock app that forces you to solve a DSA (Data Structures & Algorithms) question before the alarm stops ringing. It’s brutal. It’s effective. It’s... oddly satisfying. Here’s what it does: Wake you up with a customizable alarm Show a short coding question — usually fill-in-the-blank style Only dismiss the alarm when you get it right 😈 Optionally link your GitHub to push daily commits to your contribution graph Track your streaks and celebrate consistency 🎉 No snoozing, no shortcuts — just morning grind. 🔧 How we built it 📱 React Native + Expo for building a cross-platform mobile app 🔥 Firebase for authentication, user data, and streak tracking 🧠 Local database of curated DSA questions for now, with future plans for spaced repetition 🔐 GitHub OAuth for connecting to your profile (because if you're coding, might as well flex those green squares) 🎨 UI/UX focused on being clean and motivational, not anxiety-inducing (LeetCode, we’re looking at you) 🧩 Challenges we ran into Running alarms and app logic in the background, especially on iOS, required some serious finesse iOS permissions made us feel like we were hacking the Pentagon Getting the balance right between “fun morning challenge” and “rage quit at 7 AM” Debugging alarms at 3 AM while ironically missing sleep 😴 🏆 Accomplishments that we're proud of Alarm + question flow works seamlessly now Actually fun to use — testers didn’t hate waking up to code GitHub integratio"
      }
    ]
  },
  {
    "file_path": "./devposts/game-nlg3s7.html",
    "project_id": "game-nlg3s7",
    "title": "DeltaBlade",
    "tagline": "An endless survival game. Simple controls, lots of fun.",
    "hackathon": "",
    "built_with": [
      "c#",
      "godot",
      "piskel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/999/052/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration This game was inspired by the numerous hours of joy I experienced when playing Vampire Survivors. I wanted to recreate that experience so I created Delta Blade, a game with my own twists and ideas. How to play The controls for this game are really simple, you just move with WASD and you have to survive endless waves of monsters. After killing a certain amount of monsters, you can upgrade your weapons to increase your odds of survival. How we built it I built this game with the Godot Engine, programmed in C#. I created all the pixel art and animations with Piskel. Every single sprite in this game is made by me. Challenges we ran into I had a hard time designing the player and enemies and spent a lot of time thinking of ideas. I also had a hard time thinking of a difficulty scaling algorithm. After many hours of brainstorming, I came up with the idea that difficulty scales with level, and level increases by killing more monsters. Accomplishments that we're proud of I'm extremely proud of my patience and the time I put into this game. This game was a passion project and I am satisfied with the results. I'm also proud of quickly learning pixel art and adapting to the Godot engine to create the game before the deadline. What we learned I learned the fundamentals of pixel art and how to make it look nice. I also learned a lot about animations, C#, exporting a game, and level design. What's next for DeltaBlade My next plan for DeltaBlade is to add new weapons, new characters, new enemies, new upgrades, and just add more content to the game. I will take ideas and feedback from the community to improve Delta Blade. Built With c# godot piskel Try it out GitHub Repo sameerr.itch.io Submitted to SG Game Jam Created by Sameer Rahmani"
      }
    ]
  },
  {
    "file_path": "./devposts/grandconnect-bycidk.html",
    "project_id": "grandconnect-bycidk",
    "title": "#4 GrandConnect",
    "tagline": "Strengthening connections with your grandparents.",
    "hackathon": "",
    "built_with": [
      "javascript",
      "openai",
      "t3media",
      "twilio",
      "verbwire"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Most Innovative Use of Verbwire Winner Most Creative Use of Twilio Created by Chinat Yu My n",
      "OVERALL 2nd Place Winner Active-Wellness Track Winner Most Innovative Use of Verbwire Winner Most C",
      "Hoya Hacks 2023WinnerOVERALL 2nd PlaceWinnerActive-Wellness TrackWinnerMost Innovative Use of VerbwireWinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/359/133/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our inspiration came from our brainstorming session thinking about the relationships we have with others. We all found societal neglect to be a large issue we wanted to tackle. What it does GrandConnect is an app that facilitates intergenerational conversations between young people and their elderly loved ones. Our app uses advanced AI technology, combined with an asynchronous text messaging interface powered by Twilio, to make it easier for users to connect with their grandparents in a consistent, flexible and personalized manner. We also utilize the blockchain to create permanent memories from these conversations to be shared as NFTs among family and friends. How we built it We designed a website using the T3 stack that takes in key info about your grandparents as input. The user-provided input is then added to our own algorithms and introduced to an AI large language model [GPT-3] that helps us provide output in the form of personalized questions. This data is then integrated into Twilio, which allows us to use a text messaging interface to send these questions out to the user within a customized time frame. We used the Hugging Face language models to provide translation services through Google Cloud. Finally, memories of these conversations are stored on the blockchain using Verbwire. Challenges we ran into The project was a challenging one, with many obstacles to overcome. One of the most difficult aspects was setting up the T-3 stack, we had initial issues with setting up our working environment and deploying onto Vercel with Next.js due to confirgurations issues. Additionally, producing the code-only webpage was a major challenge, as we wanted to make sure that our website was visually appealing and easy to use for our customers. Accomplishments that we're proud of We are extremely proud of how personalized our recommendations are, and how they are driven by real sociological factors that have the potential to positively affect our users. Our use "
      }
    ]
  },
  {
    "file_path": "./devposts/gestational-care.html",
    "project_id": "gestational-care",
    "title": "Gestational Care",
    "tagline": "Nurturing Health, Empowering Moms",
    "hackathon": "",
    "built_with": [
      "chakra",
      "node.js",
      "opencv",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HealthCareCodings MedhackathonWinnerMost Practical Code",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/625/557/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "\"Gestational Care\" design - Start Workout page Gestational Care Homepage Created With React Why It's An Issue? About the Problem Doctor's Statement Tech Stack \"Gestational Care\" design - Add New Workout modal \"Gestational Care\" design - Add New Glucose Reading modal \"Gestational Care\" design - Start Workout page Gestational Care Homepage Created With React Why It's An Issue? About the Problem Doctor's Statement Tech Stack \"Gestational Care\" design - Add New Workout modal \"Gestational Care\" design - Add New Glucose Reading modal \"Gestational Care\" design - Start Workout page 1 2 3 4 5 6 7 8 9 10 💡 Inspiration Our team has long been passionate about using technology to enhance societal well-being, particularly in the realm of women's health. As we delved into the intricate challenges faced by women dealing with gestational diabetes, it was truly eye-opening. These remarkable and resilient women confront a multitude of health issues daily, including long-term risks to both their own well-being and that of their babies. Understanding their struggles prompted us to contemplate: What if technology could offer them a simplified solution? This contemplation led to the inception of GestationalCare, our ambitious project with the aim of revolutionizing women's health and enhancing pregnancy outcomes. The goal is crystal clear: develop a seamless digital tool to combat gestational diabetes, empower these women, and ensure the well-being of both mother and child. Dr. Musleh's insights, a doctor we contacted in the past, were particularly impactful, highlighting the challenges of logging blood sugar values and the urgent need to streamline this critical process for improved prognoses. 🤖 What it does GestationalCare presents a dual-pronged solution:\nBlood Sugar Monitoring: This feature allows users to effortlessly log and monitor their blood sugar levels. Real-time data aids healthcare professionals in closely monitoring the patient's health and making informed decisions. Staying"
      }
    ]
  },
  {
    "file_path": "./devposts/gamesculptai.html",
    "project_id": "gamesculptai",
    "title": "GameSculptAI",
    "tagline": "Accelerate the way games are made! From pixel sprites to 3D models, empower your game development with AI-generated game developer packages!",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-colab",
      "mongodb",
      "openai",
      "react",
      "shap-e"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/682/881/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration: GameSculptAI was inspired by the vision to revolutionize the game development process. Recognizing the challenges faced by game developers in creating detailed, high-quality assets, the idea was to harness the power of AI to simplify and enhance this creative process. The goal was to empower developers, from hobbyists to professionals, enabling them to bring their imaginative worlds to life with greater ease and speed. What We Learned: Throughout the development of GameSculptAI, we delved deeply into the capabilities and potential of AI in creative processes. Learning to integrate OpenAI's APIs, including ChatGPT and Shape API, was a significant part of the journey. We also learned about using MongoDB for data management, React and Flask for building a responsive and efficient user interface, and Google Colab for resource-intensive computing tasks. The project was a comprehensive learning experience in blending AI with traditional software development to create a unique tool. Building the Project: GameSculptAI was built on a robust tech stack: OpenAI APIs: Leveraged for generating 2D pixel sprites and 3D models from user prompts.\nMongoDB: Used for storing and managing user-generated content, enabling a dynamic gallery on the platform.\nReact: Chosen for its efficiency in building dynamic user interfaces, facilitating an interactive and user-friendly experience.\nFlask: Served as the backend framework, providing a lightweight and flexible environment for server-side operations.\nGoogle Colab: Utilized for its powerful computing capabilities, especially for resource-intensive AI model operations. Challenges Faced: One of the main challenges was ensuring seamless integration of various technologies, particularly the AI APIs with the web infrastructure. Managing the computational demands of AI processes while maintaining a smooth user experience was a significant hurdle. Additionally, navigating the complexities of AI-generated content, such as ensuring re"
      }
    ]
  },
  {
    "file_path": "./devposts/goal-tracker.html",
    "project_id": "goal-tracker",
    "title": "Goal Tracker",
    "tagline": "Having your tools to reach your goals is half the battle",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/545/500/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 This web application helps its users set and manage their goals. Users can split their goals into different stages which will then be converted into milestones. In addition, this application has other useful features, such as a progress calculator and the amount of time left until goal completion. All these features are supposed to help the users become more productive and achieve their goals better. Built With css3 html5 javascript Try it out GitHub Repo Submitted to JAMHacks V Created by Worked on the front-end Sean Wang mariyatur27 Turetska"
      }
    ]
  },
  {
    "file_path": "./devposts/g-travel.html",
    "project_id": "g-travel",
    "title": "G-TRAVEL",
    "tagline": "\"Journeys sculpted by data, adorned with dreams.\"",
    "hackathon": "",
    "built_with": [
      "amazon-ec2",
      "amazon-web-services",
      "booking.com-api",
      "figma",
      "gemini-api",
      "google-maps",
      "javascript",
      "node.js",
      "python",
      "react",
      "skycanner-api",
      "tomorrow.io",
      "tripadvisro-api",
      "youtube"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/876/821/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration :: Our inspiration for this project stemmed from a previous attempt to utilize Gemini for travel planning. During that experience, we discovered that Gemini goes beyond simple itinerary creation by leveraging various Google features such as Google Maps and YouTube to provide useful information. This realization sparked our interest in harnessing the capabilities of Gemini along with other Google functionalities and external APIs to deliver a more efficient travel planning experience for users. What it does :: G-TRAVEL simplifies travel planning by gathering your desired destination, travel dates, and trip theme. It delivers tailored day-to-day itineraries with sightseeing tips, dining suggestions, and weather-conscious outfit recommendations. It also provides a variety of flight options and personalized hotel recommendations, and estimated budgets. How we built it :: Languages: JavaScript, Python\n:: Frameworks: React for the frontend, Node.js for the backend\n:: Platforms: Hosted on AWS, utilizing EC2 for server management and S3 for data storage\n:: APIs: Google Maps, YouTube, Skyscanner, TripAdvisor, Booking.com, Gemini API\n:: Other Technologies: Figma for UI/UX design, Tomorrow.io for weather forecasts Challenges we ran into :: We encountered a challenging time frame due to concurrent school finals. Initially, our efforts to implement JSON conversion using JavaScript proved to be arduous, prompting a pivot to Python for smoother execution. Additionally, constraints within the Instagram API limited access solely to personal data, while the Booking.com API imposed a cap of 50 daily requests. :: Among the significant hurdles we faced was the effective integration of the TripAdvisor API. Stringent rate limitations posed difficulties in obtaining real-time data, essential for providing updated travel recommendations.  Moreover, we grappled with complexities within the Google Maps API, particularly in implementing dynamic traffic updates and rerouting functio"
      }
    ]
  },
  {
    "file_path": "./devposts/gen-dev.html",
    "project_id": "gen-dev",
    "title": "Gen Dev",
    "tagline": "User Interface Prototyping Made Easy",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "nextjs",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/593/140/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Contour Detection React Home Page Formatting jsx Contour Detection React Home Page Formatting jsx Contour Detection 1 2 3 Inspiration Creating user interfaces doesn't come easy to everyone. We wanted to make prototyping designs quick and easy. Optical character recognition was one of the major features we wanted to implement into our program. What it does Handwritten or computer generated text is analyzed Convert analysis to a jsx file that is rendered Redo analysis whenever there is a change How we built it EasyOCR reads handwritten and computer generated text Our backend uses a Node server to receive JSONs The backend creates jsx files Challenges we ran into When trying to implement the OCR functions of several cloud services (Azure, GCP, AWS), we ran into issues with credentials Recognizing hand written text (balancing latency vs accuracy) Sending images via POST Integrating all the components Accomplishments that we're proud of Program can recognize text The backend server is capable of writing a jsx file What we learned OCR training Writing to a file with escape characters using Node What's next for Gen Dev Send images directly via POST Improve file management system Using vector calculations to analyze whiteboard movement Built With flask javascript nextjs node.js react Try it out GitHub Repo Submitted to HackMIT 2023 Created by I worked on the backend. I looked into utilizing generative AI to convert images into code as well as utilizing OCR from different cloud providers. I also created the Node and Flask servers and assisted with the jsx creation. James Liang Avid student exploring different aspects of technology and business Kate Zheng Leo Liao Laurence Liang"
      }
    ]
  },
  {
    "file_path": "./devposts/gitexpress.html",
    "project_id": "gitexpress",
    "title": "GitExpress",
    "tagline": "Where creativity meets version control: A git-based add-on for Adobe Express",
    "hackathon": "",
    "built_with": [
      "adobe",
      "express.js",
      "figma",
      "git",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "of Best Domain Name from GoDaddy Registry Inspiration As programmers, we use git a lot, maybe too m"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/900/096/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Submitted to HawkHawks 2024 Winner of Best Domain Name from GoDaddy Registry Inspiration As programmers, we use git a lot, maybe too much. Many apps like Figma, Canva, and Adobe Express are collaborative tools, but only have basic version history. We wanted to integrate git version control with Adobe Express to enable more effective and efficient designs. Being able to compare branches side by side and merging agreed on features is obvious, yet difficult. No longer will you wake up seeing random changes on your main file! What it does Using Adobe's SDK's, we collect all objects within a file including: images, text, containers, and much more. After collecting the unique ids and variables like current translation and rotation, we store a local copy to the browser and push the changes to a remote server hosting the git repository. This repository tracks changes and allows for integration without imposing storage bloat on the user's computers. How we built it We ended up using the Add-on UI SDK and Document Sandbox to manipulate the Adobe Express file. The SDK was the main runtime and included functions to deal with local storage. We used React components and JavaScript to integrate the frontend with this SDK. We ended up needing to proxy the Document Sandbox as having two runtimes would never run together. The Document Sandbox provided access to all the nodes. The structure of a file was a very steep hierarchy with many few objects and many inheritances. We traced the documentation to go from BaseNodes to Nodes then to specific ones like TextNode or ImageRectangleNode. Each object has a unique id, which made it the perfect way to track changes. By comparing ids and values within the object, we can see what changed. We also considered hashing the entire object to quickly determine whether it changed. After comparing how it changed, we retrieved the data by going through the hierarchy and passed the information from the Sandbox directory to the UI dire"
      }
    ]
  },
  {
    "file_path": "./devposts/food-oasis-irp89a.html",
    "project_id": "food-oasis-irp89a",
    "title": "Food Oasis",
    "tagline": "Redefining Solutions for Food Deserts 🍲🏜️",
    "hackathon": "",
    "built_with": [
      "css",
      "edamam",
      "html",
      "javascript",
      "mapbox",
      "node.js",
      "react",
      "repl",
      "rest"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/187/656/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Volunteer Page GIF Home Page Recipe Browser Donation Page Resources Page Volunteer Page GIF Home Page Recipe Browser Donation Page Resources Page Volunteer Page 1 2 3 4 5 6 7 Inspiration 💡 You would think that by 2022 we would have the most basic human needs, such as access to food,  figured out by now. But no, we don’t. Currently, in America and around the world, certain areas do not have access to healthy and quality food. These areas are known as food deserts. Food deserts disproportionately affect communities with high poverty, black communities, and communities without adequate transportation. More than 33% of residents in a food desert have to travel sometimes up to 10 miles to get to their nearest grocery store. Nearly 39.5 million people in the United States alone live in these areas. What it does 🤔 There are 3 main components to Food Oasis . First, the website pings the users’ location and identifies if you live in a food desert. Users can then find out more information and resources to help them gain access to quality food. Next, there is an option to donate either money to a food bank or food to a food desert near you. Users can also sign up to volunteer at a food bank, and we connect them to one in a local food desert. Lastly,  Food Oasis lets you browse free, nutritious, and cost efficient meals. Not only are you able to make recipes, you’re also able to share them! Help out another family in need by giving your tips and tricks around the kitchen. Targeted Track : Social Good How we built it ⚙️ We used HTML and CSS to create the UI and JS for the back end. We used a Edamam Recipe API for searching for recipes. Node.JS was the evented I/O for the backend (Deafault => Repl). For CSS, we've also used Chakra & besides, JQuery was also used to access the backend. To fetch the IP, we've used IPinfo API & Mapbox for displaying the maps accordingly. The internal Query is handled by a backend running on Express. Design 🎨 We utilized design tools like Sketchpad &"
      }
    ]
  },
  {
    "file_path": "./devposts/go-outside.html",
    "project_id": "go-outside",
    "title": "Go Outside",
    "tagline": "We are a team of 3 software engineers and 1 UX designer who, in the past 24 hours, as a team worked towards a solution that would motivate people to explore and reconnect with nature.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "flask",
      "google-cloud",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/995/125/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Sitting in front of a screen for hours on end has become the new norm as the global pandemic continues to restrict social gatherings with other individuals. We noticed that people would sit in front of the screen regardless of their productivity and hence, having no work and life balance. People have said that they didn’t know what they could do or didn’t have the energy to think of an activity, so we decided to bring the activity to them. Scientists believe that interacting with nature helps ease one’s mind and also physically relax, and our web app Go Outside is here to do just that. With a carefully designed UI, we hope to engage our users in meaningful outdoor activities in different weather conditions. What it does As summer finally approaches, we know that there are people out there that want to go outside but is lack of new things to do. So we created Go Outside, an online platform for people to share their outdoor activity ideas to other, in return for an activity idea from others. Each user is asked to provide one idea to add to the central database, could be something that he/she has done before and enjoyed, and then he/she will get back an activity that someone else enjoys to try! How we built it We built the backend portion with Python and Flask (utilising its modular way of creating applications), using CockroachDB as the database. The UI was designed in figma and created in React.js. What we learned We've learned how to work with cockroachdb, sharpened up our skills in developing react web apps, and also how to deploy a service to Google Cloud Platform. What's next for Go Outside For our next step we'd like to complete the API deployment to Google Cloud Platform , and then we'll be implementing geolocation + using 3rd party weather API, tracking what kind of whether the user's area is under, in order to provide the best activity recommendations to the user. Challenges we ran into For the backend component with python, flask and co"
      }
    ]
  },
  {
    "file_path": "./devposts/generatones.html",
    "project_id": "generatones",
    "title": "Generatones",
    "tagline": "Generatones is a custom-built, custom-trained Recurrent Neural Network (RNN) with a Long Short-Term Memory (LSTM) architecture that generates aesthetically complex ringtones.",
    "hackathon": "",
    "built_with": [
      "flask",
      "html",
      "keras",
      "midi.js",
      "numpy",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Fine-tuning the LSTM architecture to achieve the best results"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/678/871/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Generatone Generatone Generatone 1 2 Introducting Generatone Receiving a call from a loved one, from an old friend or from a complete strangers. These are all special calls that we cherish, but why do they all come with the same boring ringtones? How can one limit himself to a few dozen predefined ringtones when the calls following them are so unique? This is why we decided to build Generatone, an A.I. that can create a new ringtone everytime you receive a call so that each and every of your phone's rings rings is unique. Technical details Collectively, our group members had already used various ML algorithms for projects, usually using DNN for classification. For this MAISHacks, we wanted to try out something new. We decided to settle for a project involving the generation of content by an ML algorithm. We decided to go for a ringtone generator because we did not find anybody online who had done the same project. We first wanted to build a Generative-Adverserial Network (GAN), but we then realized the complexity of building such a model with sequential data. After thinking, we decided to settle for a Recursive Neural Network using a Long Short-Term Memory (LSTM) architecture, which would facilitate the use of sequential audio data. We also decided to use MIDI instead of MP3 for the file format since the latter would have been likely to simply yield white noise, whereas MIDI is almost guaranteed to yield a result because the file format directly specifies notes to play instead of frequencies. Ultimately, we built and trained a functional LSTM that generated a variety of ringtones, and exported them to playable MIDI format. How we built it Python Keras LSTM MIDI Parsing library Flask web ap HTML/CSS Challenges we ran into We had to figure out how to work with audio files, and how to design a neural network architecture to generate ringtones. We decided to use MIDI files, since a MIDI file represents a series of notes. We self-taught ourselves to use MidiToolKit, a Py"
      }
    ]
  },
  {
    "file_path": "./devposts/genai-genesis-project.html",
    "project_id": "genai-genesis-project",
    "title": "Job Query",
    "tagline": "Unlock Opportunities with Every Word: Your Personal Job Search Assistant",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "krita",
      "python",
      "redis",
      "vertexai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/829/784/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Similarity Response A logo for our job searching tool GCP Dashboard Job Redis Vector Database Similarity Response A logo for our job searching tool GCP Dashboard Job Redis Vector Database Similarity Response 1 2 3 4 Inspiration The inspiration for our job searching tool came from observing the challenges faced by job seekers, especially during the economic downturns and disruptions caused by global events like the COVID-19 pandemic. Recognizing the importance of employment for individual well-being and economic stability, we were motivated to develop a solution that makes the job search process more efficient and effective. What it does Throughout the development of our project, we learned a great deal about the complexities of the job market, the importance of user-friendly design, and the power of technology in addressing real-world problems. We delved into areas such as natural language processing to improve job matching algorithms and data analysis to understand job market trends. This project also taught us the value of collaboration, as we worked together as a team to brainstorm ideas, solve problems, and implement our vision. How we built it Our job searching tool was built using a combination of technologies:\n    Frontend: We used jQuery and Ajax for the user interface to create a responsive and intuitive design.\n    Backend: The backend was developed with python, handling data processing and API requests.\n    Database: Redis was chosen for its flexibility and scalability to store job listings and user profiles.\n    Machine Learning: We integrated VertexAI to refine job search results based on user preferences and behavior. Challenges we ran into The main that we rain into was joining front end with the back end. \nAnother challenge was designing a user interface that is both accessible and engaging. We aimed to create an experience that reduces the stress and frustration often associated with job searching, which required thoughtful design and user testing. "
      }
    ]
  },
  {
    "file_path": "./devposts/giveacad.html",
    "project_id": "giveacad",
    "title": "GiveAcad",
    "tagline": "Making Education easy by a network system where you give and receive",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css3",
      "html5",
      "javascript",
      "php"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/903/651/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "dash board 2 logo home page 1 dashboard 1 login page 1 home page 2 dash board 2 logo home page 1 dashboard 1 login page 1 home page 2 dash board 2 1 2 3 4 5 6 7 Inspiration we got the inspiration for this Web Service from our childhood experience, How when we were young our elder brother/Sister could pass on their textbooks when they where through with it to us and we would pass it to our younger The Cycle Continues What it does It a web Service Where people can come and Donate academic Materials,Money and Time for those that would like to give but have neither Money or Academic resource, they can donate their time in offering free tutorials to those in need of them How I built it It was build with Bootstrap, Html, Css and then my Team mate did the backend with PHP\nHad to use some of my pre-existing templates with difficult adjust meet because of time Challenges I ran into the Fact that neither me or my team mate met physical was quick challenging\nthen the absence of light And working with a bad laptop were all tasking\nbut the most challenging might the new skills i had to learn to complete the project Accomplishments that I'm proud of the near completion of the projects\nthe fact that our web service would greatly improve the education sector in Nigeria makes me proud What I learned Increased knowledge of Bootstrap\nHow to add Social media buttons to a website What's next for GiveAcad mass publicity to grain customers\nimprovement of the site\nand lots more Built With bootstrap css3 html5 javascript php Try it out GitHub Repo 85.159.215.21 Submitted to NaijaHacks 2019 Created by i worked on the front end was very stressful kromate Akpan I worked on the backend of the project using laravel and deployed on linode for the first time. it was really challanging, but I lernt a lot Busola Okeowo I worked on frontend of the project(login/sign up page) Working on the project made me discover alot.I had to do alot of research work just to find out how to do alot of things relate"
      }
    ]
  },
  {
    "file_path": "./devposts/globalnest.html",
    "project_id": "globalnest",
    "title": "globalNest",
    "tagline": "- a nest for globe",
    "hackathon": "",
    "built_with": [
      "express.js",
      "github",
      "mongodb",
      "node.js",
      "react.js",
      "sendgrid",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Comming soon What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for globalNest Built With express.js github mongodb node.js react.js sendgrid twilio Submitted to MHacks 15 Created by I worked on the frontend Satyam Singh Kartik Patel Nothing much..! Om Dalwadi Dharmik Dholariya"
      }
    ]
  },
  {
    "file_path": "./devposts/githelp-z79mnd.html",
    "project_id": "githelp-z79mnd",
    "title": "GitHelp",
    "tagline": "Everyone needs to git help sometimes",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "express.js",
      "mongodb",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/407/918/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "specific repository Landing page Homepage specific repository Landing page Homepage specific repository 1 2 3 4 Inspiration In 2018, 44 million repositories were created on GitHub. With an active community of 40 million users, Github is used by junior and senior developers alike. On one hand, junior developers on GitHub often struggle to gain contributions on their repository unless they gain substantial experience, and on the other hand, senior developers interested in contributing often all contribute to popular repositories, run by companies with plenty of engineers. There is a lack of information about the repositories that do need help/features/bugs fixed for senior developers looking to contribute, which results in excessive focus on large repositories. In a team brainstorming session for HackSC, Gaurang, an undergrad freshman studying computer science, complained that they would never get help on their repositories. Megan, a full stack developer, exclaimed that she found it hard to find repositories to make meaningful contributions to, since popular repositories got most of the contributions. GitHelp is a website that connects developers who seek contributions to their repositories with developers who are willing to contribute. What it does GitHelp accounts allow you to work as a contributor or a project owner. The landing page prompts users to sign up for an account or login. After successfully logging in, users are redirected to a home page where collaborators can browse a catalogue of repositories that are seeking help. Tags are placed in the repository cards in the catalogue to make the purpose for contributions more clear. Meanwhile, repository owners can use the home page to get their projects and issues noticed by uploading a ‘request for contribution’ on the website. A contributor can view more details about the repository by clicking on a specific repository card on the catalogue. If they are impressed by the project and have knowledge about the issu"
      }
    ]
  },
  {
    "file_path": "./devposts/greencart.html",
    "project_id": "greencart",
    "title": "GreenCart",
    "tagline": "An eco-friendly grocery assistant that provides shoppers with information about the environmental impact of food items they're browsing, helping them make more informed and sustainable choices.",
    "hackathon": "",
    "built_with": [
      "autocode",
      "css",
      "domain.com",
      "flask",
      "git",
      "html",
      "javascript",
      "openai",
      "pandas",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "gif ever GIF Best gif ever 1 2 3 4 5 6 Inspiration When it comes to grocery shopping, it's easy to",
      "Best Domain Name from Domain",
      "ElleHacks 2023WinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/409/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Best gif ever GIF Best gif ever 1 2 3 4 5 6 Inspiration When it comes to grocery shopping, it's easy to overlook the environmental impact of our choices. Most of us tend to focus on price, personal taste and preferences when making our selections, as information on a product's environmental impact is not readily available in a user-friendly format that can be easily accessed and understood. That's where GreenCart comes in. Our innovative Chrome extension provides shoppers with an easy-to-understand display of the environmental impact of a food item, along with a list of recommended, more sustainable alternatives. By providing this critical information in a simple, accessible way, we aim to empower shoppers to make more sustainable choices and reduce their environmental footprint. What it does When a user is browsing a grocery delivery website and comes across a food item they're interested in, they can simply click on the extension's icon located in the top-right corner of the page, this will launch a pop-up that provides detailed information on the environmental impact of the selected item. In addition to this, the pop-up will also display several alternative products that are more eco-friendly, giving users a range of options to choose from and easily substitute their initial selection with a more sustainable alternative. How we built it For the project implementation, we used Python with Pandas to manipulate an extensive and comprehensive data set that we sourced from Kaggle, enabling us to provide our users with reliable, accurate information about the environmental impact of the food items they browse. In order to create a seamless and intuitive user experience, we decided to utilize both a pop-up and a webpage, with the webpage built using the highly adaptable React framework, and the pop-up using a combination of HTML and CSS. To further enhance the backend of our project, we utilized OpenAI's API with the help of Autocode, enabling us to use artificial i"
      }
    ]
  },
  {
    "file_path": "./devposts/general-motors.html",
    "project_id": "general-motors",
    "title": "General Motors",
    "tagline": "Code go boom boom into floor",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/766/078/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "CNN, sleepytimes is sleepy. Built With python Try it out GitHub Repo Submitted to TAMU Datathon 2021 Created by Joshua Chong Hunter Finch kxrider"
      }
    ]
  },
  {
    "file_path": "./devposts/friends-with-gifs.html",
    "project_id": "friends-with-gifs",
    "title": "Friends with Gifs",
    "tagline": "Play Gifs Against Humanity with Your Friends!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "docker",
      "giphysdk",
      "google-cloud",
      "html5",
      "javascript",
      "sketch",
      "zeplin"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      ", and at the end of the game we show a final winner who received the highest likes from players",
      "Best Use of Giphy SDK Created by I worked on the front-end and UI/UX design Hyejun Youn I wrote a l",
      "hackNY Fall 2019WinnerBest Use of Giphy SDK",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/852/637/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We were inspired by Apples to Apples, Use your Words and other such game. We thought we could build a user friendly game using Giphy's API and Google Cloud that you can play with your friends! What it does Friends with Gifs is a multiplayer game that allows players to create and join a game. A creator can decide the number of rounds they will play, and other players will receive a shared code from the creator. The game provides a prompt, and players have to select the funniest gif from a set of randomly chosen gifs. Players rate each other's choices, but cannot vote for themselves. At the end of the round there is a winner, and at the end of the game we show a final winner who received the highest likes from players. How we built it Our team was divided into two groups: front-end and back-end developers. Front-end developers started from wire-framing the game using Sketch and Zeplin, then we moved to coding the pages using HTML and Boostrap. Back-end developers worked on NodeJS, SocketIO, Giphy's API and Google Cloud Engine. Challenges we ran into Initially we struggled to even settle on an idea. For the longest time we were set on making a VR/AR experience. 3 hours of discussion led us nowhere and this idea spawned out of nowhere. We decided to go forward with it mostly because we really wanted to play this game.\nWe started by building the entire app using Flask but realized the need for sockets soon and had to switch everything over to a NodeJS server instead. SocketIO was new to all of us, and we really struggled with understanding it. For the longest time, we were not able to fix the issue of sockets disconnecting on redirects. Accomplishments that we are proud of We are proud of building a full-function application. We like how it looks and hope you do too! We are also quite proud of how we managed to pivot and get everything working on NodeJS after a lot of the code was already written for Flask. We learned a lot more backend - especial"
      }
    ]
  },
  {
    "file_path": "./devposts/fruitrecipes.html",
    "project_id": "fruitrecipes",
    "title": "FruitRecipes",
    "tagline": "Find healthy recipes by taking a picture of your favorite fruits/vegetables!",
    "hackathon": "",
    "built_with": [
      "echoar",
      "googlecloudvision",
      "html",
      "jupyter",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner echoAR: Best AR/VR Application Created by I worked on embedding echoAR 3d models onto the we",
      "Second Place Winner echoAR: Best AR/VR Application Created by I worked on embedding echoAR 3d model",
      "MenloHacks 2021WinnerSecond PlaceWinnerechoAR: Best AR/VR Application",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/432/819/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our quarantine hobbies included cooking/baking and we wanted to find faster ways to look for healthy recipes instead of searching the ingredients on a search engine. What it does The website identifies the fruit/vegetable from the picture taken and finds recipes online that use the given fruit/vegetable as the main item (i.e.apples → apple pie). The website also shows 3d models of the recipes so users can interact and see how the food looks like before baking/cooking it. How we built it We used Google Cloud Vision API to identify the fruit/vegetable from the image. To find healthy recipes, we used the search engine to find a recipe online that uses the food as the main item (i.e.apples → apple pie). We downloaded 3d models from Poly and uploaded them onto echoAR to make a 3D model of the food. Challenges we ran into The goal was for Google Cloud Vision API initially to give labels to objects(food) in the image, but the \nhackathon didn't sponsor Google Cloud, so we looked for other substitutes (listed below):\nAWS\nAlternate Google Cloud Vision API tutorial \nClassification models(Keras, CNN, Deep Forest) Jupyter \nBinary Classification(ex: Orange vs Apple) We Switched several times between app and web\nWe weren’t able to connect all our separate projects(website, AI models, echoAR 3D models) together Accomplishments that we're proud of We were able to work with systems (echoAR, Google Cloud Vision) that we never used before and use them onto our website. What we learned We learned more about echoAR, Google Cloud Vision API, and learned new concepts in HTML and python. What's next for FruitRecipes We plan on using Flask and Python to host on a google app engine instance. We also want to experiment more with google cloud vision API so we can embed it onto our website. Built With echoar googlecloudvision html jupyter python Try it out replit.com replit.com replit.com youtu.be Submitted to MenloHacks 2021 Winner Second Place Winner echoAR: Best AR/VR Application "
      }
    ]
  },
  {
    "file_path": "./devposts/green-eats-xr6s15.html",
    "project_id": "green-eats-xr6s15",
    "title": "Green Eats",
    "tagline": "Get priceless foods and save the planet :D",
    "hackathon": "",
    "built_with": [
      "css",
      "ejs",
      "express.js",
      "geolocation-api",
      "html",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/633/712/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Food Listing Webpage Project Logo Project Homepage Food Listing Webpage Project Logo Project Homepage Food Listing Webpage 1 2 3 4 Inspiration As our team was searching for solutions for problems, we found out that over 1/3 of all food is wasted. Companies just don't have the incentive to sell their spoiling food at lower prices. We realized we needed an innovative solution to incentivize companies to sell their spoiling food, Green Eats. What it does Green Eats features food listings of spoiling food on a website, which buyers can easily access. Sellers can also post listings of spoiled food, which will be stored in a JSON file and reviewed by the team to be added to the website. How we built it Green Eats is comprised of a front-end website made of Javascript, CSS, and HTML. We used Node.js and express.js for the back-end. We also used Geolocation API to get the latitude and longitude of the seller to accurately determine their listing location. Challenges we ran into One big challenge was one of our team members was in a different time zone than us, so we had a hard time collaborating and communicating with them. Also, no one on our team had experience with back-end to make a webserver, meaning we spent a long time learning how to create a webserver and linking back-end with front-end. Accomplishments that we're proud of We got the backend and the front end to work together as well as setting up a database. Included a location for longitude and latitude for finding the nearest restaurants in your area What we learned We learned express.js to create webservers, and the main HTTP method requests, such as GET and POST. We also learned how to use form data in HTML and send it back to back-end for increased functionality. Some things were completely new to us, such as Geolocation API and .ejs files, but we managed to learn how they work and how we could use them. What's next for Green Eats Next steps are polishing up the design of the website. We could also include so"
      }
    ]
  },
  {
    "file_path": "./devposts/garbageflow.html",
    "project_id": "garbageflow",
    "title": "GarbageFlow",
    "tagline": "Flow Waste to the Right Place",
    "hackathon": "",
    "built_with": [
      "python",
      "pytorch",
      "react",
      "resnet",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/421/828/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Detection Tool (Python/Flask Code) Launch Screen (React) Detection Tool (Python/Flask Code) Launch Screen (React) Detection Tool (Python/Flask Code) 1 2 3 Welcome to GarbageFlow !! Inspiration The topic of climate change caught our team's eye as we acknowledged the multitude of climate change-related problems that our planet faces. Through brain-storming and the process of elimination, we approached the concept of scanning an item's barcode to determine where it can be disposed of. This was ideated because some members of our team felt that sometimes, seeing 4 different trash options can be time-consuming and confusing, and some solve this problem by with a \"simple\" picture. Soon after, we realized that a bar code isn't as good of an idea as scanning an object, regardless of whether it even has a barcode. and determining the optimum disposal choice. What it does GarbageFlow is a machine learning application that uses computer vision to classify images of garbage into different categories, such as plastic, glass, metal, cardboard, and more. The user can take a photo of a piece of garbage using their webcam, and GarbageFlow will classify it using its trained model. How we built it For our project GarbageFlow, we utilized a combination of technologies to achieve our goals. Firstly, we used computer vision to classify different types of waste into their respective categories such as plastic, paper, glass, metal, and organic waste. For this, we leveraged the PyTorch deep learning framework and pre-trained ResNet models to train our own custom model using a dataset of waste images. Secondly, we built a web application using Flask, a Python web framework, which allowed users to upload images of waste to our system. Our model then classifies the image and provides information about the type of waste and how to recycle it correctly. Challenges we ran into We ran into a plethora of challenges while working on this project. First of all, we're all lower year CS & CE majors who"
      }
    ]
  },
  {
    "file_path": "./devposts/granolify.html",
    "project_id": "granolify",
    "title": "granolify",
    "tagline": "You are granola",
    "hackathon": "",
    "built_with": [
      "cloudflare",
      "granola",
      "javascript",
      "plasmo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "julia bock ATE prize ($2) Created by James Liang Avid student exploring different aspects of techno",
      "s Winner julia bock ATE prize ($2) Created by James Liang Avid student exploring different aspects o",
      "brainrot jia.seed hackathon ($5,772) in prizesWinnerjulia bock ATE prize ($2)",
      "Tracks",
      "julia bock ATE prize ($2)",
      "It's very easy to send tons of requests a second Granolala",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/162/915/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Tracks julia bock ATE prize ($2) worst project ($5) most iq points lost ($5) Inspiration You are granola What it does Granola everything (unless it doesn't then I don't know why) How we built it Granola everything (I have the Cloudflare functions, but they aren't happy with me accidentally DDOSing them). Replace random text with granola themed words and replace all images with granola. Challenges we ran into DDOSing Cloudflare by mistake Only works on reload Doesn't work on all websites Accomplishments that we're proud of My extension has turned on my many times while debugging It somehow also affects error messages What we learned It's very easy to send tons of requests a second\nGranolala What's next for granolify Local LLM processing so I only need to worry about DDOSing myself Improve compatibility on more webpages Granola granola Another YouTube link w/o music in case i get copy struck o.o https://youtu.be/ujUiqn2XneE Built With cloudflare granola javascript plasmo Try it out GitHub Repo youtu.be Submitted to brainrot jia.seed hackathon ($5,772) in prizes Winner julia bock ATE prize ($2) Created by James Liang Avid student exploring different aspects of technology and business"
      }
    ]
  },
  {
    "file_path": "./devposts/grow-homes.html",
    "project_id": "grow-homes",
    "title": "grow homes",
    "tagline": "what if you can grow your own homes in the virtual world",
    "hackathon": "",
    "built_with": [
      "aiva",
      "aws-polly",
      "blockade",
      "deepseek",
      "gen-ai",
      "gpt",
      "horizon",
      "llama",
      "meshy",
      "photoshop",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "s Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/413/649/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 Welcome to growHomes: Shireville, a Century 22 Virtual Estate Company. growHome vending machine - live demo: https://gyazo.com/b592d34f95900f0704da43d337969199 Inspiration : What if you can grow homes and house NPC refugees in need of homes? What inspired you to create this world? I'm currently a visiting scholar out east and missing home: California's rolling (often green) hills! I started experimenting with Horizon Gen AI text to mesh and it all looked very meshy, like lumps of hills, and I started wondering about tiny homes built into these lumps. And, what if you could grow them... What other worlds or media influenced your creative direction? Ofc, the for building a simulation app/game, farmville is the classic. But I like games where you get to build and maybe manipulate characters - Mini Sim City meets The Sims meets Lemmings (because the NPCs can't do much yet in Horizon) is the key inspiration - and a slight bit of Hobbiton, though I am wary of rights, so I'm keeping it generic - and keeping it a mix of Mything irreverence, combining modern Americana norms, say Job Simulator meets discounted real estate - but \"magic is what's wrong with it\". I wanted to add in also a bit of the mechanical wonders of The Room and Edith Finch, and so there will be bonus intricate easter egg puzzles throughout. And of course, a touch of reality, albeit, this is virtual estate, I am inspired by magical vending machines that somehow vend growable anythings. More prosaic things: Century 22 Virtual Estates is inspired by Century 21, the real estate company and the whole pretentious private island tour is inspired by my own classic spa resort app made with my corgi FJBC.me - Front Jolly Back Corgi (though we kept our NPC virtual estate agent American instead of British here). How we built it What were the key tools and processes you used to create the world? If this is a team world, who contributed and how did they c"
      }
    ]
  },
  {
    "file_path": "./devposts/greenfoot-xlvgcn.html",
    "project_id": "greenfoot-xlvgcn",
    "title": "Footprint",
    "tagline": "A way to quickly trace back your carbon footprint",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "beautiful-soup",
      "flask",
      "flutter",
      "fluttermlkit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/944/599/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 What inspired us The impending growth of climate change and its effects drives our group to take a step towards a green future. We've learned about people's lives being harmed across the world and knew actions must be taken. Climate change is super important to us, this is the 5th app that we've built to combat it, and speaking from experience there's no denying how threatening it is. When we started, we realized quickly how much carbon goes into carbon footprints of simple manufactured goods (over half a ton in total), we knew that we needed to spread the word, in a fast, easy, and impactful way. I remember visiting one of my favorite places in the world, Glacier national park (Montana), 2 times 6 years apart, and seeing horrifying changes, let alone the environmental impacts and impending famine, flooding, and mass-migrations that are coming. What it does Footprint is an app that allows the user to instantly track their carbon footprint simply by taking a photo of most objects. We provide you with an estimated mass of CO2 produced in mass released throughout the manufacturing process of your item. Scan a backpack, Scan your laptop, Scan your shoe! You will quickly get the carbon footprint of that item. On top of this, Footprint provides advice to users on how to aim to reduce their carbon footprints. How we built it We built this app using a combination of a webscraping algorithm that we built with the beautifulsoup framework and served on a flask server. We tried both a custom AI algorithm using the ImageNet (AlexNet) CNN and the firebase ML kit, which we ended up using just because of the ease of integration, even though accuracy dropped a bit. The app itself was built using flutter, a cross-platform iOS / Android platform that enables quick reload and software development. Challenges I ran into One of the biggest issues we ran into, was ironically, the wifi. Over 3 times, we spent large swaths of time thinking that we had severe bugs without code to find "
      }
    ]
  },
  {
    "file_path": "./devposts/greenhouse-4kbr3d.html",
    "project_id": "greenhouse-4kbr3d",
    "title": "GreenHouse",
    "tagline": "Providing rewards for energy saving.",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "nextjs",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/674/332/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Rewarding System greenhouse Dashboard Informational facts Rewarding System greenhouse Dashboard Informational facts Rewarding System 1 2 3 4 Inspiration Turning reward systems, normally targeted for marketing purposes, into useful tools for more sustainable living. What it does It provides an overview of your energy consumption. It rewards you for conserving energy and provides overall helpful knowledge in order to encourage greener living. How we built it Our website is built using modern tools such as Next.js and sass. Challenges we ran into Coordinating our time schedule and realizing a system for keeping the users engaged with the website. Accomplishments that we're proud of We are proud of our team coordination and our website prototype. What we learned New skills in webdesign and how high energy consumption impacts the environment negatively. What's next for GreenHouse Providing better user experience and collecting power data reliably and wireless. \nMoving on from the prototype to a fully working web application. Built With css html5 nextjs react typescript Try it out GitHub Repo greenhouse-hackatum.vercel.app Submitted to hackaTUM 2023 Created by Francisco Kusch eliaskhano Khano Adrian Lieven emsilouise"
      }
    ]
  },
  {
    "file_path": "./devposts/grand-task.html",
    "project_id": "grand-task",
    "title": "Grand Task",
    "tagline": "Grand Task is a task manager that helps families and loved ones schedule, assign, track, and schedule tasks for the elderly people in their lives.",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "github",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/386/772/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Work in Progress Landing Page Home page User Input Form Work in Progress Landing Page Home page User Input Form Work in Progress 1 2 3 4 5 Inspiration This project was inspired by my grandmother. She teaches me the importance of caring for the elderly people in my life. What it does Grand Task is a website that allows different members of a family schedule, collaborate and  assign tasks  to help their elderly family members with everyday tasks and such as: doctor's appointments\n-shopping trips \n-daily walks and exercises\n-weekly dinners\n-household chores\nThe goal of this project was to include these features:\n-family members can “pick” up tasks and not overlap \n-users can integrate their calendars to see if they can pick up tasks \n-grandparents or admin can assign tasks between different family members. How we built it I created a mockup of Grand Task with Figma. I then used HTML and CSS to bring the design to life along with some JavaScript to add some interactivity. Challenges we ran into I struggled with the form page to allow the user to add tasks, I wanted to make it appear only when a button was pressed. After a long time, I realized I was simply missing brackets in the script tags of my html file. Accomplishments that we're proud of I'm proud that I have a small form on my page that takes user input. What we learned I learned how to: \n           -create forms in HTML, CSS, and JS \n           - create and style a navbar with links in HTML and CSS What's next for Grand Task My plan for Grand Task is to complete the frontend which has a lot of missing sections and power it with a backend of node.js and use a database to store the user data and input. Built With css figma github html javascript Try it out www.figma.com GitHub Repo Submitted to Black Wings Hacks 2021 Created by This was my first time working on creating a real website instead of just snippets of html and css. Fariha Mohamed"
      }
    ]
  },
  {
    "file_path": "./devposts/greensleuth.html",
    "project_id": "greensleuth",
    "title": "GreenSleuth",
    "tagline": "GreenSleuth revolutionizes emergency response by utilizing NLP and machine learning to provide prompt assistance, potentially saving countless lives and transforming emergency services in the future.",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-maps",
      "gpt",
      "html",
      "openai",
      "python",
      "pyttsx3",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of NLP\" and \"Best Use of AI\"",
      "Future Impact Award Created by Josh Fernando Adem M",
      "s such as \"Best Use of NLP\" and \"Best Use of AI\"",
      "Hack the MISTWinnerFuture Impact Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/422/018/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Our innovative project, GreenSleuth, uses NLP and Machine Learning to revolutionize the way emergency services respond to distress calls. When the user speaks about their emergency situation, our system analyzes what is being said and provides two essential pieces of information - the user's location and the situation they are in. Whether the user only mentions a random place name or describes their location in detail, our system can extract the relevant information and provide the user with the coordinates of their location. This makes it easier for emergency services to locate the user and provide prompt assistance.\nThis project is unique because it solves a common problem that many people face during emergency situations - effectively communicating their location and situation to emergency services. With the help of NLP and Machine Learning, our system can understand natural language and extract important information from it. This makes it easier for people in distress to get the help they need quickly and efficiently, potentially saving lives in the process. Our project can have a significant positive impact on the community. In times of crisis, every second counts, and our system can help emergency services respond faster and more effectively. By streamlining the communication process between the user and emergency services, our project can reduce response times and potentially save lives. Overall, our project is a game-changer in the field of emergency services. It leverages cutting-edge technology to solve a critical problem and has the potential to make a real difference in people's lives. We believe that this project has the power to revolutionize the way emergency services respond to distress calls, and we are excited to see the impact it can have on the community. What it does Our innovative project uses NLP and Machine Learning to revolutionize the way emergency services respond to distress calls. When the user speaks about their em"
      }
    ]
  },
  {
    "file_path": "./devposts/gauchoride.html",
    "project_id": "gauchoride",
    "title": "GauchoRide",
    "tagline": "GauchoRide provides a medium to connect with fellow Gauchos for transportation. Post and find rides in your vicinity.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "google-cloud-sql",
      "google-gmail-oauth",
      "javascript",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/824/812/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Rider Form Driver Form Rider Form Driver Form Rider Form 1 2 3 Inspiration One of the main concerns for college students is transportation. It would be easier if UCSB students could just share rides in an easy and quick manner. What it does Drivers can post their route and riders can find drivers. Riders send a request to the driver and the driver accepts or denies. How we built it We started off with brainstorming ideas for the first couple of hours after the start of the hackathon. Then we decided on the technologies we would use for this project and began coding until the final submission. Challenges we ran into One of the biggest challenges we ran into was trying to establish a connection between the frontend and backend that worked.  We had to make sure we hosted the backend properly and the endpoints received the exact information it needed. Accomplishments that we're proud of We are proud of getting both the frontend and backend working in the small amount of time What we learned We learned more about how APIs work, more specifically, Google's Cloud APIs and authentication. We also had more practice with React, SQL and making a rest API. What's next for GauchoRide There is still a lot of features that we did not have time to implement. We would like to have a more fleshed out system for verifying riders and confirmation. Furthermore, we would like to maybe expand the project to more than just rides, for example, meetups. Built With express.js google-cloud-sql google-gmail-oauth javascript node.js react Try it out GitHub Repo Submitted to SB Hacks VIII Created by I worked on the back-end, where I worked on some of the API endpoints and the mailing system Ryan He I worked on the front-end of the website. I learned a lot about react and combining components to build a working website. Jeffrey Cao Guy Wilks Ryan He Daryl Ou"
      }
    ]
  },
  {
    "file_path": "./devposts/grocerbuddy.html",
    "project_id": "grocerbuddy",
    "title": "GrocerBuddy",
    "tagline": "We know you're busy - imagine being able to skip the flyers and still get the best deals! We let you type in your desired products and get a grocery store recommendation.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "beautiful-soup",
      "bootstrap",
      "digitalocean",
      "javascript",
      "python",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "deals on groceries simply because they have a busy schedule What it does Suggests the best grocery",
      "Suggests the best grocery store for someone to visit, given their products and desired quantities."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We realized that time is worth money, and people may not find the best deals on groceries simply because they have a busy schedule What it does Suggests the best grocery store for someone to visit, given their products and desired quantities. How we built it We used Flask, JavaScript, Bootstrap, Selenium, DigitalOcean (backend), and AWS (frontend) to complete the project. Challenges we ran into Selenium is fairly difficult to install on a headless server in the cloud. Also, while writing the optimizer we ran into some unexpected challenges. Accomplishments that we're proud of We are able to scrape data from three distinct sites and incorporate that into a web interface. What we learned It's difficult to implement separate components that talk to each other! Also, scraping is harder than it looks. What's next for GrocerBuddy We will continue to work on the scraper and optimizer to ensure the code can handle edge cases. Built With amazon-web-services beautiful-soup bootstrap digitalocean javascript python selenium Try it out GitHub Repo GitHub Repo Submitted to NewHacks 2022 Created by I worked on the Frontend, and I also led the team (and pulled an all-nighter in the process). Justus Croskery I worked on the web-scraper that gathered our data. Benjamin Fitzgerald I worked on the back-end using Flask and contributed towards the optimisation algorithm. sarvaSanjay Sanjay vedantswamy Swamy"
      }
    ]
  },
  {
    "file_path": "./devposts/guarden-dumfrq.html",
    "project_id": "guarden-dumfrq",
    "title": "Guarden - Guard your garden",
    "tagline": "A NodeMCU powered web app to track your Carbon Footprint",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "iot",
      "javascript",
      "nodemcu",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A NodeMCU powered web app to track your Carbon Footprint"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/569/052/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Logo HomePage Carbon Footprint Tracker Footprint logs Do some work GIF Logo HomePage Carbon Footprint Tracker Footprint logs Do some work GIF Logo 1 2 3 4 5 6 7 💡 Inspiration We often take convenience for granted. The cool breeze an air conditioner provides, or the joy of flooring the accelerator is intoxicating, but the Earth has to face toxic externalities. While we have many campaigns and awareness schemes, they can seem too generalized or superficial. Our project aims to achieve the best of both worlds - to show the user exactly what he/she/they owe to our planet and reward them accordingly for doing the suggested actions. This would help in achieving what we call Targeted Conservation, something that could add to General Conversation to help Guard the Earth ⚙ What it does We have implemented an array of software and hardware tools to identify and predict energy consumption of a user, including temperature and humidity sensors, and by extracting weather data and using automobile mileage data, we estimate the number of trees/alternative methods to remedy this energy usage. By harnessing soil data, we can harness the power of machine learning to effectively suggest the ideal plant for the user to plant. After doing so, they earn TreeCoins, which they can then redeem in stores (easily accessible through our dedicated map) for eco-friendly merch. 🔧How we built it For the Machine Learning part, we used open data, performed EDA on it, and trained a classifier on it. We used numpy, pandas, and scikit-learn for the same. For the map visualisation, we used leaflet.js through folium. For frontend of website, we used HTML, CSS and Vanilla Javascript. We used a flask backend that underpins the whole project. For the hardware, we used a nodeMCU with DHT11 Temperature and Humidity Sensor 💪 Challenges we ran into The project is very big and distinct, lots of merge conflicts and issues were faced to stitch everything together Using a hardware and communicating it with ML en"
      }
    ]
  },
  {
    "file_path": "./devposts/grit-1uk8fb.html",
    "project_id": "grit-1uk8fb",
    "title": "Grit",
    "tagline": "Git for LLM Reasoning",
    "hackathon": "",
    "built_with": [
      "cerebras",
      "figma",
      "gemini",
      "nextjs",
      "python",
      "tailwindcss",
      "typescript",
      "vectera"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Cerebras API Created by design, frontend, db Aurelia Sindhu 아이스 아메리카노 ☕️ Chinat Yu My n",
      "HackDavis 2025WinnerBest Use of Cerebras API",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/384/242/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "with Grit Thumbnail (dark) Thumbnail (light) Problem Statement Why building Grit? Features Our Web Landing with Grit Thumbnail (dark) Thumbnail (light) Problem Statement Why building Grit? Features Our Web Landing with Grit 1 2 3 4 5 6 7 8 Grit: Git for LLM Reasoning Inspiration As LLMs become more powerful, we risk outsourcing not only answers but our own critical thinking . Research on “AI Degradation” shows that passive consumption of black‑box AI outputs can erode human creativity, metacognition, and problem‑solving skills. We wanted to flip that script: instead of hiding the “how,” let’s spotlight it. Grit was born from the belief that seeing an AI’s thought process step by step can turn every interaction into a learning opportunity. What it does Live Chain‑of‑Thought Visualization: Streams token‑by‑token AI output into a dynamic, interactive graph. Branching Deep‑dives: Click any reasoning step to open a side conversation—define terms, explore sub‑concepts, view code snippets or diagrams—then return to the main thread seamlessly. Multimodal Support: Renders code blocks, LaTeX formulas, and inline diagrams in real time. Persistent Context: Every branch remembers where it came from and reconnects smoothly to the parent chain once you’re ready. How we built it Frontend: Next.js + React; WebSockets for streaming; D3‑powered Chain‑of‑Thought Graph. Backend: Node.js server orchestrating LLM calls (OpenAI) with carefully crafted prompts to elicit structured reasoning traces. Data & State: Supabase for session storage, branch histories, and user preferences. Prompt Engineering: Iteratively designed “think‑aloud” prompts so the model outputs coherent, stepwise reasoning rather than just final answers. Challenges we ran into Structured Streaming: Getting the LLM to emit a clean, step‑by‑step trace token by token required fine‑tuning prompts and handling partial JSON fragments in flight. Graph Performance: Rendering and updating a live, branching graph with dozens of nod"
      }
    ]
  },
  {
    "file_path": "./devposts/go-wheel-io.html",
    "project_id": "go-wheel-io",
    "title": "Go Wheel-io",
    "tagline": "You're just one click away from driving your dream!",
    "hackathon": "",
    "built_with": [
      "api",
      "cohere",
      "css",
      "html",
      "javascript",
      "node.js",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack-ccelerateWinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/368/095/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "On the left we have listed the linked in of developers there is this very own customized logo in between and source code on the right The Basic Interface Searching for a car through filters Searching for cars This is how we get random messages from cohere through twilio On the left we have listed the linked in of developers there is this very own customized logo in between and source code on the right The Basic Interface Searching for a car through filters Searching for cars This is how we get random messages from cohere through twilio On the left we have listed the linked in of developers there is this very own customized logo in between and source code on the right 1 2 3 4 5 6 What made us make this project?🚗 The developers of this project, we love to know more about cars. But it is difficult to surf through so many sites to know. So we built this to help users quickly find information about cars, compare features, and get their dream car according to their needs. Why This Project name? Go Wheel-io Go, Comes from the Go Daddy Domain that we have bought. (GoWheelio.select)Huge shoutout and thanks to GoDaddy.\nThe wheel? of course coz which car doesn't have wheels haha.\nio- in the end because Twilio is sending beautiful SMS to our users. Thanking Twilio for providing this great feature. Why we made this project?👩‍💻👩‍💻 We created this car query website with the goal of providing users with all the information they need to make informed decisions when purchasing a car. Our website allows users to search for and compare cars based on their specifications, features, prices, and availability. We strive to keep my information up-to-date and comprehensive, including details such as make, model, year, body type, and price range. We also provide car reviews, ratings, and information about financing and insurance options. Our hope is that my website will be a valuable resource for car shoppers and will make the process of buying a car easier and more accessible.😄 How the Proje"
      }
    ]
  },
  {
    "file_path": "./devposts/greenskills.html",
    "project_id": "greenskills",
    "title": "Greenskills",
    "tagline": "Planting the seeds for a greener future by creating affordable learning solutions for South Africa",
    "hackathon": "",
    "built_with": [
      "netlify",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Mystery Award Created by I developed the webapp",
      "The Climate Change-Makers Challenge: 2025WinnerMystery Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/291/639/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Green Skills homepage Green Skills homepage Green Skills homepage 1 2 Inspiration We see great challenges in economies transitioning towards sustainability and one of the problems we noticed is the difficulty of entering the sustainability field, with green skills courses being very expensive, especially for people in countries in the global south such as South Africa, where it could take several months to more than a year to save enough money to buy a single green skills course. What it does Our solution is a free green skills learning platform for South Africans that will also allow to connect with like minded peers and find jobs. How and why we built it Whilst we were gathering the team during the hackathon, one of our team members mentioned \n some problems he has noticed in South Africa - high unemployment, the difficulty to enter sustainability field due to high costs of courses, lack of South Africa specific courses. After that ,we made the decision to pursue an idea that will help to tackle these issues. We created a mockup with React framework and published it on netlify to illustrate how our solution works.  We discussed the idea with mentors who supported us and helped us make the decision to place an emphasis on a specific region, in our case South Africa, and to tailor the solution to that region.  Our plan is to be non-profit, and operate mostly off of donations and grants as we believe that high quality education is a right for all. Challenges we ran into The biggest challenge was coming up with an idea to tackle while we were recruiting team members, but as soon as we finished the recruitment we successfully came up with idea and aside from needing some coaching to make our solution more specific, we had a very smooth time with the project. Accomplishments that we're proud of Participating in multiple great workshops.\nForming a great team\nComing up with solution that could help solve real world problem. \nCreating Mockup to illustrate how our solution "
      }
    ]
  },
  {
    "file_path": "./devposts/groupthink-ksmj1c.html",
    "project_id": "groupthink-ksmj1c",
    "title": "Groupthink",
    "tagline": "Groupthink provides students with curated, personalized educational material based on their interests and backgrounds made to suit all ages, experience levels, and learning types.",
    "hackathon": "",
    "built_with": [
      "css3",
      "google",
      "html5",
      "javascript",
      "llm",
      "openai",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/743/370/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Inspiration Online learning has always been a student-led endeavor . They are the ones leading the search for content, articles, and summaries based on what they want to learn and their experience levels. With all the content avaliable on the internet, it can be overwhelming for people to find high-quality content that is up to date and actually suits their needs. To fix this, we aimed to reverse the direction of learning: instead of the student finding the content, the content finds the student. What it does Groupthink is a personalized education platform that curates and delivers educational content to students in bite-sized courses automatically processed into a curriculum determined by the student's needs. When first visiting the platform, they fill out a form that includes what they want to learn and their background. The platform will then automatically generate guiding questions that help the user target and tailor their experience. The content is then broken down into a sequential curriculum that separates it into groups based on difficulty and topic. Each of these topics then contain curated content that includes summaries and outside resources that were curated by our system based on the user's desired experience. From experienced subject matter experts looking to specalize in a certain area, to school-aged children wanting to explore their curiosity in a field, the platform supports it through its personalized content curation and delivery system. How we built it The platform was built using React and the standard web framework, including HTML, CSS, and JavaScript. The OpenAI API was used for personalization and form question generation, although it was combined with our own internal parsing modules and external APIs to create the full personalization system.  We also used the YouTube API to search for external videos relevant to the user. Challenges we ran into Due to the lack of documentation and unreliability with the APIs we used, we"
      }
    ]
  },
  {
    "file_path": "./devposts/guiding-light.html",
    "project_id": "guiding-light",
    "title": "Guiding Light",
    "tagline": "Speech-activated object detection app to help people with visual impairments navigate their environments",
    "hackathon": "",
    "built_with": [
      "google-web-speech-api",
      "opencv",
      "pyttsx3",
      "yolo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/599/943/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "(Evidence of us enjoying working on this project) Hi! :) (Evidence of us enjoying working on this project) Hi! :) (Evidence of us enjoying working on this project) 1 2 3 Inspiration 💡 We wanted to try working with computer vision, but also wanted to develop a tool to aid a marginalized community of people. Object detection projects are the norm for computer vision projects but we added speech commands/text-to-speech functionality for greater accessibility. What it does ✨ Once started and after being voice-activated by the user, Guiding Light uses your webcam to capture real-time views of the area around you, then it both visually and verbally identifies what objects are in your proximity. Users are supposed to point the camera in front of them as they walk in order to detect obstacles. How we built it 💻 Guiding Light uses the Ultralytics YOLOv8 object detection model, and retrieves video footage using OpenCV. It uses the pyttsx3 and SpeechRecognition libraries for text-to-speech and speech recognition functionalities respectively. Challenges we ran into 🌩️ We thought the hardest part would be training the model, but that was actually one of the easiest. One of the harder parts was working on the speech recognition. As we're writing this, we haven't figured out how to use voice commands to end the program using just audio input, so that should speak for itself (literally).\nWe're also had (/am having) difficulty figuring out the colour detection aspect of the project. I (Iman) have used a method that takes the average of the RGB values from the footage and returns the most common colour from red, green, and blue, but the applications of this are limited and being able to detect the colour of a specific object would be much better. Moreover, the original service we wanted to deploy on didn't support webcam functionality, plus I overtrained the model, plus we were both sleep-deprived the entire time -- but I've heard if you love something, you'll learn to accept it, fla"
      }
    ]
  },
  {
    "file_path": "./devposts/grow-d0oxvy.html",
    "project_id": "grow-d0oxvy",
    "title": "Grow",
    "tagline": "Grow 🌱 is a platform to grow yourself, and a plant. Your raspberry pi-powered plant only gets watered if you stay productive, and off your phone!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "python",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This was our first ever hardware hack!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/181/004/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "focus activity complete enclosed plant login screen home screen focus activity in progress focus activity complete enclosed plant login screen home screen focus activity in progress focus activity complete 1 2 3 4 5 6 Inspiration As criminal procrastinators, we wanted to change ourselves and also help others while we were at it. What it does We have a raspberry-pi powered plant that waters itself only when the user earns tokens (we call them drops ). Users can earn drops through our app by completing focus activities , which are timers that require you to stay within the app to complete. Every 30min spent in a focus activity will yield 10 drops. Every morning, the plant will water itself if and only if it has at least 10 drops. How we built it We use Firebase to host a collection of plants, and their respective drop counts. A cron job runs on the pi every morning to check Firebase and send a signal to a relay (that is in turn connected to a water pump) to water the plant. The iOS app also connects to Firebase to update the drop count of the logged in user's plant as they finish focus activities. What we learned This was our first ever hardware hack! We also used some new technologies : Figma for designs SwiftUI for making the iOS app UI (transitioning from UIKit) Lottie for animations in the iOS app What's next for Grow We want to sell a kit for others to be able to build the same plant device that we did, and publish our app to be used with the kit! The kit would include everything but the raspberry pi, and also a guide and web API to query for drop counts. Stay tuned... Built With firebase python swift Try it out GitHub Repo Submitted to HackThis Created by Sahil Ambardekar Abhishek More Retired Hackathon Enjoyer"
      }
    ]
  },
  {
    "file_path": "./devposts/gumpare.html",
    "project_id": "gumpare",
    "title": "Gumpare",
    "tagline": "Empower choices on products with eco-friendly packaging",
    "hackathon": "",
    "built_with": [
      "figma",
      "node.js",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/417/382/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Business profile Problem Space we are tackling What Gumpare does Consumer finds product with eco-packaging nearby Business profile Problem Space we are tackling What Gumpare does Consumer finds product with eco-packaging nearby Business profile 1 2 3 4 5 Inspiration Whilst the best way is to reduce the use of packages, there are many valid reasons for using packaging, e.g. keeping the product fresh & hygienic, easy for storage, etc.\nPlastic-based packaging is a popular choice as they are usually the cheapest for manufacturers, restaurants, etc. \nAs climate change, eco-friendly topic arises, many are more conscious of their choices of product & packaging. End consumers are more conscious of their choices of products. Research published by BCG shows that 50%+ of consumers would select products based on the sustainability of packaging, and 20%+ would be willing to pay 10-20% more for products with eco-friendly packaging. Our survey shows that small businesses struggle to promote their products with eco-friendly packaging, whilst end consumers find it hard to find these products. End consumers are also concerned about having little / misinformation about the actual 'eco-friendliness' of the packaging and ways of disposal correctly. What it does Gumpare is a platform to connect consumers to products with eco-friendly packaging. This is a 3-way platform: A - Businesses selling product with eco-packaging - motivated by exposure and lead gen Gumpare enables businesses to List their products (what product is it and where to get them, what eco-packing they are using) Provide promotional offers (a certain limit per month) Buy targeted advertisement slots and more vouchers to promote their products to consumers B - End consumers - motivated by making a true impact, and enhanced by gamification and rewards Consumers can earn points by Setting weekly goals (e.g. use X eco-packing product, do a small quiz to learn more about eco-packing on Gumpare, share useful tips with the commu"
      }
    ]
  },
  {
    "file_path": "./devposts/hackthefeed.html",
    "project_id": "hackthefeed",
    "title": "HackTheFeed",
    "tagline": "HackTheFeed is a cybersecurity-related RSS aggregator and live news feed. It supports encrypted notes (using a proprietary algorithm), logging in with Microsoft, and a massive repository of content.",
    "hackathon": "",
    "built_with": [
      "cloudflare",
      "digitalocean",
      "encryption",
      "fastify",
      "flowbite",
      "html",
      "microsoftazureactivedirectory",
      "mocha",
      "node.js",
      "postgresql",
      "prisma",
      "sha-512",
      "svelte",
      "sveltekit",
      "swagger",
      "tailwindcss",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Developer Experience Project Winner Best Cybersecurity Project Created by I worked on the back-end",
      "Ciena Challenge Winner Best Developer Experience Project Winner Best Cybersecurity Project Created",
      "Hack the HillWinnerCiena ChallengeWinnerBest Developer Experience ProjectWinnerBest Cybersecurity Project",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/406/986/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "List of all feeds Register page Log in page FAQ page (logged out) Creating a new encrypted note Swagger docs (API) Encrypted note content Viewing empty notes Personalized feed Home page (logged out) Decrypted note content List of all feeds Register page Log in page FAQ page (logged out) Creating a new encrypted note Swagger docs (API) Encrypted note content Viewing empty notes Personalized feed Home page (logged out) Decrypted note content List of all feeds 1 2 3 4 5 6 7 8 9 10 11 12 Inspiration With billions of dollars lost to cybercrime every year, HackTheFeed was inspired by the overwhelming need for technological literacy in the modern world. By keeping up-to-date on the latest technological trends, consumers and companies alike can better equip themselves to handle attacks on all surface vectors. Our team was inspired to create HackTheFeed by the growing need for cybersecurity awareness and education in today's world. With the increasing number of cyber attacks and data breaches, it is crucial for individuals and organizations to stay informed and up-to-date on the latest cybersecurity news and best practices. We believe that information is power, and through HackTheFeed, we aim to provide a platform for users to easily access and subscribe to relevant cybersecurity news and updates. By using Microsoft Ecosystem of platforms, we have built a personalized platform that enables any non-Microsoft application to publish tasks, information, and communications to an individual, ensuring a simple view of all relevant information. Moreover, we understand that cybersecurity is not a popular field compared to other similar fields, and people do not speak enough about it. Therefore, our project will help spread information about the latest cybersecurity news and potentially attract new people to the cybersecurity world. We believe that with the power of technology and the collective effort of individuals and organizations, we can create a safer digital world for everyone."
      }
    ]
  },
  {
    "file_path": "./devposts/greenknowledge.html",
    "project_id": "greenknowledge",
    "title": "GreenKnowledge",
    "tagline": "A web application that allows users to understand where they stand in terms of environmental impact and determine next steps they can take in order to maximize sustainability.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "flask",
      "html-css-js",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/491/110/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Homepage Homepage Homepage 1 2 Inspiration Carbon footprint calculators are amazing indicators as to where you stand in terms of emissions, and there are other resources to tackle other aspects of sustainability. However, they are quite limited, as they don’t usually provide next steps to take. We wanted to create an all-in-one “kit” that gives you an arbitrary score based on every aspect of sustainability and environmental impact, without you having to manually go to a multitude of different sites to get an idea of where you stand. What it does GreenKnowledge is an application that calculates a user’s environmental impact based on a survey. It outputs this information through GreenScore, as well as links for users to further improve their environmental impact. How we built it We used Replit’s website hosting features along with Flask and Python to create this. The reason why we used Python in addition to writing HTML, CSS, and JS is because Python enabled us to view the status of loading various resources along with timestamps directly in the console, so we could see, for example, whether an image was loading or not. For the CSS we used Bootstrap, which is a library that gives access to a whole bunch of styles. We used JS to calculate the score and display it to the users, along with links. Challenges we ran into We initially tried to get the HTML form data in Python using Flask, but that was changing the way other elements in the code worked - so we stuck to Python just for the hosting and switched to JS to get the form data. We wanted to style the HTML page that was created by the JS once the form was submitted using Bootstrap, which wasn’t working properly with the separate JS page. Instead, we embedded the JS within the HTML using the script tags and did the same for CSS to maintain consistency. Accomplishments that we're proud of One of the biggest accomplishments we had in this project was getting the HTML, CSS and JS to integrate with Python and Flask succes"
      }
    ]
  },
  {
    "file_path": "./devposts/gardenizer.html",
    "project_id": "gardenizer",
    "title": "Gardenize",
    "tagline": "Grow together for a greener tomorrow",
    "hackathon": "",
    "built_with": [
      "autocode",
      "cohere",
      "express.js",
      "figma",
      "firebase",
      "material-ui",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Best Use of Cohere API - 1st Place Created by I built the Express",
      "Second Place Winner Best Use of Cohere API - 1st Place Created by I built the Express",
      "ElleHacks 2023WinnerSecond PlaceWinnerBest Use of Cohere API - 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/582/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 💡 Inspiration We live in an age where city populations are rapidly growing outwards, encroaching on forests and parks that have been inhabited by thousands of native species for millennia. This urban sprawl is incredibly harmful to the environment, displacing animals and killing plants. Native species have never been more at risk of extinction, which is why green areas full of possible life-giving resources are more essential now than ever. Transforming an old lot into a flourishing garden will not only give back to nature but will provide the community with a united project that will foster and strengthen community bonds. By tackling the “Earth” challenge, we wanted to help promote biodiversity in our urban areas in a time of increasing urbanization. 🌱 What it does Gardenize is designed to motivate individuals into making a difference in their community. It’s very simple to set up and simplifies the process of starting a community garden by picking out personalized plant recommendations based on species native to your location. It will track the plants for you, telling you when to water and harvest each plant so that your plants can be well taken care of. It will also tell you important details about each specific plant, giving instructions on how to plant them properly. Lastly, we create a sense of communal responsibility for the garden by giving members of the community a social platform to share their garden updates, ideas, and experiences. These posts can be enjoyed by everybody in the community. 🧰 How we built it React, Tailwind CSS, and Material UI: The front end of our web app was created using React and components from Tailwind CSS and Material UI. Express.js: The back end ran on an Express.js server with several routes and endpoints to integrate with the front end. Cohere: Generative and classification models were used to create a post title generator and a toxicity detector for the social community aspect of our app. Autoc"
      }
    ]
  },
  {
    "file_path": "./devposts/grocerease-9rjd7n.html",
    "project_id": "grocerease-9rjd7n",
    "title": "GrocerEase",
    "tagline": "Save time, groceries, and money with every receipt using GrocerEase",
    "hackathon": "",
    "built_with": [
      "flask",
      "mongodb",
      "nextjs",
      "ocr",
      "python",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/237/398/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 🧠 Inspiration Each year, over 120 trillion pounds of food are wasted globally, and the average U.S. household throws away 140 pounds of food per year , translating to nearly $1,500 in lost groceries . For college students on tight budgets and busy families trying to stay organized, this waste adds up fast. We wanted to create a tool that helps people keep track of their groceries, reduce food waste, and save money—all by simply uploading a receipt. That’s where GrocerEase comes in. 🥕 What it does GrocerEase turns grocery receipts into actionable insights. Upload a picture of your receipt, and the app transcribes the items, calculates their expiration dates, and provides a visual timeline of when your food is likely to expire. You’ll know which items need to be used soon, helping you reduce waste and save money effortlessly. 🛠 How we built it Frontend: Built with Next.js for a fast and user-friendly interface. Receipt Processing: Initially tried using Tesseract for text recognition, but inconsistent fonts and faded receipts made it unreliable. We switched to Open AI , which provided accurate transcription of receipt data. Backend: Created with Python Flask , which handles expiration date calculations and shelf-life predictions. Also used MongoDB for receipt and item inventory storage. Data Source: Used food shelf-life information from the Farmers Market Association (FMA) to provide accurate estimates for fresh produce. 😅 Challenges we ran into Receipt readability: Tesseract struggled with receipts that had small, faded, or skinny fonts. Switching to ChatGPT required retraining for accuracy. Dynamic timelines: Building a shelf-life tracking system that adapts to various food types while remaining simple for users. Seamless integration: Ensuring smooth communication between the frontend and backend without creating delays in processing. 🏆 Accomplishments that we're proud of Successfully implemented a high-accuracy receipt transcription system. Created an intu"
      }
    ]
  },
  {
    "file_path": "./devposts/greenfridge.html",
    "project_id": "greenfridge",
    "title": "GreenFridge",
    "tagline": "Food sustainability right through your fridge❄️☘️",
    "hackathon": "",
    "built_with": [
      "auto-ml",
      "cloud-storage",
      "computer-vision",
      "css",
      "figma",
      "fire-store",
      "flask",
      "google-cloud",
      "html",
      "humidity-sensor",
      "javascript",
      "postman",
      "python",
      "raspberry-pi-camera-local-object-detection",
      "twilio",
      "vision-api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hardware Hack Thank you Penn Detkin Lab for lending us Raspberry Pi camera and other tools late at",
      "Citadel & Penn Detkin Lab) Best Hardware Hack Thank you Penn Detkin Lab for lending us Raspberry Pi",
      "Best Use of Google Cloud - MLH Created by I worked on developing a smart computer vision algorithm",
      "PennApps XXIII: SustainabilityWinnerBest Use of Google Cloud - MLH",
      "👨🏻‍🤝‍👨🏽 (PennApps Track) Sustainability Prize",
      "🛠 (Sponsored by Citadel & Penn Detkin Lab) Best Hardware Hack",
      "☁️ Best Use of Google Cloud - MLH",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/210/432/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GreenFridge GIF GreenFridge 1 2 3 4 5 6 7 💡Inspiration Every year, around 40 million tons of food is wasted in the United States. That is estimated to be around 35 percent, of the entire US food supply. When we waste food, we also waste all the energy and water it takes to grow, harvest, transport, and package it. And if food goes to the landfill and rots, it produces methane—a greenhouse gas that is 26x more potent than carbon dioxide.\nDrilling down further into the problem of food waste, research shows that 43% of all waste in United States actually comes from homes, which is more than food services and grocery stores combined.\nReducing food waste is one of the easiest and most, powerful actions anyone can take to help sustainability, so this weekend, our team chose to build a IoT and mobile solution that tackles food waste at homes. 🤔 What it does GreenFridge is a end-to-end IoT, data and mobile application solution that tracks what users have in their fridge, remind users of food that is about to go bad, and educate users on ways they can do their part in minimizing their carbon footprint. Its key features include: Mobile feature 1: Displays live view of food items currently in the fridge and their shelf life Mobile feature 2: Displays fridge power usage, temperature and humidity data, CO2 emissions per week, correlation between number of times fridge door was open and power. Mobile feature 3: Recommends sustainable alternatives and way to offset carbon dioxide emissions of food items currently in fridge Integration 1: Twilio messages with reminders of food that is going to go bad today and recommends ways to preserve them 🦾 How we built it IoT: Raspberry Pi Camera Local Object Detection, Humidity Sensor, Temperature Sensor Backend: Postman, Google Cloud Platform, Flask Web Scraping: Python Google Cloud Services: AutoML, Vision, Vertex AI, Compute Engine, Maps Database: Cockcroach DB, Cloud Storage, FireStore Twilio: Auto SMS Frontend: React, JS, HTML, CSS, "
      }
    ]
  },
  {
    "file_path": "./devposts/hack-n-stack.html",
    "project_id": "hack-n-stack",
    "title": "AntiTetris",
    "tagline": "AntiTetris is a cybersecurity game that leverages the balance between competitivity and education. Users can leverage cyberattacks to butcher opponents' progress and defend against cyber attacks.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "nextjs",
      "node.js",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place Overall Created by Throughout the project, I was mainly responsible for implementing the",
      "NewHacks 2024Winner1st Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/101/585/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 ANTITETRIS - Unleashing Competitive Cybersecurity Skills ANTITETRIS is an interactive cybersecurity game that brings the thrill of competition to learning essential cybersecurity attacks and strategies. In this game, players race to win the Tetris game while using cyberattacks to sabotage opponents and prevent them from winning the game. ANTITETRIS bridges the gap between gamification and education for players of all skill levels by simulating cybersecurity techniques in a controlled gaming environment. Inspiration Cybersecurity is a critical skill in today's digital world, but learning it often involves vast, theoretical material. We wanted to change this. We thought about an idea where players could learn cybersecurity principles in a way that's as exhilarating as a competitive game. ANTITETRIS was born from this - a competitive game where players could not only learn but also experience various cybersecurity attack simulations. What it does ANTITETRIS  is a two-player, cybersecurity game where players aim to stay on the game as long as possible like Tetris while fending off and launching cyberattacks. The game balances offensive and defensive tactics in an intuitive, immersive environment. Players can: Launch Cyberattacks: Perform basic simulated attacks, like DDoS attacks, phishing attempts, to disrupt opponents’ progress. Defend Against Attacks: Implement security measures by initiating attacks at the appropriate time to safeguard their resources and avoid downtime. Build & Stack Skill: As they progress, players learn how to navigate through the attacks without disrupting their game. How we built it Tech Stack: Frontend: Next.js create a smooth, intuitive interface, keeping players engaged and focused on strategy. Backend: Node.js and WebSockets power real-time interactions, creating a seamless multiplayer experience. Game Logic & Data: For managing game states, player interactions, and cyberattack simulations, we used Javascript as the backend. Cor"
      }
    ]
  },
  {
    "file_path": "./devposts/hack-md.html",
    "project_id": "hack-md",
    "title": "Spice MD",
    "tagline": "Helping you select the perfect spice combination for your health and culinary goals.",
    "hackathon": "",
    "built_with": [
      "mern",
      "powerpoint"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/313/562/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration “Spice MD was inspired by my Chinese American friend whose family always knows the right food for any situation or ailment. Although compiling 1000+ years of herbal medicine in one website is a daunting task, much less in a single weekend; I was able to narrow our scope to 100 of the world's most popular spices, their flavor profiles, and medical values based on modern studies.” - Caleb C. Hairston When you think of the most popular food, rarely are they ever sourced from the wealthiest social class; peasants had to use what they had available, and often, this led to innovation from those looking to change their meager circumstances. Ultimately, our ancestors became experts at utilizing easily cultivated plants outside their community for their medicinal, flavor, and ornamental value. Even a few generations ago, Americans used folk remedies that were shared in the form of locally sourced food recipes for ages. You might ask what happened to this art honed over thousands of years of human civilization. The answer is simply traditional soft skills across the board have been slowly phased out by our fast-paced modern life, affording little time to pursue skills deemed less essential. We believe in these remedies' extraordinary results and have anecdotally seen these herbs in action when used in our respective families' cultural dishes that are mainstays as comfort food post relocation; these spices are only recently being acknowledged by leading physicians and are seeing promising results in pre-clinical trials. As the producers of SpiceMD, we do not wish to discourage modern medicine but instead inspire consideration and accessibility for complementary medicine. What it does Recommended complementary herbal medicine on a simple-to-use web page. “Let thy food be thy medicine be thy food” - Hippocrates (400 BC) How we built it We read two books on Friday afternoon and then developed a MERN application. We chose a MERN Stack because it complimented ou"
      }
    ]
  },
  {
    "file_path": "./devposts/gradeai-r8fnpe.html",
    "project_id": "gradeai-r8fnpe",
    "title": "GradeAI",
    "tagline": "Making essay grading easier through AI, saving teachers time!",
    "hackathon": "",
    "built_with": [
      "css",
      "flash",
      "gpt-3.5",
      "heroku",
      "html",
      "javascript",
      "next.js",
      "ocr",
      "python",
      "react.js",
      "rest",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/526/939/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Application Page Landing Page Application Page Landing Page Application Page 1 2 3 Slideshow Link here: https://www.beautiful.ai/player/-N_1SnNYS3rJPTXJv7Dy/Untitled-4 Introduction Teachers bear the responsibility of guiding and inspiring young minds, navigating the challenges of limited resources, diverse student needs, and the relentless pursuit of fostering knowledge and growth. Yet out of all, teachers have to spend a lot of time grading , which can cause a serious toll on their sanity. So, we at GradeAI created an application that directly addresses this issue: GradeAI not only grades essays with great accuracy but also grades efficiently . Instead of taking 2+ hours grading simultaneously, teachers can effortlessly grade their student's papers and focus more on things with more meaning! What does GradeAI do? GradeAI can do a plethora of things. Let's take a look at some of the important ones: GradeAI can quickly assign a grade to an essay according to the course's expectations, rubric, and assignment prompt. The consistency of the grades allows teacher to completely eliminate bias within their grading. GradeAI can give feedback on each paper to explain why each essay has the grade it was assigned. This not only allows the teacher to understand the limitations of the students themselves but can give them insights on how to teach their students better. GradeAI can accept many formats of essays, including text, pdfs & other readable files, and also images. With the power of text recognition and OCR models, GradeAI has flexibility when it comes to accepting essay formats. How did we build GradeAI? We used Python and Flask primarily for the back-end part of GradeAI, and with the combination of text-recognition models and GPTs (generative pre-trained transformers), we could connect the front-end with inputs (files, text, etc.) and outputs (grades, feedback, etc.) in an efficient manner. The front-end was made with HTML/CSS, JS, TS, React.js, & Next.js. This, of cour"
      }
    ]
  },
  {
    "file_path": "./devposts/healthhack-ii-project.html",
    "project_id": "healthhack-ii-project",
    "title": "HealthHack-II-project",
    "tagline": "A great website that helps you customize your diet based on facts about your health and what your goal is",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "HealthHack-II-project A cool project that makes it possible to be healthier. An estimated 45 million Americans go on a diet each year, and Americans spend $33 billion each year on weight loss products and dieting guides\n48 million people have problems with certain foods\n35 million people in America alone have diabetes Our product Doesn’t cost a single penny!\nLets them create an account and enter a bit of information about themselves to get great meal plans and food that helps them reach their goal\nPerfect for people with food-related allergies and diabetes or for people who just want to go on a diet or lose weight How does it work? Uses online nutrition API’s to get information about food and allows the users to enter information and select various food groups to find food that suits them\nLot of backend code to store all data in a server for long-term retention (Secure)\nAllows them to find information about all the food\nAllows them to enter what they are eating\nDisplays their progress as well as consumption per food group in a separate page\nWritten in HTML, JS, CSS, and python Built With css html javascript python Try it out GitHub Repo Submitted to HealthHack2 Created by Surya Jasper Shlok Shah Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/health-saver.html",
    "project_id": "health-saver",
    "title": "Health Saver",
    "tagline": "One Stop Solution for storing all your health receipts",
    "hackathon": "",
    "built_with": [
      "css3",
      "firebase",
      "hedera",
      "html5",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/204/305/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Dashboard Logo Home Page Dashboard Logo Home Page Dashboard 1 2 3 4 ☁️ Inspiration During the pandemic, we all learned how important is to track of all your medical receipts and prescriptions. Moreover, this information might include private information as well which may prevent from people uploading/storing it on random platforms. Introducing HEALTH SAVER , a One Stop Soluton for storing all your medical documents/receipts with the help of HEDERA 🚧 What It Does It authenticates user into the app's dashboard which allows users to upload their medical receipts. The app stores it in the Hedera blockchain, so it can't be tampered with at any time, and so the bills and other private information cannot be hacked or leaked. 👨🏾‍💻 How We Built It We built the front end using HTML, CSS, React.js and Firebase and Milligram CSS to build its super easy-to-use UI. We also added a tips section that provides users with different tips that will make them aware of different health tips. We ran into many challenges when dealing with Hedera. After getting our Operator ID and Operator Key , we implemented the API. With Hedera's blazing fast API, the bills are instantly uploaded and pop up immediately. The user interface is very friendly and is not confusing at all. 👷 Challenges We Ran Into Because it was only our 2nd time using it, we had some difficulties, but in the end, we figured it out. Using the FileCreateTransaction and FileContentsQuery functions on the database, we were able to securely store files on Hedera, retaining all of our user's privacy. 🎉 Accomplishments That We're Proud Of We actually finish the entire application..yay! We are proud to have implemented to what we thought at the beginning of the hackathon 📙 What We Learned We learnt about HEDERA in a deep way through this hackathon and we are proud to have implemented its features into our app. We were based in different time zones which also meant we had to manage time efficiently throughout the hackathon. GitHub pla"
      }
    ]
  },
  {
    "file_path": "./devposts/hackwrapr.html",
    "project_id": "hackwrapr",
    "title": "HackWrapr",
    "tagline": "At HackWrapr, we provide useful information about hackathons that can’t be found anywhere else. You can think of us as a gamified spotify wrapped for hackathons! \n#hackathonsEnumerated",
    "hackathon": "",
    "built_with": [
      "figma",
      "javascript",
      "next",
      "procreate",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Rowdyhacks 2023Winner[MLH] Most Creative Use of GitHub",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/431/695/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration If you’re reading this, then like us, you’re probably passionate about attending and/or organizing hackathons. You’ve also probably found yourself looking up information regarding a hackathon either in preparation for or in review of the event. Personally, we found that the process of finding the aforementioned info can be dull, tedious, and very repetitive, so we decided to do something about it! We created a faster, engaging, and more precise tool for getting info on hackathons: HackWrapr! We know that every team will say that their project is ground-breaking and maybe they all are, but we urge you to just give ours a try. If you do, we believe that you will truly wonder why you ever searched up hackathons any other way. What it does All you have to do is paste the devpost link for the hackathon of interest, and at the push of a button, HackWrapr will scrape the internet for information on the event and provide it to you in a gamified manner. You are given a chance to guess the values of the info, and afterwards its true value will be revealed alongside whether you guessed correctly. How we built it Brainstorming: We discussed what we’d like to implement, keeping in mind the time limitation. We sketched up a draft for what the website could look like using figma. We distributed the programming amongst the three of us appropriately. Technical: Using React.js, Next.js, and Tailwind, we created the GUI/frontend of our website Our backend, created with JavaScript, takes in the devpost link submitted by our user, and uses algorithms we wrote ourselves, parses through all of the information in all the devpost submissions at the hackathon Petty note: there is no devpost api, we had to scrape all the information ourselves. It sucked, but we got through it and wanted to mention that After parsing all the info from the devpost submissions, we utilized the github api to parse through all the information from the github repositories submitted to the hack"
      }
    ]
  },
  {
    "file_path": "./devposts/healthlink-fntov4.html",
    "project_id": "healthlink-fntov4",
    "title": "HealthLink",
    "tagline": "Meet HealthLink, your AI health companion. Share meals, get advice. Achieve wellness with ease.",
    "hackathon": "",
    "built_with": [
      "applewatch",
      "dart",
      "firebase",
      "flutter",
      "javascript",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/646/189/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "This is where a user will create custom foods to be used in the future. This is the home page, where a user will find the food eaten in the last day, as well as their total calorie and macronutrient intake. This is the chat page, where a user can ask for recommendations and add meals to their food log. This is the today's meals page, where a user will find the foods in their meal plan, This is the settings screen, where a user can update their fitness info and add custom foods. This is where a user will update their crucial health information, such as height, weight, and any allergens they may have. This is where a user will create custom foods to be used in the future. This is the home page, where a user will find the food eaten in the last day, as well as their total calorie and macronutrient intake. This is the chat page, where a user can ask for recommendations and add meals to their food log. This is the today's meals page, where a user will find the foods in their meal plan, This is the settings screen, where a user can update their fitness info and add custom foods. This is where a user will update their crucial health information, such as height, weight, and any allergens they may have. This is where a user will create custom foods to be used in the future. 1 2 3 4 5 6 Inspiration We are college students looking to transform the way people interact with AI related to their health. What it does Currently, HealthLink has integrated systems where a user can upload their food info like they are texting their best friend - effortless and fun! How we built it We used Flutter to build our front end, and a server to host our cloud functions to allow the app to connect to openAI. Challenges we ran into The biggest challenge with creating our app was creating proper endpoints. Accomplishments that we're proud of We faced a lot of hurdles, but we managed to get a working MVP, and are very proud of our project. What we learned This is one of our teammate's first hackath"
      }
    ]
  },
  {
    "file_path": "./devposts/guardian-angel-op49t2.html",
    "project_id": "guardian-angel-op49t2",
    "title": "Guardian Angel",
    "tagline": "Guardian Angel, always by your side.",
    "hackathon": "",
    "built_with": [
      "deepgram",
      "expo.io",
      "fastapi",
      "google-gemini",
      "node.js",
      "python",
      "react-native",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Cal Hacks 11.0WinnerGoogle: Most impactful app",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/088/389/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "MVP Logo Introduction Stack UI design MVP Logo Introduction Stack UI design MVP 1 2 3 4 5 Inspiration Guardian Angel was born from the need for reliable emergency assistance in an unpredictable world. Our experiences with the elderly, such as our grandparents, who may fall when we’re not around, and the challenges we may face in vulnerable situations motivated us to create a tool that automatically reaches out for help when it’s needed most. We aimed to empower individuals to feel safe and secure, knowing that assistance is just a call away, even in their most vulnerable moments. What it does Core to Guardian Angel, our life-saving Emergency Reporter AI speech app, is an LLM and text-to-speech pipeline that provides real-time, situation-critical responses to 911 dispatchers. The app automatically detects distress signals—such as falls or other emergencies—and contacts dispatch services on behalf of the user, relaying essential information like patient biometric data, medical history, current state, and location. By integrating these features, Guardian Angel enhances efficiency and improves success in time-sensitive situations where rapid, accurate responses are crucial. How we built it We developed Guardian Angel using React Native with Expo, leveraging Python and TypeScript for enhanced code quality. The backend is powered by FastAPI, allowing for efficient data handling. We integrated AI technologies, including Google Gemini for voice transcription and Deepgram for audio processing, which enhances our app’s ability to communicate effectively with dispatch services. Challenges we ran into Our team faced several challenges during development, including difficulties with database integration and frontend design. Many team members were new to React Native, leading to styling and compatibility issues. Additionally, figuring out how to implement functions in the API for text-to-speech and speech-to-text during phone calls required significant troubleshooting. Accomplish"
      }
    ]
  },
  {
    "file_path": "./devposts/hackrice2016.html",
    "project_id": "hackrice2016",
    "title": "Watson Advertising",
    "tagline": "These billboards can be used in order to ensure that people know what they want and get what they need.",
    "hackathon": "",
    "built_with": [
      "azure",
      "bluemix",
      "git",
      "github",
      "go",
      "heroku",
      "html5",
      "ibm-watson",
      "ionic",
      "javascript",
      "json",
      "nest",
      "node.js",
      "sublime-text",
      "vision",
      "visual-studio",
      "wifi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/428/142/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In the past few years, the attention span of the human being has dropped from 12 seconds to 8 seconds. When viewed from the perspective of the advertising industry, this change in attention span amounts to a waste of millions of dollars of lost revenue. Advertising plays a fundamental role in the dissemination of information for nearly every corporation and the overloading of advertising has served to the determent of all companies involved. \nIn order to match with the present trends of the people,today's information spreading methods need to become more individualistic and less in the form of generic background noise the average consumer. In order to do so, we thought about improving something that everyone sees everyday, the digital billboard. Through the utility of the Watson API which is basically something which detects the type of things you're interested in based on you're appearance, age and gender in order to spread information that is relevant to individuals as well as supplementation by Google's Vision API, our billboards are able to further tailor and select advertising which is more impacful in their daily lives and thus help people gain knowledge about products they are more likely interested in. What is Watson Advertisements Watson Advertisement is an enhancement on the existing billboard by presenting relevant advertisements to people that are eyecatching providing a greater hit on the amount of the advertising which actually leads to an actionable result. The advertisement technique involved is using a camera which takes pictures of the area in front of the billboard at set intervals of time and uses the Watson API in order to categorize certain aspects of the visible and then change the billboard information into a relevant topic for a particular demographic. \nWatson advertisement only displays information that is relevant to the people that are standing in front of it and does not displays anything that is not relevant to the set of pe"
      }
    ]
  },
  {
    "file_path": "./devposts/gpteddy.html",
    "project_id": "gpteddy",
    "title": "GPTeddy",
    "tagline": "Talking Teddy Bear that teaches🐻🧑🏻‍🎓",
    "hackathon": "",
    "built_with": [
      "azure",
      "cohere",
      "django",
      "python",
      "raspberry-pi",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Home Room Track Prize🏫",
      "Best Use of Microsoft Cloud for Your Community👩🏻‍💻"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/461/380/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration 💡 The introduction of Large Language Models (LLMs) has the potential to bring about tremendous change in the work lives of future knowledge workers around the world. As current students ourselves, we reflect on our formative years in school and wonder how our educational experience might have been different if we had access to a 100-trillion parameter machine learning model on command. Would it have impacted our understanding of various topics? We are concerned about children born today and in the future, who will grow up in a world filled with intelligent artificial agents. The advent of LLMs promises to revolutionize education by offering personalized tutoring experiences for children. By effectively understanding and responding to each child's unique learning needs, LLMs can foster a deeper exploration of curiosity and pave the way for mastery learning. To comprehend the impact of LLMs on education, it's essential to analyze various aspects: Individualized Learning Paths : Customization allows children to engage with topics they're passionate about and ensures they receive the right level of challenge, preventing boredom or frustration. Instant Feedback : LLMs can provide immediate feedback on a child's performance, helping them identify areas for improvement and consolidate their understanding. This timely intervention facilitates a more efficient learning process and encourages children to learn from their mistakes. Availability and Accessibility : LLMs enable learning experiences that transcend traditional time and space constraints. Children can access personalized tutoring anytime, anywhere, and at their own pace, allowing them to learn more effectively and comfortably. However, as with all good things, we understand the need for balance. We believe parents should have the final say in their children's interactions with LLMs. Parents must have control over the outputs of LLMs to monitor their child's mental headspace, the influences they "
      }
    ]
  },
  {
    "file_path": "./devposts/hacker-s-hall-of-fame.html",
    "project_id": "hacker-s-hall-of-fame",
    "title": "Hacker's Hall of Fame",
    "tagline": "A better way to keep track of a hacker's journey. The app's usable by hackathon organizers to give hackers their badges digitally, and for hackers to keep track of these badges in a one-stop-gallery.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "flask",
      "python",
      "swift",
      "swiftui",
      "twilio",
      "typedream"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of DeSo Created by Brayton Lordianto",
      "category",
      "Hacking Birthday BashWinnerBest Use of DeSo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/055/557/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "System Flow System Flow System Flow 1 2 💡 Inspiration💡 As a hacker, one thing I wished I had was the ability to view all the stickers and prizes I got in a digital environment . Devpost makes it difficult. I intended to make a better solution. What I intended to do was to make a system to securely store hackathon stickers or badges or collectible certificates as an easy-one-stop-shop for recruiters to view and for me to more efficaciously track my hackathon journey. ⚙️ What it does ⚙️ Organizers: after being verified as a hackathon organizer, the organizer can send badges to participants by sending images and specifying the prize category. They can allow the app to automatically find users to give it to (which is immediately accessible to them) or choose usernames manually. Participants: can view their hackathon journey, look at other people’s journeys, and print their badges like certificates. Website: The website serves as a quick-look option at the badges, intended for participants to add as URLs in their LinkedIn profiles or resumes to showcase their hall of fame. 🏗️ How I built it 🏗️ the app was brought together with Flask; the Whatsapp and iOS counterparts both use Flask to interact with the relational CockroachDB database (\"users\", \"badge information\", and each \"badge\" given to each \"user\"). 🟣 Twilio 🟣 I used ngrok to connect Twilio to the flask app. I used a flask POST request that the Twilio WhatsApp bot calls whenever the user sends a text and is processed by flask. I used Twilio’s Messaging Responses to send custom messages depending on what the user is currently doing. The images sent to the WhatsApp bot are stored on Twilio, and I use them in the CockroachDB database. 🔴 DeSo 🔴 I added some DeSo code to create the images as NFTs on the DeSo blockchain, for more secure storage of the images. It’s also much more swag. ⚫ GitHub Usage ⚫ The app consists of iOS, WhatsApp, and database components. I used three different branches for each component, and it help"
      }
    ]
  },
  {
    "file_path": "./devposts/guppy-4pog76.html",
    "project_id": "guppy-4pog76",
    "title": "Guppy",
    "tagline": "impromptu speech mentor that improves structure, confidence, and communication through use of Ai",
    "hackathon": "",
    "built_with": [
      "conda",
      "openai",
      "python",
      "pywebio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/930/686/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 Inspiration Social anxiety for many is an issue that plagues their day to day lives. Due to the lingering effects of COVID-19's mass social isolation, people everywhere find it hard to reconnect. Impromptu is a method of speech that challenges one to form meaningful presentations on the spot, often a major exercise in mock trial preparations. This is where we came up with Guppy , the virtual speech companion . Guppy trains you to become a master at the art of communication. The act of impromptu speech presents itself in job interviews, wedding toast, keynote events, or just plain talking with your friends! We wanted to find a project that any one of all ages can benefit from, including use in education, corporate, social, and personal environments. We want Guppy to help reunite the world! What it does Guppy uses AI to create randomized prompts for the user to read and respond to, providing a new medium for practicing speech and communication. How we built it We used conda, python, and most importantly, openAi. Challenges we ran into We initially had a larger vision but overestimated the amount of time we had to fully execute our plan. As it was half of our first hackathons, the plethora of new knowledge being thrown at us was a bit overwhelming. Accomplishments that we're proud of We all met for the first time today and are proud of effectively communicating to solidify a product design that appeals to all of us. What we learned As first time hackers, we learned new technical skills such as developing a front end, using canva, and implementations of new AI technology. What's next for Guppy In future iteration of Guppy we defiantly want to integrate Hume Ai's API into our project to better gauge confidence, tone, and expression. We also want to integrate motion detection and video to track eye movement, posture and mannerisms. Another key thing is making Guppy more tailored towards specific audiences such as younger children, or hardened pr"
      }
    ]
  },
  {
    "file_path": "./devposts/greenq.html",
    "project_id": "greenq",
    "title": "GreenQ",
    "tagline": "Profile and track the carbon, energy, and water footprint of every AI prompt with our Browser extension championing smarter, greener usage for a more sustainable AI future.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "api",
      "bedrock",
      "chart.js",
      "chrome",
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "If AWS Bedrock is configured, Claude 3.7 Sonnet will optimize your prompt and recommend the best model",
      "Implements a background service worker for tracking"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/641/801/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "dashboard Dashboard and extension dashboard Dashboard and extension dashboard 1 2 AI Energy Usage Tracker A Chrome extension that tracks and optimizes energy usage of AI conversations, providing insights and recommendations to reduce the environmental impact of AI interactions. Features Prompt Input & Optimization : Enter your AI prompts and get optimization suggestions to reduce energy consumption On-Demand Model Recommendations : The extension analyzes your prompt when you click \"Optimize\" and suggests the most energy-efficient AI model for your specific task Energy Usage Metrics : Track energy consumption, water usage, cost, and carbon footprint Integrated Energy-Saving Tips : Receive a new energy-saving tip each time you optimize your prompt Streamlined Workflow : Single-button interface that optimizes prompts, recommends models, and records conversations AWS Bedrock Integration : Connect to AWS Bedrock to use Claude 3.7 Sonnet for real AI-powered prompt optimization and model recommendations Installation Development Mode Clone or download this repository Open Chrome and navigate to chrome://extensions/ Enable \"Developer mode\" in the top-right corner Click \"Load unpacked\" and select the ai-energy-tracker folder The extension should now appear in your Chrome toolbar From Chrome Web Store (Future) Once published: Visit the Chrome Web Store page for AI Energy Usage Tracker Click \"Add to Chrome\" Confirm the installation when prompted How to Use Configure AWS Bedrock (Optional) : Click the extension's options page (right-click the extension icon and select \"Options\") Enter your AWS Access Key ID, Secret Access Key, and select your AWS Region The extension will use Claude 3.7 Sonnet for prompt optimization and model recommendations If not configured, the extension will fall back to using dummy data Enter a Prompt : Click the extension icon in your Chrome toolbar Type your AI prompt in the text area See SAMPLE_PROMPTS.md for examples of prompts that work well with diff"
      }
    ]
  },
  {
    "file_path": "./devposts/headshotx.html",
    "project_id": "headshotx",
    "title": "HeadshotX",
    "tagline": "HeadshotX is a real-time headgear impact tracking system designed for boxing and contact sports. This data is streamed to a mobile app providing athletes and coaches with insights on impact intensity.",
    "hackathon": "",
    "built_with": [
      "dart",
      "flutter",
      "python",
      "raspberry-pi",
      "visual-studio",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/089/248/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Figma - Screen that allows user to pair headgear Figma - Main Home screen Figma - Shows the High, Medium, and Low impact. Figma - Safety Warning for Impact limit Figma - A mock of of our health history stats Figma - Populate with past sessions of overall impacts Figma - Screen that allows user to pair headgear Figma - Main Home screen Figma - Shows the High, Medium, and Low impact. Figma - Safety Warning for Impact limit Figma - A mock of of our health history stats Figma - Populate with past sessions of overall impacts Figma - Screen that allows user to pair headgear 1 2 3 4 5 6 7 8 Inspiration Sac State is the first college to recognize combat sports as part of its athletics program, moving beyond just club sports. However, in the first three months of training, a significant number of boxers have experienced concussions during sparring. What it does To address this issue, we’ve developed a solution: smart headgear designed to reduce the risk of concussions. By using advanced sensors, the headgear monitors impact forces in real-time and provides critical feedback, helping to protect athletes and enhance safety during training. How we built it We developed our smart headgear using a combination of hardware and software technologies to provide real-time impact monitoring. The hardware setup includes: Raspberry Pi Pico W – serving as the core controller for collecting sensor data. MPU-6050 Sensors – three-axis accelerometers and gyroscopes are integrated into the headgear to measure both linear and angular accelerations, which are critical for assessing impact forces. Challenges we ran into One of  chllenges we ran into being able to stream data in real-time to our mobile app to provide real time feedback. We also broke ALOT of pins testing our headgear. Accomplishments that we're proud of We are very proud to have our prototype completed What we learned What's next for HeadshotX Built With dart flutter python raspberry-pi visual-studio xcode Try it out GitHub Repo G"
      }
    ]
  },
  {
    "file_path": "./devposts/hackcore.html",
    "project_id": "hackcore",
    "title": "HackCore",
    "tagline": "\"A hack for everyone\"",
    "hackathon": "",
    "built_with": [
      "macbook-pro",
      "react",
      "surface-book",
      "swift",
      "web-apis",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We wanted to provide students like us an opportunity to get involved in the computer programming scene at an early age. What it does HackCore links hackers who need experience and people who need projects done. Users can upload their Github portfolios and/or resumes to appeal to people with higher demands. Overall, HackCore helps the community by providing free computer work to leaders and free experience to students, or anyone using the app. How we built it We built this iOS app with Swift and Xcode, along with a Django back-end. Two of us worked on the back-end while two of us worked on the iOS front-end. Challenges we ran into One of the challenges we ran into was the difficulty of merging front-end and back-end. The two of us who were working on the front-end were not very experienced in calling APIs and JSON, but several YouTube videos later, we were on our way. Accomplishments that we're proud of We are proud of successfully finishing a good looking, functional app for our first ever Hackathon. As freshmen, we didn't know what to expect, but it turned out to be really fun and a great learning experience What we learned We learned how to combine an iOS front-end with a Django Back-end.\nWe learned how to code with a deadline.\nMost importantly, we learned how to solve problems as a team. What's next for HackCore We may continue testing and working on HackCore and release it to the public, hopefully helping students like us. Built With macbook-pro react surface-book swift web-apis xcode Try it out GitHub Repo Submitted to HowdyHack 2019 Created by I worked on the backend REST API with Django.This was my first time building a REST API with Django. Thomas Dexter Abhishek More Retired Hackathon Enjoyer Andrew Doyle"
      }
    ]
  },
  {
    "file_path": "./devposts/greenhouse-library-sort.html",
    "project_id": "greenhouse-library-sort",
    "title": "Greenhouse Library Sort",
    "tagline": "Given a list of books, we found ISBN numbers and reading levels using Python's Selenium library to produce a JSON file. Created an interactive React web app to search by book title and/or author.",
    "hackathon": "",
    "built_with": [
      "css3",
      "javascript",
      "json",
      "npm",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/908/949/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "By searching \"harry potter,\" only books containing that String will be displayed. All library books displayed with their information (currently with dummy images) if nothing is entered in search bar. By searching \"harry potter,\" only books containing that String will be displayed. All library books displayed with their information (currently with dummy images) if nothing is entered in search bar. By searching \"harry potter,\" only books containing that String will be displayed. 1 2 3 Inspiration We love books! Wooo What it does Users can input book titles and/or authors and our project will filter out matching searches. Each result will display the book title, author, grade level, and its corresponding ISBN number. How we built it We converted the excel sheet into a dictionary and utilized the Selenium library to search Lexile.com. For each book, we added new categories into a json file. Using react, we created a webpage containing book information. Challenges we ran into Finding a consistent ISBN number for some books was difficult because the Google API we had originally planned to use did not match the URL for the Lexile scores. It was also our first time using React, so setting up the library and figuring out its features were time-consuming tasks. Accomplishments that we're proud of We went out of our comfort zones and learned completely unfamiliar technologies and languages. What we learned We learned to create one cohesive web page by separating into distinct roles and integrating everybody's code at the end. This gave us some insight to how the design process in an industry job may work. What's next for Greenhouse Library Sort There were many features we wanted to implement, but we didn't have enough time with our lack of familiarity with the syntax and new bugs. Built With css3 javascript json npm python react Try it out GitHub Repo Submitted to HackDavis 2022 Created by Winnie Zhu Maggie Mah Gordon Feliz"
      }
    ]
  },
  {
    "file_path": "./devposts/gotta-go-841wy2.html",
    "project_id": "gotta-go-841wy2",
    "title": "Gotta Go",
    "tagline": "A way to make sure you always catch your flight / en route & in-airport ETA and navigation app",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "flutter",
      "google",
      "tsa"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/923/098/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 How were we inspired My friends and I all have our own personal experiences of arriving late at the airport. However, the incident that inspired us to make this program came when I missed my flight to Colorado for Christmas. My family completely underestimated the time required to get through traffic, much less TSA during the height of the holiday season. It forced us to cut our trip down to a measly 2 days and bummed us out significantly. This experience encouraged us to find a solution, and thus, we created Gotta Go. What it does The goal was to create an app that determines a final Estimation time of Arrival for your flight taking factors such as, proximity, traffic, and seasonal airport trends into account. With this ETA, you will know how much time to allocate for getting through the airport. How we built it The app operates primarily through the APIs provided by Google Maps, and venue maps API provided by HERE.  This allows us to efficiently determine your location, where your destination is, and the fastest route to get there. Next, in order to narrow down the calculated ETA, we operate a database with the impending flights in the case of a delay or a cancellation. Challenges we ran into The primary challenge our group faced was implementing the Google Map APIs, as it seemed many instructions to do so were out-of-date or simply flawed, however, we were able to overcome this challenge and get Google Maps Operational in Gotta Go. We also experienced struggles finding a useful source with impending flights and TSA wait times. Accomplishments that we’re proud of We are most proud of implementing Google Maps into an app of our own, something that none of us have attempted beforehand. Our group is also gratified with our successes in converting an airport code into its address and thus determining the ETA there from your current location. Going from Airport code ie. IAH, to the address, was very complicated What we learned We learned the importance of communica"
      }
    ]
  },
  {
    "file_path": "./devposts/herd-0dv8e7.html",
    "project_id": "herd-0dv8e7",
    "title": "Herd",
    "tagline": "Save money by herding together.",
    "hackathon": "",
    "built_with": [
      "css",
      "fastapi",
      "html5",
      "javascript",
      "postgresql",
      "python",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/646/180/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "herd interface (dark blue) herd banner herd design manual herd wireframes herd logo (white) herd interface (green) herd interface (orange) herd interface (light blue) herd interface (dark blue) herd banner herd design manual herd wireframes herd logo (white) herd interface (green) herd interface (orange) herd interface (light blue) herd interface (dark blue) 1 2 3 4 5 6 7 8 Inspiration Costco is a wholesale company that sells bulk items at a discounted rate. Primarily, Costco targets businesses or families that quickly go through large amounts of food. However, this is not oriented towards single individuals, who ultimately could still benefit from the lower prices of bulk buying. Herd aims to allow single individuals to partake in the cheaper prices of wholesale, without having to commit to massive amounts of food that mostly end up going to waste anyways. Herd allows users to bid on products sold in bulk, so that it can be split into different portions based on how much the users want. What it solves Students benefit hugely from the benefits of the cheaper wholesale prices . With Herd, we've created a solution that allows college students to partake in a 'Herd', where each participant is buying a part of a wholesale item. Whether that is a massive package of 20x beef patties, or something entirely different, these products can be split up into bite-sized chunks for the students, based on their needs and wishes. On average, over a single year, one would save $1,000 USD a year from buying all your grocery needs at Costco, instead of other options (source: https://www.cnet.com/home/kitchen-and-household/how-much-can-i-save-shopping-at-costco/ ). That amount of money is a lot, especially for a student. The problem that it solves is twofold. For one, in many cases when bulk purchasing happens for individuals alone, much of the excess food exceed the expiry date, or there is just too much to go around for the short-term, eventually leading to users not getting their mon"
      }
    ]
  },
  {
    "file_path": "./devposts/hackutd-project-kbhins.html",
    "project_id": "hackutd-project-kbhins",
    "title": "Echo",
    "tagline": "Echo assists neurodivergent kids that struggle with alexithymia in learning how to differentiate facials expressions and emotions fun with games, animations, and a mascot that mirrors you!",
    "hackathon": "",
    "built_with": [
      "api",
      "blender",
      "figma",
      "javascript",
      "node.js",
      "pinada",
      "python",
      "react",
      "sambanova",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Design Created by Adam Teo Nikita Kelwada Claire Wang Anish Karthik CS Junior interested in AI",
      "HackUTD 2024: Ripple EffectWinnerBest Design",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/144/833/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home_Page Figma_Layout Home_Page Figma_Layout 1 2 3 4 Inspiration The inspiration behind our hackathon project comes from the challenges faced by young children with Autism, Dyslexia, ADHD, and other neurodivergent conditions as they navigate a world that is often unaccommodating to their needs. Many of these children also experience Alexithymia—a difficulty in identifying and understanding emotions—which makes interpreting facial expressions and social cues even harder. Traditional education systems often fall short in providing the tools and structure these children need to thrive. I’ve personally seen kids singled out for not “reading the room” or understanding social dynamics—not because they lacked potential, but because they weren’t taught in ways that resonate with them. Children learn best through experiences that are fun, engaging, and interactive. This is why we created Echo. It’s a playful, gamified tool designed to help kids differentiate emotions and expressions—both on their own faces and those of others—in real time. Echo makes this process accessible, enjoyable, and impactful, giving kids the support they need to grow with confidence in a way that truly works for them. What it does Echo is a technically sophisticated app designed to assist individuals, particularly children with Autism or other neurodivergent conditions who struggle with Alexithymia, in learning emotional recognition and expression. The app integrates cutting-edge technologies such as computer vision, 3D modeling, and machine learning to create an immersive and interactive learning environment. At its core, Echo combines a polished UI inspired by HackUTD's \"Ripple Effect\" theme, with a 3D HackUTD mascot and a secondary animated mascot that serves as an interactive guide. This guide offers real-time feedback to users as they engage with the platform. The app features two primary functionalities: a webcam-based emotion training tool, where users mirror the mascot’s facial expressions u"
      }
    ]
  },
  {
    "file_path": "./devposts/hack-the-6ix-6ix-6ix.html",
    "project_id": "hack-the-6ix-6ix-6ix",
    "title": "ventr",
    "tagline": "magnify your venture. by women, for womxn.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "figma",
      "html",
      "javascript",
      "react.js",
      "scss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/633/182/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Accounting + ChatBot Our Team!! Dashboard User Profile Accounting + ChatBot Our Team!! Dashboard User Profile Accounting + ChatBot 1 2 3 4 5 Inspiration Our team is composed of four female engineers, and we acknowledge the lack of gender diversity across tech industries and the need for proactive solutions geared towards encouraging stronger female gender representation. Not only do we notice these issues in our daily lives, but we also see all these statistics that speak to the issues women in tech face such as the gender pay gap and the leadership position gap. With consideration of the digital divide limiting education to many youth around the world, we wanted to create an application that would provide resources and aid accessibility. Hoping to contribute to tackling the issue, we have created ventr, a technological solution that safeguards the FinTech industry and encourages female-identifying entrepreneurs to efficiently manage their businesses regardless of their background. What it does ventr, a cloud-based dashboard application tailored for female entrepreneurs in FinTech, adopts a centralized dashboard that combines features from invoices to networking and role model advice. Under Company Suite, board members can customize the page, sharing it with their team for easy information access and task tracking. It’s seamlessly integrated with platforms such as Slack for a streamlined workflow. The Data Storage page is a cloud document management system that enables remote access and easy file transfer. Unlimited storage space and multiple-factor authentication for sensitive corporation data are available. The finance section takes care of a business’s financial health and ensures a successful business trajectory for its clients. ventr offers an intuitive accounting system with full account payable and receivable functions. Invoices couldn’t be easier, and Ventr automatically records transactions along with payment reminders, fixed asset management, and cash-to-a"
      }
    ]
  },
  {
    "file_path": "./devposts/hands-on-uh185z.html",
    "project_id": "hands-on-uh185z",
    "title": "Hands-On",
    "tagline": "Learn American Sign Language with an iPhone",
    "hackathon": "",
    "built_with": [
      "coreml",
      "figma",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The Wolfram Award Created by Worked on Hand Pose Landmarks and User Interface Yash ㅤ Worked on both",
      "PennApps XXIVWinnerThe Wolfram Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/581/492/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration In school, we were given the offer to take a dual enrollment class called Sign Language. A whole class for the subject can be quite time consuming for most children including adults. If people are interested in learning ASL, they either watch Youtube videos which are not interactive or spend HUNDREDS of dollars in classes ( https://deafchildren.org requiring $70-100). Our product provides a cost-effective, time-efficient, and fun experience when learning the new unique language. What it does Of course you have to first learn the ASL alphabets. A, B, C, D ... Z. Each alphabet has a unique hand gesture. You also have the option to learn phrases like \"Yes\", \"No\", \"Bored\", etc. The app makes sure you have done the alphabet correctly by displaying a circular progress view on how long you have to hold the gesture. We provide many images to make the learning experience accessible. After learning all the alphabets and practicing a few words, time for GAME time :). Test your ability to show a gesture and see how long you can go until you give up. The gamified experience leads to more learning and engaging for children. How we built it The product was built using the language Swift. The hand-tracking was done using CoreML Components. We used hand landmarks and found distances between all points of the hand. Comparing the distances it SHOULD be and what it is as a specific time frame helps us figure out whether the hand pose is occurring. For the UI we planned it out using Figma and later wrote the code in Swift. We used the SwiftUI components to save time. For data storing we used UIData which syncs across devices with the same iCloud account. Challenges we ran into There are 26 alphabets. That's a lot of arrays, comparing statements, and repetitive work. Testing would sometimes become difficult because the iPhone would eventually become hot and get temperature notifications. We only had one phone to test, so phone testing was frequently used for hand "
      }
    ]
  },
  {
    "file_path": "./devposts/hearing-aid-6xrkfd.html",
    "project_id": "hearing-aid-6xrkfd",
    "title": "Tritone",
    "tagline": "Live audio trilateration and transcription for HoH individuals",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c++",
      "javascript",
      "machine-learning",
      "numpy",
      "python",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/144/862/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Live Transcription Circuit Project Architecture Landing Page Live Transcription Circuit Project Architecture 1 2 3 4 5 6 Inspiration The inspiration for Tritone came from the desire to improve accessibility for individuals with hearing impairments. We aimed to create an IoT system that not only amplifies sound but also intelligently processes and visualizes audio, enabling users to focus on specific sounds in their environment, whether nearby or at a distance. What it does Our solution is an IoT system that: Allows users to toggle between Nearby Mode (for focusing on sounds close to the user) and Long-Distance Mode (for amplifying distant sounds). Captures audio through three embedded microphones or, as a fallback, through computer microphones. Calculates the angle of an audio source relative to the microphone setup using trilateration. Streams audio data in real-time, processes it to isolate key sounds, and provides live transcription. Displays an audio visualizer interface to help users understand the direction of voices in their environment along with what is being said. How we built it 1. Embedded System: We designed a circuit with an ESP32 microcontroller, integrating three microphones with bias resistance and coupling capacitance. Then, we used a low-pass filter and ADC pins to capture sound data. Lastly, we transmitted processed audio data over WebSocket connections to the backend for further processing. 2. Backend: We developed a server capable of handling audio data streams via WebSockets. Next, we processed audio streams for triangulation, transcription, and visualization. 3. Frontend: Our focus to be ADA compliant and the user led us to build a user-friendly landing page. Here, users can toggle between Nearby and Long-Distance Modes. Furthermore, we also integrated an audio visualizer component to represent sound directionality and intensity in real-time. 4. Fallback System: We implemented computer microphones to act as a backup when embedded"
      }
    ]
  },
  {
    "file_path": "./devposts/green-future-4fq8i7.html",
    "project_id": "green-future-4fq8i7",
    "title": "Green Future",
    "tagline": "We all want to help the environment, that's a given. But many people don't know how to start out. Allow us to aid you and give you that small push you need. Let's make a green future together!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/050/563/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Green Future Goals Dashboard Green Future Logo Green Future Goal Form Green Future Goals Dashboard Green Future Logo Green Future Goal Form Green Future Goals Dashboard 1 2 3 4 Inspiration The main inspiration behind this program was that we need as many people to aid in protecting the earth as possible, but something inhibiting that is people just not knowing what exactly they want to do or how to do it. That's how I came up with the idea for a form to receive direct user input to create goals for them, so that it's tailored to them and helps them get started. What it does The user starts off my filling out the form on the right side of the screen to their exact preferences. Once the user finishes and clicks generate, the goal will appear on the left side of the screen on the dashboard. The goal will be color coded according to the size of it (Red - Large, Yellow - Medium, Green - Small) and will be counted in the counter of the respective color at the top of the dash. Once the user is finished with their goals, they can clear all of them with the \"Clear\" button and have a fresh dashboard ready for use. How I built it The majority of this program was JavaScript, which I used to create the functions which allow for all the features to work. From there, it was a mix of CSS and HTML equally, where I created the bare elements for the page and styled them according to the color pallet. I created the logo myself with the help of some pixel art designs! Challenges I ran into It was a bit difficult finding out how to get the goals to show up on the dashboard after being generated. It took a lot of meticulous trial and error mixing all the features I had at my disposal to make things work, which took up a lot of my time. Accomplishments that I am proud of Something I was super happy to accomplish was that I was able to position all the elements in their proper places without many issues with the margins and paddings of other elements colliding with each other. It made the w"
      }
    ]
  },
  {
    "file_path": "./devposts/hanq.html",
    "project_id": "hanq",
    "title": "HANQ",
    "tagline": "A new kind of voice assistant. Always listening, zero boundaries, and ready to help.",
    "hackathon": "",
    "built_with": [
      "azure",
      "beautiful-soup",
      "pyglet",
      "python",
      "requests",
      "simpleaudio",
      "xenon"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2019 Finalists Created by David Teresi Jerry Zhu CS @UWaterloo | Retired | Fanatic O",
      "Hack the North 2019WinnerHack the North 2019 Finalists",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/840/962/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "What it does The market is crowded with \"smart assistants\" like Siri, Alexa and Google Assistant that try to be helpful, or tools to help your productivity, even though they can be annoying, slow robots with a limited understanding of human vocabulary. We decided to take the opposite approach with HANQ, creating a helpful bot designed to drive you crazy. Always listening, HANQ will interject interesting facts into your daily conversations, and convert currency for you so you're always up to date on the exchange rate. He's fun for the whole family! How we built it We used the Azure Cognitive Services API to create a speech interface, with voice recognition, named entity recognition, key phrase finding and text to speech. Since there isn't really any sort of public fun fact database available on the interwebs, we decided to get our fun facts by scraping the little instant answer boxes at the top of Google search results. We also used the XE API so that HANQ can arbitrarily convert random currencies whenever he feels like it. Challenges we ran into The whole process, from speech recognition to named entity recognition to Google search scraping to text-to-speech, used up so much time that HANQ's reaction time isn't that great. We've improved it a lot by locally caching Google search results, skipping some steps of the process in certain conditions (decreasing Internet-dependent “think” time), and customizing the Azure speech-to-text API, but there's still a lot to improve. Accomplishments that we're proud of The first big milestone was figuring out how to stream audio from the Internet directly from Python, which was crucial to reducing the response time, and how to convert from text to speech and vice versa. Once we could play back the audio, we figured out how to separate important and meaningful words from the rest of the sentences, using NLP APIs from Azure Cognitive Services. Finally, we incorporated the Xenon APIs by playing back a random currency exchange when he"
      }
    ]
  },
  {
    "file_path": "./devposts/healthmedia.html",
    "project_id": "healthmedia",
    "title": "Trash-ure Map",
    "tagline": "Share your way of cleaning the planet with your friends on Trash-ure Map!",
    "hackathon": "",
    "built_with": [
      "cockroach-db",
      "flask",
      "folium",
      "google-cloud-vision",
      "leaflet.js",
      "python",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "2nd Place Bayview Hackathon 02 FiveHacks Winner 1st Place Winner Participatory Prize Data Day Grind",
      "Second Overall Winner Best use of CockroachDB Created by I finally got around to creating a choropl",
      "Data Day Grind III Winner Second Overall Winner Best use of CockroachDB Created by I finally got ar",
      "MERGE 2022Winner2nd Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/039/691/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "diagram diagram diagram 1 2 💡 Inspiration💡 We believe that trash can be transformational and that together, as a community, we can make an impact towards climate change. Big corporations like Coca-Cola and PepsiCo are one of the biggest contributors to waste all over the world and we want to encourage their involvement in the climate change crisis by promoting transparency and trust between the customer and the company. With this mission in mind, we sought to create a social media app where everyone can contribute to the fight for our planet in a positive and tangible way. References: https://www.cnbc.com/2021/05/18/20-companies-responsible-for-55percent-of-single-use-plastic-waste-study.html ⚙️ What it does ⚙️ Our app is both a social media and a data-visualization platform. Users either create posts or view posts, much like any other social media app. However, instead of selfies or cute cat pictures, posts are all about trash that users find. They find trash, take a photo and upload it to make a difference. The data that we gather helps us make a case for companies to take more responsibility towards their waste and help shift their direction to a more sustainable approach. Each post is proof that a specific product is simply thrown away and that this product’s packaging is not biodegradable and not sustainable for the environment. After you post a picture, the image is processed under the hood and identified as a specific product for a company using AI/ML. To help better visualize each and every country’s waste distribution and to help you see the bigger picture, we created two maps that enable users to better understand our mission. The first map shows the waste in the countries we had data from and to make the user aware of their country’s contribution to the overall mission. The second map shows the data we collected and the location of where each product is found. The quantity of values in this map changes as users post about what they found in the webapp. Us"
      }
    ]
  },
  {
    "file_path": "./devposts/gumpare-kcawsp.html",
    "project_id": "gumpare-kcawsp",
    "title": "Gumpare",
    "tagline": "Empower choices on products with eco-friendly packaging",
    "hackathon": "",
    "built_with": [
      "figma",
      "node.js",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/417/827/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Useful information including disposal instructions Problem Space we are tackling What Gumpare does Gumpare connects manufacturers, businesses and end consumers for bigger impact A list of available products to consumers Consumers can find products with eco-packaging nearby Business profile for businesses to manage their products Mobile view for consumers to set location Record their purchases Scanning QR code on the package that brings consumer to our website for more information about the packaging Useful information including disposal instructions Problem Space we are tackling What Gumpare does Gumpare connects manufacturers, businesses and end consumers for bigger impact A list of available products to consumers Consumers can find products with eco-packaging nearby Business profile for businesses to manage their products Mobile view for consumers to set location Record their purchases Scanning QR code on the package that brings consumer to our website for more information about the packaging Useful information including disposal instructions 1 2 3 4 5 6 7 8 9 10 11 Inspiration Whilst the best way is to reduce the use of packages, there are many valid reasons for using packaging, e.g. keeping the product fresh & hygienic, easy for storage, etc.\nPlastic-based packaging is a popular choice as they are usually the cheapest for manufacturers, restaurants, etc. \nAs climate change, eco-friendly topic arises, many are more conscious of their choices of product & packaging. End consumers are more conscious of their choices of products. Research published by BCG shows that 50%+ of consumers would select products based on the sustainability of packaging, and 20%+ would be willing to pay 10-20% more for products with eco-friendly packaging. Our survey shows that small businesses struggle to promote their products with eco-friendly packaging, whilst end consumers find it hard to find these products. End consumers are also concerned about having little / misinformation about t"
      }
    ]
  },
  {
    "file_path": "./devposts/hears-the-news.html",
    "project_id": "hears-the-news",
    "title": "Hears the News",
    "tagline": "Listen to today's world.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "newsapi",
      "react",
      "tts-api.com"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/651/785/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration We were inspired by ourselves because some of us are near-sighted and have glasses. So we can somewhat relate to what it feels like to be visually impaired. We also have some relatives that are partially blind, and we wanted to create something that could make their lives easier. We wanted to solve a daily need for people who are visually impaired. After brainstorming a bit, we settled on Hears The News. What it does This website provides the world’s top news articles from a wide range of sources (updated daily) and has functionality that reads aloud news articles at the click of a button. How we built it We built the website with React, HTML5, CSS3 JS, and Python. To retrieve news sources, we used newsapi ( link ), and we used the built-in TTS API ( link ) for the read-aloud functionality. Challenges we ran into David doesn’t have experience with React, so it was hard distributing the workload evenly. It was also Herman’s first hackathon, so he had difficulties working in a team environment; however, as time went on, he adapted to his environment and started communicating more effectively. Furthermore, it was very hard to come up with an idea for this hackathon, because none of us know what it’s like to be mentally/physically impaired, so we had to research many common disabilities. Finally, coming up with the UI/UX was challenging, especially because we had to learn how to use Figma for the first time, but once we got comfortable with it, we were quickly able to come up with an effective design. Accomplishments that we're proud of We are proud of the TTS and the aesthetics of our website, which took hours to perfect. We’re also proud of how we managed our workload (none of us burned out). What we learned We learned how to implement a database, using Firebase as a backend, with our React app. We also learned how to run backend Python scripts to update our database. Furthermore, we learned how to use Figma to collaborate on creating website des"
      }
    ]
  },
  {
    "file_path": "./devposts/group-165.html",
    "project_id": "group-165",
    "title": "Group 165 DataMinds",
    "tagline": "Hi, we are the DataMinds! We developed a machine learning predictive model using Random Forest Regression to predict sales figure, empowering companies to make informed decisions.",
    "hackathon": "",
    "built_with": [
      "function",
      "machine-learning",
      "matplotlib",
      "matrix",
      "notebook",
      "pandas",
      "python",
      "seaborn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "For our Recent Hackathon Project Our task was to develop a predictive model capable of forecasting future sales figures for numerous companies in Singapore. The primary goal was to delve into the dataset, unveiling trends, patterns, and potential causative factors that significantly influence sales outcomes. Ideation Phase In the ideation phase, our approach involved establishing a function to predict future sales, factoring in variables such as the number of employees, SIC code, and industry density in Singapore, among others. Following the provided guidance, the data cleaning and processing phase proceeded seamlessly. Exploratory Data Analysis (EDA) Challenge However, the exploratory data analysis (EDA) posed a unique challenge during feature selection. The datasets contained an extensive array of features, making it arduous to pinpoint the most relevant ones for predictive modeling. Our aim was to maintain the data in a low-dimensional state to prevent overfitting and streamline computational complexity. Machine Learning Model: Random Forest Regressor Opting for a Random Forest Regressor as our machine learning model, we found its versatility and robustness well-suited for handling diverse data types. To assess the model's accuracy, we utilized metrics such as Mean Squared Error (MSE) and R-squared, offering a comprehensive insight into its predictive capabilities. Project Impact This project proved invaluable, providing us with hands-on experience that enhanced our proficiency in data-driven decision-making and predictive modeling. We are grateful for the opportunity to tackle real-world challenges, contributing to our growth in the dynamic field of data science. Built With function machine-learning matplotlib matrix notebook pandas python seaborn Try it out GitHub Repo Submitted to NUS Datathon 2024: Champions Group Created by Siyi Xu :) Yi Fei Lim Lim Yi Fei Lee Jia Hong Weijie Huang"
      }
    ]
  },
  {
    "file_path": "./devposts/heatseeking-fan.html",
    "project_id": "heatseeking-fan",
    "title": "Heatseeking Fan",
    "tagline": "Cooling the person who needs it most",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/251/284/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration As students we get too overwhelmed with our work leading us to not have to time adjust our fan. What it does Heatseeking Fan uses sensors to detect the hottest spot in the room and points the fan directly at it with 360° coverage. Built With arduino c Submitted to Hard Hack 2025 Created by I sure hope LockMart R&D doesn't copy our design... Oskar Kraak I 3d printed the structure and fan for the design, and contributed to the design ideas. Min-Gyu Karl Harrison Trinh"
      }
    ]
  },
  {
    "file_path": "./devposts/healthcare-email-fraud-detection.html",
    "project_id": "healthcare-email-fraud-detection",
    "title": "Healthcare Email Fraud Detection",
    "tagline": "We developed a machine learning using scikit-learn that classifies healthcare emails on a scale of 1 to 5 where 1 is most fraudulent and 5 is least fraudulent.",
    "hackathon": "",
    "built_with": [
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We're proud of participating in our first hackathon and creating a machine learning model.",
      "To use our model, click on the first link under the \"Try it out\" section",
      "To view our presentation, click on the second link under the \"Try it out\" section"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration/Projection Description We approached the Health Equity Track. The Beginner Overlay applies to our project. Healthcare fraud causes tens of billions of dollars in losses each year. Phishing is one of the most common methods scammers use to engage in healthcare fraud. We wanted to create something that would help mitigate healthcare fraud and keep patients and healthcare professionals safe online. What it does We developed a machine learning model using scikit-learn that classifies healthcare emails on a scale of 1 to 5 where 1 is most fraudulent and 5 is least fraudulent. How we built it The algorithm we used was the TF-IDF (Term Frequency-Inverse Document Frequency) Vectorizer from the library scikit-learn. TF-IDF vectorizer takes into account how many times a word appears in a text and also how important that word is. We created a list of the most common phrases used in legitimate and fraudulent healthcare emails and assigned them a value of 1 to 5 where 1 is most fraudlent and 5 is least fraudulent. This was the data we trained our algorithm on. Challenges we ran into Both of us had limited machine learning experience, so we had to conduct a lot of research on which algorithm and what data to use. Accomplishments that we're proud of We're proud of participating in our first hackathon and creating a machine learning model. What we learned We learned the worflow of creating a machine learning model and the algorithms used by spam filters. What's next for Healthcare Email Fraud Detection We want to make our model more accurate by extracting more features from healthcare phishing emails and websites. These features include web address length, the number of dots in the URL, and the number of emotionally charged words. To use our model, click on the first link under the \"Try it out\" section To view our presentation, click on the second link under the \"Try it out\" section Built With python scikit-learn Try it out colab.research.google.com docs.google.com Subm"
      }
    ]
  },
  {
    "file_path": "./devposts/hey-mia.html",
    "project_id": "hey-mia",
    "title": "Matilda | Find volunteering opportunities today",
    "tagline": "we've all been through the tedious job search process. With Matilda, landing your next job opportunity is just a conversation away. Even after a global pandemic.",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "css3",
      "dialogflow",
      "firebase",
      "html5",
      "javascript",
      "node.js",
      "webflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/086/518/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Organization dashboard that allows organizations to have real-time conversations with users. Main Landing Page Mia Chatbot window for users looking to volunteer during COVID-19. Organization dashboard where applicants are listed. Organization dashboard that allows organizations to have real-time conversations with users. Main Landing Page Mia Chatbot window for users looking to volunteer during COVID-19. Organization dashboard where applicants are listed. Organization dashboard that allows organizations to have real-time conversations with users. 1 2 3 4 5 Inspiration With the pandemic comes permanent changes in every industry -- HR is no exception. Post-COVID times will be marked with a resurge in employment and volunteering opportunities, but with stricter social distancing rules comes a more constrained hiring process in terms of resources and time. Matilda aims to optimize the job search process for those in most urgent need but little to no experience, using conversational AI to match candidates with the best opportunities to their skillset and needs, while adapting the aspect of human interaction to social distancing realities. //The Canadian government has recently announced grants for people that would be volunteering. However, non-profit organizations are struggling to answer the many emails they receive, and citizens often don't know where to start. Knowing many young people would be offering their help, we thought of building a conversational agent using Google's Dialogflow, as AI-powered chat is an increasingly popular medium for communication. What it does At its core, Mia connects users with organizations, facilitating the application process from both sides by offering an AI streamlined approach. For people looking to sign up for volunteering opportunities, they can start talking to the chatbot. Mia asks different questions and even your location, to find the closest opportunities near you in order to offer the safest and most personalized volunteerin"
      }
    ]
  },
  {
    "file_path": "./devposts/healthifai.html",
    "project_id": "healthifai",
    "title": "HealthifAI",
    "tagline": "Seamless Healthcare solutions for Providers 🏥⚕️",
    "hackathon": "",
    "built_with": [
      "d3.js",
      "docker",
      "figma",
      "firebase",
      "flask",
      "gcp",
      "grpc",
      "openai",
      "pandas",
      "postman",
      "python",
      "pytorch",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Healthcare Hack ⚕️✨ UPDATE [14",
      "Healthcare Hack Created by idk who tf is Deepak ( ͡° ᴥ ͡°) Worked on the prediction + classifier mo",
      "Best Healthcare Hack Created by idk who tf is Deepak ( ͡° ᴥ ͡°) Worked on the prediction + classifi",
      "Hacklytics 2023: A Starry NightWinnerBest Healthcare Hack",
      "Deliver: pick the best solution and build that.",
      "Best Domain Name from Domain.com ⭐",
      "Best use of Google Cloud ☁️",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/379/702/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 Primary Track — Best Healthcare Hack ⚕️✨ UPDATE [14.02.23] → Something special is cooking! Check updates for more. Inspiration 💡 Healthcare is one of the most important and critical industries in the world . Providing quality medical care to patients is essential, but it is often hindered by various challenges such as overburdened healthcare workers, lack of medical devices in rural areas, and administrative stress. With the advent of artificial intelligence and machine learning, the healthcare industry has a unique opportunity to tackle these challenges head-on and revolutionize the way medical care is delivered. With this as context, we plan to tackle the Provider Shortage & Burnout and Access to Care strategic themes. What it does 🤔 HealthifAI aims to tackle several key pain points in the healthcare industry - specifically for the following : Provider Shortage & Burnout : Intuitive, easy & safe digital patient record entry which eliminates the need for manual and legacy record entry methods. We provide an ML-powered \"soft diagnosis\" to save time for doctors and nurses. We have location-based COVID-19 alerts to better equip workers. Multilingual speech-to-text notes, because it's easier! Reminder system to help with medication/check-ups. Keeping track of everything is hard! Access to care : Multilingual communication model that transcribes speech from any language into English. This is particularly helpful in rural areas where communication is a barrier. Experimental Computer-Vision powered heart rate monitor. This transforms everyday hand-held devices into medical devices - an exciting vision for the future! How we built it ⚙️ HealthifAI was built using cutting-edge AI and machine learning technologies , including Open-AI and Flask.  The team used the Flask framework to build a RESTful API that can handle incoming requests and return appropriate responses. We used React.js & Tailwind as CSS framework. The Authentication (OAuth) has been done by Fire"
      }
    ]
  },
  {
    "file_path": "./devposts/hmmm-na7f01.html",
    "project_id": "hmmm-na7f01",
    "title": "Hmmm",
    "tagline": "ETS IT Portfolio",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I coded the IT Projects page. It was a very interesting experience, as it was my first time doing something like this."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/280/741/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration HACC 2020 What it does Showcases the ETS IT Portfolio to the public How I built it Challenges I ran into Accomplishments that I'm proud of What I learned What's next for Hmmm Built With css html javascript Try it out hacc2020.github.io Submitted to HACC 2020 Created by I came up with the wireframe/prototype my team worked off of. I coded the homepage and visualizations tab. I also filmed and edited the video. Harvey Lloyd Picar I coded the IT Projects page. It was a very interesting experience, as it was my first time doing something like this. 21Riki Fujimoto Andrew Narciso Learning Heikin21 Valera"
      }
    ]
  },
  {
    "file_path": "./devposts/herine-health-app.html",
    "project_id": "herine-health-app",
    "title": "Herine Health App",
    "tagline": "This is a health app that helps patients to consult doctors online.",
    "hackathon": "",
    "built_with": [
      "nextjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Herine Health App upgrade to Artificial intelligence Built With nextjs Try it out GitHub Repo Created by Stephen Maina"
      }
    ]
  },
  {
    "file_path": "./devposts/heart-beats-1snate.html",
    "project_id": "heart-beats-1snate",
    "title": "Heart-BEATS",
    "tagline": "Generates music dynamically with heart beat changes with signal processing and AI.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "groq",
      "openai",
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/274/231/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Average Heart-BEATS User :) Heart-BEATS: We listen so YOU can listen Arduino heart monitor Signal Processing of Heart Signals Average Heart-BEATS User :) Heart-BEATS: We listen so YOU can listen Arduino heart monitor Signal Processing of Heart Signals Average Heart-BEATS User :) 1 2 3 4 Inspiration Heart-BEATS was inspired by the need for a real-time, personalized way to help individuals manage panic attacks and anxiety. Many existing solutions offer guided meditation or generic relaxation music, but we wanted to create a system that adapts dynamically to the user’s physiological state, providing a more immersive and effective calming experience. What it does Heart-BEATS listens to the user’s bodily signals, specifically their heartbeat, and uses real-time signal processing to generate custom music beats. Measuring several attributes of the heartbeat enables us to estimate a user’s emotions. Heart-BEATS adjusts the music accordingly, helping to restore a sense of calm and stability. How we built it We integrated multiple components to bring Heart-BEATS to life: Vitals Monitoring: Capturing the user's heartbeat data using Arduino KY-039 sensors. Signal Processing: Analyzing the heart rate variations to detect stress or panic states. Sound Sample Database: A curated collection of sounds designed to promote relaxation. Custom Music Generation Software: Algorithmically generates music that syncs with the user's heartbeat. OpenAI-Guided Sample Construction: Leveraging AI-generated samples to enhance the experience. Challenges we ran into Ensuring accurate real-time heartbeat detection and processing. Designing music that responds naturally and effectively to physiological changes. Accomplishments that we're proud of Successfully implementing a system that dynamically adjusts music based on heart rate. Combining signal processing and AI-driven music generation in a novel way. Providing a potential tool for individuals who experience anxiety or panic attacks. What we learn"
      }
    ]
  },
  {
    "file_path": "./devposts/healthbru.html",
    "project_id": "healthbru",
    "title": "HealthBru",
    "tagline": "HealthBru is a fitness app that combines the power of AI with personalized workout planning. It's like having a knowledgeable gym bro as your personal trainer, but with the intelligence of AI.",
    "hackathon": "",
    "built_with": [
      "fast-api",
      "groq",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/502/068/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Analytics Dashboard Initial Load In Chatting w/ HealthBru Home Page HealthBru Fitness Advise HealthBru Weekly Workout Creation Analytics Dashboard Initial Load In Chatting w/ HealthBru Home Page HealthBru Fitness Advise HealthBru Weekly Workout Creation Analytics Dashboard 1 2 3 4 5 6 Inspiration We were inspired by the struggle of creating personalized workout plans. Most people follow generic routines or get overwhelmed designing their own programs. We wanted to create an AI-powered solution that combines professional trainer knowledge with personalization - like having a knowledgeable gym buddy who creates plans tailored specifically for you. What it does HealthBru is an AI-powered fitness companion that generates personalized workout plans in seconds. Users input their goals and stats through a chat interface, and our AI creates comprehensive week-long plans including:\nPersonalized Workouts: Daily routines with specific exercises, sets, and reps\nSmart Meal Planning: Customized nutrition with grocery-friendly options\nInteractive Calendar: Visual workout scheduling with exercise details\nProgress Tracking: Analytics dashboard with charts and metrics\nModern UI: Beautiful, gradient-rich interface\nThe app parses AI-generated plans and populates an interactive calendar for easy weekly planning and progress tracking. How we built it Frontend: React with Vite, featuring modern UI with glassmorphism effects and responsive design\nBackend: Python FastAPI server handling user data and Groq LLM API communication\nAI Integration: Groq's LLM for generating personalized fitness plans\nData Processing: Custom parsing algorithms to extract structured workout data from AI responses Challenges we ran into AI Response Parsing: Extracting structured workout data from natural language AI responses required sophisticated regex patterns and parsing logic\nCalendar Integration: Balancing detailed workout information display with clean, user-friendly interface\nReal-time Chat: Creating smooth,"
      }
    ]
  },
  {
    "file_path": "./devposts/hero-city-hg8req.html",
    "project_id": "hero-city-hg8req",
    "title": "Heroes City",
    "tagline": "The one stop website to share and support your local heroes!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "json",
      "python",
      "reac",
      "scss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/393/020/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "☁️ Inspiration We were inspired by CNN Heroes which is an annual television special and a multimedia franchise created by CNN to recognize individuals who make extraordinary contributions to their communities and the world. 🚧 What It Does Our new app, called \"Hero City\", provides a platform for users to create events and facilitate social change through protests and other specific activities. Our app is the one stop where users can help heroes do more of what they do. Our app allows people to post stories about heroes. Others can then donate to the hero so the hero can keep doing what they love. Users can organize events, such as protests, and have full analytics and control over their event. One big use case is for organizations which help the elderly. People can post stories about the charity, and then others can donate money so the charity can expand its business. 👨🏾‍💻 How We Built It We built this project using react as the front end, and python as the back end. For styling, Tailwind CSS was used. We used it’s various classes to create a sleek, fluid UI. In the backend, we used many different technologies, from Flask to Deso to Firestore. 👷 Challenges We Ran Into Challenges we ran into were time management, synchronization, and technical issues. It was very hard to connect the frontend to the backend database. 🎉 Accomplishments That We're Proud Of We solved all the integration issues\nwe were able to make a decent ui on time. 📙 What We Learned We learned a lot of team building skills and time management. We also learned how to connect a flask backend and react frontend. 🔜 What's Next For Heroes City Social media integration: Allow users to share their events on social media platforms like Facebook, Twitter, and Instagram to reach a wider audience. \nVolunteer management: Provide an easy way for organizers to manage volunteers and track their progress. This can include a dashboard where organizers can see who has signed up to volunteer, what tasks they have been as"
      }
    ]
  },
  {
    "file_path": "./devposts/healthyme-dpaixs.html",
    "project_id": "healthyme-dpaixs",
    "title": "HealThyme",
    "tagline": "Ever get to a hospital only to find out you have to wait another 3 hours? HealThyme finds the nearest hospitals from you with the shortest wait time -  improving safety and health for everyone!",
    "hackathon": "",
    "built_with": [
      "azure",
      "azure-maps",
      "css",
      "github",
      "html",
      "javascript",
      "microsoft-cloud",
      "react",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/253/358/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page - patients choose their location, hospitals can sign in Booking Hospitals - based on user location, will list nearby hospitals available for booking Waitlist - available for hospitals to update their waitlist information Map Booking Info Landing Page - patients choose their location, hospitals can sign in Booking Hospitals - based on user location, will list nearby hospitals available for booking Waitlist - available for hospitals to update their waitlist information Map Booking Info 1 2 3 4 5 6 7 8 9 10 Inspiration Canada is a large country, but with small number of local hospitals and clinics. While suffering from illnesses and pain , waiting in a crowded hospital for hours until your turn comes will never be a pleasing experience. From the healthcare workers' points of view, the overcrowded workspace could cause a chaotic environment that distract them from their work. Especially, since the space is fully occupied with patients, contagious disease infections and secondary contaminations will be rampant. This could easily expose both our community members and healthcare workers to harmful diseases. For our community and the healthcare workers that we are always thankful for, we designed a healthcare-related website that can increase their safety, time efficiency, and convenience: _ HealThyme _. What it does HealThyme takes the location of the user, and generates a map indicating each of the hospitals closest to the user as well as how many people are in line in front of them. The user interface is especially designed so that comparison would be very easy between the different hospitals in terms of their distance and wait time. Once the user has chosen a hospital or clinic they think is the best fit for their situation, the user is able to book a time at that said hospital, saving them time, and maybe even their life.\nHealThyme not only appeals to people who are seeking medical help, but it also acts as a platform for hospitals. Each hospital is able t"
      }
    ]
  },
  {
    "file_path": "./devposts/hears-the-news-vlmkfd.html",
    "project_id": "hears-the-news-vlmkfd",
    "title": "Hears The News",
    "tagline": "Listen to today's world.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "newsapi",
      "ttsapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/652/003/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "About page Home page News page (1) News page (2) About page Home page News page (1) News page (2) About page 1 2 3 4 5 Inspiration We were inspired by ourselves because some of us are near-sighted and have glasses. So we can somewhat relate to what it feels like to be visually impaired. We also have some relatives that are partially blind, and we wanted to create something that could make their lives easier. We wanted to solve a daily need for people who are visually impaired. After brainstorming a bit, we settled on Hears The News. What it does This website provides the world’s top news articles from a wide range of sources (updated daily) and has functionality that reads aloud news articles at the click of a button. How we built it We built the website with React, HTML5, CSS3 JS, and Python. To retrieve news sources, we used newsapi ( link ), and we used the built-in TTS API ( link ) for the read-aloud functionality. Challenges we ran into David doesn’t have experience with React, so it was hard distributing the workload evenly. It was also Herman’s first hackathon, so he had difficulties working in a team environment; however, as time went on, he adapted to his environment and started communicating more effectively. Furthermore, it was very hard to come up with an idea for this hackathon, because none of us know what it’s like to be mentally/physically impaired, so we had to research many common disabilities. Finally, coming up with the UI/UX was challenging, especially because we had to learn how to use Figma for the first time, but once we got comfortable with it, we were quickly able to come up with an effective design. Accomplishments that we're proud of We are proud of the TTS and the aesthetics of our website, which took hours to perfect. We’re also proud of how we managed our workload (none of us burned out). What we learned We learned how to implement a database, using Firebase as a backend, with our React app. We also learned how to run backend Python sc"
      }
    ]
  },
  {
    "file_path": "./devposts/healthy-uc.html",
    "project_id": "healthy-uc",
    "title": "Healthy UC",
    "tagline": "\"Access AI-powered food recommendations for a healthier diet with our user-friendly app. Choose nutritious options and reach your fitness goals. Download now.\"",
    "hackathon": "",
    "built_with": [
      "anaconda",
      "canva",
      "expo.io",
      "figma",
      "flask",
      "jsx",
      "node.js",
      "npm",
      "pandas",
      "python",
      "react-native",
      "selenium",
      "sqlalchemy",
      "sqlite",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Health & Wellness Main Track - 1st Place Created by Ryan Lee Edison Zhang Jessie Arroyo Javier Mira",
      "HackMerced VIIIWinnerHealth & Wellness Main Track - 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/408/731/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Team Title Page Home Page Meals Working hard Fullstack Overview Fullstack Overview Functionality Wireframe User Profile Features Home Features Meal Features User Flow User Flow React Native Development HealthyUC_BackEnd Thank you! Connect with us! The Team Title Page Home Page Meals Working hard Fullstack Overview Fullstack Overview Functionality Wireframe User Profile Features Home Features Meal Features User Flow User Flow React Native Development HealthyUC_BackEnd Thank you! Connect with us! The Team 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Inspiration 💡 When faced with an abundance of options at the Pavilion and YWDC, we faced a challenge: identifying a healthy and nutritious meal demanded a lengthy procedure. Realizing the importance of time, we endeavored to streamline this process, and so, Healthy UC was born. What it does 🦾 Boasting a comprehensive database of the Pavilion and YWDC's menu, this app guarantees to revolutionize the way you select your meals. With just a few taps, you'll be presented with a personalized meal suggestion tailored to your specific requirements - whether it's dietary restrictions, BMI, or target goals. The app even offers alternative options and shows you the nearest location to grab your healthy meal. Say goodbye to lengthy decision-making processes and hello to a simplified, efficient, and healthy lifestyle with our iOS app. How we built it ⚙️ We engaged in a brainstorming session to generate ideas, drawing from our observations of common everyday struggles. As we delved into the process, one recurring idea that emerged was the challenge of maintaining healthy nutritional diets amidst busy schedules. This inspired us to explore the intersection of nutrition and accessibility, ultimately shaping the direction of our project. Next, we utilized Figma and Canva to outline our project and guide the design of our front-end, brainstorming ideas to ensure that our app's functionality was well-aligned with the chosen tools. In parall"
      }
    ]
  },
  {
    "file_path": "./devposts/helpr-0v51kf.html",
    "project_id": "helpr-0v51kf",
    "title": "Helpr",
    "tagline": "Helping to connect people with different skill sets and abilities to be able to come together and help uplift each other. By sharing skills, everyone benefits and open environment to learn is created.",
    "hackathon": "",
    "built_with": [
      "graphql",
      "javascript",
      "mongodb",
      "mongoose",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/308/288/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 Inspiration It's a well-known idea that teaching is the best way to learn. One of the most useful study tips we've heard is to explain concepts to others in order to understand them in the best way possible. We also know that there is a great inequality on the internet in terms of learning and teaching. Many people, including us, feel very intimidated to use platforms like StackOverflow to learn skills as if questions are already asked or if they are not asked in the right way, users will be very hostile. We wanted to solve this issue by creating a reputation-based system for teaching and learning. We aimed to solve the inequality in learning and teaching by incentivizing teaching. What it does We created a community based application to help create a safe space for people to come together and share any skills they might have that other might want to learn. We know from personal experience that it's very difficult to get correct mentorship and guidance for specific problems, but this way both the mentee and mentor can benefit as both individuals are gaining something from the time they spend. The system that we have designed so far runs in a manner that people gain credits for each time they help someone else. This allows for people to be able to use those credits to then be able to learn something. Everyone has something to offer and there is always someone willing to learn. So it become a great way for people to uplift each other and create a place for quality education and helps bridge the gap in academic inequality. We also realized that people may possibly exaggerate their abilities for certain skills, so we also created a metric called reputation which would be able to help ensure that people's claims are validated to some degree. Finally, once a mentee requests help from a mentor and the mentor agrees, then the chat session would be opened and would only close once the mentee's problem has been solved or the mentee feels that the mentor c"
      }
    ]
  },
  {
    "file_path": "./devposts/hearassist.html",
    "project_id": "hearassist",
    "title": "HearAssist",
    "tagline": "A tool to enhance the real-life experience for auditory-impaired individuals",
    "hackathon": "",
    "built_with": [
      "anaconda",
      "assemblyai",
      "css3",
      "flask",
      "html5",
      "replit",
      "spyder"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "General Hacks Created by Neel Adwani yeet Akansha Gupta",
      "BostonHacks Best General Hacks Created by Neel Adwani yeet Akansha Gupta",
      "BostonHacks 2021WinnerBostonHacks Best General Hacks",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/739/294/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration COVID-19 has impacted the lives globally especially the ones with disabilities hence, we have thought of a tool focusing on helping auditory-impaired individuals by assisting them. In the current scenario, there are special schools for them, so we decided to develop a tool that will bridge the gap and will enable them to study anywhere and interact with anyone around the world. Track: Community What it does HearAssist facilitates communication with auditory-impaired individuals by providing live captions of ongoing communication. How we built it API Used: AssemblyAI Back-end: Flask, Replit Front-end: HTML, CSS Challenges we ran into Synchronizing with the AssemblyAI API was a bit difficult, but we were able to wind it up by going through the documentation. Accomplishments that we're proud of We're proud of building a prototype and finishing it up locally. What we learned We learned about AssemblyAI, web design, development, flask, and replit. What's next for HearAssist We'll be deploying it as a web application and it will even support more languages. Built With anaconda assemblyai css3 flask html5 replit spyder Try it out GitHub Repo hearassist-1.neeltron.repl.co Submitted to BostonHacks 2021 Winner BostonHacks Best General Hacks Created by Neel Adwani yeet Akansha Gupta"
      }
    ]
  },
  {
    "file_path": "./devposts/holonet.html",
    "project_id": "holonet",
    "title": "HoloNet",
    "tagline": "An IoT based Network & Newsletter to alert people about Natural Disasters (Earthquakes and Wildfires) via SMS and Emails in advance",
    "hackathon": "",
    "built_with": [
      "c++",
      "flask",
      "node.js",
      "nodemcu",
      "python",
      "react",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Re-Think Automotive Hack by ACV Winner Sponsored Route: (MLH) Most Creative Use of Twilio Created b",
      "Sponsored Route: Best Re-Think Automotive Hack by ACV Winner Sponsored Route: (MLH) Most Creative U",
      "PennApps XXIIWinnerSponsored Route: Best Re-Think Automotive Hack by ACVWinnerSponsored Route: (MLH) Most Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/650/174/datas/medium.",
    "description": [
      {
        "heading": "Description",
        "content": "Hardware Setup Signup Hardware Setup Signup Hardware Setup 1 2 3 Inspiration In last few years, the world has faced a lots of natural calamities. \nThe U.S. has sustained 298 weather and climate disasters since 1980 where overall damages/costs reached or exceeded $1 billion (including CPI adjustment to 2021). The total cost of these 298 events exceeds $1.975 trillion. In 2021 (as of July 9), there have been 8 weather/climate disaster events with losses exceeding $1 billion each to affect the United States. These events included 1 drought event, 2 flooding events, 4 severe storm events, and 1 winter storm event. Overall, these events resulted in the deaths of 331 people and had significant economic effects on the areas impacted. The 1980–2020 annual average is 7.1 events (CPI-adjusted); the annual average for the most recent 5 years (2016–2020) is 16.2 events (CPI-adjusted). Besides the United States, China and India have taken the hardest hit from natural disasters due to their massive population. Both nations accounted for over 280 crore disaster-affected people between 2000 and 2019, which is around 70 per cent of the global total. Some 79,732 people have lost their lives and 108 crore people were affected in 321 incidents of natural disasters in India in the same duration, according to the United Nations Office for Disaster Risk Reduction. While China recorded 577 natural disasters affecting 173 crore people and leading to 1.13 lakh deaths, the United States witnessed 467 incidents affecting 11 crore people in this period. What it does Holonet saves your name, email, phone number, and location. When it gets any upcoming natural disaster updates alerts you via your mail and number. Implement Machine Learning Predict the disasters using some datasets from Kaggle to increase its accuracy Disaster Record Everytime the hardware alert the users about the upcoming disaster, the type of disaster will be stored in the database such that the users can look back the record a"
      }
    ]
  },
  {
    "file_path": "./devposts/heartly-heaven.html",
    "project_id": "heartly-heaven",
    "title": "Heartly Heaven",
    "tagline": "Need help with finding love and a date? We got you!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "flask",
      "mongodb",
      "python",
      "react.js",
      "socket.io",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Don't Go Hacking My HeartWinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/832/658/datas/medium.",
    "description": [
      {
        "heading": "Description",
        "content": "Thumbnail Home Page Thumbnail Home Page Thumbnail 1 2 3 Inspiration 💕 Inspiration: Our team was inspired to make this project because we collectively agreed that it is hard for people to get out of their comfort zone in the talking stage. We wanted to counter this by creating a web application that allows two people to create a chatroom, an option to schedule a date and play various games like Wordle. What it does 🥳 Features: The features that we included within the app are a chatroom for new people to meet one another and possibly to get to know each other in a romantic way. We also added a feature where each user can schedule a date, and the web app will automatically remind them through their phone number in Twilio. The final feature we added to the web app was fun games that both users can play like tic-tac-toe and wordle, which are themed as valentines day. How we built it ☺️ The Web-App is built on React.js with Flask working on the backend. We built backends using flask and firebase functions Challenges we ran into 🤯 Challenges: We faced many challenges during the making of this project. The biggest one is building the chat section for the app. Integrating Socket.io connection with the server, therefore, we spent most of our time learning and editing it Accomplishments that we're proud of 🥺 Accomplishments: Our accomplishment was that we managed to add a chatroom as well as a gaming section which is something most of us have yet to do in a hackathon. Not to mention it was also our first time attempting a love-themed web application and we were super happy about our results overall. What we learned 🥰 Learning Experience: Ultimately, we learned how to use the functions in a much more productive way in socket.io as well as firebase. Some of us also learned how to use react.js syntax in a much deeper pathway. What's next for Heartly Heaven ❤️ Add complete the chat application with a complete socket io connection. Improve UI styling and design. On top of that, we "
      }
    ]
  },
  {
    "file_path": "./devposts/healthy-me-application.html",
    "project_id": "healthy-me-application",
    "title": "Healthy Me Application",
    "tagline": "An application which reduces food wastage and helps in maintaining healthy diet",
    "hackathon": "",
    "built_with": [
      "android",
      "android-wear",
      "fitbit",
      "java",
      "jquery",
      "mit-ai2",
      "notepad++",
      "smartwatch",
      "wamps"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/440/847/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Summary We've aimed at making an application which is android based which uses inputs from different modules such as fitbit, smartwatches etc. regarding body conditions and work done by user and transfer them to this application which calculates the amount of calories burnt by the user in a particular time interval and based on which you can manage you're food consumption using the calorie to food conversion website. Detailed Description Based on the amount of work done by the user during a day which will taken up by the sensors on the wearable tech (fitbit, smart watch etc.), this application will take inputs from these modules via Bluetooth. These inputs will then be used to calculate the amount of calories burnt between the time interval when the application was started and stopped. Furthermore, at last it will give you the accurate amount of calories you’ve burnt in the given time interval. After this, the application will redirect to our website containing database of different food available around the world from which the user can select the food items he/she is consuming at the current meal. Based on the calorie input from the android application and wearable sensor, the quantity of different food items to be consumed at the current meal can be decided by the user. Prototype 1 Details This is what we made: (Device 1) Device used for giving body inputs: Android mobile (with better sensors) (Device 2) Device used for taking inputs: Android mobile (with not so good sensors) Sensor used in current prototype: Accelerometer Mode of transfer of inputs from Device 2 to Device 1: Bluetooth Website is built seperately in order to convert amount of calories to be consumed into food standards which has to be uploaded to a domain so as to open it in the application. For now, you can view it using WAMPS on your laptops. Beyond this point, it is just a matter of fact of what can you make of it. We can make the device 2 programs with almost every API available i.e. fitbit, "
      }
    ]
  },
  {
    "file_path": "./devposts/have-i-met-you-before.html",
    "project_id": "have-i-met-you-before",
    "title": "Where's MLH?",
    "tagline": "Prevent Awkward Interactions with People You've \"Met\" Before",
    "hackathon": "",
    "built_with": [
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/250/156/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Box Cutter Gallery Default Landing Page Coaches Met Origin Countries Origin States Box Cutter Gallery Default Landing Page Coaches Met Origin Countries Origin States Box Cutter Gallery 1 2 3 4 5 Streamlit Streamlit is awesome and simple (until your app.py becomes 600 lines long). I can create a frontend without needing to learn what a useState is or other React terms. Streamlit basically processes everything from managing uploads to displaying the gallery. Domain jocelynsomnia.study\nThis domain goes out to all the MLH coaches who brave no sleep to help out at hackathons. Whether it be delayed flights or early wake up calls, the sleep schedule of an MLH coach deserves recognition.\nThe study is because I need to study for my accounting midterm on Monday o.o Box Cutter Gallery MLH sends coaches a box cutter to open boxes along with them at hackathons. Taking a picture is like getting an I Demo'd sticker at hackathons, but no one else is doing it. Inspiration I am terrible at remembering names and faces. This is especially bad with MLH coaches as you remember the face, but don't remember which hackathon you saw them at. What it does Keep a log of the people (or MLH coaches) you've met along with photos and the last date you saw them. Instead of the awkward where did I last see you, you can start with a firm hello! Also shows where they are from on a map. If you don't upload a photo during the meet it does not count as a meet. This is a feature not a bug. If you don't take a picture, are you sure you really met them? How we built it Streamlit did a lot of work. I don't know React and it enabled me to not need to learn it. Challenges we ran into Throwing everything into a single app.py is messy and a bad idea. Eventually, you're scrolling more than you are reading. Accomplishments that we're proud of It works and errors out only sometimes What we learned Do not start a project over halfway through the hackathon... What's next for Have I Met You Before? Several pages or be"
      }
    ]
  },
  {
    "file_path": "./devposts/hacknroll-case-management-system.html",
    "project_id": "hacknroll-case-management-system",
    "title": "HacknRoll Case Management System",
    "tagline": "Built for case management, this website provides a centralised and secure way of managing cases. It will be under development beyond this hackathon, so stay tuned!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration To help NGOs to better manage cases with low costs and easy to use What it does Manage cases, send reminder to admin staffs when it is closer to the important date of cases. How we built it Used React and firebase to host and manage the cases Challenges we ran into React and Firebase integration, UI designs Accomplishments that we're proud of Successfully handled file upload, sign in, set & send reminder functions What we learned It is aways important to think throuhg the user journey for user-centric products What's next for HacknRoll Case Management System We will be continue the development with continous feedbacks from NGOs to imporve the website Built With firebase react Try it out GitHub Repo Submitted to Hack&Roll 2025 Created by Stephanie Jiang noob@cs Zhihao ZeusHG Ron Quah Dasha Sychova"
      }
    ]
  },
  {
    "file_path": "./devposts/hiding-us.html",
    "project_id": "hiding-us",
    "title": "Hiding us",
    "tagline": "\"Speak Up Anonymously - Make the World a Better Place\"",
    "hackathon": "",
    "built_with": [
      "google-cloud",
      "nextjs",
      "nextui",
      "opencv",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Steel City Hacks: Winter Hack 2022WinnerHackathon: Most Relevant",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/324/610/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Hiding Us Thumbnail Hiding Us Thumbnail Hiding Us Thumbnail 1 2 Inspiration I recently took to Twitter to find a solution to a problem I was having with the platform. I had noticed that there were a large number of people posting videos of riots, fights, and other controversial content, but not sharing their message due to fear of repercussion. I wanted to create a website where people could safely and anonymously post videos of these kinds of events without fear of being judged or criticized. What it does A website where people can post videos anonymously could be a good thing because it would give people the chance to say what they think or share their experiences without worrying about being judged or punished. This could be helpful for people who are afraid to speak up because they are different or because they think other people might not like what they have to say. When people can talk openly and honestly, it can help everyone understand each other better and make the world a kinder place. How we built it The website was built using NextJS, nextui, and react for the front-end. Python, google cloud storage, and OpenCV for the back-end Challenges I ran into The challenge I ran into is processing the blurred video and sending it to the google cloud storage. The challenge took at least 4 hours because in stack overflow, people gave all types of solutions, but none of them worked. I finally found the correct solution and felt so happy. The documentation for google cloud storage is terrible and horribly complex. I wish the process was much simpler. Sending an mp4 file to google cloud storage using API routes is much more complex than I thought. There were thousands of ways to do it and made you install so many packages. After 3 hours of digging I found a solution using the npm package, formidable which made things very simple. Accomplishments that I'm proud of I am incredibly proud of the website I have created that uses OpenCV, a powerful computer vision library. O"
      }
    ]
  },
  {
    "file_path": "./devposts/handyhomes.html",
    "project_id": "handyhomes",
    "title": "HandyHomes",
    "tagline": "Find a home away from home!",
    "hackathon": "",
    "built_with": [
      "cocoapods",
      "core-location",
      "firebase",
      "mapkit",
      "swift",
      "uikit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/922/003/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were shocked by the recent fires in Australia. We thought about all the people who have been displaced due to evacuation. Our team thought it would be a good idea for Aussies to help Aussies by volunteering a residence for the displaced to stay at. This way, many Australians can have a roof over their head as they get back on their feet. What it does Our app allows users to post or find open residences or shelters. Users can see these places on the map and have the ability to contact posters. Posters have an easy page to manage their shelters. How we built it Our team employed Swift and Xcode to develop an iOS application to help Australians in need. We leveraged Firebase as a Realtime NoSQL Database to store posts. Firebase Authentication services were used to sign in and sign up users. Challenges we ran into It was troublesome to collaborate over Github due to the Swift Storyboard File. This greatly slowed our workflow, as we had to each work on the file one at a time. Accomplishments that we're proud of As a team, we are proud of completing the project in its entirety in the 24 hours allotted. We are also proud of gaining more experience in Firebase, which is beneficial in the technology industry. What we learned During these 24 hours, we learned how to use Firebase, improved our Swift abilities, and, most importantly, we learned more about the efforts that are going on in Australia to combat the bush fires and save hundreds of thousands of lives. What's next for HandyHomes Built With cocoapods core-location firebase mapkit swift uikit Try it out GitHub Repo Submitted to TAMUhack 2020 Created by I worked on UI design and I developed the presentation for the app. I also did some of the brainstorming for the app. ajayramsunder I worked mainly on setting up the Firebase database, the interface between the Swift code and Firebase, and the interactivity of the map annotations. Jeffrey Ryan Abhishek More Retired Hackathon Enjoyer"
      }
    ]
  },
  {
    "file_path": "./devposts/health-hub-hi0tmo.html",
    "project_id": "health-hub-hi0tmo",
    "title": "emergenchain",
    "tagline": "A website that stores medical records on the blockchain for convenience and emergency access.",
    "hackathon": "",
    "built_with": [
      "deso-protocol-library",
      "figma",
      "framer-motion",
      "react",
      "solidity",
      "tailwind-css"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "(MLH) Best Domain Name from Domain",
      "Hack the Valley 7Winner(MLH) Best Domain Name from Domain.com",
      "🌐 Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/254/540/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 💡Inspiration In a time of an emergency when a patient is unconscious, how can we be so sure that the first aid responders know what painkillers they can give, what condition they might've fallen ill to, and what their medical history is? Many years ago, there was an incident where a patient was allergic to the narcotics that were given to them. We want to change that and create a new standard when it comes to a new place for health records. Patients are also more entitled to more privacy as blockchain is more secure and safe as possible. With new and more secure technologies, people can use blockchain to be confident that their information is immutable and protected with encryption and a private key that only their wearable/device has. We give healthcare professionals access to data for their personal healthcare information ONLY when the patient has fallen ill. 🔍What it does Emergenchain provides three primary uses. Firstly, we offer a secure and organized way to store one's medical records. This provides a convenient way for doctors to access a patient's medical history. Additionally, we also offer a certificate for vaccines and immunizations. This way people have an easy way to access their proof of vaccination for pandemics and other necessary immunizations. Furthermore, we offer an emergency summary sheet compiled from the information on their patient's medical history. This includes known health conditions and their risk. Finally, we have a QR code that displays the emergency information tab when scanned. This acts as a precaution for when someone is found unconscious, as first aid responders/medics can scan their QR code and immediately find details about the patient's health conditions, history, emergency contact information, and treatment methods. ⚙️How we built it We designed our front end using Figma and coded it on React. For our navbar, we used react-router-dom, and for styling, we used Tailwind CSS to decorate our elements and used framer mo"
      }
    ]
  },
  {
    "file_path": "./devposts/help-wille-get-to-the-city-covid-19-version.html",
    "project_id": "help-wille-get-to-the-city-covid-19-version",
    "title": "Help Worried Wille Get to the City! (COVID-19 Version)",
    "tagline": "Help Worried Wille get to the city without any risk! Complete obstacles by identifying the correct ways to lower the risk of COVID-19.",
    "hackathon": "",
    "built_with": [
      "scratch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Game Created by Erika Wu Aditi Bhat",
      "Helloo HacksWinnerBest Game",
      "One challenge we ran into was how to use Scratch since it was our first time using it.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/189/459/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The game. The code for our project. The game. The game. The code for our project. The game. The game. 1 2 3 4 Inspiration We wanted kids to be aware on how to stay safe during the pandemic. What it does This game helps younger kids learn how to stay safe and healthy due to COVID-19. How we built it We used Scratch to make this fun game! Challenges we ran into One challenge we ran into was how to use Scratch since it was our first time using it. Accomplishments that we're proud of We are proud of finished and completing this game! Since it was our first time using Scratch as well as making a game, we ran through many obstacles. What we learned We learned how to use Scratch and how to make a game on it! What's next for Help Wille Get to the City! (COVID-19 Version) We hope that people can look at our game and learn from it! Built With scratch Try it out scratch.mit.edu Submitted to Helloo Hacks Winner Best Game Created by Erika Wu Aditi Bhat"
      }
    ]
  },
  {
    "file_path": "./devposts/healthbay.html",
    "project_id": "healthbay",
    "title": "Healthbay",
    "tagline": "Healthcare Redefined ⚕️",
    "hackathon": "",
    "built_with": [
      "blockchain",
      "c++",
      "firebase",
      "flask",
      "gcp",
      "javascript",
      "leaflet.js",
      "mqtt",
      "nodemcu",
      "python",
      "react",
      "socket.io",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Live Tracking of health data",
      "Live Ambulance Tracking",
      "Minimalistic Material-UI inspired UX with a mobile-first approach.",
      "woww!! such a helpful app. Love it <3 all the best guysss"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/501/218/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "System-Architecture GIF Mockup App-preview more-previews System-Architecture GIF Mockup App-preview more-previews System-Architecture 1 2 3 4 5 Background The advent of the 𝐂𝐨𝐯𝐢𝐝-𝟏𝟗 has turned all of our lives upsides down. At present, the traditional emergency response supply chain appears to be breaking since, Healthcare facilities are facing catastrophic challenges in providing proper medical treatment. Healthcare has become expensive, visiting hospitals increases exposed contamination since it's time-consuming and often requires creating extensive schedule changes in one's daily routine. Moreover, hospitals don’t have the capacity for a large number of incoming patients. Additionally, treatments often feel inadequate and lack personalization since Doctors are incredibly busy. According to the American Heart Association Research, every 3 days person in the world dies because of cardiovascular disease , killing more than 19 million people per year. There are many people in rural areas who can't afford medical treatment. In-home caregivers often act as the bridge between these medical professionals and the patient but this scenario has forced them to stay back at home. Besides, Community workers are not able to handle real-time monitoring of the overcrowded rural population . But due to this lack of monitoring & management, many people are dying. Keeping light on the same, it's also evident that elderly’s ability to access usual medical care has drastically decreased , and the communication with caregivers is impaired. They are more vulnerable to this disease and are little known to modern applications. Demand for remote outpatient solutions has significantly increased which would aid doctors in disease diagnosis and contribute to early detection and timely treatment of illnesses. But the accessibility gap has disconnected the connected. There is a need for a technology platform to Revolutionize the operation of existing Medical System and that's how our project He"
      }
    ]
  },
  {
    "file_path": "./devposts/historacle.html",
    "project_id": "historacle",
    "title": "HistOracle",
    "tagline": "Unlocking History's Secrets with AI Conversations ✨",
    "hackathon": "",
    "built_with": [
      "ai",
      "chatgpt-api",
      "docker",
      "elevenlabs",
      "figma",
      "flask",
      "gcp",
      "google-maps",
      "grpc",
      "huggingface",
      "ip-info",
      "leaflet.js",
      "natural-language-processing",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place - Communication Track Created by I wanted to understand my roots, so I climbed my family",
      "MetroHacks 2023Winner1st Place - Communication Track",
      "Communication Track 💬",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/702/716/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 Submission Category Age group → 18+ Submission Track → Communication 💬 Inspiration 💡 History , a crucial element in shaping one's identity, often comes off as dull and uninteresting. Understanding the importance of communicating history correctly, especially in the context of identity, motivated us to explore innovative ways to make history engaging. Thus we came up with HistOracle ! ✨ What it does 🤔 HistOracle transforms the exploration of historical figures and monuments into an interactive and delightful experience. The app caters not only to students but also to museums seeking to attract tourists worldwide. During our recent trip to Puerto Rico, we encountered the common challenge of grasping the historical significance of statues and monuments. HistOracle emerged as a solution to this problem, allowing users to interact directly with historical figures and learn about their stories. How we built it ⚙️ We built the interface using React.js and MaterialUI. After a seamless Single Sign-On (SSO) experience, HistOracle's home dashboard appears, featuring nearby statues and historical monuments. For privacy, we derive your approximate location from your public IP, displaying relevant monuments on a Leaflet.js-powered map. OpenAI's ChatGPT API scrapes metadata, including images, for historical sites. We've created a pipeline connecting these with preprocessed audio from Elevenlabs. Using the Audio-Visual Correlation Transformer (AVCT), we generate one-shot talking face animations, inferring motions from visual images and sample audio. Our architecture uses gRPC for high-performance APIs in microservices, with a Dockerized backend. The ChatGPT-powered chatbot works seamlessly! Challenges we ran into 😤 With last-minute brainstorming just two hours before the hackathon and exams looming, creativity was a challenge. We opted for a minimalistic approach, emphasizing that less is more. Time constraints and the need to keep the interface simple presented add"
      }
    ]
  },
  {
    "file_path": "./devposts/history-of-mlh.html",
    "project_id": "history-of-mlh",
    "title": "History of MLH: A Hackers Dream",
    "tagline": "Major League Hacking has opened up doors for so many people in the programming industry. As a tribute, let's take a trip down memory lane as we recount some key moments in MLH's history, through code!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hacky Birthday MLH! 2022WinnerSecond Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/039/182/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Title Screen section MLH navigation bar replica Narrow/Small road map view Large screen road map view Starting screen for the game Title Screen section MLH navigation bar replica Narrow/Small road map view Large screen road map view Starting screen for the game Title Screen section 1 2 3 4 5 6 Inspiration We wanted to create something special to celebrate a decade of empowering innovative, intelligent hackers and giving opportunities for creative minds to start their careers. So with that mindset, we went back and highlighted some key moments in MLH's history as a way to appreciate it on its anniversary. What it does What our pages allow you to do is take a walk through the years of MLH and allow you to see the organization's achievements as they come to pass using timelines. We implemented 2 ways of viewing it, one via a small game we created and the other via a road map. The game is a side scroller that takes you through the timeline as a character named \"MLH Dude\" in an artistic 8-bit-esque world where you must jump from platform to platform to make it to the end. The road map is a simple yet detailed way of doing the same, where you can see the various dates, headings, and text associated with each individual event. As a small bonus, we even included some fun facts which the user may not know of right away. How we built it We used web development-oriented languages(HTML, CSS, JavaScript) to piece together every bit of this project. We started off by coding the navigation bar on the website to look exactly like the MLH's website navbar as we believe that the page is in full effect when it's actually integrated into its proper environment. From there, we worked on the Caves game and the road map separately(split up work between group members) and then merged them in at the end. As a finishing touch, we added a title section to the page and a subtitle that outlines what exactly everything is for. Challenges we ran into Something that we found challenging was when p"
      }
    ]
  },
  {
    "file_path": "./devposts/howdyhack2020.html",
    "project_id": "howdyhack2020",
    "title": "Aggieland Adventure",
    "tagline": "\"Bow wow!\", goes Revellie. \"Oh boy! A mystery!\", goes the 12th Man. \"This is so awesome! It gives some clues to find places around Aggieland!\" Revellie barks in approval as they go to the sunset.",
    "hackathon": "",
    "built_with": [
      "c#",
      "git",
      "javascript",
      "mango",
      "nginx",
      "node.js",
      "react-static",
      "react.js",
      "vps",
      "xamarin",
      "xaml"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/210/550/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Top Dective Leaderboard Website The Top Dective Leaderboard Website 1 2 3 Inspiration We, being Freshmen of Texas A&M found the campus quite broad. Despite the Covid-19 restrictions, the ability to navigate around the campus still remained an necessity. Our day to day experiences twere already a \"Savenger Hunt\" themselves as we had to search for certain buildingns remembering certain \"clues\" about them. What better way than to make a painful activity fun by adding competition through Aggie Clues! What it does Aggieland Adventure provides clues and to specific locations on campus in a mobile application. When the user is near the location, the phone's GPS will show the nearest distance in miles on the app. One the user reaches the destination, the backend server will be notified and a successful find will be recorded in the database.In the app, the user will be able to see the description of the historical significance of the monument/location in the app. Finally, a website will show a realtime leaderboard of the high scores of other players. How we built it Android App : Xamarin\nBackend : Node, Express, and Mongo\nLeader Board Website : React JS Leaderboard Website Utilizing the power of React.js Rave and Urjeet and  created an elegant leaderboard website that connected to Saketh's API. The app is hosted on the same nginx server as the API Challenges we faced Since our most of our team didn't have any language in common, collaborating with the frontend team about the API was very difficult and time consuming. However, during the last 12 hours, we came up with a system for us to deal with the code bugs on each of our teammates end that increased out productivity exponentially Accomplishments that I'm proud of We are really proud of how we were able to completely speed up our debugging process after the 1st day. We learned We learned that we can utilize javascript as a flexible technology for a variety of technologies from Front-end web and interface design as well"
      }
    ]
  },
  {
    "file_path": "./devposts/homerunhero.html",
    "project_id": "homerunhero",
    "title": "HomeRunHero",
    "tagline": "An app To provide personalized coaching and training to baseball players, using artificial intelligence and machine learning algorithms.",
    "hackathon": "",
    "built_with": [
      "figma",
      "machine",
      "machine-learning",
      "python",
      "ui",
      "ux"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration: As avid baseball fans, our team realized a need for a more personalized coaching experience for everyone of all levels. We wanted to create a tool to help coaches and players, even normal people analyze their performance, identify areas for improvement, and provide targeted training plans to achieve their goals. What it does: HomeRunHero is an AI-powered coaching app that provides personalized feedback and training plans for baseball players. The app uses machine learning algorithms to analyze players' swing mechanics, pitch selection, and fielding techniques to provide real-time feedback and customized training plans. Coaches can use the app to track player progress, identify areas for improvement, and adjust training plans accordingly. How we built it: To build HomeRunHero, we leveraged the latest advancements in machine learning, computer vision, and data analytics. We used Python and TensorFlow to train our machine learning models, and we integrated the app with cloud-based databases to store player data securely. We also have a UX design to design a prototype of this user interface. Challenges we ran into: When we are trying to brainstorm our initial ideas into actual products. Took us too long to think, due to non of us knowing about Baseball. That is the reason of conducting this app to make more people know about it. Accomplishments that we're proud of: we did The UI, UX, Machine Learning and Deck within 3 hours. After 2 hours of brainstorming our ideas in the morning. What we learned: Building HomeRunHero taught us a lot about the challenges and opportunities of using AI in sports coaching. We learned the importance of collecting high-quality data, designing user-friendly interfaces, and integrating feedback from coaches and players to improve the app's performance. The importance of collaboration What's next for HomeRunHero We're constantly working to improve HomeRunHero and add new features to enhance the coaching experience. In the future, w"
      }
    ]
  },
  {
    "file_path": "./devposts/hit-shuffle.html",
    "project_id": "hit-shuffle",
    "title": "Hit Shuffle",
    "tagline": "Music Recommendation Playlist built with the Spotify Open API",
    "hackathon": "",
    "built_with": [
      "apis",
      "nextjs",
      "node.js",
      "react",
      "sass",
      "spotify"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/443/509/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "top 5 tracks hit shuffle thumbnail Home Page Data Collation page top 5 tracks hit shuffle thumbnail Home Page Data Collation page top 5 tracks 1 2 3 4 Inspiration We hoped to build a tool that helps users discover new music based on their moods or emotions and interests. This application uses Spotify's vast library of music and metadata to analyze a user's listening history and create custom playlists that match their current emotional state. \nAdditionally, the application provides features such as lyrics analysis, artist information, and song recommendations based on a user's favorite genres or artists. What it does The application uses Spotify's data and metadata to provide users with personalized and streamlined music experiences. The first version of the application would focus on music discovery and emotional connection, while the second version of the application would focus on music organization and management. How we built it For me to be able to build this application I set up your development environment with next Js, installed the necessary dependencies, built the component I needed for authentication of the application, use the Spotify API to fetch data, build your application UI using React components, before testing and deploying my application. Challenges we ran into Setting up authentication with the Spotify API was quite complex and required a good understanding of OAuth 2.0. It was challenging to properly authenticate my application and obtain a valid access token. The Spotify API also has some limitations, such as rate limits on requests and restrictions on certain endpoints. It wasn't easy to work within these limitations and optimize my requests to minimize API calls. The data structure returned by the Spotify API was in fact very complex and nested, which made it difficult to parse and work with. However, it wasn't as challenging to properly map the data to your application's state and update my UI dynamically. Accomplishments that we're proud "
      }
    ]
  },
  {
    "file_path": "./devposts/hyperlink-rp43wd.html",
    "project_id": "hyperlink-rp43wd",
    "title": "HyperLink",
    "tagline": "Internet everywhere. Yes, even there.",
    "hackathon": "",
    "built_with": [
      "google-maps",
      "heroku",
      "node.js",
      "stellar",
      "twilio",
      "wolfram-technologies"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/662/801/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Stellar Query Maps Browser Stellar Query Maps Browser Stellar 1 2 3 4 5 What is HyperLink https://agitated-colden-9b9902.netlify.app Everyone is addicted! Even you... Everyone is constantly looking at our phones. Everywhere we go... our phone comes with us. Although we may not want to admit it, we have become dependent on our phones, and our phones are so smart that we no longer have to be. Our phones connect us to the rest of the world, so we don't need to leave our homes. Our phones tell us where to go, so we don't even need to know where we are. Our smartphones are control our lives. Our phones are smart; however, our smartphones have a fatal flaw... Our phones need reliable internet access. It's time to address this flaw. We are expanding internet access to people who have little to no access to wifi or cellular data, through the power of existing SMS infrastructure. What it does Our service provides the ability to query questions, search for directions using google maps, load browsers, and access the stellar network over text. Information, directions, and real-time financial network for millions of people all around the world. Try It! Text: (415) 915 -2172 Commands: How’s the weather in Dallas? https://Wikipedia.com maps “Dallas” “Houston” stellar balance | pay | create | fund | list Ask Questions Looking for some quick info? Ask away! Get Directions Lost? Get directions anywhere Surf the Web No wifi? No problem, open and interact with webpages Receive or Make Payments No online banking? Make transactions all around the word with Stellar How we built it We used a Twilio SMS service for the core of our program and linked the Wolfram Alpha API, Google Maps API, and Horizon API for access to queries, directions, and the stellar network respectively. Built With google-maps heroku node.js stellar twilio wolfram-technologies Try it out GitHub Repo Submitted to Pinnacle 2021 Created by I worked on integrating our service with the Stellar Network, working with the Stel"
      }
    ]
  },
  {
    "file_path": "./devposts/homie-hub.html",
    "project_id": "homie-hub",
    "title": "Homie Hub",
    "tagline": "Homie Hub is a modern video chatting application that allows users to get into virtual meetups with others that share similar interests and can enrich their conversations with a random topic generator",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by Izaan Qaiser Saubaan Hasan [Student] Shayaan Tanvir",
      "Hack With A CrewWinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/138/618/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration\nWith national friendship among us this week, us at the Homie Hub team have worked diligently to bring our envisioned multi platform matchmaking video chat application Homie Hub a reality. We gained inspiration for our build from our personal experiences with video chat software. We have come to find other matchmaking sites unoptimized and we took a stand by redesigning the concept What it does\nWhen a user opens up Homie Hub through their browser of choice, they are greeted with a signup/login page where the user is able to create a brand new account or login with an existing one. Once the user has passed the login screen, they are shown the preliminary match making questionnaire where users are asked some general info as well as basic questions in regards to their personalities. Once completed, they are finally met with Homie Hub’s Main feature; the video chat room. Shortly after the user has joined the room, they are able to get to know one another and utilize the prompt feature that provides randomly generated icebreakers as they converse to spice up the conversation. Finally once the user is satisfied with their time, they are able to leave the call. How we built it\nWhen originally deciding on a language/platform to build our application, we settled on building it around HTML/CSS/JS because we feel that a web application would be most accessible for future friends across the globe. To further expand the reach, we also used the swift language along with its Webkit user interface to integrate the website version of Homie Hub into a much more mobile user friendly interface in the Homie Hub Application. Aside from the major coding languages used, we took advantage of Google's firebase service to help us create an online database to house all of our user data including the authentication through email and password. When it came to the actual Lastly, we utilized Agora the online video chat service to bring the chatroom aspect to life and in th"
      }
    ]
  },
  {
    "file_path": "./devposts/homify-7czehr.html",
    "project_id": "homify-7czehr",
    "title": "Artisian",
    "tagline": "Become a Professional Artist in less than 60 seconds",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python",
      "pytorch",
      "stable-diffusion"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Become a Professional Artist in less than 60 seconds"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/304/657/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "AFTER: \"a futuristic gaming chair in front of winter mountains\" Before: \"a happy snowman in front of mountains\" AFTER: \"a happy snowman in front of mountains\" BEFORE: \"a futuristic gaming chair in front of winter mountains\" AFTER: \"a futuristic gaming chair in front of winter mountains\" Before: \"a happy snowman in front of mountains\" AFTER: \"a happy snowman in front of mountains\" BEFORE: \"a futuristic gaming chair in front of winter mountains\" AFTER: \"a futuristic gaming chair in front of winter mountains\" 1 2 3 4 5 6 Inspiration Do you ever have an idea but don’t know how to visualize it or feel restricted by your lack of artistic ability? Artisian is here to make creativity accessible to everyone. With Artisian, simply draw a rough sketch of your idea (you can also add an optional text prompt), and we'll automatically generate an enhanced version of your sketch, just as if it were drawn by a professional artist! Artisian is extremely straightforward to use so anyone, even a 7-year-old kid, can become a professional artist with a few brush swipes and the click of a button in less than 60 seconds. Currently, there are a few diffusion models available online, but all of them are very limiting (purely text-to-image or image-to-image). None of them provide you with an option to draw on an empty canvas in the way that Artisian does and help you bring a sketch to life in less than a minute. What it does Our application adapts a simple and easy-to-use user interface. You start off on a blank canvas, on which you can draw using our selection of painting tools and colors. After you are done drawing, you can add additional information by typing a description of your drawing in the text box below. Then, click the generate button. This will take a capture of the drawn canvas and feed it into our diffusion model, which will process and generate a refined and high-quality image of your original sketch. How we built it We first wireframed/prototyped our design using Typedream and"
      }
    ]
  },
  {
    "file_path": "./devposts/hox.html",
    "project_id": "hox",
    "title": "HOX",
    "tagline": "enable people to visualize metadata in webAR or WebVR with multiusers session to facilitate meeting and help builders",
    "hackathon": "",
    "built_with": [
      "c#",
      "css",
      "javascript",
      "meta",
      "mira",
      "unity",
      "websocket"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/615/206/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "HOX HOX HOX 1 2 Inspiration We would like to create a paperless and sustainable workflow that allows builders to access metadata needed on the building site during the construction process and we want this workflow available in real time. In this way we can display the evolution of the information. That it is why we call HOX, from the homeobox hox gene that carries the main data and transfers them from parents to children. This is a framework that can enable multiple workflow in the industry. What it does This hack enables realtime workflow for a WebAR and WebVR experience. In this way it is possible to access all the metadata from a BIM model (whatever format it is: .obj .fbx .ifc .bxf .jsone) and transfer to SVF file through the FORGE Autodesk Platform. In this way, all the workflow through 3DMax, Unity, all the remodelling of materials, the textures will happen automatically in real-time. The most important part is that we have created a remote control for the user's experience. So the builder on site can be guided as to what he needs to do and he can access all the required information. This also allows for multi-users meetings around the same virtual model in a virtual environment that can be for VR or AR. In this special occasion, we focused on the Mira Headset for its ability in offering a cheap solution in the market. How I built it We used a Revit file and built the application with Visual Studio Code and Unity 2017.01.3. We used GitHub for the version control and to collaborate in a more efficient way. We deployed the app in Heroku and we also used the WebSocket format in order to transfer the real time state. We build also for Mira Headset for their democratic and open approach in the technology. Challenges I ran into The most challenging part is storing the Id and the Camera quaternion from the Forge Session in an external database and passing this to Unity. In Forge the model is loaded on the fly inside an empty game object and every single operation sh"
      }
    ]
  },
  {
    "file_path": "./devposts/helpr-n9gu0i.html",
    "project_id": "helpr-n9gu0i",
    "title": "Git Voice",
    "tagline": "NO! I won't type out my git commands >:(",
    "hackathon": "",
    "built_with": [
      "express.js",
      "git",
      "ngrok",
      "typescript",
      "voiceflow",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/346/705/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Alpha on Phone Voiceflow flow of commands Alpha on Phone Voiceflow flow of commands Alpha on Phone 1 2 3 4 5 6 Welcome to Git Voice! Git voice is a VS Code plugin which uses Voiceflow and Google assistant to execute Git actions remotely from any device using your voice! Increase your productivity and maximize comfort by integrating smart voice assistant features into your workflow. Inspiration We saw that there was a lack of user-friendliness in the current Git repository system. This inspired us to make Git commands more accessible with simple inputs to get the same desired effects. Enter Git Voice : An easy way to perform Git actions with simple words and phrases. All processed in an intuitive and convenient interface integrated into Visual Studio Code. Voiceflow Usage The Voiceflow API was imperative for us to develop this program. Its intuitive platform that enables intuitive and convenient logic flow control voice assistant allowed us to complete this project in such a short span of time. Moreover, HTTP support in the API made it possible for Git Voice to work from any remote location. Our program centers directly around Google Assistant, and Voiceflow allowed us to achieve our goal. How We Built It VS Code Plugin To start, we scaffolded a TypeScript VS Code extension. We then integrated Express.js to listen for requests sent from Voiceflow/the Google Assistant app. Since our local network is not exposed to the cloud Voiceflow API, we integrated ngrok, an HTTP tunneling service, into our plugin to make our VS Code instance accessible from the cloud . When the plugin receives a message from Voiceflow, it runs Git commands specified by the message inside VS Code's working directory. Google Assistant and Voiceflow To incorporate Google Assistant into our VS Code Plugin, we used the Voiceflow API to control the logic flow between receiving commands and sending HTTP requests. Depending on the given command, the API would send a HTTP request to the plugin (via the tu"
      }
    ]
  },
  {
    "file_path": "./devposts/hobnob.html",
    "project_id": "hobnob",
    "title": "Hobnob",
    "tagline": "Hobnob is a networking extension tool meant to serve as a partner to your day-to-day life in university, helping you to elevate your portfolio by expanding your professional connections.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "linkedin-developer-api",
      "mongodb",
      "nextjs",
      "openai",
      "rest",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/951/902/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Individual Event Page Tutors page 2 Home page 1 Home page 2 MongoDB Cluster Events page 2 Tutors page 1 Invidual Tutor Page Events page 1 Individual Event Page Tutors page 2 Home page 1 Home page 2 MongoDB Cluster Events page 2 Tutors page 1 Invidual Tutor Page Events page 1 Individual Event Page 1 2 3 4 5 6 7 8 9 10 Inspiration As university students, it's hard to find time in our busy schedules to learn about  events happening in our area, costing us precious opportunities to network and finding professional prospects. What it does To combat this, we created Hobnob, a networking extension tool that allows you to be updated on current events and opportunities happening around them, matches them with people with similar interests and profile using AI. Additionally, it upgrades your personal tool set through the Tutor system, ultimately enhancing your portfolio! How we built it We built it using NextJS and ReactJS frameworks, implementing the MongoDB APIs to create users and get users. We also used vectorized search function to match users together, while all the application data is processed onto, stored from, and retrieved from MongoDB using Rest API.\nWe used NLP for matching people going for a particular event with a specific reason based on their profile and history. Challenges we ran into Initially, we ran into an issue with the LinkedIn 3-Legged Authorization. However, we were able to overcome this issue and continue forward. Accomplishments that we're proud of Before, we used vectorized search on Pinecone. But this time, we used it on MongoDB, which was a new and exciting experience! What we learned We learnt that vectorized search is better on MongoDB. What's next for Hobnob The next step for Hobnob is becoming an official partner with LinkedIn, planning out a business model for the website, and pushing out new firmware and software updates to finalize the project, and bring it to launch! Built With express.js linkedin-developer-api mongodb nextjs openai rest"
      }
    ]
  },
  {
    "file_path": "./devposts/history-of-video-games.html",
    "project_id": "history-of-video-games",
    "title": "History of Video Games",
    "tagline": "A website about the history of video games.  Has demos of Spacewar, Pong, Space Invaders, and Super Mario Bros.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Video games have helped me grow into the person I am today.  Through video games, I was able to truly appreciate the art of storytelling and worldbuilding.  Because of video games, I learned to communicate with others, whether they were teammates or classmates. \n Video games inspired me to learn to code, helping me find the passion for it I have today.  This hackathon has finally given me a chance to pay homage to the thing that has helped me: our team created a website dedicated to the history of video games.  Please enjoy! What it does Our website goes over the history of video games, and demos some of the most influential and famous ones!  We have 4 demo games: Spacewar, Pong, Space Invaders, and Super Mario Bros. How we built it JS/HTML/CSS Challenges we ran into CSS Styling was particularly hard for us, since none of us had a solid background in it.\nAlso video upload is trolling but it is ok now Accomplishments that we're proud of We were really proud of the Super Mario Bros. game!  It was relatively complex to make and took a long time to get right. What we learned We all learned a bit more about CSS and fonts to spice up the web pages. What's next for History of Video Games We might add more demos in the future and write more detailed descriptions Built With css3 html5 javascript Try it out history-of-games.archimedesli.repl.co replit.com Submitted to HackBytes Created by Archimedes Li Kyle W"
      }
    ]
  },
  {
    "file_path": "./devposts/homeclinic.html",
    "project_id": "homeclinic",
    "title": "HomeClinic",
    "tagline": "Virtual healthcare is booming, but it is not working. Testing is key!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "nextjs",
      "react-native",
      "tailwind",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Future of Healthcare by DatavantWinnerRunner up",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/218/833/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Patient Mobile App - Home Screen Patient Mobile App - Dashboard / AI Nurse / Video Call Patient Mobile App - How to test Instructions Doctor's Web App - Dashboard / Patient Call Doctor's Web App - Predictions Tab Doctor's Web App - Predictions Tab Patient Mobile App - Home Screen Patient Mobile App - Dashboard / AI Nurse / Video Call Patient Mobile App - How to test Instructions Doctor's Web App - Dashboard / Patient Call Doctor's Web App - Predictions Tab Doctor's Web App - Predictions Tab Patient Mobile App - Home Screen 1 2 3 4 5 6 7 Inspiration Virtual healthcare has the potential to improve the lives of billions of people. 80% of doctors are coming online, but without integrated, affordable at home blood testing their services are severely limited. This is where HomeClinic comes in: One of our team members, Lukas, has a thyroid disorder and has experienced the difficulty of managing his medications waiting weeks for lab results and appointments. We envisioned a future that would empower Lukas and 150 million other Americans with chronic conditions to be in control in managing their conditions from the comfort of their own home: Feeling symptoms? Call our AI nurse, get connected to an on-call doctor and test at home for a quarter of the cost! We identified a testing gap that exists in the US. where millions of people are unaware of their conditions due to infrequent testing. 38% of the US population are pre-diabetic and more than 80% don’t know they have it. Similarly, more than 12% of the US population will develop a thyroid condition during their lifetime and 60% of those are unaware of their condition. Data provided by Datavant also shows that different HRR regions vary in its Percentage of Diabetic Medicare Enrollees Receiving Blood Lipids Testing ranging from 51.8% ~ 89.4%, Percent of Diabetic Medicare Enrollees Receiving HbA1c Testing ranging from 94.6% ~ 69.6%, Percent of Medicare Enrollees Having Annual Ambulatory Visit to a Primary Care Clinician 59.6% "
      }
    ]
  },
  {
    "file_path": "./devposts/how-to-clean-oceans.html",
    "project_id": "how-to-clean-oceans",
    "title": "How to clean oceans",
    "tagline": "we have not inherited this earth from our ancestors but has borrowed it from our next generation",
    "hackathon": "",
    "built_with": [
      "css",
      "html"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Domain Name from GoDaddy Registry [APAC Only] SF Hacks 2022 Created by Gourav Sharma I like to code",
      "Best Domain Name from GoDaddy Registry [APAC Only] SF Hacks 2022 Created by Gourav Sharma I like to",
      "Tidy The Hack Up IIWinnerBest Domain Name from GoDaddy Registry [APAC Only]",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Desire to do something for environment and highlight the problems and there solutions What it does It shows you what humans have done to planet and destroyed oceans  and what we are doing to save it now as realized our past mistakes How we built it By using HTML and CSS Challenges we ran into As a new comer and a student in high school lack of experience was the major challenge I faced Accomplishments that we're proud of What we learned many new things about coding and environment What's next for How to clean oceans expanding it knowledge and making it more ease to use and more motivated for those who want to protect earthg Built With css html Try it out gourav015.github.io GitHub Repo Submitted to Tidy The Hack Up II Winner Best Domain Name from GoDaddy Registry [APAC Only] SF Hacks 2022 Created by Gourav Sharma I like to code"
      }
    ]
  },
  {
    "file_path": "./devposts/howdyhack-2023-devpost-submission-demo.html",
    "project_id": "howdyhack-2023-devpost-submission-demo",
    "title": "howdyhack 2023 devpost submission demo",
    "tagline": "this is the demo for the howdy hack 2023 devpost submission demo.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration blah blah bah What it does blah blah bah\nblah blah bah\nblah blah bah How we built it blah blah bah\nblah blah bah\nblah blah bah\nblah blah bah Challenges we ran into blah blah bah Accomplishments that we're proud of blah blah bah\nblah blah bah\nblah blah bah What we learned ez What's next for howdyhack 2023 devpost submission demo blah blah bah\nblah blah bah Built With css html react tailwind Try it out GitHub Repo Submitted to HowdyHack 2023 Created by Anjali Kumar Anish Karthik CS Junior interested in AI Disc: anishfish#5103 Old Devpost Acc: anishfish"
      }
    ]
  },
  {
    "file_path": "./devposts/homestead-hfgjmn.html",
    "project_id": "homestead-hfgjmn",
    "title": "Homestead",
    "tagline": "All in one, data-driven mortgage assistance and calculation",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "python",
      "reactnative"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackUTD XWinnerFannie Mae",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/659/516/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Interesting result! Home Page! Static Analysis Enter your own stats! PCA analysis Interesting result! Home Page! Static Analysis Enter your own stats! PCA analysis Interesting result! 1 2 3 4 5 6 Homestead: Empowering Financial Mortgage Decisions Inspiration The inspiration behind Homestead stems from the need to simplify and empower individuals in making informed decisions about mortgage assistance. We aimed to leverage data provided by Fannie Mae to build a comprehensive financial mortgage assistance calculator. Our goal was to make a mobile application that made it easier for immigrants and others who might not be familiar with the complicated landscape that is mortgage financing in an all in all platform. What it does Homestead is a robust application designed to calculate crucial financial metrics such as Loan-to-Value (LTV), Private Mortgage Insurance (PMI), Debt-to-Income ratio (DTI), and Federal Debt-to-Income ratio (FedDTI). The application utilizes Flask for the backend and React Native for the frontend, providing a seamless user experience. Users can input various parameters, including credit score, monthly mortgage payments, appraisal value for the home, and additional factors like car payments. The app then calculates the likelihood of loan approval based on these parameters, offering users valuable insights into their financial eligibility. To further enhance user experience, we integrated OpenAI to provide personalized recommendations for users aiming to improve their chances of loan approval. This allows people a direction in which to look for possible improvements and concrete actions they can take without feeling lost. Moreover, we hand crafted a tutorial section to help explain the basics of the finances and statistics that might be lost on a beginner. Additionally, a resources tab offers hard links for more information, and a direct link to Zillow generates a map showcasing homes with appraisal values eligible for loans. Then, users can see locat"
      }
    ]
  },
  {
    "file_path": "./devposts/hospitally.html",
    "project_id": "hospitally",
    "title": "Hospitally",
    "tagline": "To help those that help others by maximising inventory efficiency and preventing 1.6 million theoretical cases of insufficient care",
    "hackathon": "",
    "built_with": [
      "c++",
      "css3",
      "flask",
      "html5",
      "python",
      "qt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/949/715/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Inspiration When we saw the prompt, we decided to take a deeper interpretation of creating a bright future. Rather than developing a new tool to help the community, we decided to help those that already help people -- Doctors. Hospi-tally is a Software created to solve hospital resource mismanagement. It organizes and guides the use of medicine in order to faciliate organized medicine and turn the hospital from a fearful, scary environment to a stress free environment. What it does straightforward inventory system for drugs and surgical instruments How we built it HTML, CSS, JS, Python, Flask.py, QT, C++ Built With c++ css3 flask html5 python qt Try it out GitHub Repo Submitted to LancerHacks Created by Surya Jasper Theo Sprouse Shlok Shah"
      }
    ]
  },
  {
    "file_path": "./devposts/hospichain.html",
    "project_id": "hospichain",
    "title": "HospiChain",
    "tagline": "Track resources using blockchain and alert the government of shortages",
    "hackathon": "",
    "built_with": [
      "express.js",
      "gun.js",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Place Created by Ching Lam Lau Zofia Li Private user",
      "Hack the PulseWinnerFirst Place",
      "Track resources using blockchain and alert the government of shortages",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/869/272/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Pretend it’s 2020 again. Prices are rising, hospitals are running out of supplies. Frustration ensues as covid cases broke out, danger heighted by the lack of resources to help. There was no single clear line of communication between hospital and government, and even then, data often got misput and lost. Since then, it’s been two years-- and the system still isn’t any better. So, what could we do? Enter HospiChain. What it does HospiChain informs the government of any lack of supplies encountered by a hospital in their zone of care. It shows them the urgency of the supply, so they can have a priority list while considering demands. Using blockchain technology, HospiChain allows information to get from hospitals to the government faster and simpler, informing each other of their needs. How we built it All of our data, including the hospital resources and user accounts, is stored in a Gun.js database. The React frontend renders the ui and handles all the updates and queries to the database. The app uses react-styled-components for styling the ui and react-router-dom for handling the routes. We created a peer for the database using an Express.js server, which can also be used to add new users and data to the same decentralized database. Front End React.js react-styled-components react-router-dom Blockchain Express.js Gun.js Challenges we ran into We were all new to Blockchain, so we had to research it and learn how we could implement it into our web application. We used a decentralized database, Gun.js, which we had to figure out how to use. We read through its documentation many times and spent hours setting up the database as well as debugging queries to the database, which often did not return the expected data. We also had trouble coming up with a fitting color scheme. Accomplishments we’re proud of We developed a working web application with all the main functionality we planned for in under 36 hours (while being sleep deprived for almost the"
      }
    ]
  },
  {
    "file_path": "./devposts/heart-of-the-sea.html",
    "project_id": "heart-of-the-sea",
    "title": "HeART of the Sea",
    "tagline": "Jack Sparrow with his fellow crew mates is out to find that precious treasure that lies within the sea!! Join him along this adventure and find the treasure..!!",
    "hackathon": "",
    "built_with": [
      "github",
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hidden Treasure Hack Global Hack Week: INIT 2023 Day 3 Global Hack Week: INIT 2023 Day 7 Created by",
      "AhoyHacksWinnerHidden Treasure Hack",
      "We made this awesome-looking game, although this was our first time!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/931/454/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "SEE IT'S THE FLYING BLACK PEARL Home Screen (Jack Sparrow is here to welcome you!) When you die in the game.. The Treasure!! While playing the game.. SEE IT'S THE FLYING BLACK PEARL Home Screen (Jack Sparrow is here to welcome you!) When you die in the game.. The Treasure!! While playing the game.. SEE IT'S THE FLYING BLACK PEARL 1 2 3 4 5 GitHub Developer Tools Visual Studio Code, GitHub 💡Inspiration💡 Pirates of the Caribbean! Who doesn't like that movie!! Games are really fun and are absolute mood freshers, so we tried to combine games with the Pirates of the Caribbean movie!! ❓What it does❓ You're controlling the ship to avoid enemies and get that precious treasure... You can make the ship jump by pressing SPACE (pretty hilarious but it's fun!!) and collect a particular amount of score to get the treasure!! 🏗️How we built it🏗️ We build the project using the Pygame and Python language !! 🚧Challenges we ran into🚧 We all are new to Pygame and didn't have that much of experience with Pygame. The progress was really slow in the beginning but we pulled it off nicely! 🏅🏆Accomplishments that we're proud of🏅🏆 We made this awesome-looking game, although this was our first time! 📚🙋‍♂️What we learned📚🙋‍♂️ Pygame and the logic behind game development! It was a very rich learning experience. 💭What's next for HeART of the Sea💭 More levels, more furbished and smooth, and more enemies!! Built With github pygame python Submitted to AhoyHacks Winner Hidden Treasure Hack Global Hack Week: INIT 2023 Day 3 Global Hack Week: INIT 2023 Day 7 Created by Moon . Kalash Jain Zohãib R. Oladeji Fagbewesa"
      }
    ]
  },
  {
    "file_path": "./devposts/hi-u1mds7.html",
    "project_id": "hi-u1mds7",
    "title": "LocalChain Catalyst",
    "tagline": "Empowering Blockchain Innovators: Streamline Proposal Submission, Voting, and Milestone Tracking for a Collaborative Community",
    "hackathon": "",
    "built_with": [
      "blockchain",
      "css",
      "html",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/484/920/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our project, developed for the Waterloo Blockchain Hackathon, is a blockchain-related website aimed at facilitating the proposal submission, voting, and milestone tracking process. The website comprises several key pages, including Home, Submit a Proposal, Vote on Proposals, and Milestones. The Home page serves as an information hub, providing details about the project, its objectives, and the overall concept. It offers visitors a comprehensive understanding of the platform's purpose and functionality. The Submit a Proposal page enables participants to submit their project proposals. It features multiple input text boxes for essential information, such as the Name of the Proposal, Proposal Category, and Description. Additionally, participants can upload an image related to their proposal. To ensure community engagement, a checkbox is included, requiring participants to acknowledge that their proposal must attain a certain number of votes before the community proceeds with it. The Vote on Proposals page allows users to cast their votes for the submitted proposals. Users can review the proposals, assess their merits, and vote for the ones they find most promising. This democratic approach ensures that the most popular and supported proposals receive the necessary attention. The Milestones page showcases a status progress bar for each specific proposal. It visually represents the various milestones and tracks the progress of each proposal, providing participants and the community with a clear overview of the project's advancement. Inspiration: Our inspiration for this project stems from the need to streamline the proposal submission and voting process within the blockchain community. We aimed to create a platform that encourages collaboration and community involvement while ensuring transparency and accountability throughout the project lifecycle. What it does: Our website acts as a centralized platform for proposal submission, voting, and milestone tracking. It empowe"
      }
    ]
  },
  {
    "file_path": "./devposts/how-s-it-growing-b61z45.html",
    "project_id": "how-s-it-growing-b61z45",
    "title": "How's It Growing?",
    "tagline": "Your go-to for getting the most out of your harvest.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "jquery",
      "twilio",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Winner Best Domain Name from Domain",
      "Harvest HacksWinnerThird OverallWinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/295/505/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 👩‍🌾 Inspiration COVID led to a resurgence of interest in gardening worldwide, as people grew plants to stay physically and mentally healthy, relieve stress, and quell worries about food shortages or rising food costs. While gardening can be done in isolation, it often isn't. Gardening offers a way to socialize safely outdoors. In community gardens, growers are part of a community. Some gardeners with access to large spots to garden also grew food for their community. 📚 What it does How's It Growing is a Wix social platform that connects growers with other growers and provides access to a knowledge center via SMS or a phone call through Twilio. 👩‍💻 How we built it We built the website using Velo by Wix and integrated it with Twilio for the chatbot q&a that offers same info as knowledge center. 😩 Challenges we ran into As a team of majority novice hackers, coming up and agreeing on an idea, building around it, and ensuring that we all had the same vision took several tries, and we overcame that with regular check in and communications and progress reviews. We also had to coordinate a bit with different time zones. ' There were some features we talked about there were not implemented on the front end, but we coded the back end portion for it, and it was too close to the deadline to test before publishing. Nevertheless, we figured a lot out and implemented many features! 🕸 Accomplishments that we're proud of For most of us, this is our first time exploring Wix, how it can create a sleek webpage quickly, and the expanse of its widgets and integrations. 🎓 What we learned For the majority of us, we hadn't used Wix before so we learned the ins and outs of navigating Wix and how collaboration works best when Wix only allows for one editor to be editing the page at a time. We also paved our way in learning how to manage a project and not wait last minute. We also had a lot of discussion about design and user experience and how the product works together to create meaningf"
      }
    ]
  },
  {
    "file_path": "./devposts/imagery-ai.html",
    "project_id": "imagery-ai",
    "title": "illus.ai",
    "tagline": "Image editing made consistent, as easy as a conversation ~\nNo more inpainting and writing complex prompts yourself. From photos to illustrations, modify any image, through chatbots.",
    "hackathon": "",
    "built_with": [
      "flask",
      "huggingface",
      "idc",
      "intel",
      "jupyter",
      "machine-learning",
      "openai",
      "python",
      "pytorch",
      "reflex"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/932/719/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "starting point image after adding sunglasses starting point image after adding sunglasses starting point 1 2 3 illus.ai Introducing our startup: illus.ai ~ Image editing made consistent, as easy as a conversation \nNo more inpainting and writing complex prompts yourself. From photos to illustrations, modify any image, through chatbots. Inspiration In today’s digital age, visual content is king, but creating and modifying it remains a cumbersome and technically demanding task, particularly when fine details or complex modifications are needed. The existing solutions like stable diffusion models offer some respite, but they falter when tasked with precise, efficient, and versatile image editing. For instance, when using models integrated with platforms like ChatGPT for image inpainting, users often find that the modifications are inconsistent, especially with background retention. This led us to identify a significant gap in the market: the high cost and time investment required when outsourcing image editing to professional designers, and the technical barrier for everyday users needing advanced image modifications. Problem: Inconsistent Editing by Existing AI: Current AI systems, including those used for inpainting in ChatGPT, often produce inconsistent results, failing to maintain background continuity or apply nuanced changes effectively.\nSolution: illus.ai leverages LEDITS++, an advanced model that ensures precise edits without altering the image's background, significantly improving consistency. Problem: High Resource Consumption for Artists: Artists often have to redo entire sections of their work to adjust or visualize different outcomes, which can be resource-intensive.\nSolution: With ControlNet, artists can input basic sketches and receive fully rendered image suggestions based on their prompts, streamlining the creative process. Our Vision We aim to revolutionize the design industry by replacing traditional design agencies with our AI-driven solutions, makin"
      }
    ]
  },
  {
    "file_path": "./devposts/hyperx-yinyang-i.html",
    "project_id": "hyperx-yinyang-i",
    "title": "HyperX YINYANG I",
    "tagline": "the perfect balance.",
    "hackathon": "",
    "built_with": [
      "canva",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Place Created by Sophie Yang",
      "DesignXWinnerFirst Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/224/220/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Each year, the IT peripherals industry generates just about 200 billion USD in revenue. Yet, with the hundreds of models and different kinds of headsets available to be bought, there is little innovation that differentiates one headset from another. That is precisely why the HyperX YINYANG I model was created- to bring something new, and to ultimately revolutionize how gamers and average joes come to use headphones. The model is made to focus on ergonomics and practicality. In conducting research and looking at the current standards of hundreds of headphones, the YINYANG I model takes all the industry's best features- and adds to it. Specifically, not only is this headset noise cancelling, has wired/wireless options, industry-standard compatibility a well-designed microphone/padding, but it NOW introduces: heating/cooling settings within the headphones, fidget buttons on the headset and adjustable noise cancelling levels. How we built it The designing and pitching were all done through Canva and Wix. Challenges we ran into I had initially wanted to try Blendr in order to create a 3D model. However, (and truthfully) I significantly underestimated how much time it would take to familiarize myself with the software. In the end, I decided to prioritize the expansion of the actual features, as opposed to the model. What's next for HyperX YINYANG I There is a reason why it's the first edition! We have so much more planned for this model- in the next release you can expect a lighter model and more features centered around the product ergonomics. Built With canva wix Try it out sophieyang12345.wixsite.com www.canva.com Submitted to DesignX Winner First Place Created by Sophie Yang"
      }
    ]
  },
  {
    "file_path": "./devposts/insight-ai-3189eo.html",
    "project_id": "insight-ai-3189eo",
    "title": "Insight AI",
    "tagline": "InsightAI transforms education with eye-tracking and gesture control, providing real-time insights and seamless task management. Experience the future of learning with InsightAI!",
    "hackathon": "",
    "built_with": [
      "javascript",
      "python",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Using 1 camera for 2 processes (eye-tracking and gesture-tracking)",
      "Eye-tracking and gesture-tracking"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/930/949/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Inspiration Have you ever been stuck when reading because you don't understand a word or a formula? You might be a 6 year old reading an english book or a college student reading a 500 page physics paper. You need to read through that while taking notes, solving questions that you might have, Copy and pasting to ChatGPT just to get your answer explained vaguely. With our app, you can do all of that with a simple gesture, and it can automatically detects if you are stuck on one thing using eye tracking. What it does InsightAI is a visionary AI assistant focused on education. By performing eye-tracking to find where and what the user is reading, our product can offer real-time insights. Moreover, we integrated in gesture control so the AI can complete tasks for the user. Gesture triggered tasks include taking a screenshot, flipping to the next page, flipping to the previous page, asking a question, and writing notes. Moreover, our AI can analyze the emotions of the user and offer responses accordingly with the goal of instilling confidence in our users. Overall, InsightAI offers a seamless reading experience! How we built it InsightAI was built on using ReactJS on the frontend and Python on the backend. We used an eye tracking called Eyegazer, to get initial estimates of where the eyes are focused on the screen. Then, we apply a Bayesian prior to bias it towards selecting words that appear after the previously seen word. We then combine it with a hand gesture detection using by applying Transfer Learning to find the 21 hand landmarks, then we check what pose we are doing based on the position of landmarks. Then we implemented a RAG pipeline system connected to an LLM that uses HUME AI for sentiment analysis and have 2 prompts that take emotion, eye tracking, and hand gesture into consideration. Challenges we ran into Connecting backend and frontend :( Using 1 camera for 2 processes (eye-tracking and gesture-tracking) Creating dynamic bounding boxes for ea"
      }
    ]
  },
  {
    "file_path": "./devposts/hope-simulation.html",
    "project_id": "hope-simulation",
    "title": "Hope Simulation",
    "tagline": "Mental health training with heart",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "hume",
      "mongodb",
      "next.js",
      "recall",
      "zoom"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/930/329/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration ✨ Our inspiration stems from personal experiences and direct industry needs. One team member's involvement in suicide prevention training highlighted the urgent need for more effective mental health support. Additionally, conversations with Microsoft revealed a critical demand for improved technical support training. These insights drove us to create Hope Simulation, aiming to address both mental health and technical training through innovative, interactive simulations. Problem Current mental health training programs are ineffective. Platforms like Kognito and MindWise offer fixed video-based scenario training with multiple-choice assessments that fail to engage users or foster deep understanding. Solution 🛠️ Our platform, Hope Simulation, offers a more effective and realistic approach through simulated learning in situational scenarios. This method is supported by the latest Learning Sciences research, which shows that situated learning and worked examples enhance student engagement and comprehension. For instance, Chris Piech's GPTeach paper highlights the effectiveness of interactive and realistic teacher training using GPT-based students, demonstrating the value of simulated environments for learning. Market Potential Service Obtainable Market (SOM): We can target colleges and universities globally. There are approximately 1,900 to 2,673 universities worldwide that participate in these rankings alone (Times Higher Education (THE)). For the United States specifically, there are around 4,000 universities. If we charge each institution $5,000 annually and target even 10% of U.S. universities (400 institutions), this could yield $2 million annually. Service Addressable Market (SAM): Expanding our reach to high schools and colleges globally can significantly increase our potential market. There are over 15,400 universities in Asia, 5,565 in Europe, and 5,315 in North America, totaling approximately 26,280 universities worldwide (AUBSP). By targeting 10% o"
      }
    ]
  },
  {
    "file_path": "./devposts/intelliconverse.html",
    "project_id": "intelliconverse",
    "title": "IntelliConverse",
    "tagline": "Comprehensive learning, fostering effective communication and empowering users one word at a time.",
    "hackathon": "",
    "built_with": [
      "azure",
      "express.js",
      "microsoft-cloud",
      "mongodb",
      "mui",
      "nextjs",
      "openapi",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of MongoDB Atlas Created by Bill Z I love conversational ai, its like a drug, I cant get e",
      "HackDavis 2023WinnerBest Use of MongoDB Atlas",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/484/934/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "IntelliConverse IntelliConverse is a project using Chat-GPT to assist individuals with learning disabilities (like dyslexia and ADHD) and reading difficulties. Our solution offers comprehensive answers through typed and spoken inputs/outputs, fostering effective communication and empowering users to overcome challenges. How we built it Backend Development Approach Custom NextJS server as well as Express Server Routes: Speech to text Text to speech Adding Data to Milvus and MongoDB Querying Milvus and MongoDB Removing Data from Milvus and MongoDB Chat GPT Frontend Development Approach NextJS with Material UI Implemented three chat interfaces Regular chat Voice chat Voice chat with PDF Voice chat with pdf allows the assistant to answer your questions with references from the pdf Things that challenged us: Testing Azure Speech to Text Backend Route: We encountered challenges while testing the integration of the Azure Speech to Text backend route. Ensuring the accuracy and reliability of the speech-to-text conversion posed difficulties during the development process. Recording Frontend Audio for Azure Speech to Text: Achieving high-quality audio and format compatibility was difficult but essential for accurate transcription. Overcoming these challenges involved debugging, troubleshooting, and fine-tuning the recording and conversion processes to ensure seamless integration and reliable performance. Accomplishments Really happy that we managed to successfully implement both the text to speech and speech to text features Allows us to implement a voice chat functionality as well as a voice chat with pdf functionality What we learned We gained insights in audio capture, ensuring compatibility with Azure Speech to Text. Debugging and fine-tuning ensured seamless integration and reliable performance. We enhanced our skills in audio processing and frontend implementation for audio-based applications. What’s next for IntelliConverse Customization and Training: We'll customize t"
      }
    ]
  },
  {
    "file_path": "./devposts/instudy.html",
    "project_id": "instudy",
    "title": "Instudy",
    "tagline": "An app that instantly connects the entire class together",
    "hackathon": "",
    "built_with": [
      "css",
      "etc",
      "html",
      "javascript",
      "json"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This was our very first hackathon, so we got to experience how programming in a competitive environment feels like."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The fact that many students aren't able to talk to the teacher & class quickly outside of school What it does It helps connect the entire class together at a moments notice. How we built it Challenges we ran into Time and server hosting, especially pitching the pitch in like, 4 minutes. Accomplishments that we're proud of Getting it to actually work :) What we learned This was our very first hackathon, so we got to experience how programming in a competitive environment feels like. What's next for Instudy Providing full support for Firefox; implementing Tesseract API. Built With css etc html javascript json Try it out 900d2474.ngrok.io Submitted to WolfHacks 2019 Created by I wrote most of the main code, made the server, and helped with the message format & UI. Arihan Sharma Vaarij Betala Vraj Prajapati I'm a first year Engineering Science student passionate about creating unique solutions and learning more! Kurangi Arora"
      }
    ]
  },
  {
    "file_path": "./devposts/hunt-for-the-art-7dftxm.html",
    "project_id": "hunt-for-the-art-7dftxm",
    "title": "Hunt for the Art",
    "tagline": "Hunt for the Art! is a scavenger hunt with many simple tasks (e.g. do jumping jacks) that a person can perform to reveal pixel art as a reward.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Game Development Hack Created by Xinming Zhang Ryan Lam UWaterloo Physics",
      "Best Game Development Hack Created by Xinming Zhang Ryan Lam UWaterloo Physics",
      "SacHacks IIIWinnerBest Game Development Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/411/765/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Hunt for the Art Hunt for the Art Hunt for the Art 1 2 Inspiration We were inspired by the idea that the pandemic has made many of us over-reliant on technology. We wanted our project to create interactions between the real world and people and reward them for those interactions. We also wanted to create a project that would encourage physical activity and social interactions What it does Hunt for the Art! is a scavenger hunt with many simple tasks (e.g. do jumping jacks) that a person can perform. You would click on individual squares to reveal a task and press done when you have completed the task. Each time you press done, a piece of the pixel art is revealed, representing the progress you’ve made in the scavenger hunt. When all the tasks are completed, you will be rewarded with a completed pixel art. How we built it We compiled a database of the different simple tasks that we wanted to include. Then we built a backend with python that determines the color, task, and completion of each pixel square. We then built a website (using Flask) to display all the squares as well as a way to click each square to reveal its task + mark each task as done. Challenges we ran into Creating a database of tasks that should be included in the scavenger hunt Connected the frontend and backend with Flask Correctly displaying the completed tasks (User interactions) Accomplishments that we're proud of A responsive frontend driven by fast communication between frontend and backend Clear and rewarding pixel art What we learned Learned how to integrate pixel art with complex functions Learned how to be creative with existing concepts What's next for Hunt for the Art! Have cells that aren't square-based (ie. Have triangular and irregular shapes) Allow users to edit/input their own tasks Built With css flask html javascript python Try it out GitHub Repo Submitted to SacHacks III Winner Best Game Development Hack Created by Xinming Zhang Ryan Lam UWaterloo Physics"
      }
    ]
  },
  {
    "file_path": "./devposts/ideahackerlab.html",
    "project_id": "ideahackerlab",
    "title": "IdeaHackerLab",
    "tagline": "Unlock Your Hackathon Success: Ideation Made Effortless at Idea Hacker Lab!",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hacks for HackersWinnerSecond Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/541/807/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "\"Go to the Moon\" part 3 Landing Page How it works Dashboard Ideation Tool - no prompt Ideation Tool - a social media app Research Tool - Why is threads growing so fast? Research Tool- 2024 Presidential election \"Go to the Moon\" part 1 \"Go to the Moon\" part 2 \"Go to the Moon\" part 3 Landing Page How it works Dashboard Ideation Tool - no prompt Ideation Tool - a social media app Research Tool - Why is threads growing so fast? Research Tool- 2024 Presidential election \"Go to the Moon\" part 1 \"Go to the Moon\" part 2 \"Go to the Moon\" part 3 1 2 3 4 5 6 7 8 9 10 11 Inspiration: We were inspired to create IdeaHackerLab by the growing popularity of hackathons and the need for participants to streamline the development process and present their ideas effectively through demo videos. We wanted to provide a platform that modernizes the ideation process, assisting hackers in crafting compelling pitches for their projects by using AI. What it does: IdeaHackerLab is a web app that empowers hackathon participants to create impressive demo videos and develop innovative ideas with ease. Through the integration of the GPT-3 AI model, our platform generates valuable insights and suggestions for users, elevating the quality of their project presentations. Ideation Tool Users start by submitting their hackathon idea to the ideation tool, getting a starting template for how the finished product could look, with a name, and how it was built, giving them the inspiration to pivot and create something with their own vision. They can then use several of the various generation tools to complete their project. Research Generation This tool takes a question as an input and can scrape websites for cited information in a easy to understand format, saving time spent Googling and scrolling through links Image Generation Users can generate their own images to come up with logos or graphics for their project Video Generation All hackathons require a quick demo video, and this tool can help speed up th"
      }
    ]
  },
  {
    "file_path": "./devposts/htn-zq6138.html",
    "project_id": "htn-zq6138",
    "title": "SpectraSphere",
    "tagline": "Turning snapshots into spaces you can actually explore",
    "hackathon": "",
    "built_with": [
      "cohere",
      "gemini",
      "google-cloud",
      "json",
      "lens-studio-sdk",
      "postman",
      "remote-service-gateway",
      "snap-spectacles",
      "snapchat",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Snap: Spectacles AR Hackathon: Game On! Created by Tyseer Toufiq allenngkc Allen Anindya Barua Raed",
      "Hack the North 2025WinnerSnap: Spectacles AR Hackathon: Game On!",
      "Stepping into AR for the first time 🕶️",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/742/907/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "memories uploaded to snap spectacles GIF ar overlay showing entry into story mode GIF memories unfolding as living panels in ar GIF memories reimagined through style filters in ar memories uploaded to snap spectacles GIF ar overlay showing entry into story mode GIF memories unfolding as living panels in ar GIF memories reimagined through style filters in ar memories uploaded to snap spectacles 1 2 3 4 5 🌟 Inspiration It had been years since some of us had last been together in person, and Hack the North gave us that chance. Old friends reconnected 🤝, and through Raed we met Allen, who quickly became part of the group. By the end of the weekend, we were no longer just teammates; we were friends building something meaningful together. As we caught up, we realized how much of our friendship had always been built around storytelling 📖: sharing memories, retelling old moments, and imagining new ones. Stories are more than just words; they are how we reconnect, how we preserve identity, and how we relive what matters most. That realization sparked SpectraSphere ✨. We wanted to make stories something you can not only tell but actually step inside. With Snapchat Spectacles 👓, we set out to reimagine how people experience their own memories, ideas, and imagination. Instead of scrolling through flat images, why not live inside them? 🛠️ What it does SpectraSphere turns your prompts and images into immersive AR stories 🌌 that you can step inside using Snapchat Spectacles. From the user’s perspective, it feels simple and magical: On our TypeScript web app 💻, you start by writing a story prompt or narrating one with your voice 🎙️. You then upload four images 📷 that capture the essence of your story. With a single click, those inputs are sent directly to your Spectacles 📡. Inside Spectacles, your photos appear around you in a rotatable 3D environment 🔄. You can instantly switch between creative animation styles 🎨 such as Ghibli , cyberpunk , comic , and more each reframing your st"
      }
    ]
  },
  {
    "file_path": "./devposts/interactive-3d-portfolio-website.html",
    "project_id": "interactive-3d-portfolio-website",
    "title": "Interactive 3D portfolio website",
    "tagline": "Immerse Yourself: A Dynamic Showcase of Creativity in 3D",
    "hackathon": "",
    "built_with": [
      "mongodb",
      "react",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/496/919/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration The inspiration for the Interactive 3D portfolio website came from the desire to create a captivating and immersive platform for showcasing creative work. Traditional portfolio websites often lack interactivity and fail to engage visitors on a deeper level. We wanted to break away from the static nature of traditional portfolios and provide a dynamic and visually stunning experience for users. What it does The Interactive 3D portfolio website takes users on a virtual journey through a three-dimensional space where they can explore and interact with Chinat's projects. Each project is presented in a visually appealing and interactive manner, allowing users to truly immerse themselves in the work. They can navigate through different sections, view detailed information about each project, and even interact with elements within the 3D environment. How we built it To build the Interactive 3D portfolio website, we leveraged modern web development technologies and frameworks. The website utilizes JavaScript for creating 3D graphics, to render the interactive 3D environment. We combined this with HTML5, CSS3, and JavaScript to create a seamless and responsive user interface. The content and assets were carefully curated and optimized to ensure optimal performance and a visually stunning experience. Challenges we ran into One of the major challenges we faced was optimizing performance while maintaining visual quality. Rendering complex 3D scenes in real-time can be resource-intensive, especially on less powerful devices. We had to carefully balance the level of detail and complexity of the 3D models and textures to ensure smooth performance across different devices and browsers. Another challenge was designing intuitive navigation and interaction within the 3D environment. We wanted users to have a seamless and enjoyable experience while exploring the portfolio, but it required careful consideration of user interface design and implementing intuitive control"
      }
    ]
  },
  {
    "file_path": "./devposts/interviewmonkey.html",
    "project_id": "interviewmonkey",
    "title": "InterviewMonkey",
    "tagline": "Competitive mock interviews, Tailored to any company in the world",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "fastapi",
      "javascript",
      "nextjs",
      "openai",
      "opencv",
      "python",
      "react",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/063/321/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "User Feedback/Rating Thumbnail Creating a room for company canadian tire Joining that room Posture Checking Answering Questions User Feedback/Rating Thumbnail Creating a room for company canadian tire Joining that room Posture Checking Answering Questions User Feedback/Rating 1 2 3 4 5 6 🌟Inspiration The interview process can be unpredictable and stressful, especially when you’re targeting different companies and roles. We wanted to create a tool that makes interview prep more personalized, engaging, and interactive, while simulating a competitive and realistic environment. That’s why we built InterviewMonkeyDuels, combining AI, machine learning, and gamification to offer a unique preparation experience for all skill levels. 🖥️ What it does InterviewMonkeyDuels is a game-changing platform for interview preparation. It lets users host rooms for any company and any role, with a combination of cutting-edge AI and real-time interactivity: Our AI pipeline scans the web for company and role-specific data using Selenium and GPT for page fetching and information extraction, generating relevant interview questions dynamically.\nParticipants can join rooms and compete by answering these customized questions.\nResponses are parsed in real-time by Whisper AI for speech-to-text (STT) and further analyzed by GPT for accuracy and relevance.\nA TensorFlow-based posture tracking system uses machine learning to monitor each participant’s body language, integrating posture feedback into the health-based game mechanics.\nThe LLM then rates each participant’s response and shares the ratings with everyone in the room, creating an interactive and competitive environment.\nThe game-like experience makes practicing for interviews both fun and effective, with each session tailored to the exact company and role being targeted. 🛠️ How we built it We employed a range of advanced technologies to bring InterviewMonkeyDuels to life: GPT powers both the question generation and web page scanning, pulling"
      }
    ]
  },
  {
    "file_path": "./devposts/insurework.html",
    "project_id": "insurework",
    "title": "InsureWork",
    "tagline": "We create a framework to expand the a real-estate insurance business in a seismic zone.",
    "hackathon": "",
    "built_with": [
      "python",
      "r",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackZurich 2020Winner#10 Workshop: McKinsey",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/222/428/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 1. Challenge Your task is to build a model that can predict the extent of damage that has been done to a building after an earthquake, quantified in five grades. For this purpose, you can leverage information such as: Structural characteristics of buildings Building ownership and use Municipality demographic information\nPredicting damage severity will allow recognizing the buildings that will be more affected by the quake and hence help authorities to minimize the loss of life and property in the event of such a disaster happening in the future. 2. Model Insights The model insights need to be translated into clear recommendations. Our approach, model insights and recommendations help in documenting the data processing, feature engineering, final model, and recommendations. We conducted the analysis by identifying the dataset's loopholes and normalising the skewed variables so that they don't give a variance to the dataset allowing the model to fit faster on it. Data Processing: Removing count family variable due to missing value at 260294 position Converting variables into categorical variables and integer values Removing location data (district_id, ward_id) Normalising the data using log transformation (for district ID and other location ID, age_building, height_ft_pre_eq, plinth_area_sq_ft The best model we obtained was using Random Forest without any feature engineering by simply just merging the datasets by building_ids, removing the column for building_ids and running it. However, the more stable model was obtained using C5.0 after normalising the variables to and integer and numeric system and fitting the model over it Feature Engineering: We carried out the following methods to analyse the dataset Correlation Test PCA Analysis Gradient boosting method Tree representations We implemented the following machine learning models for carrying out our multi-class classification Tree based classification Ridge-Lasso Regression C5.0 Implementation Random F"
      }
    ]
  },
  {
    "file_path": "./devposts/insightly.html",
    "project_id": "insightly",
    "title": "Insightly",
    "tagline": "Understanding Research Papers has Never Been Easier Before 🧠⚡",
    "hackathon": "",
    "built_with": [
      "bert",
      "colab",
      "css",
      "flask",
      "google-firebase",
      "html",
      "javascript",
      "jax",
      "love",
      "onnx",
      "python",
      "pytorch",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Particpation Winner XYZ Domain Prize BCHacks 4",
      "BCHacks 4",
      "Spark2Code SpreadLOVE - Join Discord ASAP!WinnerParticpationWinnerXYZ Domain Prize",
      "Best domain from domain.com 🌐",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/313/757/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration 💡 No matter what career field you’re in or how high up you are, there’s always more to learn . Research unlocks the unknowns , lets you explore the world from different perspectives , and fuels a deeper understanding. Reports state that 90% of ideas fail because of lack of research and proper background study . Nowadays for most researchers in academia, reading through different papers has become a hassle . However, it's hard for us to get insight on the same because they are very long and time-consuming to find. This inspired us to create Insightly , a smart webapp where one can effectively analyse research papers and understand key points packed with multiple other AI-based features which you'll follow through the post. But wait? why “Research”? Research is pretty much the base of every hackathon project that one has ever done & will do. But apart from this, let’s discuss the top 10 points for why one should do research. 1. Research expands your knowledge base. 2. Research gives you the latest information. 3. Research helps you know what you’re up against. 4. Research builds your credibility. 5. Research helps you narrow your scope. 6. Research teaches you better discernment. 7. Research introduces you to new ideas. 8. Research helps with problem-solving. 9. Research helps you reach people. 10. Research encourages curiosity. What it does 🤔 Insightly is a productive tool that is used to efficiently examine research papers , without needing to read through the entire paper. It streamlines easy access to published papers and significantly reduces researching time. With this platform, the user can: View summaries of the research paper(s) Find tagged topic headers for the paper Get more info on research topics through Q&A Get sentiment status of the topic See similar paper recommendations Personalized Profiling How we built it ⚙️ Insightly is crafted with 💙. We went with a minimalist approach by building the front-end with HTML , CSS & Vanilla J"
      }
    ]
  },
  {
    "file_path": "./devposts/immerge.html",
    "project_id": "immerge",
    "title": "Immerge",
    "tagline": "Immerge Empowers Refugees to Seek Opportunities and Resources",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "html",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Citro Hacks 2023WinnerBest design",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/535/662/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Immigrants often arrive in a new country with little to no resources, needing to rebuild their lives from the ground up. They face numerous obstacles such as language barriers, unfamiliar cultural norms, and a lack of support. Many struggle to find stable employment opportunities or affordable housing, and the emotional toll of leaving behind familiar surroundings and loved ones can be overwhelming. While many existing apps provide support for refugees, Immerge combines multiple features into one powerful platform. With Immerge, refugees are able to easily access resources such as legal aid, discovering community organizations, medical aid, shelter, refugee helpers, and more! What it does Immerge allows refugees to easily connect with fellow refugees and community members, fostering a sense of belonging and support. The app also provides access to vital resources that enable refugees to overcome challenges and discover new opportunities. How we built it We first built the prototype on Figma and then used HTML and CSS to code the structure and content of the app. We also used Python to code some of the app functions. Challenges we ran into The biggest challenge we faced was collaborating and communicating with each other across different time zones. Our team was also formed relatively late which led to an even tighter time crunch to meet the hackathon deadline. To address these challenges we made sure to regularly update each other on our progress and made sure everyone was able to contribute to the project. Accomplishments that we're proud of We are proud that we were able to have a prototype which included a wide range of diverse and valuable resources for refugees. In a short amount of time, we were able to build a project that addresses the unique needs of refugees and provides them with essential tools. What we learned We learned how to communicate across different time zones and optimize limited time frames which allowed us to develop a strong s"
      }
    ]
  },
  {
    "file_path": "./devposts/intellimailr.html",
    "project_id": "intellimailr",
    "title": "IntelliMailr",
    "tagline": "A website that automates the process of cold emailing employers and professors for internships and research opportunities, using Bootstrap, Flask, and Cohere.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "bootstrap",
      "css3",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "MetHacks 2023WinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/473/271/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Email generator Home screen Email generator Home screen Email generator 1 2 Inspiration Many university and high school students spend countless hours emailing professors and companies for research opportunities and internships, in search of a company or a professor that's the right fit for them. That's why we came up with IntelliMailr, an automatic cold email generator. What it does Based on information provided by the user, Intellimailr generates an email to whichever company of professor the user specifies. How we built it The web application was built using Bootstrap for the frontend, and Flask for the backend. We were able to utilize Cohere's generation features in order to generate the cold emails from user provided information Challenges we ran into We had issues connecting the front and back ends, and did not have enough time to implement all of the features we were hoping for, such as email scraping Accomplishments that we're proud of We're particularly proud of being able to use Cohere's API in an effective and practical manner, as well as being able to create a tool which can be useful to many students. What we learned We learned a lot about web development, about web scraping, and about utilizing various APIs in conjunction with one another. Many of our team members have never done backend web development, so this was an interesting learning experience. What's next for IntelliMailr Unfortunately, during the development process, our team ran into difficulties when attempting to use the Gmail API. As a result, we were unable to automate the process of sending emails to contacts scraped from the internet. If we were to continue this project further, we would love to be able to implement such a feature in order to save time for the user. Another feature that can expand the capabilities of IntelliMailr is the ability to rank professors based on their relevance to the interests of the user. In order to do this, we could utilize Cohere's rerank feature. Built W"
      }
    ]
  },
  {
    "file_path": "./devposts/ifo-twitter-bot.html",
    "project_id": "ifo-twitter-bot",
    "title": "ifo Twitter Bot",
    "tagline": "Automate tweets with ifo Institute Twitter Bot! It summarizes press releases, suggests images & citations, lets you edit posts, and navigates to Twitter. Save time & engage audiences effectively!",
    "hackathon": "",
    "built_with": [
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "3rd Overall Prize, ifoHack Created by Felix Koch Justus Beck Julia Baarck",
      ", ifoHack Created by Felix Koch Justus Beck Julia Baarck",
      "ifoHack 2023Winner3rd Overall Prize, ifoHack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/467/009/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The idea for the ifo Institute Twitter Bot was inspired by the need to streamline and simplify the process of sharing news and press releases on Twitter. We wanted to create a tool that would save time for communications staff while allowing for substantial customisation options. What it does The ifo Twitter Bot automatically generates tweets based on press releases from the ifo Institute. Users supply the URL of a press release, and the bot summarizes the content into tweet length using the GPT-3.5 API language model. It also proposes web-scraped images and citations to illustrate the tweet and allows users to edit the text and select images before navigating to Twitter to post the tweet. How we built it We built the ifo Twitter Bot using Python, Streamlit for the front-end, and the GPT-3.5 API for natural language processing. The app also utilizes web scraping techniques to gather images and citations from press releases. Challenges we ran into Our primary challenge was to create a bot that provided real value to the ifo Institute. That's why we pivoted our development goals in the evening of the first day away from the original press release generator towards a twitter post generator. Accomplishments that we're proud of We are proud of creating a user-friendly, effective tool that streamlines the process of sharing press releases on Twitter. Our solution maintains high-quality content by leveraging the power of GPT-3.5 API, and it provides users with the flexibility to edit and customize the generated tweets. What we learned Through this project, we learned how to integrate GPT-3.5 API, manage Streamlit widgets and states, and create a seamless user experience that balances automation with user control. Additionally, we gained valuable insights into team collaboration and project management during the hackathon. What's next for ifo Twitter Bot Future plans for the ifo Twitter Bot include expanding its capabilities to create more designs, improving the"
      }
    ]
  },
  {
    "file_path": "./devposts/imvu-photoreal.html",
    "project_id": "imvu-photoreal",
    "title": "IMVU PhotoReal",
    "tagline": "Take your avatar into the real world - pose, select Instagram filter and take pictures to post to feed!",
    "hackathon": "",
    "built_with": [
      "areality3d",
      "imvu",
      "mixamo",
      "opencv",
      "opengl-es-3",
      "realityscript",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)",
      "First Place Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)",
      "Hack With MeWinnerFirst Place",
      "Winner",
      "Please Like this video of my awesomely fun 3D AR app to help me win the People's Vote prize for this contest! :)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/305/632/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 (Entry in progress) Inspiration What if you could take your IMVU avatar into the real world - have it hang out, literally, “in your hands.” What if you could take Instagram videos and photos (because it happened!) and share it to your IMVU feed? (Also, I needed live Instagram effects for another project.) What it does It’s a reality Photo Booth for your IMVU avatar. IMVU PhotoReal lets you place your IMVU avatar in 3D augmented reality on any surface - you can then select from classic Instagram effects and poses to make your photo super awesome to post to your IMVU feed! How to use Place your avatar on any surface. Try to find one that’s noisy, then place your phone parallel to the surface. If the AReality3D meter shows green - it’s an excellent surface to augment on! Select the outfit you want from the camera roll. Drag-slide along the film to scroll through all of your outfits. Don’t want to see your outfits? Touch the film roll canister to toggle the film in and out. (Outfit photo inverts when selected!) Touch on the surface plane to move your avatar there. Strike a pose. Turn on some Instagram effects. Take a photo and share to feed! Buttons on the top:\nLeft - rotate 90 degrees (did you place your avatar on a wall?) \nRight - find a new surface to put your avatar on Buttons on the bottom portion: Instagram effects Camera button: post to feed! Poses Oh, Pose freebies: And your avatar can drink! (Random drink generator c/o HoloYummy) And your avatar can play piano, too! (Audio on - a random piano piece plays each time you select “Play Piano”.) How I built it Rapidly prototyped using RealityScript, a language I designed for hacks like this. \n - AR via AReality3D SLAM Cross-platform compile via Unity 5.2.1f03 mobile-optimized realtime Instagram effects using LUT hack Why did I build this? I’ve always wanted to take my avatar out with me everywhere as my pocket pet - and take Instagram photos (and videos)! This is one of few AR apps I’ve built that I find myse"
      }
    ]
  },
  {
    "file_path": "./devposts/hive-hq.html",
    "project_id": "hive-hq",
    "title": "Hive-HQ",
    "tagline": "Hive-HQ is a web app that uses an AI tracking system to detect high-traffic areas in public spaces, allowing businesses to redirect traffic flow and provide COVID-friendly experiences for consumers.",
    "hackathon": "",
    "built_with": [
      "ai",
      "figma",
      "git",
      "google-cloud",
      "machine-learning",
      "opencv",
      "pytorch",
      "react",
      "yolov5"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Google Cloud Winner Best Entrepreneurship Hack, presented by Contrary Created by I worked on",
      "Best Use of Google Cloud Winner Best Entrepreneurship Hack, presented by Contrary Created by I work",
      "Hack the North 2021WinnerBest Use of Google CloudWinnerBest Entrepreneurship Hack, presented by Contrary",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/662/303/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Foot Traffic Heat Map Annotated Stream Floor Plan Cameras Logo Foot Traffic Heat Map Annotated Stream Floor Plan Cameras 1 2 3 4 5 6 7 8 9 💡 Inspiration As society and public services reopen, stores and other areas are becoming crowded again. However, with the threat of COVID-19 variants and increasing case counts looming over society, it is still vital to be mindful of crowded areas. This is where Hive-HQ comes in – it is an AI-powered, multi-target tracking system that identifies common hotspots and bottlenecks where people crowd together in unsafe situations. We set out to build a tool to help businesses monitor their premises and prevent the spread of COVID-19, creating a safer world for everyone. ❓ What it does Hive-HQ is a full suite of enterprise management tools used to monitor and improve a location’s safety with reference to COVID-19 guidelines. Based on a user-provided floor plan and data processed from security cameras, it presents live statistics of the number of people in a given store or public area, creates a heat map of foot traffic within a certain area, and provides recommendations based on said heat map to improve customer flow. There is functionality to add, remove, and configure any number of cameras in the system. The live heat map displays the current number of customers throughout a location using a gradient coloured scale to indicate how dangerous a given situation potentially may be (blue meaning safe to red meaning unsafe). Based on this heatmap, a business can generate and implement customized recommendations that change the layout of the area (tables, displays, etc.) in order to improve circulation and eliminate bottlenecks and regions that see many customers passing through. By providing tools to help enterprises evaluate and improve the health safety of their physical locations, Hive-HQ is building safer environments for businesses and their customers. 💼 Business viability Hive-HQ builds on top of existing infrastructure. Securit"
      }
    ]
  },
  {
    "file_path": "./devposts/ingredify.html",
    "project_id": "ingredify",
    "title": "Ingredify",
    "tagline": "Transparency in your food with Ingredify – the app that analyses your food intake for you",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "figma",
      "javascript",
      "mongodb",
      "react-native",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Cohere Challenge Prizes: Top 3 Teams get a Prize Created by I created all the visual elements",
      "s: Top 3 Teams get a Prize Created by I created all the visual elements",
      "MetHacks 2023WinnerCohere Challenge Prizes: Top 3 Teams get a Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/472/569/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sample users database response Logo Sample ingredients database response Sample conditions database response Sample users database response Logo Sample ingredients database response Sample conditions database response Sample users database response 1 2 3 4 5 6 7 8 Inspiration Every year, poor diets are responsible for a staggering 11 million deaths worldwide. That's approximately one in every five deaths globally. Even more concerning, one out of every four people has a restricted diet due to medical conditions like diabetes or allergies, resulting in adverse health effects not only for themselves but also for their loved ones. But not everyone has the financial means to hire a dietitian who can inspect and advise on every food intake. With the power of AI, especially when powered by Cohere, and the use of cutting-edge technologies like the MongoDB database and mobile applications, we have created a powerful tool that can save lives, improve health, and save money. Our app allows you to spend quality time with those who matter most to you and engage in activities that you love, all while maintaining a healthy diet and preventing disease. What it does? Ingredify is a mobile app designed to help individuals keep track of their food intake and provide them with insightful analysis of the ingredients in their meals. With Ingredify, users can simply take a photo of their food, and the app will read and analyze the nutrient facts for them, providing a quick and easy way to stay on top of their daily food consumption. Users can also create a personal profile to track their daily food intake, store data such as health conditions and preferences, and get personalized recommendations based on their unique needs. Ingredify also has a built-in feature that can answer questions such as \"What are the ingredients in this meal?\" and \"What are the typical nutrient facts for this food?\" With all of these features combined, Ingredify is the ultimate tool for anyone looking to improve "
      }
    ]
  },
  {
    "file_path": "./devposts/hot-chocolate.html",
    "project_id": "hot-chocolate",
    "title": "Hot Chocolate",
    "tagline": "Bring the concert to you – Music Moments transforms any space into an immersive, interactive AR concert where you control the stage, the band, and the music, making every moment a unique experience.",
    "hackathon": "",
    "built_with": [
      "adobepremierepro",
      "blender",
      "freesound",
      "lensstudio",
      "pixabay",
      "spectacles",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/128/403/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Hot Chocolate Project Overview Inspiration Make learning new instruments more accessible, from anywhere in the world. Allow users to explore instruments without the financial commitment of buying a new instrument. Hot Chocolate themed to get ready for the cold and cozy winter. What It Does Users identify a surface to begin and an electric drum pad and piano appear in AR upon detection. Users can play by tapping virtual drum elements or piano keys. Users can move pieces of chocolate around, creating a more customizable and fun experience. How We Built It Created the chocolate-themed 3D models in Blender. Added interactability with finger gestures and user feedback. Combined visuals and sound to create an immersive experience. Challenges We Ran Into No dedicated coder on the team. No experience with Unity/Lens Studio. Limited interactive features due to coding constraints. Accomplishments That We're Proud Of Produced custom, high-quality 3D models. Created a visually engaging AR experience. Completed prototype of our project given our limited previous exposure and time constraints. What We Learned Gained experience designing for interactive AR experiences. Learned the capabilities and constraints of XR. How to collaborate with others from different backgrounds and knowledge. Learned the importance of testing and user feedback to improve and revise. What's Next for Hot Chocolate Add multiplayer, allowing for others to create a band and play music all at once together! Improve sound quality, sensitivity and accuracy of the instruments, and overall user experience. Allow users to compose, record, and share their music. Built With adobepremierepro blender freesound lensstudio pixabay spectacles typescript Try it out GitHub Repo Submitted to Immerse the Bay 2024 Created by Joshua Kim Davyn Paringkoan Jessica Ivana YUN CHING CHANG"
      }
    ]
  },
  {
    "file_path": "./devposts/interview-automation.html",
    "project_id": "interview-automation",
    "title": "Interview Automation",
    "tagline": "Creating automation for Vertically Integrated Projects (VIP) applications at Tandon.",
    "hackathon": "",
    "built_with": [
      "git",
      "html",
      "javascript",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration At the start of the 2022 semester, applications for the next semester of vertically integrated project (VIP) students began. We quickly realized that the process for managing the students, including sending them emails and finding interview slots, was very repetitive and a good target for streamlining. What it does On the landing page the user is prompted to login as a user or admin. This sends the user to the CILogon page where the user signs in using their NYU or other supported university login methods. If an administrator, the user will have access to the different VIP teams to add and manage students via a dashboard page (access to the name, application status, email, and netid). The admin will also have options to add more admin users or to create question pages. A question page contains a mix of short/long/multiple and interview questions - the admin has the ability to create questions, move them around and delete them on a page. If a student, you are able to see the other students on your VIP team. How we built it We used the Nextjs framework, which uses React, to write the pages. We used MongoDb as our database solution. We used Auth0 to manage the authentication with NYU's SSO. Challenges we ran into issues getting the authentication to work how to structure the db understanding state in react CSS integrating the DB with the front-end and authentication Accomplishments that we're proud of getting authentication working with NYU SSO creating a db and managing to pull data from it for the front-end What we learned need to have a clear idea of the details of how everything integrates together familiarity with tech stack What's next for Interview Automation We plan on polishing up the website further so that it can be used with actual VIP students. Built With git html javascript node.js react Try it out interview-automation.nrp-nautilus.io dev.hpc.nyu.edu GitHub Repo Submitted to HackNYU 2022 Created by Calvin Tian Triet Vo Sachin Iyer Aneesh Magan"
      }
    ]
  },
  {
    "file_path": "./devposts/intellicord.html",
    "project_id": "intellicord",
    "title": "IntelliCord",
    "tagline": "A Discord Bot to Track and Help Mental Health Challenges",
    "hackathon": "",
    "built_with": [
      "cohere",
      "discord",
      "gpt-3",
      "javascript",
      "natural-language-processing",
      "numpy",
      "openai",
      "python",
      "react",
      "sqlite",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A Discord Bot to Track and Help Mental Health Challenges"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/194/587/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The SQLite3 database. Classification results from co:here are stored as binary for speedy numpy processing IntelliCord A mood checker based on co:here's classification LLM Sample suggestions generated by the GPT-3 LLM. Each message is new and unique Landing page for IntelliCord The training dataset for the co:here model The sigmoid function that IntelliCord uses to grade message importance The SQLite3 database. Classification results from co:here are stored as binary for speedy numpy processing IntelliCord A mood checker based on co:here's classification LLM Sample suggestions generated by the GPT-3 LLM. Each message is new and unique Landing page for IntelliCord The training dataset for the co:here model The sigmoid function that IntelliCord uses to grade message importance The SQLite3 database. Classification results from co:here are stored as binary for speedy numpy processing 1 2 3 4 5 6 7 8 Inspiration According to Harvard Business Review, 76% of workers face some level of mental health issues at the workplace. This has been exacerbated as the pandemic has gotten worse. Lockdown has also moved people to increasingly online platforms like Discord. Thus the idea of IntelliCord came along. The main idea was to create an online debugger that helps programmers overcome the stress of programming and the debugging process. However, after a long thought, the team decided to take a more general approach and a more broad scope to support all workers. The idea of creating a Discord bot was to broaden our users, since we believed that making a webpage for this type of idea will not be as effective since people have to go through the process of opening the page and login in, etc. However through Discord, once someone added the bot they have easy access to the bot whenever they like since Discord is already a lot of people's main social platform. What it does IntelliCord is a Discord bot that analyzes chats from users and gives back a response based on the current mental sta"
      }
    ]
  },
  {
    "file_path": "./devposts/image-generation-apparatus-based-on-books.html",
    "project_id": "image-generation-apparatus-based-on-books",
    "title": "Image Generation Apparatus",
    "tagline": "Research shows the decreasing amount of readers can be attributed to the lack of images in books. IGA allows users to read books with AI generated images based on the content that they are reading.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python",
      "requests"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/431/707/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Studies show that the experience for readers is decreasing along with the number of images in books. As an effect, fewer people are inclined to read. What it does Image generator apparatus, or IGA, is both a web app and a chrome extension that allows a reader to visualize the text they are reading. On the web app, a user can pick a book from their library which is then opened in our custom pdf reader. As the reader goes from page to page an AI-generated image is shown on the screen representing the text. How we built it We used some of the industries leading technologies to create IGA. To generate an image from given text we first need to summarize the input text. This was done by the famous ChatGPT developed by OpenAI. We then took this summarized text and passed it to DALL-E , another AI by OpenAI that generates images off of text input. Once we have our generated image we can insert it into the DOM content of our page and voila we have an AI-generated image. Challenges we ran into Due to the nature of our projects API/get requests were naturally a big part. To implement this we had to learn JavaScript async/await keywords, what they do, and how they work. Unbeknownst to us this was a lot more challenging to grasp than we thought. Accomplishments that we're proud of We did it! We were able to create a fully working website and chrome extension within 24 hours! What we learned Throughout this project, JavaScript was heavily used and we learn that in some situations it can be extremely troublesome to work with. We also learned to use Flask and how to integrate it into our website with HTML. What's next for Image Generation Apparatus Based on Books We plan on adding a feature to where users can upload their own PDF's to the site along with adding real-time updating and a scrolling feature to the PDF GUI. Built With css flask html javascript python requests Try it out GitHub Repo Submitted to Rowdyhacks 2023 Created by I worked on most of the CSS for t"
      }
    ]
  },
  {
    "file_path": "./devposts/image-recognition-of-bird-species.html",
    "project_id": "image-recognition-of-bird-species",
    "title": "Image Recognition of Bird Species",
    "tagline": "Using YOLO and OpenCV to train recognition of bird species, the dataset taken from Kaggle for categories: American Goldfinch, Barn Owl, Carmine Bee-eater, Woodpecker, Penguin, and Flamingo.",
    "hackathon": "",
    "built_with": [
      "github",
      "opencv",
      "python",
      "visual-studio",
      "yolo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/206/376/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "training image Inspiration As programmers with some experience in coding, we wanted to learn how to utilize Machine Learning models within our project. Therefore, this is a beginner level project into AI but also adding a challenge to the existing project by teaching the model how to detect different bird species. What it does An image recognition program that can categorize different bird species. How we built it Using pre-trained YOLO and PyTorch models to train image recognition of bird species with the dataset taken from Kaggle for categories: American Goldfinch, Barn Owl, Carmine Bee-eater, Woodpecker, Penguin, and Flamingo. OpenCV was used as the image editor to display and draw rectangles around birds. Challenges we ran into Learning how to use different packages and integrating them into a single project. Also, working with other people and sharing code over GitHub. What's next for Image Recognition of Bird Species Maybe using Rasberry Pi to continuously look for birds that visit a bird feeder and saving each of the images and initial classifications of the bird species. Built With github opencv python visual-studio yolo Try it out GitHub Repo Submitted to SB Hacks XI Created by Youjia He Apollo Tan"
      }
    ]
  },
  {
    "file_path": "./devposts/helix-ai.html",
    "project_id": "helix-ai",
    "title": "Helix AI",
    "tagline": "Turn your everyday health data into income and support medical research with Helix AI—a secure, decentralized marketplace that lets you effortlessly monetize your metrics while ensuring privacy.",
    "hackathon": "",
    "built_with": [
      "google",
      "ipfs",
      "machine-learning",
      "node.js",
      "react",
      "ripple",
      "tensorflow",
      "xrpl",
      "zk",
      "zsnark"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/203/445/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration In today’s digital age, individuals generate vast amounts of valuable health data daily through devices like smartwatches and fitness trackers. This data, encompassing metrics such as blood pressure, oxygen levels, and activity patterns, holds immense potential for advancing scientific research, driving healthcare innovations, and ultimately saving lives. However, stringent regulations like HIPAA, PDPA, and GDPR create significant barriers to cross-border data sharing, leaving this data underutilized. Healthcare institutions face administrative burdens and legal risks when attempting to exchange or monetize health information, resulting in fragmented systems that hinder research and optimal patient care. Recognizing the lost economic and medical opportunities, we envisioned a solution that empowers individuals to monetize their health data securely while facilitating seamless data sharing for research and innovation. What it does Helix AI is a decentralized application that leverages the efficiency of the XRPL (XRP Ledger) and the programmability of EVM (Ethereum Virtual Machine) sidechains to create a secure marketplace for healthcare data. Helix AI serves both patients and institutions by ensuring privacy, transparency, and cost-effective data sharing. Users can effortlessly monetize their health data by granting consent through our app, initially focusing on data extracted from devices like the Apple Watch. This data is then utilized to create machine learning models that expedite research in the healthcare industry. By maintaining robust privacy protections through blockchain technology and advanced machine learning techniques like federated learning and differential privacy, Helix AI ensures that sensitive health data remains secure and anonymized. Pharmaceutical companies and researchers gain access to larger, more robust datasets, accelerating their research and innovation while users retain control and can earn revenue from their "
      }
    ]
  },
  {
    "file_path": "./devposts/j-i-t-just-in-time.html",
    "project_id": "j-i-t-just-in-time",
    "title": "J.I.T.: Just in TIme",
    "tagline": "The goal of J.I.T. is to take all of the unexpected things that will ruin your day, and expect them for you. In other words, J.I.T is your jit.",
    "hackathon": "",
    "built_with": [
      "google",
      "nws-api",
      "python",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In a day and age where we have to wake up daily to face the gaunlet before us, we have much that is out of our control. Wet socks from rain, a shirt drenched in sweat from the heat, traffic, absurdly long lines for your coffee, buses running off schedule, and too many more. We have a million choices to make in an instant based off of information that we cannot gather, and just like that you can ruin your entire day in that instant. Too many unknowns, and too much chaos. The goal of J.I.T. is to take all of the unexpected things that will ruin your day, and expect them for you. What it does J.I.T. takes input from a user, such as a wake-up alarm and calendar, and will pull a mass of data accessible online about your location, the weather, traffic, etc... and after that point. J.I.T. will give you all of the information you need to decide. How we built it We built it with Python and Tkinter GUI . We also used Google Maps API and National Weather Service API Challenges we ran into We learned a lot of things about Git and Github, and also how to make requests to large API services. Accomplishments that we're proud of Implement ideal algorithms to determine the most efficient route. What we learned We learned the importance of having a good version control plan. We shouldn't use Git and VS Code Live Share at the same time. What's next for J.I.T (Just in Time) Instead of a predetermined list of locations, we can make it so every building on campus can be selected. Built With google nws-api python tkinter Try it out GitHub Repo Submitted to HowdyHack 2022 Created by Samay Upadhyay Gage Mariano Andrew Leach Adam Teo"
      }
    ]
  },
  {
    "file_path": "./devposts/j-a-c-k-ai.html",
    "project_id": "j-a-c-k-ai",
    "title": "J.A.C.K. AI",
    "tagline": "Making physical therapy more accessible with GenAI and computer vision.",
    "hackathon": "",
    "built_with": [
      "javascript",
      "next.js",
      "openai",
      "python",
      "tensorflow",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "solutions and deliver the best results for our project"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/593/008/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Currently, physical therapy is not easily accessible to underrepresented segmentations such as rural patients, elderly patients, cost sensitive patients, disabled patients, and patients with a language barrier.\nAdditionally, as a physical therapist, you will teach your patients the proper form for their exercises and make sure they are performing each movement correctly. But once they are back in their home environment, how do you know whether they are still doing their exercises the right way—or at all? What it does J.A.C.K. AI uses a trained computer vision model to analyze and monitor a patient's physical therapy exercises. The model is trained on correct and incorrect forms of exercises and identifies not just if a patient is doing an exercise incorrectly, but how they are doing an exercise incorrectly. We then provide users with personalized AI-generated feedback with GPT-4. How we built it Our project is an interconnected system of 3 different AI models. Our first model was a pose detection model that determines the x and y coordinates of the different movements of our bodies. We then process these coordinates through a series of algorithms and pass them into our manually built AI model that detects whether you are doing the exercise correctly or not. We will then extract information from this model and feed it into OpenAI's GPT API to make it give us comments/advice about how we performed the exercises. Challenges we ran into A major hurdle was gathering a suitable dataset to test and train our data on. As a result, we spent considerable time developing an easy and accessible frontend to convert our pose detection classification into csv files to be processed. In terms of training our models and displaying the recommendations to users, we also faced challenges in fine-tuning parameters for our AI as well as utilizing the OpenAI API. Accomplishments that we're proud of We are proud to have presented our idea to Y Combinator as part of the YC Pitch "
      }
    ]
  },
  {
    "file_path": "./devposts/interviewerreviewer.html",
    "project_id": "interviewerreviewer",
    "title": "InterviewerReviewer",
    "tagline": "Typically, it takes a highly self-aware person and a lot of time to create a brilliant answer considering multiple perspectives on their own. Our team believes this is another skill that can be taught",
    "hackathon": "",
    "built_with": [
      "click",
      "cohere",
      "css3",
      "flask",
      "html5",
      "javascript",
      "postgresql",
      "psycopg2",
      "python",
      "railway",
      "react",
      "recaptcha",
      "shell",
      "sqlalchemy",
      "vercel",
      "waitress"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AI HacksWinnerSecond OverallWinnerBest Use of NLP with Cohere",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/328/536/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Devpost logo Logo, for the html Devpost logo Logo, for the html Devpost logo 1 2 3 Inspiration We all wish to be seen for our best qualities, but most assessments are focused not on qualifications or technical proficiency but the how well you can sell yourself. It isn’t enough to be technically brilliant; one must also appear socially well-rounded. This part of the interview is behavioral-based and more abstract, leaving most people ill-prepared to articulate themselves elegantly while remaining truthful. Being ill-prepared or not meeting the minute of specifications, hastily attempting to compensate for one's lack of ability within a closing time window, make the job search process a test of endurance. Typically, it takes a highly self-aware person and a lot of time to create a brilliant answer considering multiple perspectives on their own. Our team believes this is another skill that can be taught and simplified with coaching and practice in the privacy of your own home. What it does We created a web app that prompts the user with an interview question and then allows the user to answer the questions in the form of voice or text. After the questions, our AI grades your submission and offers advice for your current skill level and overall score. How we built it We started with researching the nuances behind answering some of the most general interview questions. After collecting over 140+ responses and weighting their viability, we trained a model using python and the Cohere API. We then arbitrarily devised a formula for grading based on classification and confidence in scoring. Typically Cohere can only analyze text, but we decided to leverage Google Cloud speech-to-text together to create a more natural feeling interview environment using the spoken word. For accessibility reasons, we enabled a text submissions option to accommodate individuals unable to complete voice submissions for medical or technological limitations. Challenges we ran into Tackling a projec"
      }
    ]
  },
  {
    "file_path": "./devposts/intouch-cnu8rs.html",
    "project_id": "intouch-cnu8rs",
    "title": "inTOUCH",
    "tagline": "With multiple electronic medical records (EMRs) across all providers a patient has, inTOUCH is a central hub for storing your medical records, drugs, and provider information in one place.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "javascript",
      "mongodb",
      "mongoose",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/362/093/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Process of creating frontend Main logo Process of creating frontend Main logo Process of creating frontend 1 2 3 Inspiration With family and loved ones who have experienced confusion, difficulty, and even serious issues as a result of medical error, we sought out to find a way to make a patients medical info (through EMRs) accessible to the patient simple, as it should be. We felt that as an individual patient, it shouldn't be impossible to find your prescriptions, medicines, doctors, and resources among all the many EMR systems that you can find online. So we thought, how can we get all of the information through different EMR systems into one system, when independent companies have no incentive to play with each other. What it does inTOUCH is accessible as a Chrome extension, which allows for a user to log in through any given patient portal to their electronic EMRs, and capture the data of their drugs, dosages, provider information, etc... This information is then made viewable through our MongoDB database system and webpage to securely connect a patient to their documents. Through the webpage, doctors and user-inputted (for over the counter) drugs can be added, and with a notification service implemented, we can efficiently communicate with medical providers with ease. How we built it Using a Google extension, we can pull data that is then inputted into our secure MongoDB database, which associates itself with the account registered into MongoDB. With a React framework, we interact with the MongoDB to then display that information on our webpage to the user. Challenges we ran into Viability and time became our worst enemy through this project as we sought to create not only a unique and interesting solution to this issue, but also a realistic solution. We originally wanted to interact with other EMRs, but we realized that with independent health care providers, they simply have and will not (without incentive) interact with each other. Why offer another company "
      }
    ]
  },
  {
    "file_path": "./devposts/intern-vine.html",
    "project_id": "intern-vine",
    "title": "ResuMate",
    "tagline": "Everyone knows it's important to get experience before getting work in their fields. But getting that first internship is difficult. Luckily, you can get someone who was in your shoes to help you.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "nextjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/143/763/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration a. We are all worried about getting internships, and even though we have each other, it would be nice to have people who were in our position to give us advice on how to achieve the internships and work we want. What it does b. Users upload their resumes and/or cover letters, and other people give feedback on how to structure and word their resumes or tell them what they could be improving on. People can give advice on what activities/subjects to focus on which will help others get the internship they want. How we built it c. We used Pinata to take users' resumes to be stored to an API and store it until someone requests to view it for feedback or to give feedback. Challenges we ran into d. Getting used to Pinata was difficult and developing so much front end was also difficult. There are a lot of different files and pieces that have to come together in order to get the website to work, so it took a lot of Error 404s and incomplete builds before we got something that worked. Accomplishments that we're proud of e. We're happy with developing a backend that helps store the login and data of users so that they can keep their feedback that people give them. What we learned f. We learned a lot of front-end design and got experience with working with designing websites with multiple people and with more than just a few pages. What's next for ResuMate g. Next we hope to implement a video recording system to have a similar feedback system but for interviews, since those would be the next step in the recruiting process. Additionally, we're hoping to get a recruiter role so that they would have a role in helping students improve on activities. Built With firebase nextjs Try it out GitHub Repo Submitted to HackUTD 2024: Ripple Effect Created by Isaac Chacko Justin Le IshaanBansal2006 Bansal winterberrylavender Lam"
      }
    ]
  },
  {
    "file_path": "./devposts/investing-for-hippies-gogreen.html",
    "project_id": "investing-for-hippies-gogreen",
    "title": "Investing for hippies #GoGreen",
    "tagline": "What if there was a model to predict the onset of environmental and financial risk events, enabling investors to make both an optimal decision on investments and protect the environment?",
    "hackathon": "",
    "built_with": [
      "pandas",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "For our project, we analyzed two datasets, one containing stocks, their prices, and other associated data, and the other containing information about the environment, mostly carbon dioxide emissions. The stock data was reported daily while the environmental data was reported yearly, so we analyzed the data on a quarterly basis to avoid losing the volatility of each stock. We wanted to identify whether a stock would rise or fall, so we classified each quarter into a drop, a rise of 0 to 0.5%, or a rise of greater than 0.5%. Based on this classifier, we developed a model that will predict whether a stock will rise, fall, or stay the same given a change in carbon dioxide emissions, enabling investors to make optimal investment decisions while protecting the environment. Built With pandas python Try it out www.kaggle.com docs.google.com drive.google.com Submitted to TAMU Datathon 2021 Created by Laren Spear https://www.linkedin.com/in/larenspear Shri Mathavan Jagadish Kumaran Jayagopal Kathan Vyas"
      }
    ]
  },
  {
    "file_path": "./devposts/ispothate.html",
    "project_id": "ispothate",
    "title": "iSpotHate",
    "tagline": "Hate speech detection as a service",
    "hackathon": "",
    "built_with": [
      "discord",
      "docker",
      "fastapi",
      "huggingface",
      "javascript",
      "pytorch",
      "streamlit",
      "wandb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "base model accuracies) to determine the best model to run our final training on",
      "2nd Place Created by It feels great having submitted this project as I consider this to be the best",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/187/346/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Discord Bot Website API Streamlit Demo Chrome Extension Discord Bot Website API Streamlit Demo Chrome Extension Discord Bot 1 2 3 4 5 6 Inspiration Imagine this scenario: You run a consumer software startup; your audience ranges from 5 year olds to 105 year olds. You're scaling fast, but then disaster strikes: hateful content. \nIt's a difficult line to walk between censorship, and offending new users. \nFor small teams, machine learning is already a pain point; difficult to deploy at scale and expensive to develop pipelines. Designing a proper solution may save the hassle for many solutions related to hate speech detectino. \nDetecting hate speech is also important to protect users and promote a healthy community and social equity. The CDC has found a positive correlation between hate speech and self harm behaviour, showing just how important it is for us to mitigate and eradicate hate speech. \nThe problem with detecting hate speech is that millions and billions of texts are being sent over the Internet at any moment, and it is very difficult to pinpoint quickly if something is hate speech or not. What it does Introducing ISpotHate, hate speech detection as a service. It allows companies to focus on their core product, rather than worrying about using complex methods to keep content safe and promote social equity. Our FREE API is one HTTP request away from eradicating hate speech, one word at a time. By simply using one line of code ( http://ispothate.eastus.cloudapp.azure.com:8000/ishate?text={text} ), replacing {text} with the actual text you want to query, we can get whether the text is hate speech or not. The API endpoint also supports a lot of other functions, as seen through the docs: http://ispothate.eastus.cloudapp.azure.com:8000/docs . Finally, we hosted many examples of apps that can use our API, including a Discord bot, a chrome extension, and a Streamlit interface for a machine learning workflow. How we built it We used fastAPI to generate a REST API endpo"
      }
    ]
  },
  {
    "file_path": "./devposts/immigrace-eijvza.html",
    "project_id": "immigrace-eijvza",
    "title": "Immigrace",
    "tagline": "An interactive web app that walks immigrants through preparing to buy a home, determine whether they can afford one, and understand the process",
    "hackathon": "",
    "built_with": [
      "css",
      "d3.js",
      "django",
      "flask",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Data Visualization - Optiver Created by Arushi Mittal Wanda F Private user Anita Yip Product o",
      "Technica 2022WinnerBest Data Visualization - Optiver",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/257/245/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Home ownership is a milestone towards achieving the \"American Dream\". It symbolizes autonomy, achievement, and national pride. But it's not just a dream for U.S. born citizens, it's also the dream my immigrant parents have and many who arrive here from other countries. However, immigrants are facing more barriers than ever before to accessing quality affordable housing. When my parents went through the homebuying process, they encountered challenge after challenge. The information was so technical and hard to understand because English isn't our first language, and the process was confusing. We ended up paying more than we thought we would’ve, and we didn’t quite know why. Of course, it doesn't have to be this way. What it does Our team spent the weekend creating an interactive web app that helps immigrants prepare to buy a home, determine whether they can afford one, and understand the process in a culturally sensitive way. How we built it We used HTML, CSS, and JavaScript for the front end, D3 for the data science modeling visualization, Python, Django and Flask for leveraging a machine learning model to predict outcomes. Challenges we ran into Some challenges we ran into were implementing the loan prediction model into the web app. While we learned a lot about Django and Flask, we ultimately ran out of time. We also could not figure out how to output the data from data visualization in a tooltip. We could console.log it, though(!). Accomplishments that we're proud of A majority of our team (3!) was participating in our first Hackathon, and we successfully worked together as a hybrid team. What we learned We pushed ourselves to learn something new, depending on what level we're at. For the UI/UX designer, we worked with a mentor to realize some visual designs via code. For the back end developer, we implemented one of first machine learning models. For the more experienced coder, we started using D3 for data visualization. What's next for Immigrace In "
      }
    ]
  },
  {
    "file_path": "./devposts/interview-pro-igtp3z.html",
    "project_id": "interview-pro-igtp3z",
    "title": "iNterview Pro",
    "tagline": "Ace your next interview with Davey, your custom interviewer!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "mongodb",
      "opencv",
      "python",
      "pytorch",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMUhack XWinnerFirst Overall Software Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/743/173/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Unity project for interviewer sim Our fully-connected web platform All 5 machine learning models together in action Unity project for interviewer sim Our fully-connected web platform All 5 machine learning models together in action Unity project for interviewer sim 1 2 3 4 Inspiration One of the biggest struggles people face is a fear of public speaking and interviews. In a world where so many aspects of our lives have been dominated, improved, and exacerbated by AI. But a field where we rarely see the use of AI is in fostering skills in socialization and real human connection. That is a fundamental issue we wanted to solve. What it does By signing up to the platform, any user regardless of their experience and confidence level can prepare for interviews and public speaking events with ease. For interviews, they have the option of providing specific details about the company they're working at and their role description, which the AI interviewer will ask useful, guided questions based on. The AI interviewer will track the user's speech patterns, facial expressions, eye contact, vocal discontinuities, and of course content in generating very useful, specific, and guided feedback as to how the user can improve in future interviews. How we built it We built a facial expression classifier model from scratch in PyTorch as well as an eye tracking model. We modified an existing lightweight architecture for facial detection and the GPT API for interview question generation and post-interview analysis. We output all of the generated responses and questions onto our sim character which is displayed to the user in a Skype call style. Challenges we ran into Integration! Combining all the different models was not an easy challenge and turning all the different data into text for the LLM. Accomplishments that we're proud of The amazing UI work and models we trained and combined. What we learned How to use different models to detect facial characteristics and emotions and connect "
      }
    ]
  },
  {
    "file_path": "./devposts/jamflow-x8syal.html",
    "project_id": "jamflow-x8syal",
    "title": "Jamflow",
    "tagline": "We have all heard of vibe coders! Individuals who have no coding background coding?? well what if we could make individuals who do not have a musical background become musicians?? Presenting Jamflow.",
    "hackathon": "",
    "built_with": [
      "firecrawl",
      "javascript",
      "natural-language-processing",
      "python",
      "sql",
      "ts"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Me and my teammate both love music ! Listening to it on drives,  hikes, workouts, on the commute! The only issue is we can't create music :(. In the age of LLM's , when even a non coder can vibe code their way to a functioning app then why can't we be able to make music. To help ourselves and millions more like us vibe code music we made Jamflow. Our Solution We solved this problem by creating Jamflow. We built a tool where a user can enter a prompt. Have Gemini 2.5 flash go through it and then actually generate working code that you can hit play on and listen to in the chat itself!! thats not it you can even edit the code and hit play to immediately see how your unique melody is whipping up. How we built our Project : We built our project by fine - tuning gemini 2.5 flash on a custom dataset that was curated by scraping extensive music documents and guides. The db was then converted to a vector db to be able to implement RAG. When a user now enters the prompt, we convert that prompt to vector embeddings, Query the vectorDB and then pass this as context to the llm via api calls. This ensures we can always generate relevant strudell code and output exactly what the user expects. What we learnt To begin with, we can confidently say that we have a pretty solid understanding of Strudell code. We even learnt a lot of the ui ux as this was the first time either of us designed the front end of an application in a hackathon and also the first time we ever designed a chatbot . The challenges Faced To begin with, there was no curated dataset available. It was practically impossible to fine tune the llm to generate accurate strudell code as we did not have a pre curated dataset of strudell docs, musical understanding research papers. Another challenge faced was we had to figure out how the user query would be converted to vector embeddings to be able to reduce latency and improve speed Built With firecrawl javascript natural-language-processing python sql ts Try it"
      }
    ]
  },
  {
    "file_path": "./devposts/intellidocs.html",
    "project_id": "intellidocs",
    "title": "IntelliDocs",
    "tagline": "Automatically generate and maintain internal documentation that scales with your codebase. Keep your team in sync with insights and real-time updates.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "gemini",
      "ngrok",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/502/455/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Developers love writing code but not updating project documentation. It’s tedious, easy to miss and can take developer’s focus away from their main work- Writing functional code. That’s where we came up with the idea of IntelliDocs - A Github app that is integrated into your repository, tracks commits in real time and generates easy to understand documentation everytime you push your code. What it does IntelliDocs is a GitHub App that listens to repository push events and automatically generates updated documentation for changed code. Upon each push to the main branch, it fetches the latest files, uses AI to generate documentation and summaries, then commits the docs to a separate repository dedicated to documentation. Additionally, it can add AI-generated summaries as comments or statuses on pull requests, keeping maintainers informed. All of this runs automatically in the background, seamlessly integrating with existing workflows. How we built it We built IntelliDocs using FastAPI to handle GitHub webhook events. The app verifies webhook signatures for security, parses push event payloads, and triggers background tasks to process commits. For local development, we use ngrok to expose our localhost and simulate real webhook calls from GitHub. The backend is structured with separate modules handling GitHub authentication, git operations, webhook parsing, and AI documentation generation. The project is containerized and configurable via environment variables, including secrets and repository info. Key technologies: FastAPI for async API endpoints and webhook handling HMAC signature verification for webhook security ngrok for local development tunneling Python environment with modular structure GitHub App authentication and API interactions AI-based doc generation (planned, stubbed for testing) Challenges we ran into Webhook signature verification: Ensuring secure and reliable verification of incoming webhook signatures to prevent spoofed requests was crit"
      }
    ]
  },
  {
    "file_path": "./devposts/jindr.html",
    "project_id": "jindr",
    "title": "#35: Jinder",
    "tagline": "Jinder allows employers to post jobs and view potential candidates. Future employees can view job postings created by a company and can swipe left or right if interested.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "firebase",
      "node.js",
      "scss",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Jinder Team Number: 35 Team Members: Arjun Sundaram, Tina Martinez, Rhea Shastri, Jax Wang, Ryan Lam Inspiration With COVID-19 causing many layoffs and unemployment rates soaring, we thought that creating a web app that accurately matched job searchers to potential employers would help people get back in the workforce with meaningful jobs. What it does Our web app is inspired by Tinder. Job seekers create their profiles with their interests and employers add jobs to the website. Next, we have a \"Tinder-like\" UI where job searchers can like or dislike jobs. Our algorithm recommends relevant jobs to job seekers and vice-versa. If both the job searcher likes the job and the employer likes the job searcher, our algorithm will detect a match and connect both parties. How we built it Frontend: Vue, SCSS Backend: Express, Node Database: Firebase/Firestore Challenges we ran into Designing the database Designing the wireframe of the project Coding the API endpoints and querying the data into the database Accomplishments Getting the web app working Having a database design that works Having a fully-fledged API working What we learned Learned Express, Firebase, wireframing, NoSQL databases What's next for Jinder Use AI/ML to help with the recommendation algorithm Better UI/UX with more functionality and features Built With express.js firebase node.js scss vue Try it out GitHub Repo Submitted to Hoya Hacks 2022 Created by Frontend Private user Jax Wang uwo 24' intermediate FE Tina Martinez Ryan Lam UWaterloo Physics Arjun Sundaram"
      }
    ]
  },
  {
    "file_path": "./devposts/invoice-tracker.html",
    "project_id": "invoice-tracker",
    "title": "Invoice Tracker",
    "tagline": "A tool for small businesses to track invoices",
    "hackathon": "",
    "built_with": [
      "jupyter",
      "python",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for NLP Created by Laren Spear https://www",
      "CBRE Challenge: Best Hack for NLP Created by Laren Spear https://www",
      "TAMUhack 2022WinnerCBRE Challenge: Best Hack for NLP",
      "A tool for small businesses to track invoices",
      "We want to help small businesses more easily track their invoices without paying for proprietary software",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We want to help small businesses more easily track their invoices without paying for proprietary software What it does It processes scans of invoices and puts them into a database to manage the payments How we built it Jupyter notebook Challenges we ran into Real-world invoice data is messy. The invoices can be in any format. Poor contrast is also a huge issue. Built With jupyter python sql Try it out GitHub Repo Submitted to TAMUhack 2022 Winner CBRE Challenge: Best Hack for NLP Created by Laren Spear https://www.linkedin.com/in/larenspear P Shiva Kumar"
      }
    ]
  },
  {
    "file_path": "./devposts/it-assist.html",
    "project_id": "it-assist",
    "title": "IT Assist",
    "tagline": "AI...IT Support...Save your time!",
    "hackathon": "",
    "built_with": [
      "claude",
      "figma",
      "firebase",
      "go",
      "nextjs",
      "react",
      "shadcn",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Startup Idea Created by Worked on the frontend using Next",
      "SacHacks VIWinnerBest Startup Idea",
      "AI will do its best to help you, otherwise making a ticket for human review",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/305/543/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Oftentimes, IT companies struggle with limited support availability, especially if the time we need urgent help is after normal working hours. 24/7 support drains the resources of a company while also resulting in slow response times and/or inconsistent service quality. We wanted a solution that would benefit both people in need of support and the IT companies providing that service, at no additional cost. What it does Problem Response Automation Call the IT company and begin talking to an AI chatbot AI will do its best to help you, otherwise making a ticket for human review A human customer service agent will review the ticket and get back to you Seamless Call/Ticket Monitoring Dashboard to enter live calls to provide necessary assistance Ability to review and change the status of tickets with just a couple of clicks AI agents wholly manage direct customer communications Cost Reduction Customers do not get charged an additional fee for after-hours IT support Companies are now able to hire less, but more specialized personnel, saving more of their budget Satisfaction Customer service quality stays consistent and fast, keeping more customers happy and incentivizing them to stay loyal to the company How we built it Wireframing Figma Frontend NextJS + ReactJS for the core application TailwindCSS, TypeScript, and Shadcn for UI development Backend Firebase for database implementation Go for web socket integration Retell AI API for hosting an AI voice agent Challenges we ran into Facilitation of real-time database updates with the AI voice agent Integrating the frontend and backend into one complete project Accomplishments that we're proud of Built working end-to-end automation for IT problems and their solutions Being able to update a database with an AI voice agent Developed UI very similar to the ones found in our wireframes What we learned Implementation of an AI agent for human communication Importance of wireframing a frontend design before coding it Use"
      }
    ]
  },
  {
    "file_path": "./devposts/interviewprep-ai.html",
    "project_id": "interviewprep-ai",
    "title": "InterviewPrep.AI",
    "tagline": "The future belongs to those that prepare for it today.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "flask",
      "openai",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/462/464/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration A company can provide as much technical training as possible, but will struggle to train a worker to be a \"good fit\" to the company. This is where behavioral interviews are implemented for companies to find candidates that are a \"good fit\" to their company values and culture. However, these interviews can be difficult and could be the deciding factor in obtaining a job offer despite any amount of previous interview rounds. What it does InterviewPrep.AI is a smart AI that will give feedback on your answers to behavioral questions and help you practice your best responses for future interviews. By taking in context about the user such as individual strengths, weaknesses, and accomplishments along with the specific company and its values, InterviewPrep.AI will provide meaningful feedback based on the information given. The user will say their answer to the behavioral question they want to practice and our application will listen to their answer and prompt our AI with the response, thus returning the valuable feedback needed. How we built it Frontend: React.js (HTML/CSS/JS) API: OpenAI API Backend: Flask (Python), Firebase (Database/Authentication) Challenges we ran into We ran into many backend issues involving our database and updating the details of the user's profile. Accomplishments that we're proud of We are proud of being able to deliver a substantial minimum viable product (MVP) with a simple UI and fully-functional core features. What we learned We learned that the use of AI has both benefits and detriments. Knowing the versatility and volatility of using AI, we had to build a product that would only be used for personal improvement and not an unfair advantage for any user. What's next for InterviewPrep.AI We plan on expanding InterviewPrep.AI's features to provide more convenience and quality for our users. InterviewPrep.AI has a possibility of being monetized and supported through venture capital investment, so we plan to seek out potential invest"
      }
    ]
  },
  {
    "file_path": "./devposts/idk-untpk6.html",
    "project_id": "idk-untpk6",
    "title": "COINSPIRE",
    "tagline": "Graphic Art Just Got Better!",
    "hackathon": "",
    "built_with": [
      "cockroach-db",
      "css",
      "express.js",
      "html",
      "javascript",
      "node.js",
      "socket.io",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/994/600/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "kirby :3 Home page Lots of blue dots from testing Very cool Jett drawing ??? kirby :3 Home page Lots of blue dots from testing Very cool Jett drawing ??? kirby :3 1 2 3 4 5 6 What it does COINSPIRE is a collaborative place where users from around the world can contribute pixel by pixel to collaboratively create a graphical image! With a timeout of one second, users can only get so far on their own and are encouraged to collaborate to take over the board. Inspiration We were inspired by games such as Microsoft Paint and Wordle, as well as collaborative tools like Visual Studio Code’s Live Share extension where users can work together simultaneously. Fun fact, we used Live Share extensively while creating this app. How does our project help the world? After the COVID-19 pandemic, our team was feeling that the world was a bit bland. Our team wanted to build a project that would help people come together to create something beneficial while having a fun and rewarding experience. We brainstormed COINSPIRE, a platform for people to collaboratively build art and one that evolves over time as more people contribute to it. We also envisioned our platform to be something that can be used daily and something that people can talk about and share. Just like wordle, we envisioned our platform to be used daily, like an ever-evolving video game that changes with its players. In short, COINSPIRE brings a bit more lemony to people’s lives. How we built it We built COINSPIRE with HTML, CSS with bootstrap, and JavaScript for our frontend, Node.js and Express.js for our backend, socket.io for webhooks and real-time client-server communication, and SQL with Cockroach DB for our database to store all data received to transmit updates in live time to all users. We hosted the website with Google Cloud services and reserved the coinspire.tech domain on domain.com. Challenges we ran into This was our team's first time working with professional database services as well as implementing feature"
      }
    ]
  },
  {
    "file_path": "./devposts/interview-pro-53qezn.html",
    "project_id": "interview-pro-53qezn",
    "title": "iNterview Pro",
    "tagline": "AI Mock Interview Assistant",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "mongodb",
      "opencv",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration One of the biggest struggles people face is a fear of public speaking and interviews. In a world where so many aspects of our lives have been dominated, improved, and exacerbated by AI. But a field where we rarely see the use of AI is in fostering skills in socialization and real human connection. That is a fundamental issue we wanted to solve. What it does By signing up to the platform, any user regardless of their experience and confidence level can prepare for interviews and public speaking events with ease. For interviews, they have the option of providing specific details about the company they're working at and their role description, which the AI interviewer will ask useful, guided questions based on. The AI interviewer will track the user's speech patterns, facial expressions, eye contact, vocal discontinuities, and of course content in generating very useful, specific, and guided feedback as to how the user can improve in future interviews. How we built it We built a facial expression classifier model from scratch in PyTorch as well as an eye tracking model. We modified an existing lightweight architecture for facial detection and the GPT API for interview question generation and post-interview analysis. We output all of the generated responses and questions onto our sim character which is displayed to the user in a Skype call style. Challenges we ran into Integration! Combining all the different models was not an easy challenge and turning all the different data into text for the LLM. Accomplishments that we're proud of The amazing UI work and models we trained and combined. What we learned How to use different models to detect facial characteristics and emotions and connect multiple platforms to each other. What's next for iNterview Pro Helping the students today to become new hires tomorrow! Built With css3 html5 javascript mongodb opencv python pytorch Try it out GitHub Repo Submitted to The AI Hackathon Created by kiyoyoneko Liu"
      }
    ]
  },
  {
    "file_path": "./devposts/inclugo.html",
    "project_id": "inclugo",
    "title": "IncluGo",
    "tagline": "Whether you use a wheelchair, a prosthetic, have visual impairments, or prefer to avoid crowded spaces, we prioritize accessibility for you — because every disability is unique.",
    "hackathon": "",
    "built_with": [
      "leaflet.js",
      "openrouteservice",
      "openstreetmap",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/328/839/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Most impactful obstacles Settings Tab Add an obstacle Profile Tab Most impactful obstacles Settings Tab Add an obstacle Profile Tab Most impactful obstacles 1 2 3 4 5 IncluGO 🚶‍♂️ Your journey. Your way. Whether you use a wheelchair, a prosthetic, have visual impairments, \nor prefer to avoid crowded spaces we prioritize accessibility for you –\nbecause every disability is unique . \nWhile wheelchair-users have to avoid stairs, people with mental disabilities might want to avoid crowded areas. There is so much diversity, that wo don't even want to put you in boxes by your diagnosis. To help you personalize the experience, you just give some hints about what is an obstacle in your live .\nSimply swipe right for situations that are a problem to you. We will offer you a route specialised for you. Before you go, you can preview the route so there are no more surprises on the way.\nChange the route as you wish, the app will learn from you and all other users so the route will be good on the first try. What we plan to implement 🔮 Adding obstacles with a personalised barrier severity A profile and settings tab A funding feature to get rid of the obstacles in the future A separate web interface for public facilities to see which obstacles have the highest overall barrier severity and should be fixed as soon as possible Built With leaflet.js openrouteservice openstreetmap react typescript Try it out GitHub Repo Submitted to HackHPI 2025 Created by Samuel Leßmann Adam Aleksandrs Morgensterns Beneditk Liebold Jhannes Reimann Niels Glodny"
      }
    ]
  },
  {
    "file_path": "./devposts/jazzy-johnathan-s-musical-adventure.html",
    "project_id": "jazzy-johnathan-s-musical-adventure",
    "title": "Jazzy John's Musical Adventure",
    "tagline": "A puzzle based game that tells the story of John, an aspiring jazz musician, who struggles to overcome his parents opposition to his dreams of becoming a jazz pianist.",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/257/443/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "our piano our piano our piano 1 2 Inspiration We wanted to create something fun, interactive, and a little silly that had a focus on jazz music, since that was a genre that we had a shared interest in. Our teammate, Seungwon, is a jazz pianist, so we wanted to use his experience with music. What it does Jazzy John's Musical Adventure is a music game where the player hears a tune and plays it back by figuring out what notes are being played. The player follows John's story through conversations between him and his mother as he comes to realize his true passion for jazz. How we built it We used the framework Phaser.JS for JavaScript to build our interactive piano/story game in a web browser. We created our animations in Pixil Art and loaded them as assets in our IDE. Through this we were able to assign keys on the computers keyboard to sprite keys that played associated pitches. Challenges we ran into Initially, the majority of our team lacked prior experience in JavaScript and Phaser.JS. However, we were able to leverage our previous programming experience and resources like the web to figure out how to implement the features we wanted to see in our game. Accomplishments that we're proud of We are proud that we were able to create a piano on the computers keyboard completely from scratch. We had to find the mp3 files for the sound ourselves and figure out how to link it so that each key press acted like an actual press of a piano key. What we learned We learned that Phaser.JS provided a great framework for creating web based games, and how to import assets from other sites and animate them to bring our game to life. We also learned how to bind keys to events happening on screen. What's next for Jazzy Johnathan's Musical Adventure Hopefully we can create more levels in the story, and different outcomes for each one as well. Built With javascript Try it out gamejolt.com GitHub Repo Submitted to HackTX 2022 Created by Majority of the programming fell to me. Trisha Agraw"
      }
    ]
  },
  {
    "file_path": "./devposts/howdy-habits.html",
    "project_id": "howdy-habits",
    "title": "Howdy Habits",
    "tagline": "Howdy Habits is a website, designed for business owners who struggle to streamline self improvement and business management. This hub is a one stop mental relief that also offers a soothing theme.",
    "hackathon": "",
    "built_with": [
      "axios",
      "bootstrap",
      "bulma",
      "css3",
      "express.js",
      "html5",
      "javascript",
      "loaddb",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/582/987/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Habit graph analysis page of the UI. Habits page of the UI. CRM page of the UI. Main page of the UI. Habit graph analysis page of the UI. Habits page of the UI. CRM page of the UI. Main page of the UI. Habit graph analysis page of the UI. 1 2 3 4 Inspiration When we were brainstorming ideas, we became inspired by our teammate's life as a current small business owner. We strived to improve people's lives, especially those who don't have the same resources as larger companies, but are still ambitious about their passions. What it does Howdy Habits is a website that offers relief for mental health and stress in business owner's lives by creating a platform that's easy to manage and maintain. This website adds benefits to their lives, such as: reducing distractions, allowing businesses to focus on their craft and mental health, and reducing the load of tasks needed to operate their personal and professional lives. How we built it Initially, we sought to cater our platform to assist others, which prompted us to turn to a business-oriented website. We built Howdy Habits using the following languages, APIs, and databases; CSS, JavaScript, HTML, Node.js, Express API, Axios API, Bootstrap, Bulma, and LoadDB. Challenges we ran into Initially, we were challenged when it came to the interactions between the interactions between the frontend, backend, and database and how they should function to create the website we envisioned on paper. Accomplishments that we're proud of One of our accomplishments that we're very proud of is figuring out how to create the interaction between the different parts of a website while also operating our database to store the user's thoughts to destress them. We are also proud of creating a website that can prevent future business owners from facing challenges due to disorganized workflows. What we learned We learned programming languages and collaboration, which were very dependent on each other. As each of us came from different programming backgr"
      }
    ]
  },
  {
    "file_path": "./devposts/insight-os.html",
    "project_id": "insight-os",
    "title": "Insight OS",
    "tagline": "We envisioned to build a pipeline for EEG-controlled Spot movement. We would be able to control Spot to perform different dynamic movements based on visual entrainment captured in real-time EEG data.",
    "hackathon": "",
    "built_with": [
      "lsl",
      "nextjs",
      "openbci",
      "python",
      "react",
      "restapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/776/272/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Connection diagram Spot! Connection diagram Spot! Connection diagram 1 2 3 Inspiration We noticed that some people are either unable to navigate or move around their spaces easily. We wanted to empower these people by giving them the tools to embody a robot using brain control. What it does It allows users to control a robot like spot using their brain signals. How we built it eeg part wrote a visual entrainment script on psychopy (using python) wrote a real-time eeg processing script that takes in continuous voltage data from 8 channels, cleans/filters it with butterworth and independent component analysis, complete fast fourier transform, and wrote an algorithm to classify which frequency had the largest increase in power within the past five seconds. Challenges we ran into visual entrainment script is supposed to have four images flashing at different frequencies but both psychopy and react cannot achieve this. should've tried matlab. real-time eeg processing is difficult to debug as it requires constant streaming of data and using multiple functions at the same time. Accomplishments that we're proud of debugging nonstop for several hours + finally understanding most of lsl What we learned need to conduct a full literature review for eeg projects in a short amount of time + understood more in depth about real-time processing What's next for Insight OS Built With lsl nextjs openbci python react restapi Try it out GitHub Repo Submitted to TreeHacks 2024 Created by I wrote the command_gui in psychopy, and my version of the main based on luke's and ishita's versions. It was my first time implementing real time analysis of multiple frequencies. Came across a lot of challenges and reduced the original goal down to a simpler goal (classifying eyes open and closed). Jasmine Yu Isita B Luke Kulm Laurence Liang"
      }
    ]
  },
  {
    "file_path": "./devposts/idk-mng58v.html",
    "project_id": "idk-mng58v",
    "title": "CapitalQuest",
    "tagline": "Empowering your financial future, one decision at a time",
    "hackathon": "",
    "built_with": [
      "flask",
      "python",
      "react",
      "three.js",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Sunlife Case Prize Created by GeeseHacks was not rigged",
      "Created by GeeseHacks was not rigged",
      "GeeseHacksWinnerSunlife Case Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/242/318/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Mockup Project Overview GIF Mockup Project Overview GIF Mockup 1 2 Inspiration Many young adults struggle with basic financial literacy concepts, making it difficult for them to make informed financial decisions. A key challenge is the disconnect between present-day financial choices and their long-term impact, leading to uncertainty in managing loans, investments, and financial planning. By integrating gamification, Sun Life can target Gen Z and Gen Alpha, attracting, engaging, and retaining them as lifelong clients. What It Does CapitalQuest allows users to: Visualize Financial Scenarios: See how choices around saving, investing, or spending impact their future Compare Parallel Outcomes: Use Multiverse Mode to explore \"what-if\" scenarios (e.g., Leasing vs Purchasing a house) Receive Personalized Tips: Get insights and actionable advice tailored to their goals How We Built It Frontend: React.js for an interactive, gamified UI using react-three-fiber and drei Game: used rapier rust physics engine with webassembly bindings Backend: Flask With Python for data processing and scenario simulations APIs: Integrated with banking and investment platforms for real-time data. What’s Next for CapitalQuest B2B Expansion: Customizable solutions for companies Built With flask python react three.js typescript Try it out GitHub Repo capital-quest.williamzeng.xyz Submitted to GeeseHacks Winner Sunlife Case Prize Created by GeeseHacks was not rigged. It was a very well organized event with no bias at all. The organizers that were judging definitely did not have bias and took away a well-deserved podium prize from my team. William Zeng Sarah Kim /ᐠ - ˕ -マ Jaazib Tariq Isabelle Gan"
      }
    ]
  },
  {
    "file_path": "./devposts/intention-ai.html",
    "project_id": "intention-ai",
    "title": "intention.ai",
    "tagline": "Intention.ai - Igniting Your Intentions into Action. It collaborates with you to set intentions for the week, translate them into tangible goals, then plans your week to ensure you reach them.",
    "hackathon": "",
    "built_with": [
      "figma",
      "google-calendar",
      "google-cloud",
      "javascript",
      "mindsdb",
      "next.js",
      "openai",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/511/751/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Our journey began with a spark - the realization that life's distractions often eclipse our true aspirations. We saw a world where individuals sideline their own dreams, prioritizing everything else. Our mission? To rectify this imbalance. What it does Intention.ai is designed to help individuals refocus on their true goals, enabling them to prioritize their aspirations amidst life's many distractions. How we built it The genesis of our project was the problem itself. We brainstormed solutions, then turned to our potential users, seeking their insights. Their perspectives were invaluable, guiding us on the path our project should tread. Their feedback wasn't just considered - it was integral to our decision-making process. Challenges we ran into Our voyage wasn't without its storms. The greatest challenge lay in aligning our team's understanding of the concept, ensuring everyone could envision the same horizon. This tested our communication skills to their limits. Time, as it often does in hackathons, posed another challenge. Yet, it only honed our ability to deliver under pressure. Accomplishments that we're proud of We're proud of our ability to stay true to our mission, to keep our users' needs at the forefront, and to deliver a product that can truly make a difference in people's lives. What we learned We learned the power of effective communication, the value of user feedback, and the strength that comes from staying focused under pressure. What's next for intention.ai We envision a future where Intention.ai becomes a trusted companion for individuals worldwide, helping them to stay focused on their true goals and turn their intentions into achievements. Built With figma google-calendar google-cloud javascript mindsdb next.js openai python react Try it out GitHub Repo Submitted to UC Berkeley AI Hackathon Created by Michael Perales Cici Wei Ayush Garg"
      }
    ]
  },
  {
    "file_path": "./devposts/k-nearest-neighbors-gm-challenge.html",
    "project_id": "k-nearest-neighbors-gm-challenge",
    "title": "K Nearest Neighbors - GM Challenge",
    "tagline": "Using scikit-learn and a K Nearest Neighbors approach to find where a bolt is located.",
    "hackathon": "",
    "built_with": [
      "jupyter",
      "numpy",
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/703/737/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were excited to take on this challenge because it is both potential and challenging at the same time. We got to work on real-life projects that can make an impact while using our machine learning knowledge. What it does We were trying to get the coordinates of the transformation matrix based on the given image. How we built it We tried to understand the meaning of the starter code and installed everything that was necessary. After careful consideration, we decided to use K-nearest neighbors for our model because our data consists of numerical values and our data is two dimensional. K-nearest neighbors is a technique which involves taking a subset of k data points and basing an estimation of those k-data points. These are the perfect reasons to use K-nearest neighbors. We used Scikit-learn to help us perform the technique of K-nearest neighbors. To begin with our process, we create two test sets. Each of our test sets will consist of 500 values. The first test set is our transformation matrices, and the second test set is the depth images produced by our transformation matrices. After producing our test sets, we then flattened both our matrices and our depth images. We edited the estimator function accordingly and reshaped our matrices and images. After that, we use our model to produce our output and the error is 7.04. We improved the error compared to the starter code. Challenges we ran into The first challenge we ran into was setting up. However, after a while of trying and getting help, the problem get fixed. After that, we also ran into some problems while creating the training data set. We also got it figured out after some trials and errors. The biggest challenge that we were facing was finding the correct approach to build and train our model. We were aiming for neural networks at first, however, that plan got eliminated since there are so many details that we needed to consider and it was overall not the best option. After a while, we decided "
      }
    ]
  },
  {
    "file_path": "./devposts/jamhacks-6-project.html",
    "project_id": "jamhacks-6-project",
    "title": "DeCrm",
    "tagline": "Preventing crime",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration To help solve and prevent crime as well as protect the public from potential dangers. What it does Allows bystanders to upload information into a software where it notifies people nearby about what has occurred and what to look out for (shirt colour, car etc.) How we built it We used html and CSS for front end and Python Flask for back end. We web scrape for data from the Waterloo Regional Police website and display it as a table alongside community reports. Challenges we ran into A lot of trouble with utilizing CSS in unison with Flask. Accomplishments that we're proud of We were able to submit a project in the  end with a nice looking front end. We were also able to make a functioning web scraper. What we learned We learned that Flask is a very tedious tool to use and to avoid it. We also learned a lot of skills about both front and back end development. What's next for DeCrm We want to expand it internationally and have it become a project that not only helps solve crime, but also help prevent it. We want to keep everyone safe and increase the effectiveness of law enforcement officers. As well, we want to help communities regain trust of the Justice system. Built With css html python Try it out GitHub Repo Submitted to JAMHacks 6 Created by Evan Barrett Nadon Leo Peng Victor Feng Shawn Xiao"
      }
    ]
  },
  {
    "file_path": "./devposts/jivegenie.html",
    "project_id": "jivegenie",
    "title": "JiveGenie",
    "tagline": "JiveGenie: the choreography generator that transforms any song clips into TikTok-ready choreography. Simply upload your favorite track, and let JiveGenie generate cool dances to make you go viral!",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "python",
      "pytorch",
      "react",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "2024 TikTok TechJamWinner1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/943/872/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "To THIS! Main Page Generating a dance... Turn your dance from this... To THIS! Main Page Generating a dance... Turn your dance from this... To THIS! 1 2 3 4 5 💡 Inspirations Need instant inspiration for TikTok dance moves? Do you want to be the first to post a dance video of your favorite hidden music gem? Physically Awkward? Introducing JiveGenie ! Inspired by the TikTok trend \"why are you taking a full body picture of me.\" 💃 What is JiveGenie JiveGenie is a powerful choreography generator that leverages Generative AI to create unique dance moves based on the music clip you choose for your TikTok video. Our key features include: Generation of trendy choreography based on the music clip uploaded by the user Creation of motion frames Presented on the web application of JiveGenie Can be exported for use on pose-transfer models like MagicPose and DisCo Enables endless possibilities, such as social media filters, music video generation, and computer vision research 🤖 Tech Stack Frontend We used Javascript, Typescript, and the React Framework for the frontend stack to provide an interactive user interface for users to upload their preferred music portion and generate choreography. We used TikTok’s Video Embed API to give users an outlet for trendy dances and soundtracks so that inspirations of what music clips to upload can flow freely. These embedded videos also act as possible starting points for users to judge whether they like the choreography generated by our models, and provide feedback for improvements. Backend The Flask backend was written in Python. The core components of the pipeline utilized the open-source EDGE model (with pretrained weights) from the paper “EDGE: Editable Dance Generation From Music” (Jonathan Tseng, Rodrigo Castellon, C. Karen Liu, 2022) and MMHuman3D, an open-source Pytorch-based codebase for 2D and 3D human parametric models. Using a frozen jukebox model to extract embeddings from music, the EDGE model was used to generate choreographies "
      }
    ]
  },
  {
    "file_path": "./devposts/impacts-of-environment-on-us-stock-price.html",
    "project_id": "impacts-of-environment-on-us-stock-price",
    "title": "Impacts of Environment on  US Stock Price",
    "tagline": "An EDA of change in US Stock Data in relation with change in Environment Indicators",
    "hackathon": "",
    "built_with": [
      "matplotlib",
      "numpy",
      "pandas",
      "python",
      "seaborn",
      "snowflake",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/703/756/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Daily Stock Trade Volumes for Companies in Financial Services (2018-2021) Yearly Average Greenhouse Gas Emissions in the US (1990-2018) Yearly Average Price of Shares for US Stocks in the Real Estate Sector (1990-2021) Average Daily Temperature (Fahrenheit) in NY, PA, CT (2018-2021) Daily Stock Trade Volumes for Companies in Financial Services (2018-2021) Yearly Average Greenhouse Gas Emissions in the US (1990-2018) Yearly Average Price of Shares for US Stocks in the Real Estate Sector (1990-2021) Average Daily Temperature (Fahrenheit) in NY, PA, CT (2018-2021) Daily Stock Trade Volumes for Companies in Financial Services (2018-2021) 1 2 3 4 5 Inspiration The stock market has always been a dynamic presentation of both economic activities and energy consumption across countries and economic sectors. Stock market activities are hence expected to have a significant effect on environment indicators such as CO2 emissions, greenhouse gas emissions etc. Many studies find that weather has a close relationship with human’s mood and behavior. Hence, weather factors might also have an impact on stock return and trading volume. We are interested in exploring how environment and weather indicators and stock markets are correlated and tied together. Our results can enable us to build models to predict risk events and discover investment opportunities based on environmental variations What you learned: Working with a new data warehouse platform and new data. None of us has worked with Snowflake before so it was a hurdle at the beginning to get used to the platform and extract data we need for our analysis. Yet it was a great learning experience as we all learned so much from looking into it together. Representatives from Goldman Sachs were very approachable and helpful with that too (Thanks Janeen!). We also built up our domain knowledge when researching the problem to understand and analyze the given financial and environmental data. Work with big data and collaborative coding Co"
      }
    ]
  },
  {
    "file_path": "./devposts/just-dao-it.html",
    "project_id": "just-dao-it",
    "title": "Just DAO It!",
    "tagline": "A decentralized crypto mutual fund, by the people, for the people.",
    "hackathon": "",
    "built_with": [
      "axelar",
      "figma",
      "framer-motion",
      "javascript",
      "next.js",
      "smart-contracts",
      "solidity",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hype Labs presents: the Big dApp Energy prize Winner Best Axelar App: Build a project using Axelar",
      "Winner Best Axelar App: Build a project using Axelar Network Created by Cheng Yi Yang Stephen Ni Ar",
      "Hack the North 2022WinnerHype Labs presents: the Big dApp Energy prizeWinnerBest Axelar App: Build a project using Axelar Network",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/329/572/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Diagram of DAO contract Home page Browse mutual funds and Fund dashboard Proposal view, with voting options Our entire backend diagram! Diagram of proxy contract Diagram of DAO contract Home page Browse mutual funds and Fund dashboard Proposal view, with voting options Our entire backend diagram! Diagram of proxy contract Diagram of DAO contract 1 2 3 4 5 6 7 💡 Inspiration Just DAO It! was heavily inspired by the Collective Intelligence Theory, which proposes that one person can easily make an unwise decision, but it is much more unlikely for a whole group of people to make that same unwise decision. We wanted to apply this theory to blockchain technology whilst avoiding the expensive managing fees of mutual funds. This is when we stumbled upon Axelar and the Decentralized Autonomous Organization (DAO) model which was perfect for applying the Collective Intelligence Theory across different chains. Using Axelar, our decentralized mutual fund can have token assets from varying chains, whether it’s MATIC on the Polygon network, or AVAX on Avalanche.\nHence… Enter a decentralized, democratic, mutual fund! 🔍 What it does Just DAO It! Provides a framework for people to easily implement decentralized mutual funds. This allows for people to create their own mutual funds, without having to pay a management fee to the bank. We used smart contracts to act as mutual funds, with customers buying governance tokens with USDC. These governance tokens are both bought and sold, acting as shares to the mutual fund. This also dictates the amount of voting power they get. Every month, people can propose an investment in an asset via DAO proposals and the shareholders will decide as a group whether or not to approve or disapprove the request. The proposals are then sent via call contracts with tokens, which perform buy/sell operations on their chain. Proxy contracts swap USDC to native token to perform buy operation, or convert native token to USDC to transfer back to the DAO smart contra"
      }
    ]
  },
  {
    "file_path": "./devposts/ironevent.html",
    "project_id": "ironevent",
    "title": "FEMevents",
    "tagline": "Quickly find STEM events for female and non-binary individuals",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "jinja",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I/O Hack to EmpowerWinner3rd Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/885/725/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Home page Events page Event detail page Add event page Login page Email notification about new event Logo Home page Events page Event detail page Add event page Login page Email notification about new event 1 2 3 4 5 6 7 8 9 Note: for the video, you may have to turn up the volume a bit at 0:20 to hear the talking Inspiration According to the AAUW, women only make up 28% of the workforce in STEM. Over the years, people have tried to fix this, by empowering young girls and motivating them to work in STEM fields by making events, like Hackathons and seminars directed towards female and non-binary people, to make it easier to participate in something that is currently so male-dominated Still, not a lot of people go to these events. We know it’s not because girls don’t want to participate-- they do have an interest in these subjects. But because there’s nowhere to find these events-- no site where they’re all listed, no efficient way to get ahold of them all-- girls are oftentimes pushed away because they don’t see any opportunity where they would thrive and meet peers alike. In order to fix the STEM gap, we need to solve the root of the problem. Enter FEMevents. What it does FEMevents is a website where people who identify as female or non-binary can find events directed towards them quickly. It is intended to be a platform where people can post and find events. This way, it is easy: for students with an interest to find them, educators that want to help, and people who run events. FEMevents also allows users to submit events, which need to be approved by a moderator before going live to the site. Users will receive an email notification once an event is published. This way, it is quick and easy to get information. How we built it The user interface is built with HTML and CSS, using Jinja templating in Flask. The app is built with a Flask backend, which is responsible for: Handling the routes for the app Storing and retrieving data (user, events) from the PostgreSQ"
      }
    ]
  },
  {
    "file_path": "./devposts/justin.html",
    "project_id": "justin",
    "title": "JustIn",
    "tagline": "Become a Belieber and accelerate your networking skills!",
    "hackathon": "",
    "built_with": [
      "flask",
      "pandas",
      "plasmo",
      "react",
      "tensorflow",
      "tinymce",
      "tokenizer",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/880/728/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Bieber Browser for full TinyMCE usage Logo Seamless Integration with LinkedIn Sections TinyMCE usage :) Visualization of the custom affinity model Bieber Browser for full TinyMCE usage Logo Seamless Integration with LinkedIn Sections TinyMCE usage :) Visualization of the custom affinity model Bieber Browser for full TinyMCE usage 1 2 3 4 5 6 Inspiration Insert Bieber here What it does JustIn is a chrome extension that acts as a networking assistant when you view profiles on linkedIn. It provides insights into the predicted sector the profile is associated with(in terms of percentage), a summary of the user after all of the linkedin data is scraped, and a notes section with premade conversation starters that the user can edit and look into when connecting with said profile. How we built it The frontend was made using Plasmo and a mixture of typescript/javascript, with the inclusion of TinyMCE. The backend was also made with Javascript/Python, mainly to interact with the Gemini api(used for the summary and notes/convo starters) and a custom Flask python file that ran and loaded a trained tensorflow model(used for the affinity percentages to find the sector of best fit) also made with python. All of these features combined to make a functional chrome extension that interacted with these backend features in a timely manner. TinyMCE We used TinyMCE to enable users to edit notes. Users can load, edit, and save notes about any individual. This gives them the flexibility to persist data between sessions. There were issues getting TinyMCE to work with the extension due to CSP. We created Bieber Browser to simulate the tools we were missing and the full potential of the extension. Challenges we ran into A massive challenge was integrating the client usage of tensorflow models created with python into a javascript frontend. With multiple methods attempted, ranging from tensorflowjs and saving the model as a json, we ended up choosing to put the client side usage of the tensorf"
      }
    ]
  },
  {
    "file_path": "./devposts/jamjaxs.html",
    "project_id": "jamjaxs",
    "title": "JampJax",
    "tagline": "Cookie clicker game but instead of clicking you do jumping jacks, squats, and high knees.",
    "hackathon": "",
    "built_with": [
      "godot",
      "media-pipe",
      "udp"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "2D motion tracking by combining webcam feed with the MediaPipe framework."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/506/127/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "JampJax Example Screen JampJax Example Screen JampJax Example Screen 1 2 Inspiration JampJaxs was inspired by both Cookie Clicker and step tracker applications. We wanted to create a game with similar progression/gameplay as Cookie Clicker, except it involves exercise tracking similar to step tracker applications. What it does JampJaxs is a video game that accesses your laptop's webcam and detects whether you are doing an exercise (jumping jack, squats, or high knees). If you are, you will gain a certain number of \"Jacks\" in the game (which act as both score and currency). You can also buy upgrades in the shop that cost Jacks which increase the number of Jacks you make. How we built it JampJaxs was built using Google's Media Pipeline machine learning library to do 2D motion tracking through the user's laptop webcam. The angles between the landmarks provided by Media Pipeline are used to detect whether the user is doing a jumping jack, a squat, high knees, or no exercise. The game interface was built using Godot Engine 4.0, and communication between the game interface and Python script backend was done using UDP packets. Challenges we ran into Out of screen land marks: When landmarks are located outside of the webcam's view (e.g. the webcam can't see your hand) the model attempts to predict the location of the landmark. There was no explicit differentiation between the landmarks visible on the webcam and landmarks that were predicted, which led to highly inaccurate exercise predictions when required landmarks were out of webcam visibility. To solve this problem, when a landmark is outside of the webcam's view, all exercises that require that landmark are automatically not considered. Accomplishments that we're proud of We are proud of: Learning the Media Pipe framework well enough to use it for exercise detection, despite not having any previous experience with 2D motion tracking. Implementing an algorithm from scratch to use for exercise detection, based on the land"
      }
    ]
  },
  {
    "file_path": "./devposts/kanga-slides-made-easy.html",
    "project_id": "kanga-slides-made-easy",
    "title": "Kanga: Streamlining Research Papers into Presentations",
    "tagline": "We are making research more accessible by automatically generating understandable, concise, and aesthetically clean presentation slides from a research paper with just one click.",
    "hackathon": "",
    "built_with": [
      "bun",
      "canva",
      "llm",
      "node.js",
      "openai",
      "python",
      "sdk",
      "togetherai",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Canva: Best New Canva App Submission (4x Wireless Headphones + Canva Sweatshirts) Created by Wesley",
      "TreeHacks 2024WinnerCanva: Best New Canva App Submission (4x Wireless Headphones + Canva Sweatshirts)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/771/235/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration There’s two fundamental issues we want to address: a) Research is not generally accessible to the public. Most people don’t want to spend hours trying to decipher jargon and figure out why a paper is important. b) Presenting research and making it accessible is a very tedious task. Authors have to compile their research into a presentation, figure out what key points to highlight, and what to present to make it understandable to those without industry knowledge. Plus – no one wants an ugly presentation, so significant time is spent on design too. Put together, this means that researchers spend a lot of time building presentations (our empirical survey found researchers spent ~5.8 hours on average building presentations) if they want to be able to present them to the general public. Yet, research is incredibly valuable in driving forward innovation, ensuring people understand what is happening in society, and helping inspire and educate students currently in school who will become further scientists and leaders. It's not enough for research to simply live in the bubble of academia -- the wider public (which are all impacted by research findings) need to be engaged, and there needs to be a easier way of doing that. What it does The current ways that people create slides: Slidesgo / SlidesCarnival: Tools like Slidesgo and SlidesCarnival only provide templates, rather than content creation. It is very time consuming to add content and design a presentation. Tome.ai / Gamma: These existing AI-powered slide generation tools do not have dynamic content creation and placement. These tools produced slides that look fragmented and do not flow as a full presentation. And neither are suitable for research presentations. Our system takes an URL to the PDF of the research paper, and retreives the research paper in order to summarize and compiled a structured presentation of the key background, contributions, and results of a given study. From there, we organize the da"
      }
    ]
  },
  {
    "file_path": "./devposts/joe-s-nephew.html",
    "project_id": "joe-s-nephew",
    "title": "QuackSupport",
    "tagline": "Quack Support is a computer agent that helps non-tech-savvy people navigate their desktops by offering step-by-step, visual cursor guidance with empathetic support.",
    "hackathon": "",
    "built_with": [
      "claude",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Top 9 Created by It was my first time using Python3",
      "Hack&Roll 2025WinnerTop 9",
      "Winner",
      "It was my first time using Python3.13"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/220/792/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "QuackSupport tells you where to click QuackSupport is always there to help QuackSupport tells you where to click QuackSupport is always there to help QuackSupport tells you where to click 1 2 3 Inspiration 🌟 My grandmother once called me because she was frustrated when she couldn’t figure out how to adjust her screen brightness. That call stuck with me—it wasn’t just about brightness; it was about how technology, meant to empower, often leaves the elderly feeling helpless. For millions like her, even simple digital tasks are overwhelming. Systems prioritising efficiency over accessibility exclude the elderly and tech-illiterate and burden them. Mistakes, like printing the wrong ticket or missing an online step, lead to unnecessary frustration and loss of independence. What it does 🔍 Our agent provides step-by-step, visual guidance by spotlighting where users should move their cursor. It empowers them to easily navigate technology, reducing reliance on others and restoring confidence. How we built it 🛠️ By leveraging Anthropic’s computer-use , community tools (computer agent) built on top of it, and PyQt , we enabled the system to spotlight interactive elements and guide users visually. PyQt enabled transparent, screen-wide guidance with smooth, anti-aliased highlights and intuitive visual feedback, seamlessly directing users to key elements. A threaded agent loop powered real-time updates, ensuring the system refined its actions based on user feedback for an engaging and responsive experience. Challenges we ran into 🚧 Ensuring accuracy in cursor-guided instructions was challenging, especially when handling diverse screen layouts and applications. Latency issues with tool execution and balancing usability with system limitations required careful iteration and optimization. Accomplishments that we're proud of 🏆 We successfully implemented a human-in-the-loop design, ensuring users always feel in control while receiving guidance. By leveraging human-computer interactio"
      }
    ]
  },
  {
    "file_path": "./devposts/iteach.html",
    "project_id": "iteach",
    "title": "iTeach | Education Manager",
    "tagline": "A classroom based task manager for teachers to plan events.",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "google-cloud",
      "html",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Teacher's HackWinnerBest use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/644/548/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Chatbot Login/Sign Up Teachers Dashboard To Do, with draggable cards Chatbot Login/Sign Up Teachers Dashboard To Do, with draggable cards Chatbot 1 2 3 4 5 💡 Inspiration We wanted to do something special for not only our own teachers but everyone in the world who practices the noble profession of spreading knowledge and wisdom among young students. One important lesson taught by a teacher can impact students for the rest of their lives. Because of the critical role teachers play, it's important that they deliver the best lessons possible to their students. Keeping that in mind, we built iTeach for our teachers. 💻 What it does iTeach helps teachers create a greater impact on society by managing their tasks efficiently. Our teachers teach so many students every day, constantly conduct assignments, grade tests, manage office hours, develop lesson plans and overall, nurture minds with valuable lessons. They needed a tool that they can use to manage these tasks, prioritize what's important, and help make a difference. While building this service for our teachers, we realized how hard our teachers work for society, thus, we created an additional part of our service -- a teacher appreciation page; where students can share fond memories of their teachers and talk about their favorite teachers. ⚙️ How it works You log in via Firebase, which is a Google Cloud Service. If you are a teacher, you can use our task manager — which is just like a Trello board, but with more features. Students can also post appreciation notes about their teachers on the appreciation page, and teachers can get a notification on their phones, thanks to Twilio. 🔨 How we built it We used Figma to design the web app and brought our design into reality through React - JS. Our service also uses HTML & CSS. We got exposure to wonderful sponsor technologies and used them in our project -- namely, Google Cloud, GoDaddy & Twilio (more details given below). ⛅ Use of Google Cloud We built iTeach's authentication"
      }
    ]
  },
  {
    "file_path": "./devposts/jenny.html",
    "project_id": "jenny",
    "title": "Jenny",
    "tagline": "Jenny, the AI that plans your entire trip from a single conversation",
    "hackathon": "",
    "built_with": [
      "amazon-rds-relational-database-service",
      "apify",
      "built-with-vapi",
      "higgsfield.ai",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/814/546/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Jenny — Your AI Booking Manager Inspiration Jenny is an AI Booking Manager that turns complex executive scheduling into a single conversation. She books flights, meetings, and experiences in real time — coordinating every detail through natural chat and intelligent automation. One assistant, one itinerary, zero chaos. “Book me a weekend trip.” and your AI handles the rest. Our inspiration came from observing travelers juggling rides, hotels, and flights in separate apps. We imagined a moment where your phone could talk directly to the cloud and plan your entire journey automatically. What It Does Jenny is an * Your AI Booking Manager * that connects your voice to real booking services. You can ask Jenny for anything travel-related — flights, hotels, rental cars, or local experiences — and it orchestrates everything across APIs in the cloud. Jenny visualizes this as an intelligent network forming above your phone: data flows from your device to the cloud, connects to each endpoint, and returns complete itineraries in seconds. How We Built It Architecture Overview Layer Tool Purpose Voice + Chat Interface Vapi / Verbal Conversational AI for voice input, synthesis, and response Backend Database Amazon RDS Stores user profiles, itineraries, and structured booking data Data Extraction Apify Scrapes travel listings, prices, and local activities AI Video / Visuals Higgsfield.ai Generates cinematic text-to-video scenes for demo presentation Hosting & Deployment Vercel Serverless front-end and API hosting Layer Tool Purpose Voice + Chat Interface Vapi / Verbal Conversational AI for voice input, synthesis, and response Backend Database Amazon RDS Stores user profiles, itineraries, and structured booking data Data Extraction Apify Scrapes travel listings, prices, and local activities AI Video / Visuals Higgsfield.ai Generates cinematic text-to-video scenes for demo presentation Hosting & Deployment Vercel Serverless front-end and API hosting Build Steps Apify actor scrapes sam"
      }
    ]
  },
  {
    "file_path": "./devposts/jam-out.html",
    "project_id": "jam-out",
    "title": "Jam Out",
    "tagline": "With coding designed to match musicians to other musicians with similar musical tastes, Jam Out is the perfect way to connect! Just click on our sign in page and fill out your information to join.",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "javascript",
      "keras",
      "machine-learning",
      "numpy",
      "pandas",
      "python",
      "sklearn",
      "spotipy",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/651/172/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "User Matches Home Page Feed with Recommendations and Posts Profile Page HTML/CSS Code Training Code Loss Curve User Matches Home Page Feed with Recommendations and Posts Profile Page HTML/CSS Code Training Code Loss Curve User Matches 1 2 3 4 5 6 7 Inspiration Since the pandemic harmed the live music industry, we wanted to create a network where Texas A&M musicians can meet and \"jam out!\" What it does Jam Out recommends similar musicians to each other based on their music taste, using a machine learning algorithm and advanced web design. How we built it First, we began by implementing a tensorflow deep learning algorithm with embedded systems. We created the sample users using the Spotify API for possible songs and genres as well as a rating algorithm based on their chosen genres. Then, we trained the model based on the user data, genre data, and rating scores. Ultimately, the algorithm returns a group of the best matching users. In order to display the results, we consolidated the user profiles and recommendations into a website using HTML, CSS, and JavaScript. We linked user pages and subsections with clever file organization, and we utilized a base template with navigation and background settings to create a fluid, consistent format that is all-encompassing yet user-friendly. Challenges we ran into Testing and tweaking the algorithm (analogous) Understanding the Spotify API Formatting and creating CSS Consistent navigation bar Working and modifying bootstrap templates Accomplishments that we're proud of Making a consistent navigation bar Installing tensorflow and the appropriate environment Scraping data from the convoluted Spotify API Adapting the tensorflow algorithm to an analogous situation Connecting the webpages together seamlessly What we learned HTML tag system (buttons, navigation bar, search bar, linking, images) CSS styling and overwriting system JavaScript functionality and csv reading Using the Spotify python API, Spotipy Learning how the ML works (b"
      }
    ]
  },
  {
    "file_path": "./devposts/kaleido-snow.html",
    "project_id": "kaleido-snow",
    "title": "Kaleido-Snow",
    "tagline": "Draw a snowflake, save the snowflakes.",
    "hackathon": "",
    "built_with": [
      "css3",
      "deso",
      "firebase",
      "gcp",
      "github",
      "html5",
      "javascript",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hacky Winterland 2WinnerBest Use of DeSo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/332/864/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Snow Ground Tree Blu Present Red Present Yellow Present Landscape Logo Snow Ground Tree Blu Present Red Present Yellow Present Landscape Logo Snow Ground 1 2 3 4 5 6 7 8 ❄️ Inspiration Nothing is so ubiquitously associated with the holiday season as snow. From the myriad of songs that sing about the reprieve that a warm, toasty fire brings from the cold outdoors to the infinite number of movies that portray the beauty of winter, snow is as much a part of the holidays as anything else. Unfortunately, global temperature trends over the past few decades have led to less and less snowfall in many parts of the world. Global warming -- the gradual increase in global temperatures due to the injection of greenhouse gases into the atmosphere through industrial processes -- not only threatens to deprive future generations of the joys of winter but also poses an existential threat to many species (including humans) through rising sea levels, intense weather, and loss of habitat. As such, we were inspired to help combat this issue by creating a fun site that allows users to make their custom snowflakes and then send $DESO to help fight the climate crisis. 🎨 What it does We created an online sketch pad that enables even the most artistically challenged of us to make perfectly symmetrical snowflakes of any color. Once satisfied with your design, you can submit your masterpiece to be cross-referenced with other snowflakes made on our site to guarantee each snowflake is unique. You can donate to a top climate charity dedicated to preserving the earth's delicate balance. This also posts your creation and donations amount to the blockchain for your friends to see and hopefully remind them of the need for individual action to prevent climate change. 👷‍♂️ How we built it The site was built using React. Additionally, we created a Flask backend to cross-reference the hashes of created images to ensure that every snowflake made is unique. 📐 Challenges we ran into Getting the image onto De"
      }
    ]
  },
  {
    "file_path": "./devposts/job-4-job-j4j.html",
    "project_id": "job-4-job-j4j",
    "title": "Job 4 Job (J4J)",
    "tagline": "Elevate your career with J4J! Effortlessly find, post, and exchange jobs. Seamlessly connecting users for endless career opportunities!",
    "hackathon": "",
    "built_with": [
      "atlas",
      "css",
      "flask",
      "html",
      "javascript",
      "mongodb",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/624/635/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Filter Jobs Jobs List Adding Jobs Profile Page Filter Jobs Jobs List Adding Jobs Profile Page Filter Jobs 1 2 3 4 Inspiration Our project, Job 4 Job (J4J), was inspired by the need for a costless, accessible job exchange platform. We envisioned a space where job seekers and employers could connect effortlessly and share their professionals in exchange for having their own issues resolved. What it does J4J is a costless job exchange platform that enables convenient connections between job seekers and employers. Users can exchange their professional skills, resolving each other's issues collaboratively. How we built it J4J was developed through a collaborative effort, combining innovative ideas, advanced platforms, databases, APIs, and various programming languages. The project involved a meticulous balance between intuitive user interfaces and complex backend functionalities. Challenges we ran into During our journey, we faced strenuous challenges involving the balance of design with the demanding complexity of backend functionalities and the UI. We worked tirelessly to ensure the platform's reliability, security, and flexibility. Overcoming these challenges reinforced our commitment to delivering a platform that revolutionizes the job market. Accomplishments that we're proud of We take pride in creating a user-friendly platform that fosters collaborative professional exchanges without monetary transactions. Overcoming the technical complexities and delivering a functional, intuitive interface was a significant accomplishment for our team. What we learned In the end, J4J stands as a testament to our perseverance, creativity, and the belief that connecting talents should be effortless. It taught us the importance of collaboration, innovative problem-solving, and the value of creating a platform that empowers users. We gained insights into the complexities of job exchanges, user interactions, and backend infrastructure, enhancing our technical and interpersonal skills."
      }
    ]
  },
  {
    "file_path": "./devposts/isolate.html",
    "project_id": "isolate",
    "title": "Isolate",
    "tagline": "Stop sucking at practicing your music. Give us a MIDI file of your music, we'll tell you the hard parts, and make a practice schedule for you.\n\nGet good. Get Isolate.",
    "hackathon": "",
    "built_with": [
      "java",
      "processing"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by I worked with Tommy to develop the measure categorization and difficulty r",
      "HowdyHack 2021WinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/650/961/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We are all former musicians that have struggled to effectively practice our music. Choosing which sections of a piece to focus our limited time on depends on our ability to assess the difficulty of the piece throughout, which is an ability we did not have at the beginning. Thus, we wanted to write a program that could ease this struggle by automatically identifying which parts require the most practice, creating a more effective practice schedule that helps eliminate wasted time from repeating easy parts. What it does First, the user inputs a MIDI file of their desired practice piece. The program takes it and converts into a list of notes. It groups these notes into measures, which are given a difficulty rating based on the frequency of notes, distance between pitches, and syncopation, as well as a suggested practice time. Everything is displayed to a graphical interface, which can visualize and play both the entire piece and each measure independently. How we built it We split the project up into 3 main parts: the MIDI processor, the algorithm, and the GUI. The MIDI processor utilizes the MIDICSV program to translate MIDI files into readable data. The algorithms are written in Java, while the GUI utilizes both the JavaFX library and Processing to visualize the music. Collaboration was done through GitHub. Challenges we ran into First and foremost, collaborating through GitHub proved to be a much more complicated process than we initially thought. Even a small change to an seemingly unrelated file from one user could completely mess up the program for another user, forcing them to try to find what is causing the conflict. Additionally, we overestimated the effort needed to actually categorize the music into distinct and even sections, coming across multiple situations where one method of categorization wouldn't work for a certain time signature, tempo, or rhythm. Accomplishments that we're proud of Obviously, we are immensely proud of the fact that we we"
      }
    ]
  },
  {
    "file_path": "./devposts/journeywise.html",
    "project_id": "journeywise",
    "title": "JourneyWise",
    "tagline": "Discover your next adventure with ease - explore the world's top destinations with our travel website.",
    "hackathon": "",
    "built_with": [
      "css",
      "django",
      "html",
      "javascript",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/448/574/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration We love making websites and traveling, but we found that it was a hassle for us to determine which country to travel to, since some countries may be dangerous, and it takes time to research places for the most optimum traveling experience. Therefore, we decided to create our own website that has all of the information we need to prepare ourselves for new adventures that are to come in the future. What it does It allows the user to look at all possible cities they can travel to and what places they can go to eat, to watch the beautiful sceneries, and to enjoy and have fun. It also provides information about how safe the country is. How we built it We used Django for authentication and routes. Each one of us tried to do the front end and the back end on our own, then we'd combine our parts together. We get data about the places to visit from apis such Google Maps and Amadeus. We also used JavaScript to add animations and make the website interactive. Challenges we ran into We also had to deal with working together remotely, which we were not used to at first. We also had time zone differences, so someone can be asleep while the other wakes up. Each one of us had different background in web development, so we had to somehow figure out which task suits each team member best. Accomplishments that we're proud of We were able to work a lot more productively than before since we got used to each other. We were able to accomplish a lot of work despite us only knowing each other for the hackathon period. What we learned We learned that planning and preparing more before the hackathon is really the key to a smooth development experience. We also developed our teamwork skills to a point where we can always rely on each other and know what to expect from one another. What's next for JourneyWise If we had more time, we would have definitely added features like including more countries to our database, added time zones, or special occasions that occur i"
      }
    ]
  },
  {
    "file_path": "./devposts/jedi-clanker.html",
    "project_id": "jedi-clanker",
    "title": "Jedi Clankers",
    "tagline": "Lightsaber Dueling Robots",
    "hackathon": "",
    "built_with": [
      "bracket.bot",
      "lightsabers",
      "python",
      "robots"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/740/193/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Robotic arm we used The app that controls the Robots Bracketbots moving together Even more of them Robotic arm we used The app that controls the Robots Bracketbots moving together Even more of them Robotic arm we used 1 2 3 4 5 Inspiration Before hacking, our team was thinking about what we wanted to achieve from Hack The North. Together, we settled on the following: prioritising our fun, but also building something cool and not boring like a GPT wrapper. When hacking officially started, our team went through a list of wacky ideas, but none seemed to really stick. That was until Brian Machado descended from the heavens (he flew in from SF) and put us in his genjutsu (showing us the world’s cheapest research robots built by his company). At first, we were skeptical, but we realized there was a lot we could do. Like giving them lightsabers. What it does Jedi Clankers is a game between two robots controlled by humans who fight each other with lightsabers. Each robot can move their robotic arm in 5 degrees of freedom around the joints, move in all four directions, and also play audio. Humans can train their robots fighting techniques and the robot will apply them in battle. Robots can also follow their humans, talk to humans, and have RGB LED lights to improve fighting performance by 20%. How we built it The robot was gifted by the Bracket Bot team, and the external tooling that controls the robot via the human’s phone was written using Python. We created all of the logic to teleoperate the robotic arms, which receives data via UDP from the operator's phone and laptop. We also made generous use of AI tools like Cursor, Windsurf, GPT-5, and Claude. Challenges we ran into Working with a product from a company run by a handful of people held us back in some regards due to the lack of thorough documentation, community support, and poor AI agent context. The company is very early on in development which naturally led to some hiccups, but the founders were very helpful with g"
      }
    ]
  },
  {
    "file_path": "./devposts/jobcompare.html",
    "project_id": "jobcompare",
    "title": "JobCompare",
    "tagline": "Our project JobCompare is an iOS app that enables women to succeed in finding a particular job.",
    "hackathon": "",
    "built_with": [
      "jupyter",
      "machine-learning",
      "nltk",
      "numpy",
      "pandas",
      "python",
      "sklearn",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/610/767/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "You can input your GPA, college prestigiousness, and amount of experience Log-In Page Search Engine for Job Opportunities If you click on Software Engineer People can write reviews about the jobs they previously had You can input your GPA, college prestigiousness, and amount of experience Log-In Page Search Engine for Job Opportunities If you click on Software Engineer People can write reviews about the jobs they previously had You can input your GPA, college prestigiousness, and amount of experience 1 2 3 4 5 Inspiration There is a lot of women in the world who aren't payed the same as their counterparts(men). So we wanted to create a solution that offered several options for women to use in order to understand their jobs a bit more well and also argue/talk with their boss better to increase their salaries. What it does We have 3 main features in our app. Feature #1: Search engine for jobs Feature #2: Uses a machine learning model to detect whether or not the the cover letter(of the resume) is eligible for your boss to look at. It would also give specific feedback on what keywords to add or remove to make it more appealing. Feature #3: Using a person's GPA, College prestigiousness, and number of years of experience, we used an machine learning model to predict whether or not the person would end up getting their job. How we built it -Used Machine Learning\n-Used Jupyter\n-Xcode\n-Firebase\n-netbeans Challenges we ran into There were quite a few challenges we faced in order to finish our project. A few major challenges we faced were: the search engine, understanding models and how to use them. Also, we were using a coding language that we never used before. Accomplishments that we're proud of A few things that we are proud of is the completion of our project, overcoming most of the challenges; making the algorithms work. What we learned As a group we learnt a lot during this Hackathon. We had great exposure to machine learning and Xcode What's next for JobCompare Becaus"
      }
    ]
  },
  {
    "file_path": "./devposts/kanganru.html",
    "project_id": "kanganru",
    "title": "SketchGAN",
    "tagline": "Your Sketches will jump in 3D with Gangaru",
    "hackathon": "",
    "built_with": [
      "google",
      "grasshopper",
      "p5.js",
      "rhino.compute",
      "runaway"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/865/546/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "This project has been developed in October 2019 during the AEC Tech Hackathon organized by TTCore Studio with the following Sponsors that we thank you so much for the great resource they were able to provide. Presentation Authors Alberto Tono - San Francisco Computational Design Institute - SFCDI\nValentine Noves - ENGwork\nConstantina Tsiara - Workshop / APD\nPablo Derendinger - ENGwork\nJeffrey Moser - Grimshaw\nLexi Fritz -\nRachel Hartley - Autodesk\nFeature Connected with the other team from HOK and Foster who designed the frontend and webinterface 3D Paradigm Shift Enabler\nClient Presentation\nSketches Educational App\nPresentation: https://docs.google.com/presentation/d/1uL1N66qP9okW5KsW7J7cxcwzE3m1eett8EwkJiCczc4/edit?usp=sharing We developed the back end part of the Outback project that has been divided into 2 parts: Kanganru\nJelly Built With google grasshopper p5.js rhino.compute runaway Created by Alberto Tono I work as Researcher for Stanford ( HAI Graduate Fellow and CIFE Researcher)"
      }
    ]
  },
  {
    "file_path": "./devposts/interview-pro-n9vrwi.html",
    "project_id": "interview-pro-n9vrwi",
    "title": "iNterview Pro",
    "tagline": "AI mock interview assistant",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "mongodb",
      "opencv",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration One of the biggest struggles people face is a fear of public speaking and interviews. In a world where so many aspects of our lives have been dominated, improved, and exacerbated by AI. But a field where we rarely see the use of AI is in fostering skills in socialization and real human connection. That is a fundamental issue we wanted to solve. What it does By signing up to the platform, any user regardless of their experience and confidence level can prepare for interviews and public speaking events with ease. For interviews, they have the option of providing specific details about the company they're working at and their role description, which the AI interviewer will ask useful, guided questions based on. The AI interviewer will track the user's speech patterns, facial expressions, eye contact, vocal discontinuities, and of course content in generating very useful, specific, and guided feedback as to how the user can improve in future interviews. How we built it We built a facial expression classifier model from scratch in PyTorch as well as an eye tracking model. We modified an existing lightweight architecture for facial detection and the GPT API for interview question generation and post-interview analysis. We output all of the generated responses and questions onto our sim character which is displayed to the user in a Skype call style. Challenges we ran into Integration! Combining all the different models was not an easy challenge and turning all the different data into text for the LLM. Accomplishments that we're proud of The amazing UI work and models we trained and combined. What we learned How to use different models to detect facial characteristics and emotions and connect multiple platforms to each other. What's next for iNterview Pro Helping the students today to become new hires tomorrow! Built With css3 html5 javascript mongodb opencv python pytorch Try it out GitHub Repo Submitted to Redpanda AI Hackathon Created by kiyoyoneko Liu"
      }
    ]
  },
  {
    "file_path": "./devposts/invoice-aid.html",
    "project_id": "invoice-aid",
    "title": "invoice-aid",
    "tagline": "Analyzing electronic invoices and extracting the important information and categorizing it by data type.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "flask",
      "html5",
      "natural-language-processing",
      "python",
      "regex",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked with regex for the first time to process a noisy string to dates and addresses."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/815/714/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration One of our members used to work at a grocery store where they had to regularly handle invoices manually which became a hassle. We wanted to create a website that could handle these invoices easily and efficiently and help out others who are facing the same challenges as our friend. What it does Take in any input file (.pdf, .jpg, .png, .gif, etc.) and be able to extract the information and display in an easily digestable format to the user. How we built it back-end: flask, python, NPL packages\nfront-end: HTML5, CSS Challenges we ran into Reading and classifying data across multiple lines. Accomplishments that we're proud of Smooth and appealing user interface. What we learned How to use new packages and integrate them all together and utilize NLP API's to process the input files and extract information. What's next for invoice-aid More efficient document upload, more file data categories. Built With bootstrap css flask html5 natural-language-processing python regex tesseract Submitted to TAMUhack 2022 Created by I worked on the routes and the rendering urjeet shrestha I worked with regex for the first time to process a noisy string to dates and addresses. fantamanatee Su I worked on using NLP to process the input files to categorize the data. Min Zhang Justin Van Nimwegen"
      }
    ]
  },
  {
    "file_path": "./devposts/jobfy.html",
    "project_id": "jobfy",
    "title": "Jobfy",
    "tagline": "Helping university students find interns, jobs, and housing",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "django",
      "html",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/511/725/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We took the inspiration of this project from LinkedIn and Airbnb where people get to search for jobs and housing. We took the ideas and combined them together which targets students. What it does Jobfy is a website for college students who can jobs and find housing areas nearby. The user begins by logging into the dashboard which then shows a list of recommended jobs based on his/her major. The user can then browse jobs and housings and see what suits the best. There is also a way for users to change their personal information such as names, major, and university name. How we built it We built it using Django framework and its sqlite database for storing users, jobs, and housing information. The website is written in HTML and CSS along with a bit of bootstrap. Challenges we ran into One challenge we ran into was keeping track of the urls of the pages user gets to browse through. Django was pointing to the wrong pages under the url extensions which results in the user getting unexpected page loadouts. This was syntax and logic error which was difficult to fix due to the amount of pages and possibilities of navigation. Accomplishments that we're proud of The biggest accomplishment in this project is being able to fully integrate the basic structure of a webapp passing information from frontend to backend and vice versa. When a user logins or changes personal information, a POST method is created by passing the data from the frontend to the backend. Other times, when users navigate to a different page, the Django returns the page with information only specific to user. What we learned We learned new technologies which are Django and Sqlite which are very powerful and scalable tools. When creating webapps for consumer use, it is very important to use the concept of abstraction which allows for maximum reusability and efficiency. What's next for Jobfy Jobfy can be extended upon a variety of new features such as connecting with other users who are attending th"
      }
    ]
  },
  {
    "file_path": "./devposts/keynotes.html",
    "project_id": "keynotes",
    "title": "Keynotes",
    "tagline": "A personalized and interactive note-creating device that leverages AI to be the best friend who'll always have the answers, and your back",
    "hackathon": "",
    "built_with": [
      "assemblyai",
      "cohere",
      "google-cloud-services",
      "mongodb-atlas",
      "nextjs",
      "python",
      "raspberry-pi",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/591/301/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration 🚀 Every student knows that feeling of utter panic when you're in your 8AM lecture, severely sleep deprived and blanking out...what did the prof just say? I guess we'll never know. Based on our highly researched data, we concluded quickly that students nowadays are some of the most easily distracted students to have existed in student kind (in fact, most students didn't even finish our survey). At Hack the North, inspired by some of the universal problems that students face, we wanted to develop a tool to revolutionize the way we learn and take notes. Enter KeyNote , the personalized notes device leveraged by AI– made for students, by students. What it does ⚙️ KeyNote is a powerful note-taking device paired with a web-app that leverages AI to expand the lesson beyond the lecture. Think, the best friend that'll always share their notes and answer the questions that you have from class. All users must do is record the lecture through our device, controlling it through the \"Start/Stop\" buttons. Then, KeyNote will process the transcript, and provide a summary of key concepts taken from the lecture, as well as the option to ask lecture-specific questions through our chat feature-- all previous transcripts being available through our curated calendar! KeyNote allows students to not only review and ask about their lecture, but they can make their own annotations and edits on top of the key concepts, just as they would on paper. There are additional features allowing users to add, delete and modify the notes, giving students the power over their own learning. How we built it  🛠️ KeyNote, our innovative web app, was constructed using TypeScript and Next.js for the front-end, while Python with FastAPI powered the backend. This blend ensured a reliable and scalable platform. Hardware integration was achieved through Python, facilitating seamless connections with our devices. Google Cloud Services played a pivotal role, enabling the retrieval and transmission o"
      }
    ]
  },
  {
    "file_path": "./devposts/kevin-4m6rbf.html",
    "project_id": "kevin-4m6rbf",
    "title": "Devin & Kevin",
    "tagline": "Devin, AI Software Engineer & Kevin, AI Product Manager",
    "hackathon": "",
    "built_with": [
      "dain",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      ": hack2school Winner DAIN Challenge: AI Agent Excellence & Innovation Awards Created by Ayush Garg",
      "Track: hack2school Winner DAIN Challenge: AI Agent Excellence & Innovation Awards Created by Ayush",
      "LA Hacks 2025WinnerTrack: hack2schoolWinnerDAIN Challenge: AI Agent Excellence & Innovation Awards",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Devin & Kevin aim to augment the role of product managers. We've heard of Copilot and other tools to help developers, but another crucial role within the team is that of the product manager. They focus on scoping out the project, assigning human capital, allocating budgets, and more, ensuring a project is seen through completion. With Devin & Kevin, this role can be automated: input your project, and receive a detailed project plan. What it does Devin & Kevin provides many functions that augment the role of the product manager: Technical scoping Assigning human capital Conducting daily standups Allocating budgets How we built it This was build primarily using TypeScript and Dain. Challenges we ran into After building the initial functionality of scoping out the technical specs of the project, I wanted to expand Devin & Kevin to encompass more of the roles that a project manager takes on. To do this, I asked a variety of teams what they thought were the most important functions of a PM, and got responses like managing budgets, allocating human capital, and conducting standups. From here, I decided to incorporate these functions as well, further lightening the load of PMs. Accomplishments that we're proud of I am proud of making a multi-agentic system that makes and solves github issues What we learned I learned that the role of a PM can completely be automated. What's next for Devin & Kevin Devin & Kevin are taking jobs everywhere - get ready for leaner tech teams. The future is now - major in gender studies instead. Built With dain typescript Submitted to LA Hacks 2025 Winner Track: hack2school Winner DAIN Challenge: AI Agent Excellence & Innovation Awards Created by Ayush Garg"
      }
    ]
  },
  {
    "file_path": "./devposts/kindlee.html",
    "project_id": "kindlee",
    "title": "Kindlee",
    "tagline": "/ˈkīn(d)lē/ Is a user-friendly web application for EDUCATING people on how you should pick the ideal location to live. Numbers don’t lie: (Data is taken into consideration from all 50 states)",
    "hackathon": "",
    "built_with": [
      "figma",
      "go",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/309/067/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "💡Inspiration During inflation and recession, people tend to move to new places, and this app helps them make the most EDUCATED decision. Plan smart and Kindlee . 🗺What it does It takes specific input parameters from users and processes and gives the states that match the criteria. Inputs such as healthcare facilities, workplace safety, road safety, financial safety, and personal residential safety are rating based on 1-5, 5 being the highest and the monthly expense the user can afford for house rent. Using this data, we return a list of states for them in the USA. ☕️How we built it Many hours of research of articles by experts in safety, finance, and psychology about the subtle factors that make the difference when deciding when to relocate. During the customer discovering phase, we interviewed three people we found online searching for home-buying advice on refit. We then tailored our application to the most significant concern common among all the people we interviewed. Their biggest fear was the proximity to emergency services and high area gun violence records. We then added what we thought was the essential information to find data for our current list. We use Go and React js for the project's backend—frontEnd on Figma. 😅Challenges we ran into The first challenge was to deduce a logic for processing data and get the results; one minor hiccup was that we could not install PostgreSQL pgAdmin sent about 2 hrs there and could do it. 🥇Accomplishments that we're proud of We completed the backend part of the app successfully and could build the logic that we thought of. 🎓What we learned If we are time bound, then we do things faster and more efficiently. 🚨What's next for Kindlee We need to integrate the app and add more features such as location share, message sharing, and emergency alarms in the app. Built With figma go react Try it out GitHub Repo www.figma.com Submitted to MetroHacks 2022 Created by I worked on back-end, using Go language. Avinil Rajendrakumar Beda"
      }
    ]
  },
  {
    "file_path": "./devposts/kickin-cuisine.html",
    "project_id": "kickin-cuisine",
    "title": "Kickin' Cuisine",
    "tagline": "The tastiest tournament on turf.",
    "hackathon": "",
    "built_with": [
      "blender",
      "cannon.js",
      "react.js",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/371/866/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration One team member is a die-hard football fan, while the other is a food enthusiast, and together we aimed to create a game that would appeal to both sets of fans. In \"Kickin' Cuisine\" food items come to life and compete in fast-paced football matches, providing players with a fun and entertaining gaming experience. With its catchy tagline, colourful graphics, and addictive gameplay, \"Kickin' Cuisine\" is set to be a hit with players of all ages. What it does? \"Kickin’ Cuisine\" is a fun and action-packed sports game where food items take to the field and compete in fast-paced matches of football. With intuitive controls and challenging gameplay, \"Kickin’ Cuisine\" is the perfect game for anyone who loves both food and football. Use strategy and quick thinking to outmanoeuvre the opposing team and score goals. With fun, cartoonish graphics and addictive gameplay, \"Kickin’ Cuisine\" is the ultimate way to combine your love of food and sports. So gather your friends, pick your team, and get ready for some food-tastic fun!\" How we built it We built this interesting game using the tools ThreeJs ReactJs CannonJs Blender Challenges we ran into It was quite difficult to implement Js as one of us is a complete beginner and finishing the project within the deadline was quite a task haha. What's next for Kickin' Cuisine The players will be able to choose from a wide range of food characters, each with unique abilities and attributes, and lead them to victory on the field Built With blender cannon.js react.js three.js Try it out foodfight.onrender.com GitHub Repo Submitted to Royal Hackaway v6 Created by Worked on building the gameplay Satyam Singh Aakanksha Rangdal"
      }
    ]
  },
  {
    "file_path": "./devposts/kidz-eat.html",
    "project_id": "kidz-eat",
    "title": "Kidz Eat",
    "tagline": "39 grams of sugar is what one soda contains. Less than 25 grams of sugar is what children need. Did you know that? Well, the students we work with do not. Which is were Kidz Eat comes to save the day!",
    "hackathon": "",
    "built_with": [
      "flutter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration My name is Jessie and My story is the inspiration for this project. I was born with an Atrial septal defect, a common birth defect with around 200k cases in the USA per year. I had surgery at 3 months old, which although helped, it would later return to haunt me. It would return in the 8th grade, where I was at a unhealthy weight. My cardiologist would let me know that if I did not change my eating ways, I could die. It was a big shock to me, but I decided to change my eating ways and become to person I am now. What it does This project is a two week course designed  to help empower students in making the decision to eat healthier options. It will also make the lesson planning much easier for the staff. How we built it We built it using flutter from the ground app. Challenges we ran into We ran into an issue where we did not have a poster board but one of the team members ran all the way to target to get it. Accomplishments that we're proud of we are proud of coming up with a way to help the children we work with. What we learned We learned that communication is very important for taking on a big task such as this and finishing. What's next for Kidz Eat KidzEat will push to finish a complete product by the summer so we can test our program during summer day camp that YMCA host. After that we would love to start our own non-profit organisation and start helping kids around the world by sending our staff members to teach our program. Built With flutter Submitted to LA Hacks 2023 Created by rickNrip Bailey"
      }
    ]
  },
  {
    "file_path": "./devposts/king-of-the-heap-temporary-name.html",
    "project_id": "king-of-the-heap-temporary-name",
    "title": "Runtime",
    "tagline": "Runtime is a online programming challenge to help newbies and experienced coders alike hone their skills in a fun, real-time, competitive game.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "next",
      "openai",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Design Created by Naveen Iyer I am a human and I live on Earth Abhishek More Retired Hackathon Enjo",
      "Peppermint Perfection - Best Design Created by Naveen Iyer I am a human and I live on Earth Abhishe",
      "HackTX 2023WinnerPeppermint Perfection - Best Design",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/635/515/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Single Problem mode Lobby Screen Level Select Screen Head-to-Head Multiplayer Single Problem mode Lobby Screen Level Select Screen Head-to-Head Multiplayer Single Problem mode 1 2 3 4 5 TLDR : Competitive programming platform that allowed for racing (like typeracer) and a 'session replay' analysis feature for educating new coders. Fully functional code execution, real-time multiplayer, connectivity, NLP analysis, and more! Inspiration As of 2023, the Software Engineer market is in shambles, and the industry is extremely competitive. In order to stand out, applicants need to hone their technical interviewing abilities. Additionally, younger students who are passionate about computer science need to be prepared to enter this job market. Most technical interviews usually involve competitive programming, which is a series of coding challenges ranging from easy to hard. Despite this, most universities fail to teach competitive programming in core curriculums. Runtime solves this by offering a comprehensive competitive programming platform that gamifies learning, while providing assistance with AI. What it does Runtime solves this by offering a comprehensive competitive programming platform that gamifies learning, while providing assistance with AI. It has several features: Realtime Multiplayer Races We've noticed that it is difficult to learn competitive programming by yourself. Runtime offers a typeracer-style coding game where players go head-to-head to complete 5-10 programming problems quickly. We aim to improve decision-making time and general syntax knowledge of the computer science community. We accomplished real-time multiplayer connectivity with Firestore. Assisted Individual Problems If you just want to review problems alone, Runtime has a single-player mode as well. This unlimited time mode offers AI assistance by providing relevant hints to a problem before revealing the solution. In our experience, most students tend to give up and check the solution when th"
      }
    ]
  },
  {
    "file_path": "./devposts/knowcovid-24-7.html",
    "project_id": "knowcovid-24-7",
    "title": "Know COVID 24/7",
    "tagline": "A website created to inform and spread awareness about COVID-19.",
    "hackathon": "",
    "built_with": [
      "css",
      "glitch",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/578/875/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration COVID-19 is a global issue that exists today, and we want to encourage everyone to stay safe and get vaccinated. What it does Know COVID 24/7 is a website created to spread awareness about what COVID-19 is, and how we can protect ourselves against it. How we built it We used glitch.com to create a website using HTML, CSS, and JavaScript. Challenges we ran into We had some difficulty with the CSS, such as changing the font color and format. Accomplishments that we're proud of We learned how to create a website for the first time, and use JavaScript to make moving buttons. What we learned We learned how to use glitch.com to create a website, and format different parts of the website using different coding languages. What's next for Know COVID 24/7 We want to add more resources about COVID, such as vaccination information. Built With css glitch html javascript Try it out know-covid-24-7.glitch.me Submitted to Citro Hacks Created by Aditi Bhat Erika Wu"
      }
    ]
  },
  {
    "file_path": "./devposts/kingdom-of-cards-uzlp5v.html",
    "project_id": "kingdom-of-cards-uzlp5v",
    "title": "Kingdom of Cards",
    "tagline": "Welcome to the \"Kingdom of Cards,\" a strategic game where players navigate a battlefield with a mix of strategy, wit, and luck. Strategically choose your cards to defeat the enemy.",
    "hackathon": "",
    "built_with": [
      "c#",
      "foundry",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Foundry SDK Created by Brent Johnson Chinat Yu My name is Chinat Yu",
      "Immerse The BayWinnerBest Use of Foundry SDK",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/668/211/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Card Sample Card Sample Card Sample Card Sample Card Sample 1 2 3 🃏 Inspiration \"Kingdom of Cards\" was inspired by the classic charm of traditional card games and the immersive potential of mixed reality technology. We envisioned a game that merges the tactical depth of card-based strategy with the engaging and interactive experience offered by modern technology. The goal was to create a game that appeals not only to seasoned strategists but also to those fascinated by the evolving realm of mixed reality. 🌐 What it Does \"Kingdom of Cards\" is a mixed reality strategy game where players duel as leaders of rival kingdoms. Using a deck of 15 cards, players deploy units across three tactical lanes on the battlefield, aiming to reduce their opponent's health to zero. The game incorporates a mana system, allowing for increasingly powerful plays as the game progresses. The unique aspect is the use of holographic representations of units, bringing the game to life on any surface without the need for specialized hardware. 🛠️ How We Built It The game was developed using Unity and built for the Quest 3 platform, enabling an immersive mixed reality experience. We integrated Foundry for multiplayer functionality, allowing players to connect and duel with others seamlessly. The design focuses on intuitive controls and hand tracking and an interface that leverages the mixed reality capabilities of the Oculus Ecosystem that works on Quest 2 and Quest Pro. ⚔️ Challenges We Ran Into Creating a balanced yet dynamic gameplay within the mixed reality environment posed significant challenges. Ensuring that the holographic elements worked flawlessly without specialized hardware required meticulous design and testing. Balancing the game mechanics, such as the mana system and card abilities, to ensure a fair and engaging experience was another hurdle. 🏆 Accomplishments That We're Proud Of We are proud of successfully blending a traditional card game's strategic depth with the captivating ele"
      }
    ]
  },
  {
    "file_path": "./devposts/know-before-you-go.html",
    "project_id": "know-before-you-go",
    "title": "Know Before You Go",
    "tagline": "The parking app for all Stony Brook drivers",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "css",
      "html",
      "javascript",
      "opencv",
      "photoshop",
      "python",
      "raspberry-pi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Innovative: Easy out-of-the-box Winner 1010data’s Pick: Most Significant Use of Data Created b",
      "Hack@CEWITWinnerMost Innovative: Easy out-of-the-boxWinner1010data’s Pick: Most Significant Use of Data",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We wanted to design an app using the Internet of Things. Parking on campus is notoriously terrible for all that are involved, so we decided to combine the two and made this project! What it does Determines if there are available parking spots around Stony Brook campus real time, and can preform analysis on each spot to determine how long it has been currently open, and its parking trend over a long period of time. How I built it We used a python based algorithm and Photoshop to determine if specific pixels from our raspberry-pi camera were being shown, and preformed pixel analysis between spots we placed on the ground. We then uploaded this information to our raspberry pi hosted server and then to the website we created. Challenges I ran into. The vision algorithm was especially difficult to overcome, because of the exact nuances that went into the processing and differentiating between meaningful, and non-meaningful pixels. Also uploading our data to the server and updating the website real time was difficult. Accomplishments that I'm proud of. We successful processed an image from a camera, then uploaded that to a server, without computer vision or app development experience. What I learned. That hard work really does pay off, and the power of a simple camera and a good idea. What's next for Know Before You Go, We want to become the standard for Stony Brook parking, and we believe the app we made could help all on-campus drivers avoid the constant problems that occur from an everyday commute. We have some interesting plans with IR reflecting paint to take our model to the real world. Built With android-studio css html javascript opencv photoshop python raspberry-pi Submitted to Hack@CEWIT Winner Most Innovative: Easy out-of-the-box Winner 1010data’s Pick: Most Significant Use of Data Created by I designed the Mechanical model of a parking spot and the camera stand. I have also worked on creating a website that directly updates the parking spot image wi"
      }
    ]
  },
  {
    "file_path": "./devposts/kingdom-of-cards.html",
    "project_id": "kingdom-of-cards",
    "title": "Kingdom of Cards",
    "tagline": "\"Kingdom of Cards\" is a mixed reality strategy game where players command holographic units in a battle of wits and tactics to conquer rival kingdoms.",
    "hackathon": "",
    "built_with": [
      "foundry",
      "meta",
      "oculus",
      "quest",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/666/915/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 🃏 Inspiration \"Kingdom of Cards\" was inspired by the classic charm of traditional card games and the immersive potential of mixed reality technology. We envisioned a game that merges the tactical depth of card-based strategy with the engaging and interactive experience offered by modern technology. The goal was to create a game that appeals not only to seasoned strategists but also to those fascinated by the evolving realm of mixed reality. 🌐 What it Does \"Kingdom of Cards\" is a mixed reality strategy game where players duel as leaders of rival kingdoms. Using a deck of 15 cards, players deploy units across three tactical lanes on the battlefield, aiming to reduce their opponent's health to zero. The game incorporates a mana system, allowing for increasingly powerful plays as the game progresses. The unique aspect is the use of holographic representations of units, bringing the game to life on any surface without the need for specialized hardware. 🛠️ How We Built It The game was developed using Unity and built for the Quest 3 platform, enabling an immersive mixed reality experience. We integrated Foundry for multiplayer functionality, allowing players to connect and duel with others seamlessly. The design focuses on intuitive controls and hand tracking and an interface that leverages the mixed reality capabilities of the Oculus Ecosystem that works on Quest 2 and Quest Pro. ⚔️ Challenges We Ran Into Creating a balanced yet dynamic gameplay within the mixed reality environment posed significant challenges. Ensuring that the holographic elements worked flawlessly without specialized hardware required meticulous design and testing. Balancing the game mechanics, such as the mana system and card abilities, to ensure a fair and engaging experience was another hurdle. 🏆 Accomplishments That We're Proud Of We are proud of successfully blending a traditional card game's strategic depth with the captivating elements of mixed reality. The game stands out for its in"
      }
    ]
  },
  {
    "file_path": "./devposts/koelkast.html",
    "project_id": "koelkast",
    "title": "Koelkast",
    "tagline": "A smart inventory management solution for Refrigerators",
    "hackathon": "",
    "built_with": [
      "flask",
      "gcp",
      "inception",
      "mongodb",
      "node.js",
      "opencv",
      "python",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/939/182/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "UI Design Logo Inside Fridge UI Design Logo Inside Fridge UI Design 1 2 3 Inspiration The inspiration for this project was from our personal experiences living with bad roommates, who overstuffed the fridge with a lot of food, that used to be expired or took our food. We wanted to tackle this problem and make a solution to manage the inventory of the fridge or a shared closet. What it does The solution uses cameras to monitor, who is placing and removing items to/from the Fridge and what they are placing/removing. It achieves this using computer vision, technology to recognize the user from the registered set of users for a certain device. How we built it The solution was primarily split into two parts, the machine learning side and the user interface. The machine learning side was completely built in python, from client to server, using opencv,flask, tensorflow, and using the pre trained model inception v3. The half the project also controlled the devices cameras to detect movement and detect objects to be recognized. The user interface side of the project was built on react, using bootstrap and semantic ui. The interface allowed the users to checkout the inventory of their devices, and what items each user had. The two sides were bridged using Node.js and mongodb, which acted as the central data storage and communication point from the machine learning and the user interface. Challenges we ran into The computer vision side of the project was extremely challenging in the limited time, especially detecting objects in the frame without using Deep Learning to keep the client processing load at a minimum, Furthermore, the data-sets had to curated and specially customized to fit this challenge.was In terms of the back-end, it was difficult to connect the node server to the python machine learning scripts, so we went with a micro service solution, where the machine learning was served on two flask endpoints to the node server which handled all the further processing. Fin"
      }
    ]
  },
  {
    "file_path": "./devposts/kyro-vjui8k.html",
    "project_id": "kyro-vjui8k",
    "title": "KYRO",
    "tagline": "Imagine never having to scour the Internet for hours to find the best product for you is😲Introducing KYRO, your digital financial assistant that helps you save money on every! single! e-purchase!",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our financial and managerial academic backgrounds have constantly exposed us to the innovative ways technology is used to optimise the inner workings of businesses and corporations. We wanted to use our knowledge, along with existing technologies, to improve the e-commerce experiences of the masses every single day . What it does KYRO inspects your purchasing history and continually tracks online deals, discounts, and other money-saving bargains to provide you with timely product recommendations over a text conversation. Being built as a chatbot means you can have your queries answered in convenient text form, while being fed reliable data and personalised recommendations. Challenges we ran into It was easy to get lost in intensive ideation, so we had to make sure KYRO's comprised only the most crucial features that our end-user would need. What's next for KYRO Iteration time! Built With python Try it out drive.google.com Submitted to NUS Fintech Month Hackathon 2023 (Round 2: Prototype) Created by Gavin Rozario Hi there! My name's Gavin and I hack for social good. I’m best at project management, product research, and pitching!"
      }
    ]
  },
  {
    "file_path": "./devposts/krishai-htkagf.html",
    "project_id": "krishai-htkagf",
    "title": "KrishAI #16",
    "tagline": "Cut the crap & save your plant with 𝐊𝐫𝐢𝐬𝐡𝐀𝐈",
    "hackathon": "",
    "built_with": [
      "android",
      "firebase",
      "firestore",
      "gcp",
      "java",
      "openweathermap",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Place Created by Pratyay Banerjee Trying to learn how to learn ;) Saif Ali Private user Debdu",
      "Hoya Hacks 2021WinnerFirst Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/376/083/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF 1 2 Inspiration Every year, an estimated 10% of the global produce goes waste due to pests and crop pathogens. This is the reason why crop productivity in many countries is declining. For example, India is among the top producers of several crops such as wheat, rice, pulses, sugarcane and cotton. Most farmers cannot tell if a crop is diseased or not just by looking. Farmers rely on the income they get from their crops and many go broke if their crops turn bad. What it does KrishAI is an artificially intelligent mobile app that tells you if your crop is diseased. We have generated our own Tensorflow Lite Model which showed an accuracy of 91.54% and used Firebase ML Kit to host the same. Our pest detection algorithm provides farmers with the phone numbers of local pest control facilities. We also show effective tips on agriculture and display predicted weather data so that farmers can plan their crops accordingly. Our app is available in most local languages like Hindi, Bengali, Chinese, Korean, etc. How we built it Our project KrishAI is crafted with love. The application itself is built by using Android. We are also using some other free API's from OpenWeatherMap for accessing weather information. The Tf.lite model is used for the analysis of the plant image. For the backend, we're using GCP for image post processing & endpoint data compression. The authentication of our app is being served via Firebase Authentication. And last but not the least, the chat server was deployed on a free dyno of Heroku. Challenges we ran into Initially, we were facing a problem to setup the Tf.lite model on our project as it was a very buffed one, so we had to reduce the dataset parameters & then optimize it so that it can run seamlessly on low end smartphones. Another important problem that we faced was to compress the uploaded image size on the GCS & throw that endpoint directly to cloud functions. Accomplishments that we're proud of We are proud of finishing the project "
      }
    ]
  },
  {
    "file_path": "./devposts/koacoach.html",
    "project_id": "koacoach",
    "title": "KoaCoach",
    "tagline": "Koa is your personalized Wellness Coach",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-text-to-speech",
      "openai-agent-sdk",
      "react-native",
      "supabase",
      "unify",
      "vapi",
      "wispr"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Safety first"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/501/326/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Record Journal Entries Koa, the conversational therapist and mascot of our app Map displaying the user's progress until 100 wXP Home screen on mobile Connect with therapist Chat with AI therapist Record Journal Entries Koa, the conversational therapist and mascot of our app Map displaying the user's progress until 100 wXP Home screen on mobile Connect with therapist Chat with AI therapist Record Journal Entries 1 2 3 4 5 6 7 KoaCoach Your personalized wellness coach that actually supports you Inspiration Two-thirds of our generation deals with mental health challenges, but most wellness apps feel cold and generic. They give everyone the same advice, track the same metrics, and wonder why people stop using them after a week. We wanted to build something different—a wellness coach that learns who you are, adapts to your specific situation, and keeps you engaged long enough to actually make a difference. What it does KoaCoach is your personal wellness companion powered by an AI wellness coach that feels genuinely human. You can have real conversations about what's bothering you, journal your thoughts, and build healthy habits through our gamified system. The core is our conversational AI wellness coach, trained on expert demonstrations to provide thoughtful, personalized responses. It remembers your history, understands your communication style, and offers relevant suggestions for whatever you're dealing with. We use a points system called wellness experience points (wXP) that you earn through journaling, talking with your AI coach, and staying consistent. It's inspired by Duolingo's approach—simple gamification that motivates without feeling manipulative. Reach 100 wXP and earn a $5 gift card. Behind the scenes, we use a multi-agent system that handles different aspects of support. One agent manages proactive outreach—calling users when they need encouragement or haven't checked in. Another focuses on ongoing support during conversations. Most importantly, our crisis "
      }
    ]
  },
  {
    "file_path": "./devposts/koiosgpt.html",
    "project_id": "koiosgpt",
    "title": "KoiosGPT",
    "tagline": "KoiosGPT is an AI-powered application that utilizes Language Models (LLMs) to enhance users' understanding of research articles and personal PDF documents.",
    "hackathon": "",
    "built_with": [
      "deta",
      "nextjs",
      "openai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Created by This was a solo project :) Arihan Varanasi Full-Stack ML Developer with a knack fo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/673/354/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Upload your own pdfs and chat with them Home page Chat with Research Articles Upload your own pdfs and chat with them Home page Chat with Research Articles Upload your own pdfs and chat with them 1 2 3 4 Inspiration The inspiration behind KoiosGPT stems from the need to simplify the process of comprehending research articles and personal documents. Often, individuals struggle with extracting the main points and key insights from lengthy texts. KoiosGPT aims to bridge this gap by utilizing AI and LLMs to provide users with concise summaries and valuable information. What it does KoiosGPT allows users to upload research articles and PDF documents as well as use a built-in search feature to find articles, which are then processed using advanced AI algorithms and LLMs. How we built it KoiosGPT is built using a combination of frontend and backend technologies. The frontend is developed using modern web technologies such as Next JS and React, while the backend utilizes Next JS and Cloud SDK. The AI part uses a variety of GPT APIs. Challenges we ran into I had challenges incorporating the cloud server as there were many bugs with it I also had a challenging time making the PDF viewer Accomplishments that we're proud of Incorporation of LLMs and GPT with understanding complex information that can help anyone, including researchers, students, and teachers User-Friendly Interface: We created a sleek and intuitive user interface that prioritizes usability and enhances the overall user experience. Cloud Integration: The seamless integration of the cloud SDK enables users to store and retrieve their files securely, enhancing the accessibility and convenience of the application. What we learned I learned how to develop my own PDF viewer and I learned how to save and retrieve data from a cloud server. What's next for Koios GPT More research articles providers other than Arvix Conversational history Multi-language support More information and analysis on articles Making page respon"
      }
    ]
  },
  {
    "file_path": "./devposts/kyro.html",
    "project_id": "kyro",
    "title": "KYRO",
    "tagline": "Imagine never having to scour the Internet for hours to find the best product for you is😲Introducing KYRO, your digital financial assistant that helps you save money on every! single! e-purchase!",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "flask-api",
      "nginx",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Proceed to next round Created by Keane Axel Ong Gavin Rozario Hi there! My name's Gavin and I hack",
      "NUS Fintech Month Hackathon 2023 (Round 1:Ideation)WinnerProceed to next round",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our financial and managerial academic backgrounds have constantly exposed us to the innovative ways technology is used to optimise the inner workings of businesses and corporations. We wanted to use our knowledge, along with existing technologies, to improve the e-commerce experiences of the masses every single day . What it does KYRO inspects your purchasing history and continually tracks online deals, discounts, and other money-saving bargains to provide you with timely product recommendations over a text conversation. Being built as a chatbot means you can have your queries answered in convenient text form, while being fed reliable data and personalised recommendations. Challenges we ran into It was easy to get lost in intensive ideation, so we had to make sure KYRO's comprised only the most crucial features that our end-user would need. What's next for KYRO Iteration time! Built With amazon-web-services flask-api nginx python Submitted to NUS Fintech Month Hackathon 2023 (Round 1:Ideation) Winner Proceed to next round Created by Keane Axel Ong Gavin Rozario Hi there! My name's Gavin and I hack for social good. I’m best at project management, product research, and pitching!"
      }
    ]
  },
  {
    "file_path": "./devposts/kohi.html",
    "project_id": "kohi",
    "title": "KoHi",
    "tagline": "Build your own virtual coffee shop, engage in coffee chats and network with a professional community!",
    "hackathon": "",
    "built_with": [
      "adobe-creative-suite",
      "adobe-xd",
      "autoflow-plugin",
      "blender",
      "canva",
      "figma",
      "miro",
      "motion-plugin",
      "procreate"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best UI/UX Created by prototyped prototypes Phoebe Wang i drew the little character Roselyn Huynh l",
      "Hack with Us - TechNova 2022WinnerBest UI/UX",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/205/102/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration ☕ \"Kohi\" is the Japanese word for coffee, but we pronounce it as 'Kō-Hi to imitate a friendly greeting. As first-year engineering students, we realised the very apparent gap in practical knowledge and experience among young motivated professionals. For those underrepresented in technology or those without proper access to technological literacy, the biggest roadblock is the lack of access to resources like mentorship and community . Our main goal is to facilitate networking and encourage personal branding and creativity. What it does 🤔 KoHi lets users create a personalized coffee shop, complete with a menu that acts as their resume, and browse through other professionals' shops in their area to 'match' with mentors, mentees, and peers for coffee chats. Our virtual coffee shop acts like a self-contained metaverse for the users. The chat and calendar feature makes connecting and scheduling both efficient and inviting. The ability to view your matches' availability makes it easy to create a no-conflict schedule while getting the most out of coffee chats. Users can expand their coffee shops and add personal touches while waiting for 'customers' to buy a coffee from them in order to become a part of their professional network. The nature of KoHi encourages a judgement-free zone, where matches are solely based on professional compatibility as opposed to other superficial factors. The organized messages and notifications inbox, as well as collaborative calendar, streamline the networking process substantially and we hope that KoHi attracts eager students and professionals unsure of where to start. How we built it ⚙️ We used Blender to model a 3D coffee shop, Evercast to collaborate on our 3D model, and Figma to create an app prototype showcasing our model and the aforementioned features. We used Outflow to wireframe and Motion plug-in to animate our icons and logos. We conducted two moderated usability testing sessions, transcribed and compiled on Miro."
      }
    ]
  },
  {
    "file_path": "./devposts/krave-v4mri3.html",
    "project_id": "krave-v4mri3",
    "title": "Krave",
    "tagline": "Track your save",
    "hackathon": "",
    "built_with": [
      "css3",
      "github",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Track your save"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/645/464/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "landing page of our project. landing page of our project. landing page of our project. 1 2 Inspiration In our day to day life, we face saving issues and many of us can’t keep a track of the savings. Our team through this problem and decided to create a simple savings tracker with a user friendly design in order to assure that even a beginner can use it without any problem. What it does Krave , is a >money management< web that focuses on tracking user’s savings. \nUsers are able to input their salary, bills (extra savings and expenses), and their spending. From there, Krave is able to estimate user’s daily spending. Then, on each day, users are able to input their spending based on their category, food, cab (or transport), groceries, shopping, and others. Krave will then automatically sum up the user’s savings and spending for the week, month, and since they used the web How we built it We used HTML5,CSS3 and Java script in order to make our project. Challenges we ran into At first we had a problem of calculating > monthly expenditure and then tracking the past week expenses properly because there was some error in our code. But hopefully the issue was sorted after some discussion. Accomplishments that we're proud of Within a short span of time (48 hrs) , we discussed and came up with such a wonderful idea and made a fully functional website . What we learned We learned team work , and to work under a specific time , handling the task with a sound mind and also improved our web skills . What's next for Krave We are looking to implement it in the form of a mobile app which will make it more accessible for the user. Built With css3 github html5 javascript Try it out pruthvirajjadhav1.github.io Submitted to OHacksIO Created by Mainak Dey ... pruthviraj jadhav Flavia Gabriella aryan mahure"
      }
    ]
  },
  {
    "file_path": "./devposts/land-of-a-thousand-hills-collectibles.html",
    "project_id": "land-of-a-thousand-hills-collectibles",
    "title": "Land of a Thousand Hills Collectibles",
    "tagline": "Collectible cards (with a digital twist!) and engraved wooden tokens to increase awareness of Haven's social impact and customer engagement at the Land of a Thousand Hills social enterprise cafe.",
    "hackathon": "",
    "built_with": [
      "canva",
      "chatgpt",
      "cloudflare",
      "express.js",
      "figma",
      "gap",
      "github",
      "ip-info",
      "javascript",
      "jimp",
      "node.js",
      "prisma",
      "serverless",
      "sharp",
      "tailwind-css",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DeisHacks 2023WinnerHidden Gem",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/374/078/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "the physical marketing kit System Architecture the physical marketing kit System Architecture the physical marketing kit 1 2 3 Inspiration 💡 Every time a customer goes to Land of a Thousand Hills Cafe , every dollar they spend goes back directly into their community to provide services to homeless youth . This is an incredibly important and beautiful narrative, and we wanted to find a way to connect people to the positive impact of their everyday actions (even something like buying a cup of coffee). How it works ️🤔 We created 5 unique, collectible cards that can be handed out by the cafe with purchases above a set amount. One side of the card contains a catchy one-liner connecting the coffee and impact (e.g. “Your coffee did some good today”). The other side is printed with a content-drive message that conveys a direct impact and describes work being done by Haven (e.g. “Haven helped arrange permanent housing for 341 homeless youth in 2022 ”) Desktop Preview Mobile Preview Desktop Preview Mobile Preview Each card is also printed with a unique letter, and together all 5 cards spell out ‘HAVEN’ . Customers are encouraged to collect all the cards and receive a free, laser-engraved wooden token when they collect all 5. There is also a digital version of the cards that can be accessed through a QR code; a custom QR code stamp can be used by employees to stamp customer’s cups, and if they scan the code they will be brought to this digital version. In addition, there is a separate landing page that contains the QR code that the non-profit can use to advertise these cards digitally. How we built it ⚙️ Marketing cards were designed on Canva . They were printed in colour, and prototypes were made using construction paper and glue sticks to create a ‘real card’ feel. The QR code stamp was designed using CAD software and printed using Markforged 3D printers available on-site. The wooden tokens were designed as image files and latter converted into vector format, so that they co"
      }
    ]
  },
  {
    "file_path": "./devposts/language-buddy.html",
    "project_id": "language-buddy",
    "title": "Language Buddy",
    "tagline": "Learn new languages and meet new friends!",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "html",
      "javascript",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Created by Ebtesam Haque Shalini Kumari Ava Chan Muntaser Syed i like to read good fo",
      "Hack APACWinnerThird Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/372/516/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Learning a new language is not an easy task, what's better than learning a new language and making new friends at the same time? Inspired by student exchange buddy programs, we would like to build an app that pairs individuals who are aiming to learn a new language with native speakers who would like to brush up on their English. As the mobile internet user penetration is less than 50% in the APAC region (data in 2019), we aim to tackle the digital divide and make our app available to users living in no-internet coverage areas by integrating voice chat. What it does Sign up via phone call Save data to the database Testing Call +14085122253 for testing Note: You can call international numbers for free using Google Hangouts:) How we built it Programmable voice chat using Twilio Landing page (web) using html, css and javascript Database and hosting using Firebase Challenges we ran into Some of us are not so familiar with backend development and data structures and spent a lot of time learning. Accomplishments that we're proud of We built a functional prototype! What we learned We learnt a lot about how to use Twilio (the Autopilot feature) and Firebase What's next for Language Buddy Matching algorithm for individuals with the same interest Mask personal information to improve security Built With css firebase html javascript twilio Try it out GitHub Repo Submitted to Hack APAC Winner Third Overall Created by Ebtesam Haque Shalini Kumari Ava Chan Muntaser Syed i like to read good food reviews, then eat said good food but im usually broke :("
      }
    ]
  },
  {
    "file_path": "./devposts/langbridge-ai.html",
    "project_id": "langbridge-ai",
    "title": "LangBridge AI",
    "tagline": "Real-Time Multilingual Marketing Insight & Content Agent",
    "hackathon": "",
    "built_with": [
      "amazon-bedrock",
      "bright-data",
      "javascript",
      "minimax-api",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of MiniMax Winner Best Use of Bright Data's MCP for Web Access in AI Agents Winner Top 5 Overal",
      "Best Use of MiniMax Winner Best Use of Bright Data's MCP for Web Access in AI Agents Winner Top 5 O",
      "MCP - AWS - Enterprise Agents ChallengeWinnerBest Use of MiniMaxWinnerBest Use of Bright Data's MCP for Web Access in AI AgentsWinnerTop 5 Overall Teams",
      "Winner",
      "we won about $1.5k across best use of minimax and bright data mcp!!!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/639/621/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "LangBridge AI pipelines Langbridge Front-End LangBridge AI pipelines Langbridge Front-End LangBridge AI pipelines 1 2 3 Inspiration In today’s global market, brands must speak the language, literally and culturally, of diverse audiences. But it’s hard for marketers to know what Gen Z in Japan or professionals in France are saying about products, trends, or campaigns. We wanted to build an agent that not only understands real-time international sentiment but also generates localized, high-quality marketing content all automatically. What it does LangBridge AI is a real-time multilingual marketing agent that: Takes user input like a product/topic and target regions Scrapes real, live web content (e.g., reviews, Reddit, marketplace data) using Bright Data MCP Uses Amazon Bedrock LLM (Claude) to craft smart, culturally adapted prompt instructions Sends these prompts to the MiniMax API , which generates localized ad copy and creative media briefs How we built it Frontend: A lightweight React form where users select product, countries, tone, and platform (e.g. “Instagram ad for Gen Z in France and Japan”) Backend: Python-based FastAPI server to orchestrate the pipeline Bright Data MCP: Used their MCP Server API to pull live search results and snippets for product-related queries in each target country Amazon Bedrock: Leveraged Claude or Command R+ to parse the scraped content and generate structured instructions (e.g. “Make a 15s Gen Z-friendly TikTok ad with humor in Japanese”) MiniMax API: Used those structured prompts to generate the final ad copy in each language, styled appropriately for each platform and audience Challenges we ran into Multilingual search scraping: It was challenging to craft reliable queries for different languages and extract meaningful snippets under rate-limiting conditions Prompt design across two LLMs: Claude and MiniMax have different input expectations, so we had to fine-tune the way prompts were passed from one to the other Maintaining tone"
      }
    ]
  },
  {
    "file_path": "./devposts/laugh-a-lot.html",
    "project_id": "laugh-a-lot",
    "title": "Laugh-a-lot",
    "tagline": "Uniting the world, one laugh at a time!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "cockroachdb",
      "css",
      "css3",
      "express.js",
      "html5",
      "javascript",
      "natural-language-processing",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/224/774/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Homepage Inspiration As two of our teammates descended into a moment of discord, we found the importance of a ubiquitous yet significant natural force-human laughter. Our two comrades bore their fangs at each other due to their disagreement on whether Waterloo was a great school or not. They disputed on and on about Waterloo’s courses and faculty, but it took a third party to completely end their debate. Our third member finally intervened with a simple yet true joke; UW is tundra in the winter, do you guys think you can live as polar bears? Suddenly, all three parties broke the tension with their thunderous laughter, and the conflict was resolved. The inspiration for this game came after two students on our team shared a moment of uncontrollable laughter. We discovered laughter’s great healing abilities and wanting to share the great gift of laughter with others, our team decided to create a try not to laugh app. What it does Our web app presents users with hilarious shorts from Youtube and Reddit, giving them opportunities to laugh and rid themselves of the worries that they have accumulated throughout the day. The goal of the app is to be as funny as possible; inversely, the users’ goal is to avoid laughter as much as possible. Every time the user avoids laughter, they are rewarded a point, and if the users find themselves with as little as a grin on their face they lose their streak. Finally, their score is tallied and they are granted a place on the leaderboard when compared with their friends. Then an AI learns the user’s laughter patterns and tries to predict the type of video they find funny. This way, the users help us understand how to make them laugh. How we built it We built this project with multiple goals in mind. We wanted to make use of as many sponsored services as sensibly possible, and we wanted to use our collected skills to the best extent. Therefore, we ended up choosing a CERN stack (CockroachDB, Express, React, NodeJS) along with Co:here to s"
      }
    ]
  },
  {
    "file_path": "./devposts/learnify-h2bjt8.html",
    "project_id": "learnify-h2bjt8",
    "title": "A",
    "tagline": "A",
    "hackathon": "",
    "built_with": [
      "a"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "A Built With a Submitted to ForgeHacks 2025 Created by Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Kosei Tsukamoto"
      }
    ]
  },
  {
    "file_path": "./devposts/leafting.html",
    "project_id": "leafting",
    "title": "Leafting",
    "tagline": "Empowering local entrepreneurs and farmers through deep learning.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "html5",
      "keras",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration One of the most overlooked jobs in our modern world is our farmers, who, through sweat and hard work, are the foundation of our century's exponential intellectual and technological growth. \nWe wanted, through our project, to give back to those who have served us so much, and who filled our plates with quality food.\nWith the increasing prices and the shortcoming of production due to the lack of labor in recent years, we wished to look for a solution to help farmers deal with their crops.\nWe present Lifting. What it does Through an image recognition program founded upon a convolutional neural network, Leafting can detect the presence of diseases in crops, while developing solutions to help farmers act before it gets too late. How we built it Flask, Python, HTML5, CSS for the front-end\nNumpy, Pandas, OpenCV, Keras, Scikit-learn for backend Challenges we ran into The many classes present in our model led to a high run-time. We had to use optimization techniques for our model. We encountered difficulties exporting the model to a single function and relaying the input image from the website to the model. Accomplishments that we're proud of We are proud of the efficiency and accuracy of the model. The website is simple and easy to use. What we learned We learned Flask, TensorFlow and CNN, and exporting models. What's next for Leafting Democratize our product and expand classes and datasets Built With bootstrap css html5 keras python tensorflow Try it out GitHub Repo Submitted to MAIS Hacks 2022 Created by Xin Lei Lin Wenhe Z Muyuan Yang"
      }
    ]
  },
  {
    "file_path": "./devposts/leftovers-love-h63w5d.html",
    "project_id": "leftovers-love-h63w5d",
    "title": "Leftovers Love",
    "tagline": "Introducing Leftovers Love, the ultimate web application designed to help you make the most out of your leftovers. With Leftovers Love, users can effortlessly discover new recipes using leftovers!",
    "hackathon": "",
    "built_with": [
      "huggingface",
      "next",
      "next-auth",
      "plotly",
      "postgresql",
      "prisma",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/166/920/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Growing up, food was never been a problem for my family. At home, the well-stocked refrigerator and pantry made food seem to have an unlimited supply. Going grocery shopping meant our family picked out only the freshest-looking produce and meat, giving little thought to where it came from. Going into high school, I joined various volunteering organizations, always eager to help out my community any way I could. I began volunteering at a local food bank, combining my love for cooking my desire to make a difference. Every week, I prepared dozens of meals for families in need. The gratitude that these families showed made the experience all the more rewarding, as I got to know another side of the community around me. As I heard their stories, I discovered my own internalized beliefs about food as a commodity, whereby many of these families struggled with just putting food on the table. I realized that some of these patrons had gone to my school. One day, I experienced this reality in an unexpected way. I had forgotten my lunch, and a classmate—someone I recognized from the food bank—shared their meal with me. What was never a cause for concern from me meant the entire world to these families, and despite her own challenges, she was willing to show kindness. These experiences taught me the true meaning of compassion and community, and I knew I needed to do more to help those in need. What it does Leftovers Love helps minimize food waste by finding recipes for leftovers with the following features: Processes user's leftover ingredients Displays compatible recipes Personalized AI to generate recipes for unique combinations Helps with finding local food banks to donate to How we built it Backend Next.js Server Prisma ORM for database queries using PostgreSQL backend Spoonacular API for recipe fetching Huggingface API for AI generation Frontend Tailwind CSS Framework Plotly for interactive mapping ShadCN UI Framework Challenges Integrating multiple APIs and ensu"
      }
    ]
  },
  {
    "file_path": "./devposts/leafpilot.html",
    "project_id": "leafpilot",
    "title": "LeafPilot",
    "tagline": "LeafPilot is an AI-powered LaTeX editor, built for education. Ask about a concept, upload rough notes or record your lecture's audio, and you'll receive clean PDF results with embedded animations!",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "groq",
      "manim",
      "next.js",
      "python",
      "shadcn",
      "tailwind",
      "typescript",
      "zustand"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2025WinnerGroq",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/759/548/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration For such a widely used typesetting platform (you could format this very blurb in it!), we were surprised that there wasn’t an editor for LaTeX with built-in AI support. We saw a clear opportunity: students and researchers often spend more time debugging formatting than focusing on content. We wanted to change that, especially for students who want to create clean, professional notes, complete with interactive diagrams and even animated visualizations. What it does Think of LeafPilot as Overleaf with Copilot , or Cursor for LaTeX . It allows you to: Generate and compile LaTeX directly in your browser. Seamlessly embed Manim (3Blue1Brown-style) animations into your documents. Upload your own resources (like text notes or even an audio recording ) and have LeafPilot structure, typeset, and enhance them into a polished PDF. In short: LeafPilot turns raw ideas into beautifully formatted, animated documents with AI as your co-pilot. How we built it Frontend : Next.js + Tailwind for speed and flexibility. Backend : Python with FastAPI to handle requests efficiently. AI Integration : Groq as the inference engine powering LaTeX generation, file summarization, mp3 transcription, and embedding-based retrieval.  Gemini flash as the reasoner, deciding on agent tool calls, speeding up inference times! Extras : We connected LaTeX compilation and Manim rendering into the pipeline so everything works in-browser without the typical setup headaches. Challenges we ran into Getting LaTeX compilation and Manim rendering to work smoothly in a browser context. Managing asynchronous agent workflows (AI + compilation + file processing) without things breaking mid-stream. Designing a frontend experience that feels fast and intuitive despite the heavy lifting happening behind the scenes. Debugging… lots of debugging. Accomplishments that we're proud of Built a working prototype of an AI-powered LaTeX + Manim editor , something we couldn’t find anywhere else. Successfully integr"
      }
    ]
  },
  {
    "file_path": "./devposts/leftovers-love-v3t74d.html",
    "project_id": "leftovers-love-v3t74d",
    "title": "Leftovers Love",
    "tagline": "Introducing Leftovers Love, the ultimate web application designed to help you make the most out of your leftovers. With Leftovers Love, users can effortlessly discover new recipes using leftovers!",
    "hackathon": "",
    "built_with": [
      "huggingface",
      "next",
      "next-auth",
      "plotly",
      "postgresql",
      "prisma",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/171/182/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Growing up, food was never been a problem for my family. At home, the well-stocked refrigerator and pantry made food seem to have an unlimited supply. Going grocery shopping meant our family picked out only the freshest-looking produce and meat, giving little thought to where it came from. Going into high school, I joined various volunteering organizations, always eager to help out my community any way I could. I began volunteering at a local food bank, combining my love for cooking my desire to make a difference. Every week, I prepared dozens of meals for families in need. The gratitude that these families showed made the experience all the more rewarding, as I got to know another side of the community around me. As I heard their stories, I discovered my own internalized beliefs about food as a commodity, whereby many of these families struggled with just putting food on the table. I realized that some of these patrons had gone to my school. One day, I experienced this reality in an unexpected way. I had forgotten my lunch, and a classmate—someone I recognized from the food bank—shared their meal with me. What was never a cause for concern from me meant the entire world to these families, and despite her own challenges, she was willing to show kindness. These experiences taught me the true meaning of compassion and community, and I knew I needed to do more to help those in need. What it does Leftovers Love helps minimize food waste by finding recipes for leftovers with the following features: Processes user's leftover ingredients Displays compatible recipes Personalized AI to generate recipes for unique combinations Helps with finding local food banks to donate to How we built it Backend Next.js Server Prisma ORM for database queries using PostgreSQL backend Spoonacular API for recipe fetching Huggingface API for AI generation Frontend Tailwind CSS Framework Plotly for interactive mapping ShadCN UI Framework Challenges Integrating multiple APIs and ensu"
      }
    ]
  },
  {
    "file_path": "./devposts/layoff-evaders.html",
    "project_id": "layoff-evaders",
    "title": "Layoff Evaders",
    "tagline": "Stay fit AND employed with Layoff Evaders!",
    "hackathon": "",
    "built_with": [
      "c#",
      "firebase",
      "git",
      "meta",
      "python",
      "streamlit",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Second Place: YUNZII AL66 Wireless Mechanical Keyboard Created by Ex: I worked on the back-end",
      "DeltaHacks XIWinnerSecond Place: YUNZII AL66 Wireless Mechanical Keyboard",
      "Mapping VR motion tracking accurately to in-game movements.",
      "The technical intricacies of integrating VR motion tracking with meaningful gameplay mechanics.",
      "Integrating wearables for deeper health insights, such as heart rate and step tracking.",
      "Winner",
      "Ex: I worked on the back-end. It was my first time using Node, which was a little intimidating, but I learned a lot."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/214/089/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Settings Layoff Evaders Fitness Dashboard Personalized Chat Settings Layoff Evaders Fitness Dashboard Personalized Chat Settings 1 2 3 4 5 What do software engineers fear the most? Unemployment. But what they should really be scared of are the physical health risks associated with sitting for prolonged periods of time. What it does Layoff Evaders is a VR fitness game where players embody a software engineer fleeing from your evil boss. Dodge office obstacles and navigate through standup meetings, annual budget cuts, and performance reviews, all while performing real-life exercises like squats, lunges, and jumps. A connected dashboard tracks and displays stats like calories burned, jumps completed, and time spent active, empowering users to monitor their health. How we built it We used Unity for game development and integrated motion tracking with VR controllers to detect physical exercises in real-time. For stat tracking, we created a backend using Firebase Realtime Database to store user data, while a sleek dashboard was developed with Streamlit for viewing progress and achievements. Each gameplay element was designed to align real-world movements with engaging VR mechanics. Challenges we ran into Mapping VR motion tracking accurately to in-game movements. Designing exercises that are fun yet accessible to players of all fitness levels. Creating humorous and relatable obstacles that resonate with tech workers. Balancing gameplay difficulty to keep it both challenging and entertaining. Accomplishments that we're proud of Successfully gamifying fitness in a way that resonates with a specific audience. Creating a polished VR experience with accurate motion detection. Designing an interactive dashboard that motivates users to stay active. Infusing humor into a health-focused project, making it approachable and memorable. What we learned The importance of accessibility and inclusivity when designing fitness solutions. The technical intricacies of integrating VR motion t"
      }
    ]
  },
  {
    "file_path": "./devposts/lattice-data-at-your-fingertips.html",
    "project_id": "lattice-data-at-your-fingertips",
    "title": "Lattice: Orchestrating end-to-end web workflows at scale",
    "tagline": "Massively parallelized agentic research workflows using spreadsheets as a primitive",
    "hackathon": "",
    "built_with": [
      "agents",
      "apis",
      "llms",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Spreadsheet-Adjacent Hack (Air Pods Max per team member) Created by a little bit of everything Welt",
      "Pear VC: Best Customer Insights ($25k Unncapped SAFE + Office Hours w/ Partners [1st] & Office Hour",
      "Paradigm: Best Spreadsheet-Adjacent Hack (Air Pods Max per team member) Created by a little bit of",
      "Finding the right form of outreach for the best point of contact",
      "We first find potential companies, and then for each company, find a set of defined attributes.",
      "Spreadsheets are one of the best ways to visualize bulk agentic outputs and enable a lot of cool things.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/270/406/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Individual sheets Design End to end workflow Individual sheets Design End to end workflow Individual sheets 1 2 3 4 Massively parallelized agentic research workflows using spreadsheets as a primitive Summary Over the past few months, there've been a lot of really cool agentic research products that've been released (Exa, OpenAI/Perplexity Deep Research, etc). In general, these are point solutions and relatively sequential in manner (ie, the next action is conditioned on the previous actions). But AI much more exciting if we can: Build products around end-to-end workflows Do this at scale that humans never could (ie, browse hundreds of websites at once) We want to build something that takes advantage of the parallelized nature of research agents to solve end-to-end workflows en masse (we can run hundreds of agents at once!). What is this? Lattice allows you to orchestrate complex end-to-end research workflows at scale, with complex/structured dependencies. Consider a sales representative sending cold outbound: This involves: Finding potential companies to sell to and qualifying them Finding potential points of contact at these companies Finding the right form of outreach for the best point of contact Draft + sending the email Today, Lattice solves the vast majority of this workflow – and we do this at scale, across hundreds of companies in parallel. We first find potential companies, and then for each company, find a set of defined attributes. https://imgur.com/a/bsq1S3i Then, for each company, we can find the key people we want to reach and augment this information. https://imgur.com/a/7b0FhLY Then, for each companies' list of people, we can qualify them based on attributes we defined + have researched. https://imgur.com/a/dl6gfzL Finally, we can pipe all the research information to a language model to produce a final work product. https://imgur.com/a/fAdaElA We do this at scale and save a considerable amount of time over manual research – but also existing tools th"
      }
    ]
  },
  {
    "file_path": "./devposts/late-night.html",
    "project_id": "late-night",
    "title": "Study Buddy",
    "tagline": "A web application to re-imagine your study experience",
    "hackathon": "",
    "built_with": [
      "css3",
      "django",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/994/817/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "TO do List Resources Music Lounge Pomodoro TImer Ace in Exams TO do List Resources Music Lounge Pomodoro TImer Ace in Exams TO do List 1 2 3 4 5 6 7 Inspiration This project was inspired by the theme which is 'Late Night hacks' since students study mostly at night, we created a study application to help students study better. What it does it gives students a unique study experience all in one place. It comes packaged with tools like a - study timer sleep time calculator\n-resources section music lounge study game section How we built it collaborated on replit\n## Challenges we ran into web hosting challenges Accomplishments that we're proud of _cross platforming from around the world working together at a team What we learned collaboration \n## What's next for Study Chuddy\nWe will keep in touch and continue building Built With css3 django html5 javascript Try it out study-chuddy-2.netlify.app GitHub Repo youtu.be Submitted to LateNightHacks Created by I worked on content writing and designed web page in this project. The whole content is written and arranged by me. Nishant Kumar Sahu Worked on the study music section and the study game to create a better study experience for students on the application. EMEKA ⚡️ Creative Software Engineer, bodybuilder. I worked on making the sleep clock calculator. Haoyu Zhang Anuvab Bandyopadhyay Hi there ! believe in the power of collaboration and always striving to inspire others and push the boundaries of what is possible."
      }
    ]
  },
  {
    "file_path": "./devposts/lego-ninjago-fanpage.html",
    "project_id": "lego-ninjago-fanpage",
    "title": "Sons of Garmadon",
    "tagline": "We wanted to create a safe, judgementless environment for Ninjago lovers both young and old to be able to express their love for and learn a little more about the popular show.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The desire to release our inner children really drew us to create this project. It was often awkward going to forums trying to relive our childhood, so we created this website. What it does Our website allows the user to read a little about Ninjago and take a personality quiz. How we built it Our website was built primarily through HTML and CSS, with Javascript used to add functionality. Challenges we ran into One of the major challenges we ran into was trying to do too much with the website, resulting in certain sections not being completed to the level we wanted. Accomplishments that we're proud of What we learned We learned a lot about how to use GitHub for collaboration. What's next for We hope to use the knowledge we learned to potentially create other projects in the future. As well, we hope to finish some of the uncompleted sections to ensure the website is more friendly and functional for users. Built With css html javascript Try it out GitHub Repo Submitted to TAMUhack X Created by Maximillian Hsu zhihangan Jay Koh"
      }
    ]
  },
  {
    "file_path": "./devposts/libra-csqgta.html",
    "project_id": "libra-csqgta",
    "title": "Libra",
    "tagline": "An inexpensive, secure, and hassle-free gateway to book therapy sessions.",
    "hackathon": "",
    "built_with": [
      "cocoapods",
      "figma",
      "photoshop",
      "storyboards",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/715/001/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Session summary UI/UX Design of our application Sign-up screen Initial check-up screen One question in check-up screen Pick-your-therapist screen Homescreen Session summary UI/UX Design of our application Sign-up screen Initial check-up screen One question in check-up screen Pick-your-therapist screen Homescreen Session summary 1 2 3 4 5 6 7 8 Inspiration In many cultures, when you ask for therapy, you are looked down upon. When you can care about your physical health without any sort of embarrassment, why is caring about your mental health not normal? Furthermore, people across the world also struggle greatly with accepting and identifying the fact that they need mental help. With Libra, we want to do two things: firstly, remove the stigma surrounding therapy, and secondly, track your mental well-being for you. What it does Libra has three key features: Daily check-in - When the user creates an account, they are prompted to answer questions from the DSM-5 criteria (official criteria to identify mental illness) in the initial check-up questions. Based on the response, the app generates an emotional happiness rating and suggests the user seek therapy through the application (if required). If the user chooses to seek therapy, they will be directed to pick one of their suggested therapists, meeting time, and communication method. Otherwise, the app will continue to give the user daily mood checks. If it’s below 50% for a long period of time, the app will prompt another suggestion for therapy. In-app real-time messaging function - The application features a function for the user to safely text and express their conditions to a licensed therapist if the user does not want to see the therapist face-to-face. By implementing the function, we have provided a more gentle and immediate way for users who are in need, no matter when or where they are. In-app video chat - The application features a private video feature that allows the user to connect directly with their therapis"
      }
    ]
  },
  {
    "file_path": "./devposts/leaseease.html",
    "project_id": "leaseease",
    "title": "LeaseEase",
    "tagline": "LeaseEase harnesses AI to demystify the Canadian Residential Tenancy Act, providing easy-to-understand legal guidance and auto-generating essential forms like T1 and N7",
    "hackathon": "",
    "built_with": [
      "cohere",
      "langchain",
      "openai",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "McHacks 11WinnerLeverage technology to build a more environmentally and socially sustainable future (TELUS)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/739/478/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "A filled T1 form with a finishing response from the assistant Project Logo Landing page for the website Chat bot Prompting with respect to a Tenant to generate a T1 form A filled T1 form with a finishing response from the assistant Project Logo Landing page for the website Chat bot Prompting with respect to a Tenant to generate a T1 form A filled T1 form with a finishing response from the assistant 1 2 3 4 5 Inspiration\nThe genesis of LeaseEase lies in the escalating housing crisis in Canada, where landlords have increasingly exploited students and other vulnerable groups. Recognizing the urgent need for accessible legal resources, we envisioned LeaseEase as a beacon of support and empowerment. Our goal was to create a tool that simplifies the complexities of tenant rights under the Canadian Residential Tenancy Act, making legal protection accessible to those who need it most. What It Does\nLeaseEase is a groundbreaking application that combines a Large Language Model (LLM) with Retrieval-Augmented Generation (RAG) to interpret and apply the Canadian Residential Tenancy Act. It transforms user queries into actionable advice and automatically generates crucial legal documents, such as T1 and N7 forms. This functionality ensures that underprivileged groups are not only informed but also equipped to assert their rights effectively. How We Built It\nOur journey in building LeaseEase was a blend of innovative technologies and user-centric design. We utilized Streamlit for an intuitive front-end experience, integrating OpenAI and Cohere for the NLP and LLM functionalities. The backbone of our data operations was ChromaDB, a vector database, and we leveraged LangChain to seamlessly connect all these components. Challenges We Ran Into\nDeveloping LeaseEase was not without its hurdles. Integrating the backend with the frontend to accurately display the agent's thought process and RAG citations was a significant challenge. Additionally, creating the vector database and formattin"
      }
    ]
  },
  {
    "file_path": "./devposts/libre-quiz.html",
    "project_id": "libre-quiz",
    "title": "Libre Quiz",
    "tagline": "Free, open source, alternative to iClicker.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "mui",
      "nextjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/313/164/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Check out our demo slideshow! Click to advance through the slides with demo videos Try our app here! Inspiration At the University of Waterloo, we noticed that a lot of students were frustrated with having to pay $50+ for a program called iClicker.  The program allows instructors to ask students questions during their lectures and record their answers.  We felt there was no need for students to pay so much for such simple software, and there was no reason that instructors should have to grapple with the difficulties of getting it setup.  We addressed this problem by creating LibreQuiz. What it does LibreQuiz allows users to sign up, and then create and join classes.  Every class has a set of quizzes that the class owner can choose from, each quiz having a set of questions made by the class owner.  The class owner can then start a quiz, and students who have joined that class will be able to see and answer the current active question.  Teachers can then grade the question, and see immediate results to get of sense of where their class is with a topic. How we built it LibreQuiz is built on the web powered by Next.js on the frontend and Firebase on the backend.  We also used the Material UI component library to keep our styles consistent and code organized. Challenges we ran into Many of our group members were not at all familiar with the technologies we planned to use when the project was just getting started.  We spent many hours trying to find ways to get our project not only to work, but to be structured in a maintainable way since we were not familiar with all of the best practices and typical methods ahead of time. In addition, the creation of LibreQuiz coincided with a very busy time for all of us on the team with a combination of midterms, projects, and other events going on in our lives.  Thankfully, in the end we were able to find the motivation to work on LibreQuiz in the spare time we did have, and in the end got a viable product. Accomplishments that"
      }
    ]
  },
  {
    "file_path": "./devposts/life-detox.html",
    "project_id": "life-detox",
    "title": "LIFE DETOX",
    "tagline": "In the United States, anxiety and depression are at an all-time high. We developed a site that shares tools we’ve created to filter and untangle your life online and in person.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "css3",
      "discord",
      "javascript",
      "python",
      "twilio",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of NLP with Cohere Created by I created the Discord Bot and integrated Cohere Dylan Page I",
      "Give Back Hacks 3WinnerBest Use of NLP with Cohere",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/313/743/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 🎭 Inspiration Every day people put on a brave face and are expected to be happy as if it is a personal responsibility. Unfortunately, we are simply a product of our community, and if we don’t foster an environment that supports positivity and weeds out negatively. However, toxic positivity is possible where no one can be constructively honest. Our system is designed not to delete negative comments but what can be considered destructive criticism or harassment. Once an environment is stable, the individual can take the initiative can make reasonable and positive changes that can have an instant effect on mood. Examples: diet, exercise, positive affirmations, healthy coping strategies, reasonable targeting, and empathetic learning. 🧼 What it does We have prepared three tools for cleaning up your life: We developed a website using Velo by Wix for removing hostile forces from your life. On our site, you can set up our discord bot to monitor your discord channel. This bot understands contexts using Cohere and then deletes toxic comments. A chat is not for determining whether or not your relationship is toxic powered by Twilio . ☕️ How we built it First we had to learn how to create a discord bot, so we followed a tutorial on how to make a basic bot, and then used the lessons from that video to create a bot that suited our needs. Since we also had to integrate Cohere into this bot, we had to learn how to teach the Cohere ML algorithm how to reliably predict what we were looking for by tweaking the examples we fed it until it started to properly moderate according to our standards (we figured this out entirely via their documentation, which was nice to be able to do). To create the bot, we used Discords Developer portal to create a bot profile, and then added all of the bot's functionality into the cloud IDE replit. From there it was just trial an error with test Discord server's until we got it right. We then created a chat bot that fallow our toxic relationship q"
      }
    ]
  },
  {
    "file_path": "./devposts/libra.html",
    "project_id": "libra",
    "title": "LiBra",
    "tagline": "Harmonizing Bras",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "ar",
      "c#",
      "java",
      "sql",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "working in unity, AR, and Android studio for the first time."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The fact that 80% of women wear the wrong sized Bra even thought Half of America is women. What it does Android Studio app that calculates your bra size using an AR Ruler How We built it unity, ARCore, C#, Android Studio, SQL, Java, XML Challenges we ran into working in unity, AR, and Android studio for the first time. Accomplishments that we proud of Getting a functioning app with design What we learned AR and app dev What's next for LiBra Bettering the UX/UI design for the AR ruler Built With android-studio ar c# java sql unity Submitted to TechTogether Boston 2020 Created by nina Wiggins Janki Chaudhari Computer Science and Software Engineering student at University of Western Ontario"
      }
    ]
  },
  {
    "file_path": "./devposts/let-them-cook-9yb6za.html",
    "project_id": "let-them-cook-9yb6za",
    "title": "Let Them Cook",
    "tagline": "Nearly 40% of food in the U.S. is wasted. Reduce yours by Leting Them Cook, a recipe AI tool that generates fridge-cleaning recipes that are both beneficial to your wallet and the world.",
    "hackathon": "",
    "built_with": [
      "blip2",
      "css",
      "figma",
      "flask",
      "langchain",
      "openai",
      "pinecone",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      ": \"What categories are there in the fridge?\" We then processed each category individually"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/510/643/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Browse all recipes (Desktop) Home page (Mobile) Search entire recipe database (Desktop) (our main fridge image we test our product using) Browse all recipes (Desktop) Home page (Mobile) Search entire recipe database (Desktop) (our main fridge image we test our product using) Browse all recipes (Desktop) 1 2 3 4 Inspiration Nearly 40% of food in the U.S. is wasted. Reduce yours using Let them Cook, a recipe AI that generates fridge-cleaning recipes based on your fridge. Beneficial for both your wallet and the world. What it does (Frontend) This app's main function is generating recipes based on the ingredients you already have in your fridge, which is done in 3 steps. First, the AI needs to see what is in the user's fridge. The app opens up the user's mobile camera, the user pans it to the fridge, and the AI scans this picture for ingredients. Second step is the review step; the AI displays what it detected, and the user can add or delete ingredients as they please. (Some ingredients may not be detected due to various reasons such as lighting, angle, whether it's covered in a layer of plastic, hidden away behind a different ingredient, etc.) This feedback will also improve future accuracies as the AI will learn which ingredients it detected and did not detect successfully. Lastly, with this accurate list of ingredients the user is trying to use, the AI generates recipes that uses up as much of this list as possible. Each recipe has high-level information including name of the dish, picture, and description. The user can search to give certain queries and narrow down results. To learn more about a recipe, the user can click on it and a new screen will show ingredients, instructions, and other details given directly from the recipe website. Other than this main recipe generation feature, we built additional features such as: recent recipes to show up in the home tab for easy access, and a tab to show the entire recipe database to allow queries beyond what the fridge co"
      }
    ]
  },
  {
    "file_path": "./devposts/learnique.html",
    "project_id": "learnique",
    "title": "Learnique",
    "tagline": "Classrooms are too big for students we provide, AI interactive video lectures,irl real time notes,let you ask questions without stopping class, a helpful AI Tutor, and an educative social media.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "openai",
      "svelte",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/729/250/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "AI Study Partner Logo Team Social Media Statistics Interactive Lecture AI Study Partner Logo Team Social Media Statistics Interactive Lecture AI Study Partner 1 2 3 4 5 Inspiration 🤔 When we first started this pitchathon we had no idea in mind, however when we heard Jermey Dela Rosa talk about how artificial intelligence could be used to make a positive impact, and he mentioned how education would change due to it we came up with our idea.  Even in high school we find the rushed generalized lectures we receive to not help us in learning so we decided to do something about it. What it does We actually made most of the features of the app and you can access it in https://learniqueapp.netlify.app/ You can upload a video lecture and as you watch it you will be asked questions to make sure you are learning. At any moment you can ask questions based on whats happened so far. If you are in a classroom listening to a lecture you can turn on your microphone and the lecture will automatically be turned into notes. Additionally you can ask the ai about it. You can ask questions too our tutor ai who will actually help you learn it will teach you how to solve your question not just answer it (Not Created) Educative Social Media where you answer questions after watching shortform videos.\n## How we built it\nWe used Firebase, OpenAI, SvelteKIT, TailwindCSS Built With firebase openai svelte tailwindcss Try it out learniqueapp.netlify.app www.canva.com Submitted to W3B Pitchfest Created by Helped make the website with my fellow partner. Also ran facebook ads to get some proof of interest. Lastly, helped develop the pitching. José Mestres Created the web application helped getting data from advertisements and helped create presentation Eduard Faus Passionate developer who also loves business"
      }
    ]
  },
  {
    "file_path": "./devposts/legal-ease-jqu34d.html",
    "project_id": "legal-ease-jqu34d",
    "title": "Legal-Ease",
    "tagline": "Focus on business. We'll handle the law!",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini",
      "nextjs",
      "tailwindcss",
      "you.com"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/932/266/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Translating your contract Legal-Ease Home Page Branding Built your own contract Generating your contract Contract Sample Translating your contract Legal-Ease Home Page Branding Built your own contract Generating your contract Contract Sample Translating your contract 1 2 3 4 5 6 💡 Inspiration Young freelancers are often inexperienced in business law, which can lead to several challenges: Contract issues: They may struggle with drafting or understanding complex contracts, potentially agreeing to unfavorable terms. Intellectual property rights: Many are unaware of how to protect their work or may inadvertently infringe on others' rights. Tax obligations: Understanding self-employment taxes and deductions can be overwhelming for newcomers. Business structure: They may not know the pros and cons of different business entities (sole proprietorship, LLC, etc.). Client disputes: Lack of legal knowledge can make it difficult to handle disagreements or non-payment issues professionally. Insurance needs: Many young freelancers overlook the importance of professional liability insurance. Data protection and privacy laws: They may be unaware of their responsibilities regarding client data. Employment law: When subcontracting or hiring assistants, they might not understand their obligations as employers. To mitigate these risks, young freelancers should consider: Seeking mentorship from experienced professionals Taking basic business law courses Consulting with a lawyer for critical matters Joining professional associations that offer legal resources 🤔 What it does Educates freelancers and expedites the contracting process. This solution empowers freelancers with essential legal knowledge while simplifying contract creation and execution, saving time and reducing potential disputes. 🛠️ How we built it Front end: NextJS, Tailwind CSS Back end: Flask, You.com Framework: Figma 💥 Challenges we ran into Transcribing PDF text Querying certain statistics using You.com citations 🏆 Accom"
      }
    ]
  },
  {
    "file_path": "./devposts/leveler.html",
    "project_id": "leveler",
    "title": "Leveler",
    "tagline": "Level the playing field with ML powered resume anonymization",
    "hackathon": "",
    "built_with": [
      "propelauth",
      "python",
      "sbert",
      "spacy",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DEI Hack - Sponsored by Fidelity Created by I worked on the similarity scoring model (with SBERT an",
      "Best DEI Hack - Sponsored by Fidelity Created by I worked on the similarity scoring model (with SBE",
      "TechNova 2024WinnerBest DEI Hack - Sponsored by Fidelity",
      "It was our first time using streamlit so it was a challenge to learn a new technology.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/047/274/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration We wanted to develop a tool that helps remove bias in the hiring process, evaluating candidates solely on their qualifications. Personal information on a resume has been known to introduce gender bias, and we aim to prevent this by providing employers with anonymized resumes that highlight a person's skills without revealing their identity. Our goal is to create a fairer job market where talent is recognized and valued, regardless of demographic factors. By focusing on qualifications alone, we hope to empower diverse candidates and promote a more inclusive workplace. What it does After signing in, users enter their qualifications and experiences.  This data is anonymized to remove information that can reveal a candidates gender, ethnicity, religion and socio-economic background. Their qualifications are matched to the job description and a match score is generated. The anonymized information is forwarded to the employer How we built it Frontend: We developed the client-side of our web application using streamlit, crafting interactive user interfaces and components. Backend: We used PropelAuth for user management and authentication. We used spacy for anonymization and SBERT for resume to job description matching. Anonymization: Spacy Matching: SBERT Challenges we ran into It was our first time using streamlit so it was a challenge to learn a new technology. What's next for Leveler We plan to add Zero Knowledge Proof to verify a candidates qualifications on an employers behalf. Built With propelauth python sbert spacy streamlit Try it out GitHub Repo Submitted to TechNova 2024 Winner Best DEI Hack - Sponsored by Fidelity Created by I worked on the similarity scoring model (with SBERT and cosine similarity) and the anonymization (with spaCy)! Iman Umair-Qaiser UWaterloo CE '26 Nadia Bhola Lavanya Yadav Trying to learn how to do things"
      }
    ]
  },
  {
    "file_path": "./devposts/leftovers-love.html",
    "project_id": "leftovers-love",
    "title": "Leftovers Love",
    "tagline": "Introducing Leftovers Love, the ultimate web application designed to help you make the most out of your leftovers. With Leftovers Love, users can effortlessly discover new recipes using leftovers!",
    "hackathon": "",
    "built_with": [
      "huggingface",
      "next",
      "next-auth",
      "plotly",
      "postgresql",
      "prisma",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "s Winner (TPIA) this project is awesome Created by I came up with the idea of LeftoversLove, I integ",
      "brainrot jia.seed hackathon ($5,772) in prizesWinner(TPIA) this project is awesome",
      "Tracks",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/164/958/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Growing up, food was never been a problem for my family. At home, the well-stocked refrigerator and pantry made food seem to have an unlimited supply. Going grocery shopping meant our family picked out only the freshest-looking produce and meat, giving little thought to where it came from. Going into high school, I joined various volunteering organizations, always eager to help out my community any way I could. I began volunteering at a local food bank, combining my love for cooking my desire to make a difference. Every week, I prepared dozens of meals for families in need. The gratitude that these families showed made the experience all the more rewarding, as I got to know another side of the community around me. As I heard their stories, I discovered my own internalized beliefs about food as a commodity, whereby many of these families struggled with just putting food on the table. I realized that some of these patrons had gone to my school. One day, I experienced this reality in an unexpected way. I had forgotten my lunch, and a classmate—someone I recognized from the food bank—shared their meal with me. What was never a cause for concern from me meant the entire world to these families, and despite her own challenges, she was willing to show kindness. These experiences taught me the true meaning of compassion and community, and I knew I needed to do more to help those in need. What it does Leftovers Love helps minimize food waste by finding recipes for leftovers with the following features: Processes user's leftover ingredients Displays compatible recipes Personalized AI to generate recipes for unique combinations Helps with finding local food banks to donate to How we built it Backend Next.js Server Prisma ORM for database queries using PostgreSQL backend Spoonacular API for recipe fetching Huggingface API for AI generation Frontend Tailwind CSS Framework Plotly for interactive mapping ShadCN UI Frameword Challenges Integrating multiple APIs and ensu"
      }
    ]
  },
  {
    "file_path": "./devposts/lenseye.html",
    "project_id": "lenseye",
    "title": "Lensgame",
    "tagline": "A decentralised social network built on top of the Lens protocol, for building, sharing, and discussing AI tournaments in two player perfect information games.",
    "hackathon": "",
    "built_with": [
      "dart",
      "flutter",
      "javascript",
      "lens",
      "lensprotocol",
      "polygon",
      "solidity",
      "web3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This strategy defects on the first move, and plays the opponents last move every turn thereafter."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/291/638/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 In The Prisoner's Dilemma, two agents are given a choice: cooperate with their partner for mutual reward, or defect for individual reward. The dilemma faced by the agents is that, regardless of what their opponent does, they are always better off defecting than cooperating. But the combined outcome when both defect is worse than if they cooperate. For a purely rational agent with no prior knowledge, always defecting is the correct choice. A variation on this is an iterated prisoner's dilemma, multiple rounds are played, and the previous responses of each agent are given as an input to the players. This vastly widens the space of feasible strategies, and can lead to some diverse and unexpected strategies performing best. We wanted to build a platform for running these kinds of challenges. Players can create strategies which contain logic to compete in challenges. Strategies are smart contracts and exist on-chain. Each turn, they are given the history of their opponent's moves, as well as their opponent's address.\nThis allows strategies to make decisions based on their opponent's previous choices. Passing the address of their opponent allows the strategy to call them directly, and probe it with previously unseen input. Challenges are run on chain through Challenges contracts. Strategies can be registered for challenges, where they  join the pool of competing strategies, and are scored and ranked by the Challenge contract. For the Prisoner's Dilemma, one of the simplest strategies you might consider is to defect every time. This can be implemented using the following smart contract. contract AlwaysDefect is Bot {\n    constructor(uint256 owner_profile, string memory name) Bot (owner_profile, name) {}\n\n    function play(address, bool[] calldata, bool[] calldata) external pure override returns (bool) {\n            return true;\n    }\n} We can register AlwaysDefect on a specific challenge, where it will be automatically run against all other strategies "
      }
    ]
  },
  {
    "file_path": "./devposts/leveled-playing-field.html",
    "project_id": "leveled-playing-field",
    "title": "Leveled Playing Field",
    "tagline": "Proof of concept for a game powered by the blockchain that is less venerable to cyberattacks: ideally preventing hacking. We believe this will be the future of competitive gaming at the highest levels",
    "hackathon": "",
    "built_with": [
      "c++",
      "cid",
      "devpost",
      "github",
      "ipfs",
      "morailis",
      "solidity",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/320/228/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Unity Unity Unity 1 2 💡 Inspiration What do games like Valorant, Destiny 2, Counter-Strike: Global Offensive, PUBG, Grand Theft Auto Online, Fall Guys: Ultimate Knockout, Fortnite, and Call of Duty: Warzone have in common? They had a great online scene before they were an overabundance of Hackers ruined it. Videogames are an investment for players, Professionals, teams, and developers looking for entertainment, stable income, consistent engagement, and longevity, respectively. We believe online tournaments deserve an extra layer of protection. 💻 What it does Our web app, Leveled Playing Field, is built with the following features:\nOn the player side, your goal is to attack the enemy's base by any means. While on the back end, all data will be stored on a decentralized network using blockchain; By doing this, hackers would have a more challenging time altering game data or making fictitious accounts. Players can instantly purchase game collectibles rather than wait for third-party payment processors to complete their fiat cash transactions. ⚙️ How we built it Game Engine: Unity Backend: Moralis Smart Contract: Solidity Decentralized Protocol: IPFS 🧠 Challenges we ran into Completing the project was challenging because we had to implement the project by a deadline. As my first time using Unity, I had to learn the basics of the game engine. Due to the difference in the time zone, we had some difficulty collaborating, but we managed to get the project done. 🥇 Accomplishments that we're proud of Completing the project in the given time. Learn the basics of Unity and Moralis. Implement the smart contract and the database. Building a game with Unity that is fun to play. 📖 What we learned How to make a game using Unity. How to use Moralis API. 🚀 What's next for Leveled Playing Field We plan to add more features to the game.\nIntroduce more levels to the game.\nAdd more characters to the game. Built With c++ cid devpost github ipfs morailis solidity unity Try it out GitHub Rep"
      }
    ]
  },
  {
    "file_path": "./devposts/lighthouse-4ykcjn.html",
    "project_id": "lighthouse-4ykcjn",
    "title": "Lighthouse",
    "tagline": "Mental health resource locator",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "snowflake",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/790/656/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration One of the biggest barriers that people face when trying to access mental health is a lack of knowledge. It can be overwhelming to try and understand what type of treatment you'd benefit the most from, who's in your area that would be able to help you, etc, especially when there are an overwhelming amount of options out there. Lighthouse aims to be the first place people come to when they're lost while trying to get the help they need. What it does Lighthouse takes queries from a user based on what type of mental health support they're looking for, whether they're looking for a specific type of service, like CBT or group therapy, or for specialized support based on a part of their identity, such as support for LGBTQ+ people or survivors of abuse and domestic violence. Providers on the website are all verified prior to letting their profiles be shown by requiring proof of registration with a provincial certifying body for their occupation. How we built it We used Streamlit for the frontend, and FastAPI and Snowflake for the backend storage and query processing. Challenges we ran into One important part of our project was being able to use natural language queries, and a stretch goal was had was to implement a RAG LLM agent that would act as a guide to using the website. However, we ran into authentication issues with Snowflake and OAuth that prevented us from implementing those features, but we were still able to implement filter-based searches with important fields such as insurance and specialized support. Accomplishments that we're proud of Iman: This was Angie's first hackathon and she implemented most of the frontend, and did a great job with working with CSS and Streamlit! This was also my first time developing a backend and I'm glad I was able to implement the minimum features for our idea. What we learned Iman:  I got to learn about working with Snowflake and backend technologies for the first time.\nAngie: I learned how to use CSS and streamli"
      }
    ]
  },
  {
    "file_path": "./devposts/life-planner-pw351h.html",
    "project_id": "life-planner-pw351h",
    "title": "Life Planner",
    "tagline": "A small and fast planning app to quickly share with your friends and family a list of events. Great for planning trips. The description is in markdown making it really customizable.",
    "hackathon": "",
    "built_with": [
      "bulma",
      "express.js",
      "firebase",
      "github",
      "html",
      "javascript",
      "node.js",
      "python",
      "svelte",
      "visual-studio-code"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "PantherHack2022WinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/986/598/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "LifePlanner LifePlanner LifePlanner 1 2 Before we begin: In the video the calendar and time does not appear in the screen recording so please check it out on the actual website at lifeplanner.tech About the Project: We wanted to make something that could be incorporated into a person's daily life.  LifePlanner helps people plan events together. The user creates a room or joins a room by putting in a room ID given by a friend. When a user creates a room, they are taken to a screen where they can put the event title and description and be given a room ID. They can put in their phone number to get messages about the events. We built the code using Svelte, Bulma, express.js, Twilio, and Firebase. Some of the challenges that we ran into were trying to come up with an idea as well as make the room shareable with others and make an API. Some accomplishments that we're proud of are making a good idea as well as creating an API to help make sharing the rooms easier. Another thing we're proud of is the inclusion of markdown to help make a customizable user experience.  One of the team members knew nothing about web development, but through this project, they were able to learn some of the basics of web development. We were also able to learn what Twilio was and how we can utilize it. We want to make LifePlanner more customizable as well as visually appealing in the future. Built With bulma express.js firebase github html javascript node.js python svelte visual-studio-code Try it out lifeplanner.tech GitHub Repo Submitted to PantherHack2022 Winner Most Creative Use of Twilio Created by I have given the idea and contributed in the website. It was a great experience for me and my team. Maruthi Karthik Singh A aspiring full stack developer I helped make the video as well as work on some of the front-end programming. Shayaan Rahim I helped on a lot of the core functionality including connecting svelte to fire base and designing the architecture behind the rooms. Eduard Faus Passio"
      }
    ]
  },
  {
    "file_path": "./devposts/linguavista-language-cultural-learning-platform.html",
    "project_id": "linguavista-language-cultural-learning-platform",
    "title": "LinguaVista - Language & Cultural Learning Platform",
    "tagline": "See, speak, and connect with others around the world through AI-powered, immersive visual learning.",
    "hackathon": "",
    "built_with": [
      "coquitts",
      "electron",
      "express.js",
      "insanely-fast-whisper",
      "llama3",
      "ollama",
      "python",
      "react",
      "stablediffusion3",
      "typescript",
      "zoomrtms"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/269/612/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Diagram of each component of the LinguaVista app A user chatting with LinguaVista's edge AI agent about French culture A user is greeted by the LinguaVista home page with options to select a subject to learn about A user can customize their profile to focus on certain subjects, interests, or strengths Users can view notes about their previously logged conversations so they can keep track of their learning. Diagram of each component of the LinguaVista app A user chatting with LinguaVista's edge AI agent about French culture A user is greeted by the LinguaVista home page with options to select a subject to learn about A user can customize their profile to focus on certain subjects, interests, or strengths Users can view notes about their previously logged conversations so they can keep track of their learning. Diagram of each component of the LinguaVista app 1 2 3 4 5 6 💡 Inspiration💡 Despite a digitally-centered world that is the most connected in all of human history, many students, communities, and schools across the world still lack access to the internet. And with research as well as people claiming visual learning is beneficial for those learning complex subjects and engaging with culture, limited access to information, especially lots of visual aids and resources on the internet, makes education that relies on verbal communication challenging. The benefits of remote education tools were clearly illustrated as the world faced a global pandemic, forcing schools to push resources online, and further hurting communities that lack digital connection, and as the world continues to further become digital-centric, more solutions are needed to ensure future generations are educated no matter their location on the globe. A US elementary school teacher known by the LinguaVista team expressed her desire for more opportunities in the classroom to show students visuals and experiences for them to learn about rich subjects like science, social studies, and language arts (Engl"
      }
    ]
  },
  {
    "file_path": "./devposts/linkup-96m7x1.html",
    "project_id": "linkup-96m7x1",
    "title": "LinkUp",
    "tagline": "LinkUp is a browser-based game created with Unity that creates a more immersive and fun way to meet up with friends online at the safety of your home by connecting users to a live video and text chat.",
    "hackathon": "",
    "built_with": [
      "c#",
      "css",
      "ejs",
      "html",
      "javascript",
      "peerjs",
      "photon",
      "socket.io",
      "unity",
      "webrtc"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/659/764/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Video Chat Web App Logo Main Menu Main Lobby Open Video Chat Video Chat Web App Logo Main Menu Main Lobby Open Video Chat Video Chat Web App 1 2 3 4 5 6 💡 Inspiration 💡 Due to the pandemic, there has been a large shift to learning and meetings being done online through the various online meetings platforms. However, attending these meetings has now become quite a gruesome task especially after people have been spending hours on end in them over this past year. We feel that traditional online meetings need to be updated to make them a more enjoyable task. We plan to accomplish this by making joining meetings more fun and enjoyable by adding a game-like aspect when joining calls. ❓ What it does ❓ Link Up works by allowing individuals to join various video meeting rooms by using a game in which you control a character to move into the specific room you want to join. Once you move towards the room it starts a voice and video call on our very own Link Up website, with your own room ID. 🏗️ How we built it 🏗️ Frontend: HTML, CSS, JS\nBackend: NodeJs, Socket.io, PeerJS, WebRTC, EJS\nDeployment: Heroku \nGame: Unity, WebGL, Photon\nLogo: Figma \nPitch Video: Adobe Premiere Pro The video chat application was built using vanilla HTML/CSS/JS while using EJS as a templating language. For the backend, we used Socket.io, PeerJS, and WebRTC to create peer-to-peer connections within the browser running on a NodeJS server, connecting you with players within the Link Up game. 🚧 Challenges we ran into 🚧 Throughout the process of creating LinkUp we ran into a variety of challenges when bringing our idea to fruition. During the deployment of the meeting platform we came across an issue in which certain users videos were not being registered, due to Heroku using different ports when trying to establish a peer-to-peer connection, however through some troubleshooting we were able to solve this problem. Another aspect of this project that was causing us some difficulties implementing was the mult"
      }
    ]
  },
  {
    "file_path": "./devposts/locallinker.html",
    "project_id": "locallinker",
    "title": "LocalLinker",
    "tagline": "It is a website that provides recommendations of local businesses to users.",
    "hackathon": "",
    "built_with": [
      "css3",
      "firebase",
      "google-cloud",
      "google-maps",
      "openai",
      "postgresql",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Many local businesses are closing down gradually as many locals are unaware of the presence of shops. This website serves as a bridge between locals and businesses in Singapore. What it does It uses Openai API to generate recommendations based on our database of local businesses in Singapore. Built With css3 firebase google-cloud google-maps openai postgresql react Try it out GitHub Repo Submitted to Hack&Roll 2024 Created by alyssaongyx Ong"
      }
    ]
  },
  {
    "file_path": "./devposts/livelink.html",
    "project_id": "livelink",
    "title": "Livelink",
    "tagline": "Vision for Social Media: A Mixed Reality Lens",
    "hackathon": "",
    "built_with": [
      "android",
      "android-studio",
      "arcore",
      "express.js",
      "firebase",
      "firebase-authentication",
      "flask",
      "google-app-engine",
      "google-cloud",
      "google-cloud-firestore",
      "java",
      "node.js",
      "oci",
      "oracle-cloud",
      "python",
      "react",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Google Cloud Winner Best Hack using Oracle Cloud Infrastructure Created by Worked on the fro",
      "[1st Place] Best Use of Google Cloud Winner Best Hack using Oracle Cloud Infrastructure Created by",
      "LA Hacks 2021Winner[1st Place] Best Use of Google CloudWinnerBest Hack using Oracle Cloud Infrastructure",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/451/376/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Linking with a user! Livelink on mobile and web Detecting face (this works on static images and live in-person)! Profile rendered (this works on static images and live in-person)! Linking with a user! Livelink on mobile and web Detecting face (this works on static images and live in-person)! Profile rendered (this works on static images and live in-person)! Linking with a user! 1 2 3 4 5 Inspiration Many times, during job fairs and recruiting sessions, we have found it difficult to express ourselves to company recruiters and portray our capabilities and passion . With a large pool of talented candidates and a small, limited number of recruiters, it is difficult and sometimes nearly impossible to fully portray yourself. To combat this issue, we developed Livelink to help people link professionally and efficiently. Recruiters simply use the mobile app with or without AR lens to immediately scan rooms and see everyone's professional profile . This should streamline the recruiting process and help candidates express themselves successfully. What it does Livelink leverages facial recognition , augmented reality , and speech recognition to provide a seamless experience for users to link with others live and in-person with ease. The user can create a professional profile on the web app by uploading an image of themselves for facial recognition and a biography. Then, using the mobile app, others can view that profile if they scan that user. Their profile will be dynamically rendered via AR for recruiters and others to see. How we built it The project work was split into 3 main segments: the web application, the mobile application, and the backend. Web App The web application was built in React.js and was used to handle profile creation and update. This was also where users uploaded their profile pictures on which facial recognition was conducted. The UI/UX of the web application was designed in a Figma prototype before we reformatted the HTML and CSS to cooperate with React"
      }
    ]
  },
  {
    "file_path": "./devposts/locate-my-luggage.html",
    "project_id": "locate-my-luggage",
    "title": "Locate my Luggage",
    "tagline": "A compact setup with an application to locate your luggage",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-maps",
      "javascript",
      "mapbox",
      "python",
      "raspberry-pi",
      "react-native",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Created by Neel Adwani yeet Avinash Upadhyaya K R",
      "Bon Voyage HacksWinnerThird Overall",
      "Accurately tracking the luggage and providing a good UX for users to track their luggage using different map solutions.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/603/912/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Traveling and visiting new places has become a major part of the lifestyle of most people all around the globe. Whether we are traveling near or far, no matter whichever mode of transport we take, luggage is a common thing that we always take good care of. A very common phenomenon, while we are traveling, is missing your luggage or theft of luggage. What it does We built that application that you can use to track your luggage using our different map solutions. The raspberry pi pings our server every time with its location, which is shown onto the embedded map. How we built it We used Raspberry Pi with a power bank for the hardware setup and React Native along with Mapbox and Google Maps (Google Cloud) for the mobile app. Although, a cheaper circuit can be built using NodeMCU with GPS Module, we had to use a  raspberry pi due to the unavailability of components. Challenges we ran into Issues with Android Studio and Gradle. Integrating the map was also a challenge. Accomplishments that we're proud of Accurately tracking the luggage and providing a good UX for users to track their luggage using different map solutions. What we learned Building react native apps and integrating Mapbox and Google maps What's next for Locate my Luggage We'll develop a cheaper and more feasible circuit when we have a GPS Module. Built With flask google-maps javascript mapbox python raspberry-pi react-native replit Try it out GitHub Repo GitHub Repo GitHub Repo replit.com Submitted to Bon Voyage Hacks Winner Third Overall Created by Neel Adwani yeet Avinash Upadhyaya K R"
      }
    ]
  },
  {
    "file_path": "./devposts/lossn-t.html",
    "project_id": "lossn-t",
    "title": "Quicture",
    "tagline": "A privacy-first solution to sharing images fast and losslessly leveraging P2P and a no-login approach.",
    "hackathon": "",
    "built_with": [
      "docker",
      "fastapi",
      "google-cloud",
      "poetry",
      "python",
      "socket.io",
      "tailwind",
      "typescript",
      "webrtc"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A privacy-first solution to sharing images fast and losslessly leveraging P2P and a no-login approach."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/880/768/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "An example of a room The homepage An example of a room The homepage An example of a room 1 2 3 Inspiration We stumbled upon a common yet not talked about issue regarding image sharing. Any time you need to ask a friend to share photos with you, they may typically send these photos to you over some social media/messaging app like discord or instagram (or sometimes even email). This is insanity! Images that are shared over these platforms are always heavily compressed, and this means that you are compromising on the quality of these images. Well why not Airdrop? Essentially, Airdrop/Nearby share use either Bluetooth or a local wireless connection which both have their limits. The biggest one is the fact that in order for either of those to work, you must be within a close proximity (100ft or so) of each other. Now if you take p2p, it can work across the whole internet. You can be 1000s of KM away and get faster speeds. What it does Quicture allows you to create/join \"rooms\" where you can lossesly share images with your friends over a direct peer-to-peer (p2p) connection. This bypasses the need for a traditional backend which means no storage costs, networking costs & all of the other costly parts of a traditional image sharing platform. Additionally, users have the option to store images temporarily and privately on the cloud in case other users are not available for a peer-to-peer connection. These images are automatically deleted after 7 days. How we built it We used Next.js for the frontend and Sockets.io to establish a peer-to-peer connection within the client. For the backend, we utilized FastAPI to build the API and connected the application to a GCP cloud bucket via the async gcloud CLI. (see https://api.sharethephotoswithus.us/docs ) Challenges we ran into Pretty much all of our issues were placed around the p2p aspect of the program. Due an initial misunderstanding, we didn't have any progress until the last night. Accomplishments that we're proud of After a "
      }
    ]
  },
  {
    "file_path": "./devposts/local-ly.html",
    "project_id": "local-ly",
    "title": "Local.ly",
    "tagline": "Share what you do, Find what you love, Local.ly",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "firebase",
      "html",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Financial Hack (Sponsored by Capital One) Created by I worked on the front-end of the project and e",
      "Capital One) Created by I worked on the front-end of the project and editing the overall design for",
      "Best Financial Hack (Sponsored by Capital One) Created by I worked on the front-end of the project",
      "TechTogether AtlantaWinnerBest Financial Hack (Sponsored by Capital One)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/417/400/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Your Business -> Stories Page Landing Page Login Page Logged In Home Page Mandy's Ice Cream -> Products Page Mandy's Ice Cream -> Updates Page Mandy's Ice Cream -> Stories Page Your Business -> Analytics Page Your Business -> Posts Page Your Business -> Stories Page Landing Page Login Page Logged In Home Page Mandy's Ice Cream -> Products Page Mandy's Ice Cream -> Updates Page Mandy's Ice Cream -> Stories Page Your Business -> Analytics Page Your Business -> Posts Page Your Business -> Stories Page 1 2 3 4 5 6 7 8 9 10 Inspiration We were inspired by not only the Love Your City theme but we also were inspired by social media and e-commerce sites like Twitter and Etsy, respectively. We wanted to take similar concepts from those websites and incorporate the support small/local businesses aspect to it. Especially for small businesses who are just starting shop and may be unaware how to promote their own business well. What it does Local.ly aims to uplift and support local communities by connecting consumers to local businesses more simply. Consumers are able to view business profiles by searching them and clicking the top right arrow. They will be redirected to another page with subpages titled products, updates, and stories, all of which contain information to help consumers view information such as product listings, events, and updates are within driving distance and can be purchased through the website. Users can engage with these local businesses - by liking, sharing, and viewing their content - and can put products from a business on hold/deposit before buying. Business owners are able to view their analytics to grasp an overview of their overall engagement and sales which can be used to further develop their business. How we built it We first built a model on Figma to organize our ideas, then began to develop the website with HTML, CSS, Javascript, and Firebase. Challenges we ran into We had a few difficulties with incorporating all our ideas into the website, bu"
      }
    ]
  },
  {
    "file_path": "./devposts/lit-em.html",
    "project_id": "lit-em",
    "title": "Lit(m)",
    "tagline": "Lit(m) captures your concert experience, finds the most hype moment, and posts it to Instagram — all automatically. Live in the moment — Lit(m) takes care of the rest.",
    "hackathon": "",
    "built_with": [
      "flask",
      "mongodb",
      "openai",
      "python",
      "raspberry-pi",
      "twelvelabs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/626/296/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration At concerts, people often miss out on the real experience because they’re too focused on recording, editing, and posting clips to social media. We wanted to build something that lets people live in the moment without sacrificing the chance to share the best parts of their night. That’s where Lit(m) comes in — an automated system that captures and shares the highlights for you, so you can focus on the music, not your screen. What it does Lit(m) is a Raspberry Pi-powered camera system that captures live concert footage, detects the currently playing song, finds the most iconic lyric, automatically clips that portion of the video, and uploads it directly to your Instagram story. The result is a seamless, AI-curated concert highlight — without ever taking your phone out. How we built it We connected a camera to a Raspberry Pi and wrote Python scripts to manage video capture and file handling. Analyze the video using Arc Cloud for real-time music recognition. Utilize OpenAI to help identify the most popular lyric. Send a full concert clip to Twelve Labs to analyze the video and locate the timestamp that matches the lyric. We trim the video to only include that portion using ffmpeg. Finally, the clip is uploaded automatically to Instagram Stories after successful login. The whole pipeline is coordinated with a lightweight Flask backend running on the Pi. Challenges we ran into a lot. Accomplishments that we're proud of We got everything running smoothly on a Raspberry Pi — including multiple API calls and real-time video processing! What we learned How to integrate multiple APIs into a real-time pipeline under hardware constraints. How to process audio and video in sync, and apply AI models to enhance user-generated content. That it's totally possible to bring together music recognition, video editing, and social media automation — even at a concert. What's next for Lit(m)? Add real-time filters and lighting enhancements using computer vision. Support more"
      }
    ]
  },
  {
    "file_path": "./devposts/loca-nbxors.html",
    "project_id": "loca-nbxors",
    "title": "LOCA",
    "tagline": "A virtual travel guide that uses AI to identify and provide information on various monuments and other objects of interest, with information scraped from online and crowdsourced from the community.",
    "hackathon": "",
    "built_with": [
      "flask",
      "google-cloud",
      "python",
      "react",
      "redis"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place Prize - Travel Track Winner YCombinator Challenge Created by Set up the Google Cloud inte",
      "See the presentation and awards ceremony here: https://www",
      "- Travel Track Winner YCombinator Challenge Created by Set up the Google Cloud integrations and the",
      "YHack 2022Winner1st Place Prize - Travel TrackWinnerYCombinator Challenge",
      "Presentation + Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/899/999/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Team Bulldogs and Huskies LOCA logo LOCA app login screen LOCA app featured landmarks nearby LOCA app camera LOCA app description of monument LOCA backend publishing scraped Wikipedia data Tech stack Team Bulldogs and Huskies LOCA logo LOCA app login screen LOCA app featured landmarks nearby LOCA app camera LOCA app description of monument LOCA backend publishing scraped Wikipedia data Tech stack Team Bulldogs and Huskies 1 2 3 4 5 6 7 8 9 Presentation + Award See the presentation and awards ceremony here: https://www.youtube.com/watch?v=jd8-WVqPKKo&t=351s&ab_channel=JoshuaQin Inspiration Back when we first came to the Yale campus, we were stunned by the architecture and the public works of art. One monument in particular stood out to us - the Lipstick (Ascending) on Caterpillar Tracks in the Morse College courtyard, for its oddity and its prominence. We learned from fellow students about the background and history behind the sculpture, as well as more personal experiences on how students used and interacted with the sculpture over time. One of the great joys of traveling to new places is to learn about the community from locals, information which is often not recorded anywhere else. From monuments to parks to buildings, there are always interesting fixtures in a community with stories behind them that would otherwise go untold. We wanted to create a platform for people to easily discover and share those stories with one another. What it does Our app allows anybody to point their phone camera at an interesting object, snap a picture of it, and learn more about the story behind it. Users also have the ability to browse interesting fixtures in the area around them, add new fixtures and stories by themselves, or modify and add to existing stories with their own information and experiences. In addition to user-generated content, we also wrote scripts that scraped Wikipedia for geographic location, names, and descriptions of interesting monuments from around the New Have"
      }
    ]
  },
  {
    "file_path": "./devposts/look-n-listen.html",
    "project_id": "look-n-listen",
    "title": "Look 'n Listen",
    "tagline": "Transform your emotions into music. Our AI reads your mood from expressions and text, curating personalized Spotify playlists for instant mood enhancement. Elevate your well-being, one song at a time.",
    "hackathon": "",
    "built_with": [
      "fer",
      "flask",
      "javascript",
      "node.js",
      "openai",
      "python",
      "react",
      "spotipy",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AI Hack Created by she11fish she11fish Frederic Tu Shawn Jiang Borys Langowicz U of T | Class of '2",
      "Best AI Hack Created by she11fish she11fish Frederic Tu Shawn Jiang Borys Langowicz U of T | Class",
      "Hack the Valley 8WinnerBest AI Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/622/891/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Homepage Homepage Homepage 1 2 🌟 Inspiration We're inspired by the idea that emotions run deeper than a simple 'sad' or 'uplifting.' Our project was born from the realization that personalization is the key to managing emotional states effectively. 🤯🔍 What it does? Our solution is an innovative platform that harnesses the power of AI and emotion recognition to create personalized Spotify playlists. It begins by analyzing a user's emotions, both from facial expressions and text input, to understand their current state of mind. We then use this emotional data, along with the user's music preferences, to curate a Spotify playlist that's tailored to their unique emotional needs. What sets our solution apart is its ability to go beyond simplistic mood categorizations like 'happy' or 'sad.' We understand that emotions are nuanced, and our deep-thought algorithms ensure that the playlist doesn't worsen the user's emotional state but, rather, optimizes it. This means the music is not just a random collection; it's a therapeutic selection that can help users manage their emotions more effectively. It's music therapy reimagined for the digital age, offering a new and more profound dimension in emotional support. 💡🛠💎 How we built it? We crafted our project by combining advanced technologies and teamwork. We used Flask, Python, React, and TypeScript for the backend and frontend, alongside the Spotify and OpenAI APIs. Our biggest challenge was integrating the Spotify API. When we faced issues with an existing wrapper, we created a custom solution to overcome the hurdle. Throughout the process, our close collaboration allowed us to seamlessly blend emotion recognition, music curation, and user-friendly design, resulting in a platform that enhances emotional well-being through personalized music. 🧩🤔💡 Challenges we ran into 🔌 API Integration Complexities: We grappled with integrating and harmonizing multiple APIs. 🎭 Emotion Recognition Precision: Achieving high accuracy in emotion "
      }
    ]
  },
  {
    "file_path": "./devposts/loominal.html",
    "project_id": "loominal",
    "title": "Loominal",
    "tagline": "Loominal is an AI-powered knowledge engine designed to accelerate team onboarding and knowledge transfer. Allow any team member to get answers without having to interrupt the workflow of others.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "drizzleorm",
      "flask",
      "gemini",
      "github-api",
      "linear-api",
      "neon",
      "neon-postgres",
      "next.js",
      "notion-api",
      "paithon",
      "pgvector",
      "postgresql",
      "python",
      "react",
      "slack-api",
      "tailwindcss",
      "typescript",
      "vellum",
      "xenova-transformer"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Linear: Best Agents of Linear Created by I worked on the Linear tickets, environment setup, and int",
      "Hack the 6ix 2025WinnerLinear: Best Agents of Linear",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/628/034/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our Mascot Lou Landing Page - hero section, dark mode Landing Page - hero section, light mode Custom Auth0 Login Page Dashboard Organizations Dedicated Organization Page The Workspace Third-Party App Integrations Prompt Response Response - Durkk Mode List of Sources for the Response Settings Page Our Mascot Lou Landing Page - hero section, dark mode Landing Page - hero section, light mode Custom Auth0 Login Page Dashboard Organizations Dedicated Organization Page The Workspace Third-Party App Integrations Prompt Response Response - Durkk Mode List of Sources for the Response Settings Page Our Mascot Lou 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 The Problem 💭 Meet Rachel, a newly hired software engineer, eager to make her mark. She joins a mature team with a large, fast-moving codebase and a mountain of tribal knowledge. Her goal is simple: start contributing valuable code and feel like a real part of the team. But instead of writing features, she’s spending her days lost in a maze of Slack threads, GitHub issues, Linear tickets, and outdated Notion docs. Rachel has tons of \"why\" questions: Why was this API designed this way? Why was that PR reverted? Why are we prioritizing this over that? But she’s hesitant to constantly ping senior developers—they’re busy, and she doesn’t want to seem unprepared. So she resorts to piecing things together alone, context-switching across dozens of tools, trying to reverse-engineer decisions from fragments of information. She’s not unqualified, just uninformed. This experience is more common than teams admit. Onboarding is a silent tax on engineering productivity, not just in time lost, but in knowledge withheld. It can take weeks, sometimes months, for new hires to reach full velocity. The real bottleneck isn’t writing code—it’s understanding the why behind it. The friction comes in two forms: The Human Problem:\nNew engineers feel pressure to be independent, yet they're overwhelmed by a lack of context. They don’t want t"
      }
    ]
  },
  {
    "file_path": "./devposts/loudsical.html",
    "project_id": "loudsical",
    "title": "Loudxical",
    "tagline": "Text editor that speaks to you🗣️ - built on top of Lexical📝",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "lexical",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/235/652/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Cover Cover 1 2 3 4 5 💡Inspiration Ever thought about building your own Google Docs? How about incorporating a Notion liked editor on your app? You can choose to build these things from scratch or do the wiser thing by using Lexical's text editor. Lexical is a extensible text editor framework that has 3 main qualities: reliability, accessibility, and speed. Lexical is used by 100s of applications around the world. Some of its applications include a text editor that may be used by users to write long-form content (for example: blog, essays, research paper). For these users, features associated with spell-checking and proof-reading are very important, since more mistakes are made for long-form content. Inspire by famous children's book author Jim Trelease, who once said \"The more you read out loud your writing, the better you get it,\" we decided to build Text-to-Speech(TTS) functionality within Lexical. TTS allows users get to hear their writing before submission and this has a number of benefits: 1) Users can identify the tone of the piece and the transitions between ideas\n2) User can correct awkward sentences\n3) Users can find spelling mistakes We decided to call our version of Lexical: Loudxical 🤔What it does Loudxical is a web application and comprises of an extension of Lexical editor with TTS functionality within the editor. Loudxical has all the functionalities of the \"rich text editor\" Lexical along with several features associated TTS. 🦾 How we built it Frontend: React.js, Tailwind Packages: Lexical Deployment: Netlify Tools: Netlify, Git 🎨UI/UX Our Figma file consists of Mockups and Design Documents we used to build our application. We were heavily inspired by the revised version of Iterative design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling your solution & then finally deploy it. Discover : a deep dive into the problem we are trying to solve. Define : s"
      }
    ]
  },
  {
    "file_path": "./devposts/loveatfirst-tech.html",
    "project_id": "loveatfirst-tech",
    "title": "matchmadein.tech",
    "tagline": "Code Your Way to Connection: Where Shared Commits Lead to Committed Relationships.",
    "hackathon": "",
    "built_with": [
      "flask",
      "github",
      "javascript",
      "python",
      "react",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2023WinnerMost Creative Use of GitHub",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/591/758/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The user \"favorited\" Homepage After entering GitHub Username The user \"favorited\" Homepage After entering GitHub Username The user \"favorited\" 1 2 3 Inspiration We’ve all been in a situation where collaborators’ strengths all lie in different areas, and finding “the perfect” team to work with is more difficult than expected. We wanted to make something that could help us find people with similar strengths without painstakingly scouring dozens of github accounts. What it does MatchMadeIn.Tech is a platform where users are automatically matched with other github users who share similar commit frequencies, language familiarity, and more! How we built it We used a modern stack that includes React for the front end and python Flask for the back end. Our model is a K-Means Cluster model, and we implemented it using scikit-learn, storing the trained model in a PickleDB. We leveraged GitHub's API to pull user contribution data and language preferences data for over 3 thousand users, optimizing our querying using GraphQL. Challenges we ran into A big issue we faced was how to query the Github API to get full representation of all the users on the platform. Because there are over 100 million registered users on Github, many of which are bots and accounts that have no contribution history, we needed a way to parse these users. Another obstacle we ran into was implementing the K-Means Cluster model. This was our first time using any machine learning algorithms other than Chat-GPT, so it was a very big learning curve. With multiple people working on the querying of data and training the model, our documentation regarding storing the data in code needed to be perfect, especially because the model required all the data to be in the same format. Accomplishments that we're proud of Getting the backend to actually work! We decided to step out of our comfort zone and train our own statistical inference model. There were definitely times we felt discouraged, but we’re all proud of each"
      }
    ]
  },
  {
    "file_path": "./devposts/lost-fishies-buys-pizza.html",
    "project_id": "lost-fishies-buys-pizza",
    "title": "Lost Fishies Buys Pizza",
    "tagline": "The Mama Mia Pizzeria has been using their authentic pizza recipes, however, their customers are unhappy. Through data analysis, we find the problems engraved within operations and provide solutions.",
    "hackathon": "",
    "built_with": [
      "celonis",
      "excel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/703/362/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Violations page. Data analysis page which contains the basic analysis of #of orders, total throughput time, total net profit, and customer satisfaction. Graphics of order page containing the graphics of orders made in certain districts and types of pizzas made. Process overview page that summarizes events through out the day. Weekly glance of profit and customer satisfaction throughout the week. Conformance page. Violations page. Data analysis page which contains the basic analysis of #of orders, total throughput time, total net profit, and customer satisfaction. Graphics of order page containing the graphics of orders made in certain districts and types of pizzas made. Process overview page that summarizes events through out the day. Weekly glance of profit and customer satisfaction throughout the week. Conformance page. Violations page. 1 2 3 4 5 6 7 The Mission The Celonis challenge provided data from a real-world takeaway pizza place. At first glance, the business seems to be going well and they have sustainable traffic that keeps the pizzeria running. However, after just slight investigation, one can note that they have a very low rating for their authentic recipe and they are often loosing money with each pizza made. We wanted to investigate the data and see why a friendly local restaurant is not receiving the recognition it deserves. The tools of excavation For this challenge, we used the suite of tools built within the Celonis suite. Mainly, we made a workspace with analyses that contains a large variety of components that made it easy for us to view the subtle differences the change of variables can make. Problems buried in the data Confusing website Orders that are made through the website are on average 18 minutes slower from order placed to pizza received. All credit card purchases are done through the website and they are on average 9 minutes slower Orders made through the website are not descriptive enough and require chefs to call the customer in orde"
      }
    ]
  },
  {
    "file_path": "./devposts/lucy-1o3xnj.html",
    "project_id": "lucy-1o3xnj",
    "title": "Lucy",
    "tagline": "your virtual caretaker",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "html",
      "html5",
      "javascript",
      "python",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The Prettiest Hack Created by Private user Private user Ava Chan Shalini Kumari",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/363/991/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Mental Health is a real issue. Unfortunately it is not given the care it deserves.\n2020 was a rough year, with Corona forcing people to quarantine themselves, the feeling of loneliness and isolation was higher than ever.\nSometimes, it's hard to express yourself and we get it. (It's also possible that your therapist might not be available at that particular time). In an attempt to solve the above issue, we present to you Lucy. What it does Caretakers/therapists can register their patients on our website. Lucy,  our voicebot will ask the patients some vital questions about well being and then the responses will then be stored and will be available at our website to the caretakers/therapists for analysis in order to help in providing their patients the therapy they need. Testing Call or text +1 469 392 4576 Tip: you can call international numbers for free using Google Hangouts:) How we built it Front-end development using html, css and javascript Back-end development using Firebase Sentiment Analysis using python and its libraries Chatbot development using Twilio Challenges we ran into We were in a time crunch and that was definitely an issue. Storing the responses was also an issue. We struggled with firebase a lot. Accomplishments that we're proud of We built a working prototype What we learnt We learnt a lot about using Twilio for chatbot development and Firebase for back-end development What's next for Lucy Better Sentiment Analysis Robust backend Alert system\n-When a value exceeded the threshold, the app will alert the corresponding healthcare provider Built With css firebase html html5 javascript python twilio Try it out GitHub Repo Submitted to StarHacks TechTogether Seattle Winner The Prettiest Hack Created by Private user Private user Ava Chan Shalini Kumari"
      }
    ]
  },
  {
    "file_path": "./devposts/makeuoft.html",
    "project_id": "makeuoft",
    "title": "Tune Turn",
    "tagline": "Play your music carefree as we help you turn your music sheets",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "flask",
      "java",
      "mediapipe",
      "opencv",
      "python",
      "qualcomm-hdk-8450"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MakeUofT 2023WinnerMusic",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/387/042/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡 Inspiration 💡 Some of our team members have played musical instruments in the past. They know the pain of stopping or pausing while playing the music to flip over their music sheet. Using the hands to flip over a music sheet is not ideal since the hands should be on the instrument to play the music at all times. Since the eyes have to be on the music sheet to read music, why not use the eyes to flip over the music pages instead? And keep our hands on the instrument. ❓ What it does ❓ TuneTurn tracks the angle of the musician's head using openCV and uses it to detect whether the user's head is turned to the left or right, and accordingly flips the page of the music sheets, allowing for a hands-free experience. The app also has a vast library of music stored which the user can access and listen to and get a better idea of how to actually play the song of their choice before they start. 🤔 How we built it 🤔 Using computer vision (OpenCV) in an app deployed using Qualcomm HDK 8450, we track the movement of the head to trigger the change of page based on which way the head is moving based on the angle that is formed. We ensure then send a request to a Flask server, and ensure only 1 request is sent even though the user's head will be in the turned position for a few hundred milliseconds. The server processes the request and accordingly flips the sheet by using pyautogui to control the computer's left/right keys. 😰 Challenges we ran into 😰 It was our first time using OpenCV and we struggled a lot with accurately tracking the coordinates of the desired landmarks on the user's face as choosing the wrong ones would make it difficult to accurately detect whether the user's head is turned. Another major challenge was using Android App Studio to do the ML using Qualcomm as we had never used it before. We primarily code in Python and found the drastic change to Java quite difficult, especially since we had to do relatively complex ML using openCV. 🥇 Accomplishments that we'r"
      }
    ]
  },
  {
    "file_path": "./devposts/luna-tech.html",
    "project_id": "luna-tech",
    "title": "Luna Tech",
    "tagline": "Personalized Wellness: AI-powered Dietary Supplement Suggestions Tailored Specifically for Women’s Health",
    "hackathon": "",
    "built_with": [
      "ai",
      "cloudflare",
      "css",
      "flask",
      "javascript",
      "llms",
      "ml",
      "postgresql",
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/075/756/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Website Display Inspiration Before 1993, women were rarely included in clinical trials. Even today, women still remain underrepresented in medical research, vastly limiting our understanding of how women, particularly women of color, react to and experience drugs and other medical procedures. Existing research published in medical journals typically remains unseen from the general public, and nuances of the research are easily lost when relayed through news articles or social media. We aim to consolidate all existing medical research about women's health and make findings more accessible to the general public. What it does Our website allows users to search questions (\"How can I increase my fertility?\", \"How can I feel less bloated during my period?\") and receive well-informed, research-based advice about lifestyle changes and dietary supplements to take. Our model takes into account personal demographics (age, race, previous medical history) and live-time data (BPM, menstrual cycle duration, oxygen levels, sleep duration) and consolidates it with published research papers to make a well-informed decision. Live-time information, such as BPM, menstrual cycle duration, and sleep duration, is also displayed on the dashboard. How we built it For frontend, we used Node.js. \nThe model itself utilized an algorithm similar to mixture of experts. Many small LLMs, each an expert on a specific topic (sleep, menstrual cycle, drug interactions) generate advice with a corresponding confidence score. A larger LLM takes these responses and produces a distilled piece of advice that is well-informed, accurate, and comprehensive. Challenges we ran into After training the smaller LLM models, we discovered the advice was too generic and sometimes even included other genders. This was due to one of our decisions early on, where we realized our original idea of finding the 50 most relevant research papers to train our small LLMs was infeasible for the scope of the project in terms of time"
      }
    ]
  },
  {
    "file_path": "./devposts/mallet-1niz3t.html",
    "project_id": "mallet-1niz3t",
    "title": "MALLET",
    "tagline": "MALLET is a one stop shop for management of the modern portfolio. MALLET passively crawls the web, gathering sentiment on a user's investments. For businesses, MALLET expands to include stock buybacks",
    "hackathon": "",
    "built_with": [
      "gemini",
      "pandas",
      "python",
      "vader",
      "yfinance"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Hello we are MALLET: a creative way to organize and compute your portfolio whether you are a large firm or any individual. Firstly, we have a personal crypto manager that allows the use of a powerful decenteralized blockchain system within our api. We use ALPACA API to gather and conduct trades rather than directly implementing a blockchain to keep data safe and allow for 2 directional transactions without fear of crypto rug pulling or transactional scams. Then for each branch of crypto we use a web crawler to find and update sentiment scores daily on a specific branch of crypto such as solana and bitcoin. Sentiment analysis is crucial for crypto trading due to its value being tied directly to public opinion. Next, we have a business view that not only has the crypto manager, but also allows firms to determine the time they would buy their own stock and inflate their prices. The buyback analysis uses quantitative analysis on the companies cash flow and other aspect to conduct statiscal analysis and find out whether or not it is a good buy. Built With gemini pandas python vader yfinance Submitted to Blu's Hacks 2025 Created by Denis Vorobyev sreyas-p"
      }
    ]
  },
  {
    "file_path": "./devposts/love-thy-neighbourhood.html",
    "project_id": "love-thy-neighbourhood",
    "title": "Love Thy Neighbourhood",
    "tagline": "A community app to connect with your neighbourhood!",
    "hackathon": "",
    "built_with": [
      "auth0",
      "express.js",
      "mongodb",
      "node.js",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/035/074/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Profile Page Opening Page Log-In Page Choose Your Neighbourhood Feed Making Posts Profile Page Opening Page Log-In Page Choose Your Neighbourhood Feed Making Posts Profile Page 1 2 3 4 5 6 7 Inspiration Since COVID-19 has started, the virtual environment and quarantine made people numb to the lack of social interaction within the community. In-person interactions diminished and connections in neighborhoods are lost. People got distant and are more used to online socialization. They rarely meet new people. With our app, we hope to bring the community together and encourage positive social interactions. What it does Love Thy Neighbourhood is a social media platform with the goal of connecting people in neighbourhoods and the overall betterment of the community. How we built it We built the frontend with Typescript, React, and Auth0, and we used Node + Express, MongoDB, and Amazon S3 buckets for the backend, deployed to an EC2 instance. Challenges we ran into A major issue we faced was the time constraint. We struggled to implement all of the features that we envisioned, such as the user profile creation and viewing. Accomplishments that we're proud of We made working user authentication. What we learned We learned how to do a full-stack project with various features (user profile, posts, uploading files, and user account) What's next for Love Thy Neighbourhood Add ability to edit profile and view other profiles. How to run the program Option 1: Open our deployed website https://app.netlify.com/sites/love-thy-hood/deploys/62d4213e43a4526778973168 Option 2: Clone repo, cd to client, run npm i and npm start Built With auth0 express.js mongodb node.js react tailwind typescript Try it out GitHub Repo Submitted to Recess Hacks 2.0 Created by I make and deploy and make API . Steven Chen I wrote the database schemas, added S3 integration, and also made the frontend communicate with the backend using axios. Jay Ren Helo Webpage Design and Front-end Coding Leanne Kim Worked on "
      }
    ]
  },
  {
    "file_path": "./devposts/macsim-store.html",
    "project_id": "macsim-store",
    "title": "MacSim.Store",
    "tagline": "An old App Store where anyone can vibe code to create retro apps on a simulated MacOS GUI! WYSIWYG...",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Regional Highlights | AMER Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entreprene",
      "World’s Largest Hackathon presented by BoltWinnerRegional Highlights | AMER",
      "\"The best way to predict the future is to invent it.\" - Alan Kay",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/588/156/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Macintosh 1984 Simulator - Interactive Computing History 🖥️ What it does Step back in time to 1984 and experience the revolutionary Macintosh computer that changed personal computing forever! This pixel-perfect recreation brings the original Mac OS to your browser with fully interactive applications, authentic window management, and that iconic black-and-white aesthetic. But this isn't just a static museum piece - it's a living, breathing development environment where users can create their own apps using three different paradigms spanning 40+ years of programming evolution: MacCode 1984 : Visual interface builder with classic Mac styling BlockCode 2015 : Drag-and-drop visual programming with colorful blocks VibeCode 2025 : AI-powered natural language app creation - just describe what you want in plain English! 🚀 How we built it Built entirely in React and TypeScript with Tailwind CSS , this simulator features: Authentic Boot Sequence : Complete with the classic Mac smiley face Pixel-Perfect UI Recreation : Every menu, button, and window styled to match 1984 Advanced Window Management : Draggable windows with proper z-index handling and focus management Complete Application Suite : Calculator, Notepad, MacDraw drawing app, and Breakout game Nested Development Environments : Apps that let you build other apps - meta-programming at its finest! SVG-to-PNG Export : Create drawings in MacDraw and download them as modern image files The crown jewel is VibeCode 2025 , which uses sophisticated prompt engineering to interpret natural language and generate fully functional web applications complete with HTML, CSS, and JavaScript. 🎯 What makes it special Educational Time Machine : This project serves as an interactive history lesson, showing how far user interfaces have evolved while demonstrating that good design principles are timeless. Progressive Programming Paradigms : Experience the evolution of software development: 1984 : Direct interface manipulation and visual "
      }
    ]
  },
  {
    "file_path": "./devposts/ludwig.html",
    "project_id": "ludwig",
    "title": "Ludwig",
    "tagline": "A physical robot to play any sheet music you want!",
    "hackathon": "",
    "built_with": [
      "opencv",
      "python",
      "raspberry-pi",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2024 Finalists Created by I worked on the code to read the sheet music image with Op",
      "Hack the North 2024WinnerHack the North 2024 Finalists",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/024/595/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 💡 Inspiration 💡 Have you ever wished you could play the piano perfectly? Well, instead of playing yourself, why not get Ludwig to play it for you? Regardless of your ability to read sheet music, just upload it to Ludwig and he'll scan, analyze, and play the entire sheet music within the span of a few seconds! Sometimes, you just want someone to play the piano for you, so we aimed to make a robot that could be your little personal piano player! This project allows us to bring music to places like elderly homes, where live performances can uplift residents who may not have frequent access to musicians. We were excited to combine computer vision, MIDI parsing, and robotics to create something tangible that shows how technology can open new doors. Ultimately, our project makes music more inclusive and brings people together through shared experiences. ❓What it does ❓ Ludwig is your music prodigy. Ludwig can read any sheet music that you upload to him, then convert it to a MIDI file, convert that to playable notes on the piano scale, then play each of those notes on the piano with its fingers! You can upload any kind of sheet music and see the music come to life! ⚙️ How we built it ⚙️ For this project, we leveraged OpenCV for computer vision to read the sheet music. The sheet reading goes through a process of image filtering, converting it to binary, classifying the characters, identifying the notes, then exporting them as a MIDI file. We then have a server running for transferring the file over to Ludwig's brain via SSH. Using the Raspberry Pi, we leveraged multiple servo motors with a servo module to simultaneously move multiple fingers for Ludwig. In the Raspberry Pi, we developed functions, key mappers, and note mapping systems that allow Ludwig to play the piano effectively. Challenges we ran into ⚔️ We had a few roadbumps along the way. Some major ones included file transferring over SSH as well as just making fingers strong enough on the piano that could wit"
      }
    ]
  },
  {
    "file_path": "./devposts/lyceum.html",
    "project_id": "lyceum",
    "title": "Lyceum",
    "tagline": "Unlock Limitless Learning with AI 🤖",
    "hackathon": "",
    "built_with": [
      "ai",
      "dall-e",
      "figma",
      "firebase",
      "game-center",
      "gpt",
      "llm",
      "storekit",
      "swift",
      "swiftui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place Prize Created by Brayton Lordianto Long Hoang Pratyay Banerjee I share memes more than I",
      "University of Bridgeport HackathonWinner1st Place Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/456/831/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration 💡 In the wake of the COVID-19 pandemic, online education has boomed exponentially, making EdTech a necessity for millions of students worldwide. To create educational content that keeps up with the times, it is crucial to leverage the latest technologies and tools available. Our team of four is developing a mobile app called Lyceum that combines the power of Swift programming language with OpenAI's ChatGPT API and DALL-E 2. This cutting-edge technology enables us to provide adaptive learning experiences that are personalized to each student's needs. What it does 🤔 Our Lyceum app generates AI-generated adaptive questions on the curriculum using three different formats: Multiple Choice, Fill-in-the-Blank, and Short Answer. But it doesn't stop there. The app also allows students to verse their friends in battles of wit, making learning a fun and engaging experience. Additionally, the app enables students to create their own syllabus using the latest AI technology, giving them the flexibility to study anything they want. As we continue to innovate and improve our app, we are committed to providing the most advanced and effective educational content that adapts to the changing trends in the world. Our app represents a new era in education, where the latest technologies and tools are harnessed to unlock limitless learning. We believe that the future of education is bright, and we are proud to be a part of it. How we built it ⚙️ Swift → Programming Language Xcode → Used as an IDE for project Lyecum OpenAI's ChatGPT API → Bleeding edge LLM AI API DALL-E → For generating custom digital images from textual descriptions. SwiftUI → For rapid-developing user interfaces. Figma → For Creating Hi-Fidelity & Low-Fidelity Prototypes & Markups. Design 🎨 We were heavily inspired by the revised version of Double Diamond design process, which not only includes visual design, but a full-fledged research cycle in which you must discover and define your problem before tackling y"
      }
    ]
  },
  {
    "file_path": "./devposts/magicloops.html",
    "project_id": "magicloops",
    "title": "InstaRizz",
    "tagline": "InstaRizz is a wearable enabled smart application that allows you to recongize people based on the video feed of your Meta Ray Bans, providing scraped information about them and pickup lines to use.",
    "hackathon": "",
    "built_with": [
      "magic-loops",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/098/860/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Example RayBans Example of a profile that is generated Example RayBans Example of a profile that is generated Example RayBans 1 2 3 🌟 Inspiration InstaRizz emerged from the idea of blending tech with social interactions in a way that’s both fun and innovative. We wanted to push the boundaries of wearable tech and AI to create a tool that offers real-time insights on the go, giving users an edge in social situations and a bit of extra charm. 📲 What it does InstaRizz streams live video from Ray-Ban’s smart glasses to Instagram Live. As it streams, it captures snapshots of people’s faces in real time and runs facial recognition using OpenCV. Once a person is identified, the app searches for public information through a custom AI pipeline. InstaRizz then creates a short bio and generates three personalized pickup lines, displaying them to the user instantly, giving a boost in any social setting. 🛠️ How we built it 1.  Streaming Setup: We connected the Ray-Ban’s video input to stream directly to Instagram Live.\n2.  Snapshot Processing: Using OpenCV, we periodically captured frames and conducted facial recognition.\n3.  Reverse Identity Search: We identified individuals with a custom classifier trained on a database of consenting people who wanted the ability to be recognized.\n4.  AI-Driven Personalization: With the person’s name, we ran a custom API on Magic Loops to pull relevant data using perplexity search. Claude then generated a short bio and three unique pickup lines. This project brought together live streaming, facial recognition, machine learning, and natural language processing into a seamless experience. 🚧 Challenges we ran into • Real-Time Processing: It was a challenge to sync the live video feed with real-time facial recognition.\n• Database Training and Perplexity Search: Training an accurate classifier and refining perplexity search for relevant information took a lot of fine-tuning.\n• Privacy Concerns: We carefully considered the ethical implications and e"
      }
    ]
  },
  {
    "file_path": "./devposts/mad-molecool.html",
    "project_id": "mad-molecool",
    "title": "Mad Molecool",
    "tagline": "An all in one space for molecular biologists to save the world a little faster one LLM chat at a time",
    "hackathon": "",
    "built_with": [
      "flask",
      "github",
      "idc",
      "intel",
      "mongodb",
      "propelauth",
      "python",
      "pytorch",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AI/ML Hack Winner Best use of Intel® Developer Cloud Created by Sapana Dhakal Prajwal Sharma Fiorin",
      "Best AI/ML Hack Winner Best use of Intel® Developer Cloud Created by Sapana Dhakal Prajwal Sharma F",
      "HackDavis 2024WinnerBest AI/ML HackWinnerBest use of Intel® Developer Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/867/719/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Fine-tuned LLM on the backend Notebook dashboard with auto-generated summaries Electronic Lab Note book which follows the Design-Build-Test-Learn format Creating a notebook Sidebar to navigate to other notebooks Chemcyclopedia--find all the latest info on chemicals! Fine-tuned LLM shared on huggingface intel leaderboard Login Page Fine-tuned LLM on the backend Notebook dashboard with auto-generated summaries Electronic Lab Note book which follows the Design-Build-Test-Learn format Creating a notebook Sidebar to navigate to other notebooks Chemcyclopedia--find all the latest info on chemicals! Fine-tuned LLM shared on huggingface intel leaderboard Login Page Fine-tuned LLM on the backend 1 2 3 4 5 6 7 8 Inspiration It's not uncommon for molecular scientists to express frustration with outdated software tools used to aid their research. Many scientific software applications were developed years ago and may not have kept pace with advancements in technology or the evolving needs of researchers. As a result, scientists may encounter limitations such as poor user interfaces, lack of compatibility with modern operating systems, or inefficient data processing capabilities. Overall, the work of molecular biologists has far-reaching implications for human health, agriculture, industry, and the environment, making invaluable contributions to the advancement of science and the betterment of society; therefore, it's important their technology is on par! What it does Our application is an all in one space for molecular biologists! Its an LLM-powered electronic lab notebook with easy access to common biochemical information, a finetuned LLM lab partner for thinking through hard problems together, and simple recordkeeping in-line with the Design-Build-Test-Learn workflow common to synthetic biology. Each notebook has autogenerated summaries via Gemini API, the chemical encyclopedia is easy to understand, and the main fine-tuned chat bot is capable of answering your most technical "
      }
    ]
  },
  {
    "file_path": "./devposts/maple-valley-fr7j0g.html",
    "project_id": "maple-valley-fr7j0g",
    "title": "Maple Valley",
    "tagline": "Dive into Canada's tech gold rush with Maple Valley!",
    "hackathon": "",
    "built_with": [
      "lstm",
      "matplotlib",
      "numpy",
      "pandas",
      "plotly",
      "python",
      "random-forest",
      "runql",
      "sklearn",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "CxC 2025WinnerrunQL Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/293/799/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "RunQL Inspiration We noticed that diving into data feels a bit like treasure hunting—especially when the treasure is discovering trends in Canadian tech investments! Inspired by the RunQL Canadian Tech Investment Challenge, we wanted to turn raw, messy data into actionable insights that investors, entrepreneurs, and policymakers could actually use. Plus, who doesn't love a good Canadian success story? What it does Maple Valley is an interactive, data-driven investment analysis platform that explores the vibrant Canadian startup scene. It provides intuitive insights into investment trends, sectoral and regional hotspots, and investor behaviors, while cleverly predicting where the money (and maple syrup!) will flow next How we built it With a mix of creativity, caffeine, and coding skills, we crafted an analytics pipeline using Python and some awesome analytical tools: We built Maple Valley by diving deep into the Canadian tech investment dataset, starting with Python and Pandas to clean and preprocess the data—handling missing values, standardizing formats, and engineering new features. For visual storytelling, we used Plotly to create interactive charts, such as heatmaps showing regional investment hotspots and line graphs tracking funding trends over time, all integrated into a sleek Streamlit dashboard for real-time exploration. On the predictive side, we employed ElasticNet, Gradient Boosting Regressor/Classifier, KMeans, LSTM and Random Forest Regressor/Classifier to do predictive analysis. Challenges we ran into The complex correlations of different features are hard to navigate, analyze and present but we got through it with some time grind! Understanding what to explore and what ML models to use for predictive analysis was difficult, we had to do a lot of testing and finetuning. Accomplishments that we're proud of Illuminated key Canadian tech investment trends clearly and compellingly Pinpointed investor behaviors with Sherlock-level precision Developed pred"
      }
    ]
  },
  {
    "file_path": "./devposts/manat-ai.html",
    "project_id": "manat-ai",
    "title": "Manat.ai",
    "tagline": "Manat.ai turns early-stage ideas into actionable insights, providing a landscape of competition, market size, feasibility, and co-founder matchmaking. It's your Bloomberg terminal for startup ideation",
    "hackathon": "",
    "built_with": [
      "flask",
      "flowise",
      "langchain",
      "nextjs",
      "openai",
      "react",
      "redis",
      "serp",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/633/129/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "s Manat.ai Logo UI 1 s Manat.ai Logo UI 1 s 1 2 3 Inspiration\nOur journey began from a place of personal struggle, often encountering the bottleneck of validating numerous business ideas brewing in our minds. The scenario of scribbling down a groundbreaking startup idea in Apple notes is all too familiar, followed by the tedious chore of toggling between tabs to research its potential. This routine not only hindered our momentum but also clouded our judgment with information overload. It was this friction that birthed the idea of Manat.ai - a tool envisaged to streamline the initial validation of startup ideas using Language Model Machines (LLMs), serving as a preliminary sieve to filter through the feasibility of our potential startup ideas. What We Learned\nThe project was a rich learning ground. We delved into the art of analyzing business ideas, identifying key data points for an initial assessment. The event also brought us together as a team, teaching us the essence of collaboration. We explored various cool technologies including Langchain and OpenAI, and harnessed LLMs to fuel our application, marking our first stride into integrating such advanced AI into a project. How We Built Manat.ai\nUtilizing the Flowise platform, we orchestrated LLM flows comprising nodes and chains from OpenAI and Flowchain. This structure allowed us to incorporate conversational agents and AutoGPT for smarter workflow designs. The backend was engineered using Redis, Flask, and Express to interface with APIs, handle Python analytics, and manage data storage. On the frontend, we employed Next.js and JavaScript, crafting a user-friendly interface to interact with our system. Challenges Faced\nOur first time building an LLM application was a blend of excitement and hurdles. Designing chains and creating intelligent agents capable of web access and task execution posed a steep learning curve. The modular nature of our work - different teams focusing on LLM workflows, Python scripts for ana"
      }
    ]
  },
  {
    "file_path": "./devposts/marihacks-2019-gh87im.html",
    "project_id": "marihacks-2019-gh87im",
    "title": "FastER",
    "tagline": "A traffic alert system that helps reduce ER vehicles' travel time by warning civilian cars on their path.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "java",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/775/637/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Interface of ER vehicle user. Logo A civilian vehicle represented by the green box. Red squares represent ER vehicles, blue squares represent civilian cars, green square represents car that user is controlling. Purple square represents ER vehicle that user is controlling. Interface of civilian user prior to the alert being sent. Interface of civilian user receiving the alert. Interface of ER vehicle user. Logo A civilian vehicle represented by the green box. Red squares represent ER vehicles, blue squares represent civilian cars, green square represents car that user is controlling. Purple square represents ER vehicle that user is controlling. Interface of civilian user prior to the alert being sent. Interface of civilian user receiving the alert. Interface of ER vehicle user. 1 2 3 4 5 6 7 Inspiration In Canada, the national response time goal for paramedics is a generous 9 minutes for the most serious emergencies, but even that goal is only being met 30% of the time. This means that many are not receiving the care they immediately need, and in cases such as heart attacks, this delay may be fatal. FastER was created with the ambition of dramatically reducing that transportation time, which ultimately has the potential of thousands of lives. What it does FastER is an installable mobile application that alerts its users of incoming ER vehicles even before they can hear or see them, allowing them to clear the road in advance, thus reducing the ER vehicles' lost time caused by traffic. The application offers its users an estimated time of arrival of the ER vehicles and gives them an instruction to efficiently clear the path. FastER will also be automatically connected to the emergency vehicles, hence when they are assigned to navigate to a particular location, the most time-effective path will automatically be generated for them. This data is then uploaded to the server and notifies all cars that are on the ER vehicles' path with specific instructions. How we built it "
      }
    ]
  },
  {
    "file_path": "./devposts/maple-valley-16xe75.html",
    "project_id": "maple-valley-16xe75",
    "title": "InsightOps",
    "tagline": "We’re turning clicks into stickiness!",
    "hackathon": "",
    "built_with": [
      "arima",
      "hidden-markov-model",
      "keras",
      "knn",
      "lstm",
      "markov-chain-analysis",
      "pandas",
      "plotly",
      "prophet",
      "python",
      "random-forest",
      "scikitlearn",
      "streamlit",
      "tensorflow",
      "xgboost"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "CxC 2025WinnerFinalist",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/293/788/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We love the idea that data-driven decision-making doesn't have to be dull! When we discovered Federato's RiskOps, a cool SaaS platform that helps insurance underwriters navigate complex business risks, we knew we had to get involved. Our inspiration came from wanting to use the power of data science to make users' experiences not only efficient but enjoyable, creating insights that actually matter. What it does Our awesome data pipeline transforms vast amounts of event-based user interaction data into clear, actionable insights. It reveals patterns that help keep users hooked, recommending personalized next steps in real-time to make sure underwriters stay engaged, productive, and happily exploring high-value features. How we built it We developed a comprehensive analytics pipeline utilizing Python alongside advanced analytical tools and frameworks: Data Processing & Management: NumPy, Pandas, Joblib, PySpark Interactive Visualization: Plotly, Streamlit Advanced Predictive Modeling: XGBoost, Prophet, ARIMA, KMeans, LSTM, Markov Chain Models Performance Optimization: Chunk-based processing, CSV-based intermediate storage Key steps included: Column Cleanup: Removed irrelevant columns, retaining only features critical for analyzing user engagement. Geographic Data Imputation: Implemented KNN imputation to handle extensive missing location data. Filtering & Feature Engineering: Focused on relevant user segments, excluded incomplete data, and introduced vital time-based features such as session durations and latency metrics. Outlier Handling: Utilized z-score methodologies to remove data anomalies, ensuring accuracy and reliability. Predictive Modeling: Trained advanced predictive models (XGBoost, Markov Chains, and LSTM) to analyze sequences of user actions and their impact on retention. These models assessed user moves by identifying critical interactions and transitions that significantly enhance engagement and session duration. Challenges we ran into Hand"
      }
    ]
  },
  {
    "file_path": "./devposts/marihacks.html",
    "project_id": "marihacks",
    "title": "Silent Voice",
    "tagline": "Functional English to American Sign Language Tranlsator.",
    "hackathon": "",
    "built_with": [
      "jupyter-notebook",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Silent Voice Silent Voice is developed after realizing that people with hearing disabilities often get the short end of the stick when it comes to translation and linguistic software developments. To overcome this issue, we developed a speech to American Sign Language (ASL) translator. During our pitch, we will present the challenges we overcame to get here. The GitHub link has our software we created at MariHacks. Built With jupyter-notebook python Try it out GitHub Repo Created by Laurence Liang"
      }
    ]
  },
  {
    "file_path": "./devposts/manus-orchestrating-refinement-based-generative-manim.html",
    "project_id": "manus-orchestrating-refinement-based-generative-manim",
    "title": "Manus: Orchestrating Refinement-Based Generative Manim",
    "tagline": "Manus creates video-based content through on-the-fly interpretation of Manim scraped from its documentation through efficient & iterative LLM techniques, quickly providing users with educative content",
    "hackathon": "",
    "built_with": [
      "claude",
      "manim",
      "next.js",
      "python",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/384/007/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Example snapshot of tutorial Interactive UI and Output of Model Multimodal Generation Architecture Data Scraping & Validation Architecture UI of drag-and-drop Example snapshot of tutorial Example snapshot of tutorial Interactive UI and Output of Model Multimodal Generation Architecture Data Scraping & Validation Architecture UI of drag-and-drop Example snapshot of tutorial Example snapshot of tutorial 1 2 3 4 5 6 Inspiration While the integration of AI tools has grown exponentially over the last few years, it is been limited by fundamentally providing video-based material for students and users to understand. This gap has demonstrated a strong barrier in many institutions, as research often demonstrates that video or tutorial based material is a critical way of interpreting information, especially in math and CS related material. One such roadblock is with understanding advanced topics presented in readings or textbooks – visualizations of these ideas would help alleviate a lot of initial confusion much faster than throwing questions into LLMs or scouring the web for additional content. Oftentimes, existing generative tools can fail by not understanding context or not having enough detail, structure, or organization. What it does Manus intelligently ingests any type of material – be it a screenshot of a paper a student is reading or a picture of a page of a textbook – and translates it into a short video that users can walk through to better understand that specific topic. How we built it Behind the scenes, there is a lot going on with generating this end result. To accomplish this task, we used Manim, a Python library that can create mathematical animations and represent LaTeX, which are generated in parallel and pieced together into one cohesive video. We leveraged Claude with claude-3-7-sonnet and claude-3-5-haiku. But Manim isn't a well-versed library compared to something like React or PyTorch. Given its relatively niche nature, we leveraged auto tool use with "
      }
    ]
  },
  {
    "file_path": "./devposts/markswift.html",
    "project_id": "markswift",
    "title": "MarkSwift",
    "tagline": "An AI teaching assistant to help professors to get help them with grading or document checking fast and easy",
    "hackathon": "",
    "built_with": [
      "marvin",
      "openai",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Engaging Hack Created by I worked on the entire project Satyam Singh",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/632/034/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "exam paper grading Communicating and grading the document via chat for structured output exam paper grading Communicating and grading the document via chat for structured output exam paper grading 1 2 Use Case Title: Grade your student's test papers within minutes Description: I used marvinAI with openAI to build this, marvin plays a role in structuring the output as per our desire whether it is a list, string, boolean or number it helps to get a structured output to use. With that I used OpenAI's gpt 3.5 turbo model to analyze the question papers and check it's factuality, integrity and at the same time match it with the paper that the professor uploads. problem it is solving: normally it takes weeks for teaching assistants or professors to grade a test paper and by the time we get the result and feedback we already have another test or quiz on our head so this helps to give feedback and result within minutes using AI, it will cut the cost of having to pay hefty amount of money too to the TAs and get the work done sooner so that students can work on it and improve on time. Tutorial for Use and Best Practices: I used MarvinAI's documentation i.e. https://www.askmarvin.ai/welcome/what_is_marvin/ and openAI's official documentation i.e. https://platform.openai.com/docs/introduction Impacts on Learning: It's gonna make a huge impact on students by providing them with feedbacks on the same day so that they can work on it and improve for the next one and at the same time save some funds of the college Limitations and Ethical Considerations: there are some limitations i.e. identifying the student's handwriting which is something even humans can't do sometimes hehe, but we have a solution for it that I might work on in future i.e. fine tuning an image processing large language model with bad handwritings Even validating the answers by AI was tough but that's when I thought that after AI checks it by it's own it can compare it with factuality with the other pdf with correct"
      }
    ]
  },
  {
    "file_path": "./devposts/mariokart-ar.html",
    "project_id": "mariokart-ar",
    "title": "34 - MarioKart/AR",
    "tagline": "Experience MarioKart but in AR 😎",
    "hackathon": "",
    "built_with": [
      "8thwall",
      "blender",
      "html",
      "javascript",
      "scaniverse",
      "sketchfab"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[Niantic] Best Use of 8th Wall! Created by Ayush Garg Youjia He",
      "Los Altos Hacks VIIWinner[Niantic] Best Use of 8th Wall!",
      "We want to perfect this project by implementing animations and developing more tracks to make available for the user.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/445/705/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡 Inspiration 💡 We both share a love for video games and thought why could we not combine video games and exercise together, but not like how most people perceive it. Not the next Wii Sports or Kinect but a new version of games that requires both technical skills and physical fitness. From there we decided that we needed to incorporate our game in Augmented Reality and as soon as we set our minds on that we both almost instantly thought of the first game to receive this hybrid treatment be Nintendo's Super Mario Kart. 😮 What it does 😮 Our application allows users to play Super Mario Kart in an Augmented Reality environment. Users can collect stars to experience a 1.5x speed boost or accidentally run into the banana peels to slow yourself down enough to get a ticket. The user also has the option to run after their car as everything is in Augmented Reality allowing users to have a surreal experience. ✍️ How we built it ✍️ We built this application using 8th Wall, JavaScript, HTML, Blender, Scaniverse, and SketchFab. We used 8th Wall as the IDE to edit our code and to host our application as well as convert it to a web AR application. JavaScript and HTML were used to write code for the application. We used Scaniverse to scan the stage of Jupiter Dome and Blender to model a navigation mesh. There was also some models sourced from SketchFab 😾 Challenges we ran into 😾 Our team had only 2 members instead of the regular 4 which made us both pickup more work. Our team had a member with no hackathon experience and minimal coding experience which had its challenges but on the bright side it was a learning experience for the both of us. Originally when we started using 8th Wall but the Wayspot scans wouldn't process on the 8th Wall website and we believe it's because of the network connection. While we were coding we had to do a lot of guess and checks as the models we used weren't made by us and sourced so we had no idea how they would fit our needs. 🏆 Accomplishments that"
      }
    ]
  },
  {
    "file_path": "./devposts/marky-future.html",
    "project_id": "marky-future",
    "title": "Marky.future",
    "tagline": "The advent of generative AI underscores the necessity of content creation for a successful business. We stepped up to help Marky revolutionize this process and save countless hours for clients.",
    "hackathon": "",
    "built_with": [
      "bert-tokenizer",
      "github",
      "google-cloud-vision",
      "pandas",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "s and researching other models, we found that the Google Cloud Vision OCR served us the best"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/643/442/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration AI tools have made rapid content creation more accessible for businesses. We were interested in using AI to solve a real market need and create something useful at the 2023 Datathon. We were also inspired by the ability to work with a real dataset. What it does Our model trains on user approval data to learn what posts will be accepted or declined in the future. Both the image and tabular data were used as inputs to the model. Long form language data such as the caption, title, and text within the image was embedded. Categorical data , such as the tone and template, was one-hot-encoded. Finally, the image itself was analyzed. Combining these three streams of information together proved to be a complex task, but the understanding generated by our model provides insight into effective social media post creation. How we built it Our model was built using three different models that aggregate into one single prediction. Text/language data was embedded using a bert tokenizer, image data was embedded using a convolutional neural network. The text and image data were fed into an attention network, the result of which was combined with categorical data to a final fully-connected post-classification layer. The outline of this process is shown in the attached flowchart. Technologies used included pytorch, pandas, pillow, Google Vision OCR, and a bert tokenizer. Many elements of our system were heavily customized. Challenges we ran into One of the challenges we faced was that choosing the right cloud services, API’s, and code libraries is not as simple as picking the most common or accessible. For example, when extracting text from the images in the dataset, we originally planned to use a common OCR (optical character recognition) library like Tesseract. However, the quality and consistency of our model was hindered by the inconsistency of Tesseract. By taking inspiration from previous Datathon winners and researching other models, we found that the Googl"
      }
    ]
  },
  {
    "file_path": "./devposts/marshox.html",
    "project_id": "marshox",
    "title": "MARSHOX",
    "tagline": "sharing models",
    "hackathon": "",
    "built_with": [
      "arkit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/771/252/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "MIT Consulting work Built With arkit Try it out GitHub Repo Created by Conceptual design and strategy. Technical and creative project management. Pitch directing and producing project scope. Hannah Luxenberg Alberto Tono I work as Researcher for Stanford ( HAI Graduate Fellow and CIFE Researcher)"
      }
    ]
  },
  {
    "file_path": "./devposts/massipl.html",
    "project_id": "massipl",
    "title": "MassIPL",
    "tagline": "Project focused on a website redesign to help MassIPL reposition itself towards a broader audience.",
    "hackathon": "",
    "built_with": [
      "adobe",
      "canva",
      "figma",
      "premiere",
      "weebly"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Marketing Hack sponsored by Hubspot - Sales and Marketing Strategy Consulting Session Created by I",
      "Best Marketing Hack sponsored by Hubspot - Sales and Marketing Strategy Consulting Session Created",
      "DeisHacks 2022WinnerBest Marketing Hack sponsored by Hubspot - Sales and Marketing Strategy Consulting Session",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/826/432/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Through conversation with the leaders at MassIPL, we learned that the organization is looking for more effective ways to increase the outreach of its energy-saving program to attract a more diverse pool of faith-based communities and individuals who care about climate justice. It also strives to be a thought leader in educating the faith-based communities on the necessity and benefits of reducing their carbon footprint. However, its current positioning makes the organization looks like a religious organization that serves a relatively exclusive group of houses of worship, which puts constraints on its ability to increase member diversity and gain access to funding channels. We quickly realized that these challenges present opportunities. We created a brand new website that showcases their unique secular position and an effective tool, the environmental stewardship calculator, that will drastically increase member engagements. What it does and how it can help The new website we created offers a brand-new look that is easy on the eyes and friendly to read. We made the messages we were hoping to convey clearly and powerfully without giving the impression of being a religious organization. We added more content to the website, such as blogs, to improve search engine optimization while educating and entertaining our readers at the same time. We made the interface clean and easy to navigate. Another great tool we developed is the environmental stewardship calculator. It will be an excellent resource for our prospective members to see their current carbon footprint and how much it can be reduced by taking on different projects based on their budget. With just a couple of inputs and clicks, a person can see the estimated carbon emissions. The calculator then goes one step further to recommend things that the house of worship can do today, such as replacing lighting with LED light bulbs. This can help MassIPL turn more leads into prospects and encourage houses of"
      }
    ]
  },
  {
    "file_path": "./devposts/mccompass.html",
    "project_id": "mccompass",
    "title": "McCompass",
    "tagline": "Find the nearest McDonalds with the McCompass",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We love McDonalds. What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for McCompass Built With javascript Submitted to HackTX 2023 Created by adorawu Wu"
      }
    ]
  },
  {
    "file_path": "./devposts/matchavibe.html",
    "project_id": "matchavibe",
    "title": "Matcha Vibe",
    "tagline": "Make the best of every meeting. We use real-time analytics with personalized AI agents to convert valuable human experiences into actionable insights for key decision makers for business and education",
    "hackathon": "",
    "built_with": [
      "docker",
      "elevenlabs",
      "gemini",
      "groq",
      "javascript",
      "luma",
      "lumaai",
      "node.js",
      "websockets",
      "whisper",
      "zoom",
      "zoom-api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/269/219/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Taiki demonstrating the model Taiki demonstrating the model Taiki demonstrating the model 1 2 Matcha Vibe Inspiration Sen no Rikyu, the founder of the Japanese tea ceremony, explained its philosophy with this phrase: 一期一会 (ichi-go ichi-e): one time – one meeting. Life is about seizing every moment. Business pitches, lectures, and personal conversations are all fleeting— so make them count . The Problem: Remote meetings lack presence and depth—listeners get distracted, engagement is low, and tracking audience feedback is difficult. If you cannot perceive your audience's status, your meetings are left sub-par. Inspired by the Japanese tea ceremony philosophy, we set out to enhance real-time engagement in virtual meetings: The Solution: AI-driven avatars and immersive environments that make online meetings not just as good as in-person, but even better. Matcha and meditation apps like Otsuka ekkomi brought premium meditative experiences into the digital realm. We asked ourselves: How can we take this further and enable meaningful, premium interactions to be held online? We focused on the educational and healthcare benefits of AI companionship and metrics, and hence redefined virtual meetings to be more dynamic, engaging, and memorable. Thus, we came up with our real-time meeting analytics tools and responsive interactive experience we call Matcha Vibe. We create meetings that match your vibe. Everyone does Zoom meetings. We turn Zoom meetings into personalized experiences tailored to real-time consumer feedback . Why This Matters 90% of communication is non-verbal cues , which are hard to track online. We capture real-time engagement metrics to analyze each meeting participant’s mood, attention, and interaction levels, allowing businesses and educators to adjust dynamically. Seamless group experiences using Zoom’s API —turning meetings into engaging, responsive environments that feel as immersive as real-world interactions. What It Does Real-Time Speech & Gesture Analy"
      }
    ]
  },
  {
    "file_path": "./devposts/mbtify.html",
    "project_id": "mbtify",
    "title": "MBTIFY",
    "tagline": "Leverages advanced Natural Language Processing and Machine Learning technologies to administer streamlined and adaptive MBTI personality tests through fewer than 10 short-answer questions.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "intersystem",
      "kaggle",
      "openai",
      "openai-api",
      "python",
      "reflex"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Cal Hacks 10.0WinnerBest Use of InterSystems IntegratedML",
      "Stay on Track: Consistently ensure that you are on the right path by periodically reviewing your goals and progress.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/644/089/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Frustrated by the traditional MBTI's barrage of questions? So were we. Introducing MBTIFY: our web application streamlines your MBTI assessment using advanced Natural Language Processing and Machine Learning. Forget the indecision of Likert scales; MBTIFY's conversational AI prompts you with tailored, open-ended questions. Answer naturally—the AI adapts, selecting queries to pinpoint your personality type with ease. Welcome to a smarter, streamlined path to self-discovery. What it does MBTIFY is a web application designed to administer MBTI personality tests in a more efficient and streamlined manner. Unlike traditional MBTI tests that require answering hundreds of questions, MBTIFY aims to achieve accurate results with fewer than 10 short-answer questions. Users can respond to these questions via text or audio input. The application leverages Natural Language Processing (NLP) and Machine Learning (ML) technologies to analyze the answers and determine the user's MBTI type. How we built it Frontend: Reflex for a user-friendly interface. Voice Recognition: Converts spoken answers to text. NLP: Cohere and OpenAI analyze responses for emotional and syntactic insights. ML: Intersystems IntegratedML utilizes 60,000+ Kaggle MBTI questionnaire responses to train a predictive AutoML model. This model interprets Likert scale responses, determining MBTI type with a confidence level. Immediate results are provided if a confidence threshold is met, or the system dynamically selects further clarifying questions. Challenges we ran into Reflex on M1 Macs: Faced compatibility issues with the Reflex UI framework on M1 chipset Macs, requiring optimization for cross-platform functionality. SQLAlchemy with sqlalchemy-iris: Experienced limitations in integrating SQLAlchemy with the sqlalchemy-iris dialect, leading to custom code solutions for effective database operations. IRIS Cloud Connectivity: Encountered difficulties in connecting to the IRIS cloud server, necess"
      }
    ]
  },
  {
    "file_path": "./devposts/mate-messenger.html",
    "project_id": "mate-messenger",
    "title": "Mate Messenger",
    "tagline": "Communication with others is something that every single one of us relies upon on a daily basis to assist us in our various endeavors. With Mate Messenger, you can do exactly that easily and simply.",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "firebase",
      "kotlin"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/034/728/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo for our messaging app Login Screen for our app Sign up screen for our app Database where email and passwords were stored Logo for our messaging app Login Screen for our app Sign up screen for our app Database where email and passwords were stored Logo for our messaging app 1 2 3 4 Inspiration Our main inspiration behind creating Mate Messenger is that we realized that not all opperating systems have access to convenient and secure messengering apps. So, using the Android opperating system as a vessel for our ideas, we worked hard to create an all around secure and sleek messaging app. What it does The application starts off with asking you to either Log in or Sign up. The sign up screen will then lead you to a page which will ask for various pieces of information such as your name, email, and desired password. Logging in then asks you for the email and password that was associated to your account so that you may view your messages. Once in, you are free to view your messages and chat with others. How we built it Our method of choice to create this messaging service was using a programming language called Kotlin, which is mainly tailored to creating apps for Android. We used a software called Android Studio to work with the difference activities (Various screen) along side the Kotlin Code itself. Everything from the login to the messaging ability itself was created using Kotlin. We also used the built in emulator to test our code every now and then. The data inputted into the app is stored in an online data base called Firebase , which holds all the messages corresponding to the various accounts. Challenges we ran into One of the biggest problems we faced was that the coding process was very time consuming, even with a group. There were many different elements to this idea which we had not seen until after we started such as programming, which added on to the estimated time we had in our heads. By that point,  it was too late to switch idea's or simplify it, so "
      }
    ]
  },
  {
    "file_path": "./devposts/mcbroken.html",
    "project_id": "mcbroken",
    "title": "McBroken",
    "tagline": "Wanna know if your local McDonald's ice machine is broken?",
    "hackathon": "",
    "built_with": [
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Winner Created by I worked on the front-end",
      "jacobsHack! 2019WinnerOverall Winner",
      "Winner",
      "I worked on the front-end. It was my first time using React, which was a little intimidating, but I learned a lot."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/884/327/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Just like any other person we occasionally crave a certain ice-cream by a certain vendor but as people worldwide have realized unless the starts are aligned for you, the craving will not be satisfied.\nHence we developed a tool to at least save us the walk. What it does Scrapes McDonald's database for information on restaurants and detailed information on ice machines and displays status for all restaurants in Germany. How we built it Built a scraper using python and a front-end with react Challenges we ran into There are more (outdated and discontinued)libraries for google maps integration into react than broken ice machines in Bremen Accomplishments that we're proud of Finding a working library , successfully displaying the data and literally scraping McDonald's restaurant data for all of Germany. What we learned Hours of coding can save you minutes of having to choose the right library What's next for McBroken A certain royalty member.. Built With python react Submitted to jacobsHack! 2019 Winner Overall Winner Created by I worked on the front-end. It was my second time using React, and we worked intensely with different packages, but I learned a lot! Cihad Colak I worked on the front-end. It was my first time using React, which was a little intimidating, but I learned a lot. Mudassar Zahid"
      }
    ]
  },
  {
    "file_path": "./devposts/mathincovid.html",
    "project_id": "mathincovid",
    "title": "EduGames",
    "tagline": "Welcome to Edugames, an educational website that allows students to develop basic reading and writing skills in the 17th century by using the power of technology in history.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "javascript",
      "jquery",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "This is in fact our very first hackathon. When we heard about it, we were very excited to participate and tried to prepare for it. So, when we went to the hackathon we thought we were ready. At first, everything was a struggle. Before the hackathon started, we all had to learn about different things that we didn’t really have experience on like Python, HTML, CSS, and JavaScript and had to learn all about Github and how to share files to each other. We were complete beginners to web applications. Yet still, we were able to create our first web application. Our project is about being able to teach colonial children in the US. Next we will expand our horizons by moving from the 1600s to modern day children.\nJayadev:\nI built it using Flask. I helped all around with most of the HTML, CSS, and JavaScript in our project. I honestly learned so many things when building this project from major things like how time consuming and how much hard work it can be to create a website to small things like what is AJAX. I spent a lot of time in Stack Overflow finding answers to so many questions. Before I entered, I didn’t know any CSS and JavaScript at all and only knew Python and HTML. Even then I decided to challenge myself and I told my group that I would work on the front end and help out with the Flask as I knew about Flask a bit more than them. Unfortunately, none of my teammates knew anything about the front-end so I started off with learning how to create a Login and Register using Flask and some HTML. Using many different tutorials and such, I decided to download something called Twitter Bootstrap and it helped greatly for the website in terms of CSS. After that I went through many obstacles trying to put in our first Python game, the Pythagorean theorem game. During this stage I learned a lot through Stack Overflow and learned how to transfer information from the Python file to the HTML using AJAX. In the end this hackathon was a great experience for me and learned a lot fr"
      }
    ]
  },
  {
    "file_path": "./devposts/mechangelo.html",
    "project_id": "mechangelo",
    "title": "Mechangelo",
    "tagline": "Light painting robotics system🎨🤖",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "github",
      "python",
      "swift",
      "uarm"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Interactivity Hack -- Track Prize🎨 Our team's Light painting robot, Mechangelo, combines physical a",
      "Interactivity Hack track because it allows users to pre-edit their light paintings using an iOS dra",
      "Interactivity Hack track prize and would appreciate the opportunity to continue exploring the inter",
      "HackPrinceton Spring 2023WinnerMost Creative Use of GitHub",
      "This submission was one of top 5 finalists of the hackathon. Image is taken from the official hackathon discord.",
      "Best Interactivity Hack -- Track Prize🎨",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/435/974/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Team Discord: chief_of_mischief#8050 Aydin#8215 oneoverzero#6553 BrayLord#5744 UPDATE: FINALIST This submission was one of top 5 finalists of the hackathon. Image is taken from the official hackathon discord. Inspiration 💡 The world of art has undergone a significant transformation in recent months with the advent of GANs and other deep learning technologies. Models such as DALL-E, mid-journey, and Stable Diffusion have revolutionized the way we think about creating our interaction with art. They have shown us that machines can be trained to generate images that are not only stunningly beautiful but also unique and unpredictable. These novel models have demonstrated that artificial intelligence can be trained to produce strikingly beautiful and captivating artwork that is both distinct and unpredictable. However, while these models excel at creating digital art, they are yet to leave a mark on traditional forms of art such as painting, sculpture, and pottery. Amidst this exciting and dynamic art scene, our team is captivated by the lesser-known yet incredibly fascinating art form of light painting. We explore the endless possibilities and creative potential of this unique medium, where light becomes the brush and the world becomes the canvas. Light painting is a way of creating pictures using a camera and a light source, such as a flashlight, glow stick, or LED light. It's like drawing in the air with light! To create a light painting, you set your camera to a long exposure, which means that the camera's shutter stays open for a few seconds or even minutes. During this time, you can use your light source to \"draw\" or \"paint\" in the air, and the camera will capture the light trails you create. The best part about light painting is that you can be really creative and make all kinds of cool pictures. You can write your name, draw shapes, or even make it look like you're holding a ball of light! The possibilities are endless. Having attempted creating "
      }
    ]
  },
  {
    "file_path": "./devposts/meal-master.html",
    "project_id": "meal-master",
    "title": "Meal Master",
    "tagline": "An app that improves your diet based on your needs and current eating habits and allows you lookup recipes suggested.",
    "hackathon": "",
    "built_with": [
      "edamam-nutrition",
      "openai",
      "prisma",
      "python",
      "railway",
      "trpc",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Cross Club Hackathon 2023WinnerCCH Gold",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/433/422/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Signup Logo Recipe Reccomendations Signup Logo Recipe Reccomendations Signup 1 2 3 4 5 Inspiration Our main source of inspiration came from our nutrition lesson in Biology Class. As me and my friend were talking about nutrition, and how it’s often overlooked. Then we found out about this hackathon. Knowing that we wanted to help people with nutrition, and now had the chance to do so, we began! What it does Our app, called Meal-Master, gives users what they can eat, based on their diets. First, you can enter some information, such as weight, height, and more, to get your Daily Recommended Intake (DRI). Next the app compares this with their actual intake, and does this by inputting their meals throughout the day, and then calculating it. Then by comparing the two, the app figures out the user's needs. By telling the prompt to ChatGPT’s AI, it can give ingredients and recipes that the user can eat. Then they can look up those recipes on the app, and look at all the information, and a link to the website. How we Built it Our application consists of Expo and React Native for the frontend mobile application. This application connects to a tRPC server that runs on a Vercel Lambda instance built using Next.js. For receiving the nutrition and recommendation data, we made use of the Edaman and OpenAI API respectively. While building our backend we prototyped our API routes in Python and then translated it to TypeScript for our tRPC server. Challenges we had Installing the ChatGPT API was a hassle, since the documentation for it was a bit confusing but we figured it out.\nTrying to set up a development environment to work with our app. Accomplishments we’re proud of Using the ChatGPT API, as we could basically use ChatGPT in our own code\nWorking with an enterprise-grade modern mobile application development workflow What we learned Learned more about API Installation, and how to use the documentation properly.\nLearned how to work with OpenAI systems.\nWorking with tRPC in the ba"
      }
    ]
  },
  {
    "file_path": "./devposts/mechasort.html",
    "project_id": "mechasort",
    "title": "MechaSort",
    "tagline": "Waste sorting robotics system at recycling facilities♻️🦾",
    "hackathon": "",
    "built_with": [
      "arduino",
      "computer-vision",
      "flask",
      "python",
      "raspberry-pi",
      "react",
      "xarm"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hardware Hack👩🏻‍🔧 Our project reflects a tight integration of both hardware and software",
      "Beginner Hack👶🏻 Our team is composed of 3 first-time undergraduate hackers and 1 non-first time hac",
      "Hack for a Real World Use Case by Pear🍐 Our project addresses the critical problem of the hazards f",
      "Payments Hack by Checkbook💵 On a branch of this project (checkbook-test), we have developed a basic",
      "Hack Using Frontier Tech by Pear🥇 In this project we were able to combine technologies and tools in",
      "because his first hackathon did not have such a prize)",
      "Best Web Frontend by Vercel 🎨",
      "Sustainability Grand Prize🍀",
      "Best Hardware Hack👩🏻‍🔧",
      "New Frontiers track🗡️",
      "Cotopaxi's Choice Award🎲",
      "Best Use of Dolby.io📽️",
      "Best Beginner Hack👶🏻",
      "Best Hack for a Real World Use Case by Pear🍐",
      "Best Payments Hack by Checkbook💵",
      "Best Use of Data Hack by HRT📅",
      "Best Hack Using Frontier Tech by Pear🥇"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/391/721/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration 💡 Forging connections between software and robotics has been an ever-increasing area of promise, especially with the proliferation of machine learning and small electronics. We’ve explored this field by creating a multilayered system, particularly inspired by use cases in sustainability. Recycling workers, particularly sorters , play a paramount role in the recycling industry, and are unsung heroes of the sustainability movement. Every day they process the mountains of trash we produce, inspecting waste to ensure that recyclable materials may be used to create new commodities. Their efforts are essential in keeping our environment clean and healthy. Every can, bottle, and piece of paper that is sorted represents an incremental step in the fight against waste and environmental degradation. Sorting and processing facilities, including material recovery facilities (MRFs), pose numerous hazards to workers, such as: Exposure to harmful materials and substances , such as used sharp objects, industrial and household chemicals, dead animals, and biohazards. The risk of exposure is heightened by fast-moving conveyor belts and the need to quickly identify hazardous materials. Moving machinery , such as compactors, conveyor belts, and sorting machinery, which require maintenance and servicing. If lockout-tagout procedures are not followed, workers may face injury. Respiratory hazards from dust and airborne contaminants, including micro-particles of plastics, glass, biohazards, toxic substances such as asbestos or silica, and other respiratory irritants. Awkward positions and repetitive motion injuries, from the physical demands of sorting and processing materials. Although sorting technologies have developed significantly, they are not able to match the fine motor skills and judgment of human workers. Thus, innovating towards streamlining the sorting process stands as an impactful contribution to both human health and the sustainability movement at la"
      }
    ]
  },
  {
    "file_path": "./devposts/medi-finder.html",
    "project_id": "medi-finder",
    "title": "Medi Finder",
    "tagline": "Discovering Hospitals, Healing Communities",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "git",
      "github",
      "google-cloud",
      "google-maps",
      "html",
      "javascript",
      "python",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/390/503/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Contacting hospital via automated call Home Page List of Hospitals in a 10km radius Contacting hospital via automated call Home Page List of Hospitals in a 10km radius Contacting hospital via automated call 1 2 3 4 Inspiration The inspiration behind Medi Finder came from the need for an easy and efficient way to locate hospitals in an emergency. The current methods of finding nearby hospitals can be tedious and time-consuming, especially in stressful situations. We wanted to create a solution that would make it simple and straightforward for anyone to quickly locate the nearest hospital and get the help they need. What it does Medi Finder is a web application that allows users to find the nearest hospitals within a 10km radius. The user can either allow the app to access their current location or manually enter their address. Once the user's location is determined, the app searches for all hospitals within the radius and displays the results in a list format. The user can then view the address, contact information, and distance of each hospital. Most importantly, the app has a feature to send an automated call to the hospital with the user's current address, asking for an emergency ambulance. How we built it Medi Finder was built using various web technologies such as HTML, CSS, and JavaScript. We also used the Flask web framework for the backend, which allowed us to connect to a database of hospitals and perform search queries. We integrated the Google Maps API to determine the user's location and calculate distances between the hospitals and the user. We used Twilio to send the automated call to the hospital. Challenges we ran into One of the biggest challenges we faced was determining the radius for our hospital search. We wanted to find a balance between a radius that was too small, limiting the number of results, and a radius that was too large, resulting in too many irrelevant results. We also had to make sure that our database of hospitals was up-to-date and "
      }
    ]
  },
  {
    "file_path": "./devposts/medicai-6jdg8a.html",
    "project_id": "medicai-6jdg8a",
    "title": "MedicAI",
    "tagline": "Solving for all of your medical needs and more using artificial intelligence to get valuable insight",
    "hackathon": "",
    "built_with": [
      "berriai",
      "gpt-4",
      "langchain.js",
      "nextjs",
      "react",
      "tailwind",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Corpus HacksWinner2nd Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/480/406/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Main Dashboard Home Page AI information about medicine! Main Dashboard Home Page AI information about medicine! Main Dashboard 1 2 3 Inspiration We were inspired after reading articles and learning that millions of people around the world don't understand the side effects and risks of certain medicines. With this newfound discovery, we decided to develop a code to help inform the people about medicines and drugs in order to educate the people and prevent further sickness and harm. What it does Our project uses AI to provide reliable information about medicine like its side effects, uses, nutritional value, and how much it costs. We also have similar features for vaccines where people can learn facts about vaccines and whether they need it or not. Another feature we have is that the user can see how to treat their illness that they have. Some smaller features include a BMI calculator that can help calculate the user's BMI so that they can track if they are healthy or unhealthy. How we built it We used ReactJS, NextJS Framework, and Tailwind CSS for our frontend side of the code, and for the backend we used GPT-4, BerriAI, and LangChain.js Challenges we ran into Formatting Prompting Organization Slow WiFi :( Accomplishments that we're proud of Used a new AI model What we learned Learned about the uses of BerriAI Learned more about medicines Built With berriai gpt-4 langchain.js nextjs react tailwind vercel Try it out medic-2vsy73ho0-yasheck.vercel.app GitHub Repo Submitted to Corpus Hacks Winner 2nd Place Created by I worked on the backend and frontend. Combined all the tools together and found the PDF to base the data on Yash ㅤ I helped come up with the idea for the code, wrote some parts in the backend and frontend, formatted the slides for presentation, and helped with prompting. Prashant Vaid"
      }
    ]
  },
  {
    "file_path": "./devposts/medicapp-yd2rwc.html",
    "project_id": "medicapp-yd2rwc",
    "title": "Medicapp",
    "tagline": "Health and safety is one picture away. Upload a profile for easy to access medical information.",
    "hackathon": "",
    "built_with": [
      "faceapi",
      "flask",
      "imgur",
      "javascript",
      "node.js",
      "npm",
      "python",
      "tailwind",
      "virtual-environment"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/663/849/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Image analysis Logo Home Page Profile Editor Image analysis Logo Home Page Profile Editor Image analysis 1 2 3 4 5 Inspiration: What makes so many conditions and viruses dangerous, such as Covid and allergies, is the fact that they are not always visually apparent. Oftentimes allergies and other medical conditions are triggered from outside parties that didn’t know you had the medical problem, and this became our inspiration for Medicapp. We wanted it to be easier to access someone’s medical issues so that accidental injuries can be avoided as efficiently as possible, including at locations such as parks, landmarks, and monuments. Medicapp helps with this problem by allowing individuals to upload a selfie which is then connected to their medical conditions so that any other individual can take a picture of them and access their set of medical problems. Features: We used databases to store user data given by the user with all their data being connected to their selfie. Then using apis such as Faceapi for A.I and imgur api for image uploading we can retrieve the data from our databases through a single picture. The Faceapi A.I facilitates the face recognition software that allows us to match a picture of someone with their selfie uploaded in our databases, and we connected all this to our front-end website with tailwind and javascript. Challenges: Not being very experienced with databases and apis this ended up being an extraordinary learning experience. With the help of mentors and the internet we managed to get all of it up and working with very little time to spare. We were also very inexperienced with tailwind so styling became a time consuming task but with hard work and effort we put everything together fairly nicely. How we built it: This project was built using tailwind css and Javascript. Face recognition uses FaceApi to create and match descriptors of the processed faces. Then using a database, we compared the faces to that of previous user profiles. Once we"
      }
    ]
  },
  {
    "file_path": "./devposts/medic-ai-x7lco5.html",
    "project_id": "medic-ai-x7lco5",
    "title": "Medic.ai",
    "tagline": "the cutting-edge healthcare platform revolutionizing the way doctors access and interpret medical data.",
    "hackathon": "",
    "built_with": [
      "ai",
      "auth",
      "axios",
      "cohere",
      "css",
      "flask",
      "html",
      "javascript",
      "langchain",
      "next.js",
      "python",
      "react",
      "serpapi",
      "typscript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/655/209/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Medic.ai Medic.ai Medic.ai 1 2 About MedicAI MedicAI is a groundbreaking web tool designed to revolutionize medical research and practice. By leveraging advanced natural language processing and machine learning, MedicAI analyzes a patient's comprehensive medical history and demographics to deliver a curated list of peer-reviewed journal articles tailored to their specific profile. This innovative approach aims to reduce biases in medicine, providing healthcare professionals with personalized, evidence-based information to make more informed decisions and ultimately improve patient outcomes. Inspiration The inspiration for MedicAI arose from a recognition of the pressing need to address biases in medical research and practice. It became evident that there was a gap in providing doctors with access to personalized, evidence-based information tailored to the unique profiles of their patients. This realization sparked the vision for MedicAI - a tool that would leverage cutting-edge technology to bridge this gap and revolutionize the way medical professionals access information. Learnings Throughout the development of MedicAI, our team gained invaluable insights into the complexities of medical data processing and the nuances of contextual search. We delved deep into natural language processing techniques, learning how to parse and interpret intricate medical histories and demographics to extract meaningful insights. Moreover, we honed our understanding of the importance of peer-reviewed research in driving evidence-based healthcare decisions. Building the Project The development of MedicAI was a multidisciplinary effort, bringing together expertise in natural language processing, machine learning, and medical research. We utilized state-of-the-art models and techniques to process and analyze patient data, ensuring the highest level of accuracy and relevance in the generated article recommendations. Additionally, we integrated with reputable databases of peer-reviewed jo"
      }
    ]
  },
  {
    "file_path": "./devposts/mediscript-f85lej.html",
    "project_id": "mediscript-f85lej",
    "title": "MediScript",
    "tagline": "Let us document, let doctors care for health. Doctors spend more time caring for data transcription and organization than for patients' healthcare. Join our journey to see doctors, be doctors.",
    "hackathon": "",
    "built_with": [
      "gguf",
      "llama",
      "node.js",
      "python",
      "pytorch",
      "react-native",
      "tamagui",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/646/674/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "wireframing logo list of patients patient profile voice to text in progress voice to text completed wireframing logo list of patients patient profile voice to text in progress voice to text completed wireframing 1 2 3 4 5 6 Inspiration Unleashing Untapped Technological Potential:\nWith the rapid development of technology, it’s puzzling why nearly all documentation processes are still manual or highly decentralized. Processes such as transcribing are often outsourced to international talent, translation is often on a doctor-to-doctor basis, and summarization of patient records is often manual as well. While new AI solutions are able to aid processes like summarization, the healthcare industry remains in a precocious stage, juggling issues like security and privacy as well as the highly crucial nature of yielding data as accurately as possible. Filling the Gap:\nWe noticed a significant gap in the current solutions available: they were either highly labor-dependent or current technological documentation websites/applications are too generalized and/or work independently. Therefore, current solutions fall short, resulting in issues like inaccuracy and inefficiency. Thus, the need for a comprehensive and targeted solution that solves the pain points of documentation woes of doctors is one we are seeking to address. Informed by User Research:\nOur journey was propelled by insights from extensive user research. Findings illuminated the frustrations and challenges faced by healthcare professionals when dealing with existing solutions, be it using documentation applications independently, or manual documentation modalities. We saw firsthand the pressing need for a more streamlined and user-friendly healthcare app. What it does Mediscript is a consolidated patient-centered platform for the documentation and organization of patient data. With voice-to-text transcription and translation from almost every language, we are able to reliably replace this labor-reliant aspect of patie"
      }
    ]
  },
  {
    "file_path": "./devposts/medkit.html",
    "project_id": "medkit",
    "title": "MedKit",
    "tagline": "Let's stay on track together!",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "javascript",
      "prisma",
      "react-native",
      "realtimedatabase",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Let's stay on track together!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/660/445/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We all get prescribed medicine and end up forgetting to take it. By creating a fun, bright, and encouraging mobile app, we hope to help people keep up with their health and well being. Even beyond the individual, caregivers can also benefit from MedKit when managing medication routines of loved ones. By promoting medication adherence, reducing health risks, and providing customization options, MedKit was created to help users manage their medication regimens effectively, offering peace of mind and ensuring that patients follow their prescribed treatment plans. What does MedKit do? MedKit is a peaceful,  yet whimsically bright app designed to monitor or create medication schedules, motivate users to stick to their prescribed treatments, and manage easily forgotten medical information. It promotes user responsibility for scheduling and logging medications and allows for easy access to prescription history. What's next? MedKit has many potential features and we hope to continue developing it in a fun and creative way. Some new ideas include such as a progress calendar for tracking medication adherence and a more interactive mascot for a more interesting user experience. Challenges we ran into Connection issues in regards to Expo on UTD guest wifi, as well as using Expo itself and overcoming the web to mobile development learning curve. How we built it This app was built using React Native, Expo, TailwindCSS, Firebase, Javascript Accomplishments that we're proud of This was our first time developing a mobile app!! We're proud of our fun user interface design and learning React Native and Expo in 24 hours. Built With expo.io javascript prisma react-native realtimedatabase tailwindcss Submitted to HackUTD X Created by Li Shen Katherine Nguyen"
      }
    ]
  },
  {
    "file_path": "./devposts/medifae.html",
    "project_id": "medifae",
    "title": "Medifae",
    "tagline": "MediFae allows anyone, regardless of medical background, to provide their medical information at the simple touch of a screen!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "peer2peer",
      "react",
      "webrtc"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/374/143/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "events page for clients to view alerts home page with various tasks onboarding page for clients to enter information qr code page, allows for seamless transfer of data events page for clients to view alerts home page with various tasks onboarding page for clients to enter information qr code page, allows for seamless transfer of data events page for clients to view alerts 1 2 3 4 5 Inspiration Picture this — today is a busy day. Your general care physician has referred you to a different hospital. Your dentist wants to schedule an appointment with you for your wisdom tooth surgery… with a new surgeon. You need to prepare the stacks on stacks of materials that each new doctor needs to give their diagnosis and perform treatment. Once you get to these new medical providers, it turns out that the paperwork you have is so dense and complicated, they need to spend a couple of days sorting through it all just to be able to incorporate it into their systems. One of our team members was in this exact scenario just before this hackathon.\nIf only we could have an app that integrates with most major healthcare data systems, helps manage appointments and medications, and allows for easy and secure communication with doctors. We aim to help make health records accessible and manageable to the client and all of their healthcare providers in order to provide unity within the healthcare system. Our name is inspired by the trusty fairy Navi from The Legend of Zelda, who acts as protagonist Link’s navigator and companion. Just like Navi, we hope to not only guide you on your healthcare journey, but also put providers in sync so that they can place their sole focus on caring for the clients who deserve it. Many individual hospital systems have this, but there is no one solution for all healthcare needs. What it does MediFae is a comprehensive peer-to-peer health platform adapted for the needs of all users. With a simple scan of a QR code, healthcare providers can seamlessly access all "
      }
    ]
  },
  {
    "file_path": "./devposts/meinmalzahlung.html",
    "project_id": "meinmalzahlung",
    "title": "Meinmalzahlung",
    "tagline": "Meinmalzahlung is a demo version of a system that is supposed to work similar to and improve upon einmalzahlung200.de, where students can one time request a fixed amount of money from the government.",
    "hackathon": "",
    "built_with": [
      "eid",
      "next.js",
      "node.js",
      "react",
      "sqlite",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackHPI 2023WinnerChallenge 2",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/450/920/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing page Goal We have strived to fix some glaring issues we have personally encountered with the previous implementation. Our main goals were scalability, privacy, security and also user-friendliness. So in a nutshell, we wanted a system that uses less data from the student and especially less data transfer between different parties to ensure all of our goals. System In the system we developed, the first thing that happens, is that all official universities sent some data about their students as hashed data to us. This ensures that we can check whether a specific student is enrolled in a university but gives us and potential hackers no easy access to this information. With the start of the compain, students can use eID to login on our site. We handle the communication between the government databases and the student and then hash the student's data to compare with the data we received from the universities. Thus we can easily check whether the user is really an enrolled student and is also a German citizen and can ask them for their IBAN. After that we can initiate the payment to the student. Improvements Due to innovative technology students have to invest less work since the data transfer between the student and their university, that was previously realized by an additional code, is now handled by us. This makes the entire process much easier and more enjoyable. Technologies We implemented a website that handles the communication between the student, the government and us by using the eID API. The Website itself is built in React.js with TypeScript and handles all the information the student has to give us to receive the payment. For secure encryption we have used multiple frameworks such as next.js, prisma and SQLite. Built With eid next.js node.js react sqlite typescript Try it out GitHub Repo Submitted to HackHPI 2023 Winner Challenge 2 Created by Niels Glodny Justus Beck Aleksandrs Morgensterns Max Thorn Tobias R Niharika Gujela"
      }
    ]
  },
  {
    "file_path": "./devposts/medmap.html",
    "project_id": "medmap",
    "title": "MedMap",
    "tagline": "By using real-time data, we optimize bed availability, reduce ER overcrowding, and speed up patient admissions ultimately saving lives when it matters most.",
    "hackathon": "",
    "built_with": [
      "convex",
      "next.js",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "BeachHacks 8.0WinnerMonitor",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/333/946/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Hospital List Hospital Detail Manage Hospital Landing Page Hospital List Hospital Detail Manage Hospital 1 2 3 4 5 6 Inspiration The inspiration for this project came from witnessing the struggle many hospitals face with overcrowded emergency rooms and the constant shortage of available beds for critical patients. During peak times, delays in getting patients into a bed can have life-threatening consequences. This inspired me to develop a solution that uses cutting-edge technology to solve this issue. What it does The Real Time Hospital Bed Tracking System helps hospitals manage bed availability in real-time. By using React , and Convex the system monitors bed occupancy, predicts demand, and alerts hospital staff when beds become available. This allows hospitals to: Optimize bed usage by predicting when beds will be free. Reduce wait times for emergency patients. Prevent overcrowding in ERs and other departments. Improve patient care by ensuring timely admissions. How we built it Real-Time Data Collection: I developed a system to monitor bed occupancy by tracking patient admissions and discharges. Integration: The system integrates with the hospital’s existing management software to streamline bed allocation and reduce errors from manual tracking. User Interface: I created a dashboard that allows hospital staff to view available beds, receive alerts, and manage bed assignments efficiently. Challenges we ran into Real-Time Bed Tracking: One of the biggest challenges was tracking the availability of beds in real-time. Hospitals are fast-paced environments, and the status of beds can change quickly. Ensuring that the system accurately reflected bed occupancy at all times was difficult, especially when patients were transferred or discharged unexpectedly. Sending Admission Requests: Another challenge was integrating the system with the hospital's existing admission process. Automating the process of sending bed availability updates and admission requests to"
      }
    ]
  },
  {
    "file_path": "./devposts/meetum.html",
    "project_id": "meetum",
    "title": "MeeTUM",
    "tagline": "We believe that what current social meetup apps are lacking is spontaneity. Our app solves this by offering a platform to meet up with others instantly or within the next 12 hours.",
    "hackathon": "",
    "built_with": [
      "amazon-ec2",
      "dart",
      "flutter",
      "mongodb",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/152/794/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Find activities and join them GIF Homescreen GIF Start a new activity GIF Find activities and join them GIF Homescreen GIF Start a new activity GIF Find activities and join them 1 2 3 Inspiration We started this challenge with a very clear problem statement (Make Munich a City where no one feels alone). Since loneliness is such a common and well-understood problem, there have been plenty of apps before us trying to solve this issue. We wanted to understand, where these apps fall short and we believe we have nailed it down to one core thing: The biggest friction in existing meetup apps is the time that passes between the user opening the app, when they crave social connection and the time when it actually comes to meeting the people. There are so many points at which any one of the involved users could get cold feet or just not be bothered anymore. What it does We therefore designed the entire app around getting people together as quickly as possible. We make this happen through the following:\n    - Limit any meetups to the next 24 hrs → focus on spontaneity\n    - Simple UX that focusses on the most important features\n    - Smart recommendation algorithm which means that users don’t have to endlessly swipe through options\nWe built a System that revolves around what we call “Activities”. For example if I wanted to play a game of Billiards, I could create an activity, and then others can join me. You can think of them like a lobby in a multiplayer videogame. How we built it We built the UI in Flutter and hosted it as a Web-App, since this would allow us to do a live demo that people can interact with. Our backend consists of a REST-API in Python that manages a MongoDB and also contains our algorithm for matching activities. The matching algorithm we built for the new suggestions is based on the similarity between the past activities that the user joined and the overlap between the requested activity and existing open ones. When the user adds their activity, it matc"
      }
    ]
  },
  {
    "file_path": "./devposts/mednow-3w8mxt.html",
    "project_id": "mednow-3w8mxt",
    "title": "MedNow",
    "tagline": "Find first aid nearby.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "figma",
      "github",
      "javascript",
      "react-native",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Find first aid nearby."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/224/578/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "UI/UX Landing Homepage Update Medical Information First Aid Resources Who Can Be a Medic? Map & QR Code UI/UX Landing Homepage Update Medical Information First Aid Resources Who Can Be a Medic? Map & QR Code 1 2 3 4 5 6 7 8 9 10 Inspiration We noticed that UW has been providing menstrual products in bathrooms across campus. However, off-campus, emergencies still arise. Along with the healthcare system being overwhelmed and ambulance times being delayed, MedNow weaponizes location data to help deal with emergencies. Whether you need a menstrual product, bandaid, EpiPen, or even CPR, someone nearby may just be able to buy you a little time before the ambulance arrives or the issue resolves itself. What it does MedNow is a mobile app that takes voluntary “medics” and sends them notifications when someone needs help. When a patient clicks “Help,” their information such as medical history, emergency, and location data are sent to either basic medics or intermediate medics, basic being those who could deal with something like a bandaid and intermediate being those who are first aid trained and could deal with larger issues. If and when the paramedics arrive, they will have special authentication to scan a QR code to receive the patient’s health card info and more detailed personal data than what was provided to the medic. MedNow also includes an educational page of basic first aid demos and a monthly summary logging how many people you’ve helped. If you’re uncomfortable with sharing your personal information, you can still click “Help” as a guest and your location will be sent to nearby medics. If the situation allows, you can fill out what the emergency is as the medics find their way to you and nearby medics will have the opportunity to accept or decline your emergency. If accepted, they will be directed to Google Maps to find the patient; if declined, other medics will still have the opportunity to accept similar to Uber finding another nearby driver although they may "
      }
    ]
  },
  {
    "file_path": "./devposts/mednotify.html",
    "project_id": "mednotify",
    "title": "MedNotify",
    "tagline": "MedNotify is a website that uses AI to recognize patients, their medications, and their illnesses. This helps medical staff identify and prevent medication errors during a patient's stay.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "python",
      "wolfram-technologies"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/656/401/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The realization that people truly needed help in the hospital system was an inspiration. Which is a fact I especially know from familial experience. However, during the opening presentation the idea to make a patient safety platform came into my head. After researching for quite a bit I figured out that one of the number one errors which staff make is under dosing or over dosing patients on medication. Which as you can image ultimately can lead patients to death. So in order to make patient's life more safe MedNotify logs patient files in order to aid staff in correctly dosing patients. What it does MedNotify is a website with an AI named MedBot (created by us). MedBot captures patients faces and then displays the corresponding patient file. This allows for healthcare workers to view patient weight, height, age, condition, and medication immediately. Taking the stress off health professionals when it comes to treating the patient. How we built it We built MedNotify by using html and css for the front end of the website. And for the backend we used python and integrated parts of the html. Additionally, we used WolfRam Alpha in order to answer any questions health professionals may have. Challenges we ran into Some challenges we ran into were that one of our team members has never coded before so when making the frontend using flex boxes was very complicating at first. Secondly, at about 9am MedBot started to not register the website so it could not identify 'patients'. Accomplishments that we're proud of We are proud of making this as a whole! What we learned We learned a lot. Face recognition, how to use wolfram, frontend, and coding. What's next for MedNotify Next we would like to update the UI of the website in order to be more elevated and include all of the aspects displayed. Also we would like to make it into an app in order to make this a portable tool for hospitals to use. Built With css html python wolfram-technologies Try it out GitHub Repo Subm"
      }
    ]
  },
  {
    "file_path": "./devposts/mentalog.html",
    "project_id": "mentalog",
    "title": "Mentalog",
    "tagline": "A virtual speech assistant to help you log and let out all of your feelings",
    "hackathon": "",
    "built_with": [
      "api",
      "css3",
      "firebase",
      "google-cloud",
      "html5",
      "javascript",
      "speech-to-text",
      "text-to-speech"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of Google Cloud Color Hacks Winner CanaKit Raspberry Pi 4 4GB Starter PRO Kit - 4GB RAM Winner",
      "2nd Place Cohackathon Hack And Wellness Winner Best use of Google Cloud Color Hacks Winner CanaKit",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/405/687/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "2 Min Video link: https://youtu.be/hyyxaDjXVww Inspiration Throughout the process of brainstorming our ideas, we focused on coming up with an effective solution for mental health problems. Even though our team members are from various countries, we agreed on the fact that people around the world are commonly suffering from psychological issues. We realized that the majority of the people are struggling with seeking help or finding someone to talk to and share their thoughts with. With that, we thought that a friendly approach to the users is indispensable for Mentalog to deliver direct support. By “Mentalog: Mental Health + Logbook,” we aim to form a positive environment for the users as a digital therapist. What it does Mentalog’s primary function is the speechbot function, which allows the users to log their day/mood by talking directly to it. We intended the feature of the chatbot to look friendly to allow users to approach comfortably. The chatbot uses the user’s speech and converts it to a text API. Next, we have an additional diary function that allows the users to record their moods or daily life. How we built it Prior to the main process, we started with brainstorming and researching the current problems occurring within people suffering from psychological problems to determine whether the functions of Mentalog can effectively help the intended users. We mainly used Repl.it to collaborate virtually for the leading web features. Also, we used Firebase to facilitate the process of signing up and collecting diary entries into the database. Next we used cloud text to speech API as well as speech to text API for the speech bot. Lastly we created the functions using javascript. Challenges we ran into One of the biggest challenges that affected our team was the difference in time zones and collaborating through a virtual environment. Since we had to overcome the time zone difference for both the collaboration and the workshops, which was about 15~17 hours max among"
      }
    ]
  },
  {
    "file_path": "./devposts/melodoodle.html",
    "project_id": "melodoodle",
    "title": "Jamboard ♫✏️",
    "tagline": "Low-cost, paper-based instrument board —making music more economically inclusive for all.",
    "hackathon": "",
    "built_with": [
      "math",
      "mediapipe",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/975/254/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration If you've ever seen a YouTube video of someone composing music from scratch, playing piano and guitar in their homes, or out busking on the streets, you may have thought: \"I want to play an instrument like that too.\" For those of us fortunate enough to pursue our musical fantasies, this problem is solved as simply as buying a new instrument. However, there are others who do not have the capacity to own an instrument on a whim. We wanted to change that. What it does JamBoard is a tool similar to a DJ's soundboard that allows you to create music by drawing shapes that represent drums, piano, saxophone, and more on a piece of paper. When you connect your device (i.e., budget Android phone), you can tap on the various shapes which creates pitched musical notes. The sounds are consistent and so you can effectively create musical pieces with it (see our attached video!) Instruments supported: piano, saxophone, drums, and kazoo (and more can be automatically generating by providing just one sound file) How we built it We built JamBoard using what is essentially pure math. On startup 'calibration' occurs, we run the webcam through a series of processes to turn it into a black and white shape grid. We then essentially count the number of contours and how round the object is to determine it's shape, area, color and exact location - no AI tomfoolery. Two webcams are set up, one with a bird's eye view, and one with a table's eye view. They create a constant feed of video frames, which we use baselines from the calibration step to determine when the user is touching a certain shape. When a shape is touched, we use the corresponding instrument's singular sound file to generate a pitched note based on the colour and size of the shape. When you drag your finger from one shape to another, they interpolate (blend) together and create a smooth sliding sound. TECHNICAL DIFFICULTY Since working with similar image processing pipelines are a relatively common route f"
      }
    ]
  },
  {
    "file_path": "./devposts/mentalbase.html",
    "project_id": "mentalbase",
    "title": "MentalBase",
    "tagline": "A NLP powered database that simplifies the process of finding mental health resources in a private way.",
    "hackathon": "",
    "built_with": [
      "co:here",
      "css",
      "flask",
      "git",
      "github",
      "html",
      "javascript",
      "natural-language-processing",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "[ https://github.com/HitanshBhatt/UofTHacksX ] Inspiration Any academic setting naturally comes with stress and anxiety. We have personally witnessed some of our close friends struggle to speak out for help and guidance when evidently struggling with mental health issues, only because they weren't sure if there are any resources available, and if there are, how to access them. Some are more comfortable than others when speaking up for themselves and seeking help. Provided below are consequences of inadequate access to mental health services: Access : About 28,000 youths in Ontario were on waiting lists for mental health treatment in 2020; doubled since 2017 [1] Stigma : In a 2019 survey, 75% of respondents expressed reluctance to disclose a mental illness to coworkers [2] Morbidity : The disease burden of mental illness in Ontario is 1.5 times higher than all cancers put together and more than 7 times that of all infectious diseases [3] Mortality : Mental illness can slash 10 to 20 years from an individual's life expectancy [4] Economic Loss : $50 billion per year is the estimated annual economic cost of mental illness in Canada, related to loss of productivity and reductions in quality of life. This accounts to around ~2.5% of Canada's GDP [5] We see this as a major problem and decided that we want to create a platform for such people where they can get direct access to existing mental help resources. What it does MentalBase is a platform where you can get all your mental health resources at one place. You can anonymously talk to an Artificial Intelligence bot, or if you're comfortable, an agent who will not know who you are unless you choose to disclose that information. You can type in any concerns to the bot and it will provide you with a list of resources that match your search query. Furthermore, if you're seeking for more human-like responses, or are just looking for someone to talk to, you can chat with an agent and they will help you to the best of their ab"
      }
    ]
  },
  {
    "file_path": "./devposts/merchmatica.html",
    "project_id": "merchmatica",
    "title": "Merchmatica",
    "tagline": "A new kind of merch",
    "hackathon": "",
    "built_with": [
      "ai",
      "ai3d",
      "ai3d-api",
      "amazon-rds-relational-database-service",
      "amazon-web-services",
      "amplify",
      "bash",
      "cloudfront",
      "controlnet",
      "devto",
      "fal",
      "flux",
      "flux-canny",
      "flux-depth",
      "github-actions",
      "javascript",
      "kiro",
      "lora",
      "napkinmatic",
      "nextauth",
      "nextjs",
      "node.js",
      "postgresql",
      "printful",
      "printify",
      "prisma",
      "rds",
      "react",
      "replicate",
      "rodin",
      "route53",
      "s3",
      "stripe",
      "tailwind",
      "transformers",
      "tripo3d",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/749/079/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration This was a Deep End of the Pool experiment : could we vibe-code a complex, enterprise-grade, multi-value-prop AI ecommerce platform with no manual code fixes—only plugging AWS credentials? Merchmatica is also inspired by Stephen Wolfram’s *A New Kind of Science . Where Wolfram showed that *simple local rules in cellular automata can generate infinite complexity, here we ask: What happens when simple licensing + payment rules generate an entire merch economy? A creator sets a royalty % A fan generates an AI design A store curates products A Stripe split propagates payouts From these atomic rules emerges a new kind of commerce : unpredictable, generative, and computationally irreducible. What it does Merchmatica (aka Project cameo-ecosystem — named after my dog and AI design collaborator @corgi.cam ) is a platform for an emergent merch ecosystem. Creators directly license and monetize their likeness for AI-downstream content creation that flows into physical merch. Fans can spin up their own stores, generating apparel, postcards, even 3D-printed figurines from licensed creator IP. Payments & fulfillment are handled through Stripe Connect and merch APIs, turning fan-inspired generated creations into tangible goods. Instead of a top-down catalog, Merchmatica works like a commerce automaton : creators, fans, and stores play out simple rules that give rise to complex global markets. How we built it We started with a single prompt: “Create Spec: Cameo Ecosystem: allow fans to generate brand-true images and products such as postcards, apparel and 3D printed figurines (2D/3D) from Creators, then sell products via stores.” Then let the Kiro agent autopilot it through: Spec generation + architecture by Kiro Implementation assisted by VSCode Copilot Stack: Next.js SSR + AWS Amplify + Stripe Connect + FAL/Replicate for AI gen Multi-layered environment loader for secrets + debug endpoints for production validation Like cellular automata rules encoded in Mathemat"
      }
    ]
  },
  {
    "file_path": "./devposts/memory-uk3ayg.html",
    "project_id": "memory-uk3ayg",
    "title": "Memory",
    "tagline": "Understanding effortlessly.",
    "hackathon": "",
    "built_with": [
      "amazon-dynamodb",
      "javascript",
      "lambda",
      "python",
      "react",
      "velo",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/457/733/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration We are a group of university students who experienced high school during the COVID-19 pandemic so we feel that support in education is greatly needed for all students of all ages, in all specialties. What it does Memory is a flashcard applciation that allows you to upload flashcards, play interactive games, and view them. It accepts multiple types of formats, and it's a business product that will keep you engaged with whatever content you're learning. Uses AI to instantly generate study resources such as flashcards and practice quizzes from uploaded notes Users are able to access other flashcards and practice quizzes, focusing on any topic, from any user There is a study tracker to record goals for the day and what was accomplished How we built it We used the Wix Velo platform to build the majority of our application, including the frontend Wix Elements, and APIs such as Wix Data, Fetch, Authentication, Pricing, and Members API. These APIs helped us augment the backend, which we also improved the latency of using backend tools such as AWS Lambda, EC2, and DynamoDB. For the AI aspect, we used a Lambda endpoint hosting GPT-3.5 turbo/LLaMa pretrained model on a GPU to generate queries in real time, and send them back using JSON embedded HTTP responses. Challenges we ran into Wix loads very slowly, and the documentation was very long. We solved this issue by going through the most difficult parts first, and also cloning data when needed to improve speed. Accomplishments that we're proud of Some of our group members have never made a website before so it was very exciting to create each page and learn about UI/UX Creating the flashcard generator was immensely satisfying especially since this is a resource that we are now able to use for our own education Creating the quizzes based on flashcards was also very exciting because we had never worked with Velo before and we had never done a project like this so being able to overcome many \"firsts\" helped us"
      }
    ]
  },
  {
    "file_path": "./devposts/melodicmind.html",
    "project_id": "melodicmind",
    "title": "MelodicMind",
    "tagline": "Three steps to help you tackle stress and soothe your mind!",
    "hackathon": "",
    "built_with": [
      "gpt",
      "huggingface",
      "musicgen",
      "musiclm",
      "next.js",
      "python",
      "pytorch",
      "streamlit",
      "tailwind",
      "typescript",
      "verbwire"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "United Hacks 2023WinnerMost Innovative Use Of Verbwire API",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/555/774/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "NFT Mint PolygonScan Home Page Memories Add Memory SupportBot NFT Mint PolygonScan Home Page Memories Add Memory SupportBot NFT Mint PolygonScan 1 2 3 4 5 6 Inspiration Mental health is an important issue. In 2017, over 1 in 8 people suffer from mental health issues. I wanted to solve the difficulties of dealing with mental health, and I realized that there are not many apps that have a concrete plan to help make the burden a bit easier. Therefore, I wanted to create a solution that was a simple plan that anyone could follow, and use my application to promote mental health and help become happier and more successful. I wanted to create a proof of concept that could be turned into a viable product, as well as help myself and others that have struggled with mental health issues to feel better! What it does MelodicMind is an application that provides a simple three step process: create a journal entry, remember happy memories, and talk about it with an AI chatbot. It is a soothing and relaxing application to make the process of destressing easier, and calm the mind after a stressful situation. This three step process works because you first document the situation to see if you can reflect on it, then remember some happier moments, and finally, you can talk to a bot about your problems, and they can give you feedback about what you should do! How we built it For the machine learning portion of our app, we fine tuned GPT-3.5 and LLama for the Chatbot, stable diffusion and OpenAI image generation, MusicLM and MusicGen training, sentiment analysis hyperparameter tuning and pipeline workflows using HuggingFace transformers, tokenizers, and embedding layers. This was all hosted on streamlit. For blockchain tools, we used web3.storage’s API for IPFS and Filecoin decentralized storage, the VerbWire API to create an NFT and mint it to 7 mainnet and 5 testnet chains. Finally, we used the T3 stack (Next.JS, Tailwind, Typescript, Prisma ORM) as well as a firebase DB. We modified V"
      }
    ]
  },
  {
    "file_path": "./devposts/memorify.html",
    "project_id": "memorify",
    "title": "Memorify",
    "tagline": "Imagine combining the nostalgia of a photo album with the practicality of a Rolodex, enhanced by the magic of AI! Providing an innovative way to commemorate and reflect on life's journey!",
    "hackathon": "",
    "built_with": [
      "cohereapi",
      "django",
      "midjourney",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/737/620/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Our hackathon project was inspired by the incredible pattern recognition capabilities and visual literacy inherent in human cognition. We decided to combine the nostalgia of a photo album with the practicality of a Rolodex, enhanced by the magic of AI. What it does The system receives a journal entry and contact details for individuals mentioned in the entry from the user. It subsequently generates a contact book containing the contact information for each person referenced in the entry, accompanied by a personalized avatar. Users have the option to select avatars from The Simpsons, Marvel, or Looney Tunes, based on the personality of each contact. With each new journal entry, the contact book grows, including details of mentioned individuals. Users can easily access a consolidated view of all entries featuring a specific contact, providing a comprehensive overview of interactions. How we built it We utilized React and Tailwind CSS for the frontend designed initially on Figma and used Django and Kintone at the backend.  We used Cohere's Generate API endpoint to analyze a journal entry. Firstly, it suggests a suitable title for the entry. Next, it identifies people mentioned in the entry along with their associated personality traits and characteristics. After obtaining this information, the app inputs final details such as contact information for each character using rolodex functionality. Users can choose from three pre-set art styles for the visuals they want to generate for the characters, aiming for a nostalgic feel. Upon submission, Midjourney AI is employed to create a unique cartoon avatar for each person. In addition to this, the app enhances the visuals to more accurately represent the personalities and traits of the characters. Overall, the app transforms textual descriptions into engaging visuals, including personalized cartoon avatars and visual representations of each character's traits. Challenges we ran into Despite numerous atte"
      }
    ]
  },
  {
    "file_path": "./devposts/meds-ai.html",
    "project_id": "meds-ai",
    "title": "Meds AI",
    "tagline": "Stay healthy & spry with Meds AI!\n\nMeds AI is an iOS app that analyzes the health product you’re considering against your current regiment, alongside pre-existing conditions, for informed decisions!",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "faceid",
      "google-cloud",
      "openai",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/653/940/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 Targeted Tracks → Healthcare: Patient Safety - Sponsored by PRHI The Problem: Adverse Drug Reactions Let’s talk about Adverse Drug Reactions, or ADRs. Hospitalized Americans experience over two million serious ADRs , resulting in over 106,000 deaths annually (FDA). That’s over double the amount of deaths from vehicle crashes. As someone who was bed-bound by a medication that only worsened my condition, I understand this problem all too well. And it exists outside of the hospital, too: 1 in 5 Americans take three or more drugs (CDC). Add in the hodgepodge of unregulated over-the-counter, vitamins, and dietary supplements that are skyrocketing in popularity, and we vastly increase the risk of harmful drug interactions. Even the most acute doctors can’t keep up with the millions of supplements on the market. What if there was a way for patients to make sure that their health products don’t conflict with one another or any pre-existing conditions, in order to prevent ADRs? And what if we could put that solution in their pocket? The Solution: Meds AI Meds AI is an iOS application that analyzes a new health product against the user’s current regiment, alongside pre-existing conditions. Through optical character recognition and artificial intelligence, a user can simply snap a picture of the product’s ingredients to receive a recommendation before they even enter the checkout line. User Flow: Sign-in with Face ID — Security is paramount for patient information, and Face ID is the gold standard.\nOnce logged in, users will be redirected to their health products page Users can scroll through their current list of medications, OTCs, and supplements Users can navigate to their conditions page, and add any relevant conditions Users can add a new health product through snapping a picture of the product and its ingredients. This filters through OCR and AI to evaluate the product against the user’s current regiment and conditions, ultimately recommending for or agai"
      }
    ]
  },
  {
    "file_path": "./devposts/mergr.html",
    "project_id": "mergr",
    "title": "Merge",
    "tagline": "Don't like merge conflicts? Neither do we!",
    "hackathon": "",
    "built_with": [
      "cli",
      "openai",
      "python",
      "textual"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/117/276/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Merge! Command Line Interface Architectural Flowchart Merge! Command Line Interface Architectural Flowchart Merge! 1 2 3 4 Inspiration As developers, we know the frustration of dealing with merge conflicts—especially when they interrupt our workflow and slow down our progress. We wanted to build a tool that takes the complexity out of conflict resolution and makes it as simple as possible, allowing us to get back to coding with minimal disruptions. What it does Merge is a one of a kind, command-line tool that visually highlights merge conflicts and provides intuitive options to resolve them with a single keystroke. By showing both current and incoming changes side by side, Merge makes it easy to decide which version to keep or merge both. It’s a fast, streamlined way to tackle conflicts without ever leaving the CLI environment. How we built it We built Merge using Python and the Textual framework for a clean CLI-based interface. The backend uses a combination of custom conflict detection logic and file staging management to handle and display conflicting sections in code files. Challenges we ran into One of the biggest challenges was building an interface within the CLI that feels as intuitive and visual as a GUI-based tool. We wanted to focus on accessibility by allowing users to to either type or click their merge resolution. Furthermore, implementing conflict resolution logic that integrated well with our interface took trial and error. Accomplishments that we're proud of We’re proud of creating a tool that simplifies a common pain point for developers and provides a seamless user experience within the command line! Building an effective visual layout within a CLI and fleshing out various features ranging from conflict resolution, resolution options, keyboard binding, and a couple user experience treats. What we learned We learned a lot about building interactive command-line interfaces and the intricacies of parsing and resolving merge conflicts through our own "
      }
    ]
  },
  {
    "file_path": "./devposts/micro-money.html",
    "project_id": "micro-money",
    "title": "Micro Money",
    "tagline": "A micro loan service that helps alleviate people struggling from Covid-19 financial issues using easy loan payments thanks to the IBM Watson Studio and the Capital One APIs",
    "hackathon": "",
    "built_with": [
      "capital-one",
      "css",
      "html",
      "ibm-watson",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Connectivity Hack Created by I worked through the issues we faced with IBM Watson Studio",
      "Best Connectivity Hack Created by I worked through the issues we faced with IBM Watson Studio",
      "IvyHacks: First Ivy League HackathonWinnerBest Connectivity Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/239/702/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration for Micro Money In these unprecedented times of Covid-19, one of the biggest challenges was shortage in demand faced by small/local businesses, be it restaurants, small cafes or small brands. In fact, people who were evicted from their homes because of their inability to pay rent were also hardly hit. This is where Micro Money comes in – a micro-loan service platform that connects people in immediate need of money to tons of lenders who are willing to help people in need and extend them a small amount of loan. This is what we envision our platform to be – a place where people in need of some money can get access to it quickly, without any hassle. In fact, these people can create their own campaigns (think, crowdfunding campaigns) and even get money from multiple lenders – speeding up the process of lending and solving their problems. What it does The main purpose of Micro Money is to serve as a platform for the people who were hit the hardest by the pandemic and providing them access to capital by connecting them with multiple lenders willing to offer financial help. Borrowers (people in need) can create campaigns through the platform describing the amount of money they need, why they need it and when they will be able to repay the amount. Lenders can view currently active campaigns based on where they are located and choose people they want to offer money to. Check whether borrowers are eligible for the loan by leveraging our Loan Eligibility Predictor, a custom made classification machine learning model trained, built, and deployed inside IBM Watson Studio. Create accounts for lenders and borrowers through the Capital One Hackathon API which speeds up the process of transferring money reliably and efficiently. Once a person signs up as a borrower or a lender, an account is created for them using the Capital One Reimagine Banking Hackathon API. A borrower can instantly start filling out details for the campaign he wants to create. Based on the campa"
      }
    ]
  },
  {
    "file_path": "./devposts/merp.html",
    "project_id": "merp",
    "title": "merp",
    "tagline": "merp wip",
    "hackathon": "",
    "built_with": [
      "mangomangomangomango"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "we are suffering Built With mangomangomangomango Submitted to HackUTD 2024: Ripple Effect Created by Monish K Keshav Dharshan"
      }
    ]
  },
  {
    "file_path": "./devposts/mercury-ai-manager.html",
    "project_id": "mercury-ai-manager",
    "title": "Mercury | AI Manager",
    "tagline": "AI manager to help managers manage their time",
    "hackathon": "",
    "built_with": [
      "gitlab",
      "google-cloud",
      "javascript",
      "nextjs",
      "node.js",
      "react",
      "restapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/484/405/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Files section Home Page Feedback for individual files Files section Home Page Feedback for individual files Files section 1 2 3 4 Mercury | AI Manager 🪐 🚀 About the Project Mercury | AI Manager is an intelligent code review assistant built with Next.js 15 that integrates with GitLab’s API to automatically fetch repository data, analyze source code, and provide high-quality feedback using Google Cloud’s Gemini AI models . The goal is to automate and accelerate code quality checks—something every developer can benefit from. 💡 Inspiration The idea for Mercury was born from my personal struggle with managing time during manual code reviews. As a developer, juggling deadlines and maintaining code quality often became overwhelming. I realized there needed to be a smarter, faster, and more accessible way to receive feedback—especially for solo developers or small teams without dedicated reviewers. That’s when I envisioned Mercury : an AI-powered assistant that would review your GitLab-hosted codebase and offer structured feedback within seconds—just like a senior developer would. 🛠️ How I Built It Framework : Next.js 15 with the App Router Auth : GitLab OAuth2 for secure access to private repositories Backend : Node.js API Routes and serverless functions AI Feedback Engine : Integrated with Google Cloud’s Gemini models for intelligent code analysis and review Deployment : Vercel 🧠 Features: OAuth-based GitLab authentication Repository list and branch selector AI-generated code quality feedback written directly to .md files Context-aware suggestions for improving readability, maintainability, and efficiency Feedback powered by Google Gemini AI models for cutting-edge analysis 🔍 What I Learned Hands-on experience with GitLab's REST API , including auth scopes and secure access patterns Advanced usage of Next.js App Router for API integration and route protection Structuring real-time interactions between a codebase and an AI model How to communicate effectively with Google C"
      }
    ]
  },
  {
    "file_path": "./devposts/mindmap-we485x.html",
    "project_id": "mindmap-we485x",
    "title": "MindMap",
    "tagline": "To do list meets mind map online",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/589/951/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 ToDoMap: Motivational Mindmapping App 🚀 Inspiration In our fast-paced world, staying motivated and organized can be challenging. Traditional to-do lists often feel rigid and uninspiring, while complex project management tools can be overwhelming. ToDoMap bridges this gap by combining the visual power of mind mapping with motivational elements to help users stay focused, inspired, and productive. 🎯 What it does ToDoMap is an interactive mindmapping application that transforms how you organize thoughts, goals, and tasks. The app features: Visual Node Creation : Create four types of nodes - Goals (blue), Ideas (yellow), Tasks (green), and Inspirations (pink) Interactive Canvas : Drag-and-drop interface with smooth animations and visual feedback Priority Management : Color-coded priority system (high, medium, low) with visual indicators Progress Tracking : Real-time completion statistics and progress visualization Daily Motivation : Rotating inspirational quotes to keep you motivated Smart Persistence : Auto-save functionality with local storage Data Portability : Export/import capabilities for backing up your mindmaps 🔧 How we built it ToDoMap was built using modern web technologies: Frontend : React 18 with TypeScript for type safety and component architecture Styling : Tailwind CSS for responsive design and beautiful gradients Icons : Lucide React for consistent, beautiful iconography Build Tool : Vite for fast development and optimized production builds Storage : Local Storage API for data persistence Deployment : Netlify for seamless hosting and continuous deployment 🏗️ Architecture The application follows a clean, modular architecture: Component-based design with clear separation of concerns Custom hooks for state management and side effects Utility functions for data persistence and quote management TypeScript interfaces for type safety across the application 💪 Challenges we ran through Smooth Drag & Drop : Implementing responsive drag-and-drop functionality "
      }
    ]
  },
  {
    "file_path": "./devposts/milk-fgak0s.html",
    "project_id": "milk-fgak0s",
    "title": "milk",
    "tagline": "it's milk",
    "hackathon": "",
    "built_with": [
      "milk"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration It was inspired by milk What it does It's milk How we built it Blender and Milk Challenges we ran into Milk Accomplishments that we're proud of It looks like milk What we learned IDK What's next for milk MORE MILK, Chocolate Milk? Built With milk Try it out drive.google.com Submitted to lhtester Created by Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/mindcraft-v7it3c.html",
    "project_id": "mindcraft-v7it3c",
    "title": "MindCraft",
    "tagline": "Experience the future of gaming with MindCraft – where eye recognition meets physical motion control in Minecraft. Mine, build, and explore your virtual world like never before!",
    "hackathon": "",
    "built_with": [
      "adhawk",
      "mediapipe",
      "opencv",
      "python",
      "xbox"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Enhance the precision of gesture recognition and eye-tracking algorithms to ensure accurate and responsive gameplay."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/589/196/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡Inspiration Our journey began as avid gamers, deeply passionate about the Minecraft universe. We thought of ways to transcend the traditional gaming experience. Instead of being tethered to a keyboard and mouse, we envisioned a world where our bodies could seamlessly merge with the digital realm. With the introduction of AdHawk MindLink glasses and the power of OpenCV technology, this vision transformed into a compelling reality. Our desire was simple yet profound: to unlock a new dimension of play, where players could use their entire body, from limbs to eyes, to interact with the virtual world. This immersive project encapsulates our unwavering commitment to pushing the boundaries of technology and redefining the human-gaming interface. 🎮 What it does Imagine stepping into your favorite virtual world, but instead of relying solely on a controller, you become the controller. Our project enables you to control in-game actions in Minecraft not just with your hands, but with your entire body including your eyes! You can jump, walk, build and destroy by simply moving as if you are doing it in real life. You can turn around just by moving your eyes around on the screen. It's a seamless blend of reality and the virtual, where the boundaries between player and game blur. 🤖 How we built it OpenCV, Python, MediaPipe: Created a script to translate live video camera feed into in-game Minecraft actions. AdHawk MindLink Glasses and SDK: Used the glasses and the AdHawk Python SDK to track eye movement on the screen to rotate the player's view. Xbox Kinect Sensor: The sensor takes in the live camera feed into the computer. GitHub: Since our team worked on multiple separate functions of the project at once, we used GitHub extensively for collaboration. Branches, issues, and pull requests kept our code clean and organized, while reviews were used to keep each other updated on the progress of different features. Our README page and \"Getting started\" wiki page also document impo"
      }
    ]
  },
  {
    "file_path": "./devposts/meter-one.html",
    "project_id": "meter-one",
    "title": "Meter One",
    "tagline": "An all-in-one solution for blood oxygen saturation, heart rate, and white blood cell count; consolidating blood tests into a single medical device solution.",
    "hackathon": "",
    "built_with": [
      "altium",
      "arduino",
      "c",
      "dart",
      "figma",
      "flutter",
      "keras",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/350/135/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "VGG16 Bidirectional LSTM RNN, 4 batch size, 10 epochs, 70-30 split Meter One - An All-in-One Medical Device Solution Solution Pipeline Prototype PCB model of hybrid pulse oximeter controlled by arduino nano (camera not shown since no manufacturer 3d model was available) Image of expected data from camera sensor (Top: Baseline healthy WBC count, Bottom: Lower WBC count) Upload custom video recorded by Meter One Device - Flutter App Page Patient dashboard page showing clinical data - Figma wireframe (with template data) VGG16 LSTM RNN, 4 batch size, 20 epochs, 70-30 split VGG16 Bidirectional LSTM RNN, 4 batch size, 10 epochs, 70-30 split Meter One - An All-in-One Medical Device Solution Solution Pipeline Prototype PCB model of hybrid pulse oximeter controlled by arduino nano (camera not shown since no manufacturer 3d model was available) Image of expected data from camera sensor (Top: Baseline healthy WBC count, Bottom: Lower WBC count) Upload custom video recorded by Meter One Device - Flutter App Page Patient dashboard page showing clinical data - Figma wireframe (with template data) VGG16 LSTM RNN, 4 batch size, 20 epochs, 70-30 split VGG16 Bidirectional LSTM RNN, 4 batch size, 10 epochs, 70-30 split 1 2 3 4 5 6 7 8 9 Inspiration The medical community and hospital infrastructure were put to the test with the quick and rapid appearance of COVID-19. Hospital efficiency needs to streamlined in order to optimize the delivery of health care to patients who urgently need it. This means expediting as many tests as possible as well as being able to monitor patient status that could indicate detreating health. Additionally, \"by closely monitoring the molecular and immunological data in 326 cases of COVID-19 patients, we suggest that adverse outcome is associated with depletion of [white blood cells ]\" (Lu, 2020) . Thus, a connection between more efficient devices in the hospital and a need for measuring white blood cell count (WBC) is established . The proposed solution is "
      }
    ]
  },
  {
    "file_path": "./devposts/mercadvisor.html",
    "project_id": "mercadvisor",
    "title": "Carista",
    "tagline": "Get hyper-personalized guidance about your next car purchase",
    "hackathon": "",
    "built_with": [
      "flask",
      "heroku",
      "next.js",
      "openai",
      "python",
      "scikit-learn",
      "tailwind",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/865/771/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Home Screen. Our Logo It even works on mobile! A friendly assistant to find your perfect car. The recommendation is given in simple panels After a recommendation, you can watch a review to increase trustworthiness. Home Screen. Our Logo It even works on mobile! A friendly assistant to find your perfect car. The recommendation is given in simple panels After a recommendation, you can watch a review to increase trustworthiness. Home Screen. 1 2 3 4 5 6 7 Inspiration At the Tum.ai Makeathon, an AI-themed event, our team took on the Mercedes Benz x Salesforce Challenge. We saw an opportunity to transform the typical chatbot experience, drawing from the challenge's goal of integrating artificial intelligence into customer service. The problem we identified was clear: existing chatbots for product recommendations were uninspiring and often felt like a tedious experience. This gap became especially significant in the context of Mercedes Benz, a brand synonymous with luxury and innovation. As the automotive industry shifts toward online-first sales, we wanted to ensure that the digital customer journey was just as engaging and personalized as visiting a dealership. We were inspired to create Carista, a chatbot designed to make product recommendations fun and exciting, tailored to each customer’s unique preferences. By focusing on hyperpersonalization, we aimed to revolutionize how customers interact with automotive brands online. With this motivation, we set out to build a solution that could set the standard for a new era of online car sales. What it does Carista is an AI-powered chatbot designed to give users hyperpersonalized advice on choosing the perfect Mercedes Benz model. By asking a series of questions about the user's preferences—such as desired vehicle type, budget, performance expectations, and lifestyle needs—Carista customizes the entire car-selection process to ensure an engaging and tailored experience. The chatbot uses these insights to present a curated li"
      }
    ]
  },
  {
    "file_path": "./devposts/meta-connect-zn34jk.html",
    "project_id": "meta-connect-zn34jk",
    "title": "Meta Connect",
    "tagline": "Swiftly Taylor relationships to understand each other a bit more",
    "hackathon": "",
    "built_with": [
      "llama"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/159/309/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Description Meta-Connect enhances social media connections by making them deeper and more meaningful. Our AI Agents mimic users' behaviors and personalities, engaging in conversations to evaluate the potential for new friendships. Once a strong match is identified, users are notified and can start chatting with contextual insights and conversation starters. Additionally, our sentence suggestion feature assists users in crafting responses based on the conversation context. Features AI-Powered Matching: Personalized AI Agents simulate user interactions to assess friendship potential. Compatibility Check: Analyzes conversations to determine the likelihood of a successful friendship. Sentence Suggestions: Real-time suggestions to enhance your conversations. Technologies Used Llama 3.2 Nebius Next.js Built With llama Try it out GitHub Repo Created by James Liang Avid student exploring different aspects of technology and business Gen Ichihashi cs @uw Ri Hong"
      }
    ]
  },
  {
    "file_path": "./devposts/merry-stems.html",
    "project_id": "merry-stems",
    "title": "Merry Stems",
    "tagline": "A children's game designed to provide exposure to STEM careers from a young age through mini games and vignettes of prominent women in STEM fields",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/290/281/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Mini game 1 Title page of the game Mini game 2 Mini game 1 Title page of the game Mini game 2 Mini game 1 1 2 3 4 Inspiration Dana Scully, a doctor and a criminal investigator, is one of the main characters of the X Files, and the origin of the term 'The Scully Effect', a phenomenon where girls who had grown up watching The X Files were more likely to pursue careers in STEM as adults. This led me to understand that exposure to STEM-related media at an early age, especially if it features strong female leads and role models prominent in their respective fields, would leave a positive and lasting impression of STEM fields on young children (especially girls) and lead them to view STEM-related careers as viable career paths for them. Merry Stems is a play on the term meristematic, referring to undifferentiated cells in plants that are capable of growing into any type of plant tissue, and are often found in the fastest growing, newest portions of a plant. What it does Merry Stems is a game designed for children ages 5 to 7 with the goal to introduce them to STEM fields and careers from an early age through mini games and modules exploring responsibilities and skills of various roles, such as computer science, mechanical engineering, medicine, and more.\nAt the end of each mini game, players are presented with a short biography of a prominent female contributor to the field related to the mini game. How we built it We built this entire project using Figma. Due to time constraints, we decided that creating a medium-fidelity prototype of our idea would be the goal for the project. We were all beginners in using the platform and first created our wireframes. We then connected the flows to fully prototype our idea. We also consulted with children and parents of children in our target demographic to ensure that our idea would be valuable if implemented. Challenges we ran into Our group is formed of three beginners. So, the first challenge we ran into was to get familiarized wi"
      }
    ]
  },
  {
    "file_path": "./devposts/milliondollarhomepage-site.html",
    "project_id": "milliondollarhomepage-site",
    "title": "MillionDollarHomepage.site - missed deadline by 10s :-(",
    "tagline": "Own your piece of the vibe coded version of the Million Dollar Homepage",
    "hackathon": "",
    "built_with": [
      "bolt",
      "ionos",
      "netlify",
      "supabase"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/598/266/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Million Dollar Homepage - Own Your Pixel Legacy Inspiration 🎨 Inspired by Alex Tew's legendary 2005 Million Dollar Homepage, we've reimagined this iconic piece of internet history for the modern web. The original site sold one million pixels for $1 each, creating a fascinating digital canvas of early web entrepreneurship. Our version brings this concept into 2025 with modern web technologies, real-time editing capabilities, production-ready payment processing, and a robust backend infrastructure. What it does 🚀 Million Dollar Homepage is a full-stack collaborative digital canvas where users can: Purchase Pixel Parcels : Buy 10x10 pixel squares for $1 each on a 1000x1000 pixel grid with real payment processing Create Pixel Art : Use our built-in pixel editor with a 16-color palette to design custom artwork Upload Images : Transform any image to fit your purchased parcels with automatic resizing and splitting Interactive Canvas : Zoom, pan, and explore the entire grid with smooth navigation and performance optimization Real-time Selection : Visually select multiple parcels to create larger designs with instant feedback Secure Payments : Full Stripe integration with webhook processing for reliable payment confirmations Reservation System : 30-minute reservation periods with automatic cleanup to prevent conflicts Production Infrastructure : Complete backend API with security, rate limiting, and database-ready architecture How we built it ⚙️ Full-Stack Architecture Frontend (React + TypeScript) React 18 with TypeScript for type-safe, component-based UI Zustand for lightweight, performant state management HTML5 Canvas for high-performance grid rendering and smooth interactions Tailwind CSS for responsive, utility-first styling Stripe.js for secure client-side payment processing Backend (Node.js + Express) Express.js API server with comprehensive security middleware Stripe Server SDK for payment intent creation and webhook processing CORS & Helmet for security and "
      }
    ]
  },
  {
    "file_path": "./devposts/mindrealm.html",
    "project_id": "mindrealm",
    "title": "MindRealm",
    "tagline": "A Personalized Meditation Assistant that tracks your Brainwaves",
    "hackathon": "",
    "built_with": [
      "api",
      "brainwaveosc",
      "datastaxastra",
      "eeg",
      "php",
      "processing"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hardware Hack presented by Digi-Key Created by I worked on the desktop application and DataStax Ast",
      "Best Hardware Hack presented by Digi-Key Created by I worked on the desktop application and DataSta",
      "Mental Health HacksWinnerBest Hardware Hack presented by Digi-Key",
      "A Personalized Meditation Assistant that tracks your Brainwaves",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration When it comes to Mental Health, the power of meditation is often underestimated. According to the researchers, individuals that meditate on a regular basis have demonstrated higher focus and concentration, and significantly lower levels of stress and anxiety than individuals who don't meditate. What it does MindRealm is a personalized tool that is connected to an EEG headset to fetch meditation values from the user's brainwaves. Our Desktop Application allows the user to log in, meditate with relaxing music for as long as they want and even compete with their fellow zen enthusiasts to reach up the leaderboard. How we built it An EEG Headset with one electrode on the prefrontal cortex and two reference electrodes is connected to the PC via Bluetooth and accessed through a Serial Port. That data is plotted using BrainwaveOSC and sent off to our desktop application, which is built using processing. Our application plots that data and plays some music at specific volume levels, depending upon the meditation levels of the user. Details like username, score and time are sent off to a DataStax Astra database for further processing that data and display it on the leaderboard. Challenges we ran into Linking processing with DataStax Astra database was a challenge at first, but we overcame it by using PHP as a mediator in between to send off curl requests to the database. Accomplishments that we're proud of We're proud of building a fledged desktop application and integrating it with DataStax, despite the challenges. What we learned We learned about sending POST requests using cURL, and somewhat about postman for APIs. Additionally, we learned how EEG headsets can be interfaced directly with a computer via Bluetooth, without using an Arduino in between. What's next for MindRealm We're planning to host it on a server, make it available to the public, and probably include self-assessment meditation kits (with an EEG headset). Built With api brainwaveosc datastaxastra"
      }
    ]
  },
  {
    "file_path": "./devposts/mint-ur-wellness.html",
    "project_id": "mint-ur-wellness",
    "title": "Mint-Ur-Wellness",
    "tagline": "Become addicted to personal wellness instead of social media through NFTs, Blockchain, & AI.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "blockchain",
      "clerk",
      "esp32",
      "ethereum",
      "hardware",
      "neondatabase",
      "next.js",
      "nft",
      "openai",
      "stripe",
      "tailwind",
      "typescript",
      "verbwire",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/028/369/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In today's fast-paced digital world, we're all guilty of it—mindlessly scrolling through social media, captivated by content that adds little value to our lives. We know it harms our mental and physical well-being, yet the addictive nature of these platforms keeps us hooked. So I asked myself, why not turn the tables? What if mental and physical wellness could be just as addictive? What if improving ourselves became a game we couldn’t stop playing? That’s the bold idea behind Mint-Ur-Wellness —a revolutionary platform that transforms health into an engaging and rewarding journey, just like the games and apps we can’t put down. What it does Mint-Ur-Wellness is a next-generation wellness platform that merges physical fitness with mental well-being in a gamified, seamless experience. Picture this: physical exercises guided by smartglasses that track your every movement, providing real-time feedback and scoring your accuracy. On the mental wellness side, I’ve integrated activities such as journaling , to-do lists , goal setting , and self-check-ins . Every time you complete an activity—be it physical or mental—you earn points. But here’s the twist: those points can be used to mint NFTs , making self-improvement not just rewarding, but fun, and dare I say, addictive . How I built it The foundation of Mint-Ur-Wellness starts with the smartglasses I developed. Using an Arduino BLE , OLED display , and ESP32 , I created a device that is not only lightweight but also highly efficient in transferring data via Bluetooth. The sensors inside track your movements with precision, sending the data to the smartglasses for real-time feedback, all written in the Arduino IDE. Choosing BLE and ESP32 was a deliberate move—they deliver seamless, real-time communication without compromising on speed or accuracy. On the software side, I built the platform using Next.js , layering in a suite of APIs to supercharge its functionality: The OpenAI API provides intelligent feedback an"
      }
    ]
  },
  {
    "file_path": "./devposts/mistral-oui.html",
    "project_id": "mistral-oui",
    "title": "Mistral-OUI",
    "tagline": "Contextual AI based on Vision and Summary in AR on a Magic Leap 2",
    "hackathon": "",
    "built_with": [
      "c#",
      "magicleap",
      "mistral",
      "node.js",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/825/975/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Generated Contextual UI testing the app with the jury Generated Contextual UI Generated Contextual UI Generated Contextual UI Generated Contextual UI testing the app with the jury Generated Contextual UI Generated Contextual UI Generated Contextual UI Generated Contextual UI 1 2 3 4 5 6 Inspiration The vision behind Mistral-OUI combines the innovative fields of Vision and Augmented Reality (AR) to revolutionize user interaction within their physical environment. Inspired by the potential to seamlessly blend digital information with the real world, our project aims to leverage AR technology to enhance user experiences in a multitude of contexts, enriching daily tasks and interactions with a layer of intuitive, contextual digital augmentation. What it does Mistral-OUI is an augmented reality application designed for Magic Leap 2 that intelligently recognizes the user's surroundings and dynamically generates a user interface (UI) tailored to their current context and situation. This spatial and contextual UI aims to significantly boost productivity and enhance the overall user experience by providing relevant, on-the-fly information and tools across a wide range of activities. How we built it The development of Mistral-OUI involved integrating advanced vision and AR technologies to create a contextually aware system capable of understanding and interacting with the user's environment in real-time. By utilizing Magic Leap 2's robust AR capabilities, we designed the app to analyze the spatial and contextual data of the user's surroundings and subsequently generate a customized UI that seamlessly integrates into their field of vision, offering interactive elements pertinent to their current needs.\nIn the background, a two step process allows the experience to run The image is captured and described thanks to https://github.com/vikhyat/moondream Another API call to the Mistral API allows to create new html pages based on the context previously captured Challenges we ran in"
      }
    ]
  },
  {
    "file_path": "./devposts/mindtrak.html",
    "project_id": "mindtrak",
    "title": "MindTrak",
    "tagline": "Mindtrak, 1 right step towards mental freedom.",
    "hackathon": "",
    "built_with": [
      "no",
      "time"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Mind Trak 🌟️ 1 step towards mental freedom Why this project? 63% of students in California has experienced some sort of emotional breakdown A whopping 45% has  reported feeling depressive feelings At Least 32% of teens have some sort of anxiety disorder Features of Berry n Perry ⚡️ Sophisticated locally ran AI Trained on books of psychology Automatically find optimized times to send you surveys! Tech Stack Frontend 🖥️\n-Reactive Native Backend ⚙️ Python Flask, Ollama, Openchat Impact on Users Reduce anxiety for students Increase Grades of Students Makes the school experience more enjoyable Reduce rates of Depression, Suicide and ETC. Glimpse In the Future More Effective DB: Currently, we only use Jsondb, in the future we can use POSTGRES to improve user data Hardware Integration : Add connection to watches and similar hardwares to Built With no time Try it out GitHub Repo Submitted to CruzHacks 2024 Created by Its jover Edward He mid Developer TBH, average at coding ig. Jerry Y Abeyah Calpatura Ashish Ramanan \"Python\" \"Java\" \"GDscript\" \"Html\" \"CSS\" \"JavaScript\" \"React\" \"React Native\""
      }
    ]
  },
  {
    "file_path": "./devposts/michelle-and-jose-s-transporthacks-projecct.html",
    "project_id": "michelle-and-jose-s-transporthacks-projecct",
    "title": "Transguard",
    "tagline": "Warehouse tracker ⛟!",
    "hackathon": "",
    "built_with": [
      "css3",
      "django",
      "figma",
      "github",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Request data from third party warehouses.",
      "Track number of days the inventory is stored at third party sites."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/386/902/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "transguard transguard transguard 1 2 3 Transguard - The quickest way for entrepreneurs to store their goods. Inspiration Many businesses, especially e-commerce companies, face constant inventory management challenges. To adapt to conditions brought about by the COVID-19 pandemic - high leasing costs, popularity of online shopping, and existing seasonal and cyclical fluctuations in inventory levels and storage needs - many businesses are shifting from traditional brick-and-mortar models to e-commerce, and many new businesses were founded with this model as well. Some of the biggest modern day supply chain challenges include inventory management and strain on the shipping industry, which we seek to offer solutions for with our on-demand warehousing program. What it does Our program identifies third party warehouses on the bases of proximity to shipping destinations and storage availability and matches companies to these warehouses to store their inventory. Request data from third party warehouses. (Authenticate user before returning inventory.) Parse through inventory information to extract inventory levels and other relevant information while constantly updating this data. Display warehouse information, including available and total amount of storage area (on web or mobile app). Match inventory needs to storage availability and display date and storing recommendations. Track number of days the inventory is stored at third party sites. How we built it Firstly, we built a webpage layout using Figma. Then, we created an interactive login and home page using HTML and CSS while developing data csv scripts with accurate information using Python. Challenges we ran into First, we did not know which tools we would build our project on. While most of us knew a little bit of everything, we did not know how to get the project rolling. It was a matter of understanding what were the best options for us with what we had in hand. Accomplishments that we're proud of We are really pro"
      }
    ]
  },
  {
    "file_path": "./devposts/mission-control-aec.html",
    "project_id": "mission-control-aec",
    "title": "Mission Control AEC",
    "tagline": "Web Management for Building Knowledge Modeling System",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "javascript",
      "mongodb",
      "tensorflow.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/770/882/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration This project was built on top of HOK's recently open-sourced Mission Control, a tool that uses .Net and the Revit API to collect BIM data from Revit, load it into MongoDB, and then display it using a Angular.js web interface. What it does This project makes it easier for BIM managers to perform QC and Audits on large numbers of projects. Specifically, it identifies how many views exist in each project, and how many of those aren't assigned to a sheet. Once these are identified, users are able to press a button, and use Autodesk's Design Automation for Revit remove all of the unnecessary views without having to manually open each file. How I built it It is built using Angular.js , Mongo DB, Revit API, Mongoose, D3.js Challenges We ran into Data Not available for the testing.\nTo solve this, we created a fake data generator, to populate the needed data into Mongo. No one on the team was familiar with Angular.js. \nWe learned it over the course of the weekend, and hit our heads over things such as not being able to use standard javascript commands (like Math.round()) in Angular expressions (Hooray for learning about filters!) Accomplishments that I'm proud of The first step that opens the door to a real BKM and performs actions based on classification and prediction in the BIM Models. Rasing the arrival of AI in the AEC What I learned How to use Design Automation for Revit Revit.io how to transfer plugin in a cloud environment https://youtu.be/PbuEXHTc8XY What's next for Mission Control AEC Implement tensorflow.js for accurate time series and predictions Built With angular.js javascript mongodb tensorflow.js Try it out GitHub Repo Created by I wrote the mongo queries, edited most of the Angular.js, wrote the fake data generator, and ate way too many snacks. Daniel Clayson Danny Bentley Alberto Tono I work as Researcher for Stanford ( HAI Graduate Fellow and CIFE Researcher)"
      }
    ]
  },
  {
    "file_path": "./devposts/mindtrics.html",
    "project_id": "mindtrics",
    "title": "Mindtrics - Mind metrics. Made simple",
    "tagline": "17% of global workers actively manage their work time. Mindtrics, an unobtrusive brain-computer interface, offers a more exhaustive portal into personal productivity insights and stress reduction.",
    "hackathon": "",
    "built_with": [
      "brainflow",
      "javascript",
      "logitech",
      "openbci",
      "opencv",
      "python",
      "torch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/588/488/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Action Detection View Mindtrics logo Start session Session ongoing Focus chart Dashboard View Mouse and gaze variance chart GIF Gaze estimation and variance Brainflow GUI Action Detection View Mindtrics logo Start session Session ongoing Focus chart Dashboard View Mouse and gaze variance chart GIF Gaze estimation and variance Brainflow GUI Action Detection View 1 2 3 4 5 6 7 8 9 10 Inspiration The inspiration behind \"Mindtrics - Mind metrics. Made simple.\" stems from the growing importance of mental well-being and cognitive performance in our fast-paced digital world.\nWe wanted to create a tool that effortlessly integrates into daily life, leveraging cutting-edge EEG technology and Logitech's superior audio hardware to provide users with actionable insights into their focus levels and mental state. How we built it Our project, Mindtrics, in order to create a seamless way to maintain the state of flow when carrying out any productive tasks, uses the following: Logitech webcam Logitech headphones (with the proposed application of EEG electrodes onto the headphone frame) Logitech keyboards Logitech mice Instead of utilizing a timer-based system which can lead to breaking of the flow state, we focus on ensuring that users can extend these flow ranges beyond just a set timer. Our project incorporates real-time EEG data acquisition which is used to identify the level of focus that a person has had throughout time. In case the person goes below a specific threshold of focus, we can indicate this using our interactive website or through peripherals that allow RGB lighting. This provides a subtle way of indicating if the user is still in a state of flow or if they are unable to focus, ensuring that they do not experience any interruption. Additionally, we provide many insights that a lot of users find actionable and intriguing. We make a step to a future of integrated non-intrusive BCI-s. What it does EEG Measurement (Through electrodes mounted on headphones): We used OpenBC"
      }
    ]
  },
  {
    "file_path": "./devposts/mintoir.html",
    "project_id": "mintoir",
    "title": "Mintoir",
    "tagline": "Minting memories through the blockchain.",
    "hackathon": "",
    "built_with": [
      "crypto",
      "eth",
      "ethereum",
      "etherscan-api",
      "expo.io",
      "flask",
      "hardhat",
      "javascript",
      "mediapipe",
      "native-base",
      "nft",
      "pil",
      "pinata",
      "python",
      "react-native",
      "ropsten",
      "solidity",
      "typescript",
      "walletconnect"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Our lives are full of memories that we want to keep forever. You can’t just take a photo and hope for the best."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/798/655/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 💡 Inspiration Memories are too precious to be lost in the abyss of time. That’s why we take pictures, send holiday greeting cards, and keep heirlooms. With the COVID-19 pandemic, we lost the ability to truly store these sentimental memories. For example, we can no longer send postcards around the world without 6-month+ delays. Our lives are full of memories that we want to keep forever. You can’t just take a photo and hope for the best. Introducing, Mintoir (Mint + Memoir); an intuitive cross-platform mobile application that allows you to turn your favourite moments into digital tokens that will last forever on the blockchain, ensuring that you won’t ever forget what matters most. 🔍 What it does Once the user connects their wallet through our one-click portal, they will be greeted by our dashboard where they can browse trending memories on the blockchain, or view their own. Next, if they wish to mint a memory, they will be prompted to the builder screen. Users can configure the source image file, select from a suite of memory templates or create their own, edit their source image, apply AI-generated backdrops based on their location, and add a message/title to the metadata. Once they are happy with the memory built, they can mint the NFT on the blockchain with a single button. ⚙️ Tech stack Frontend React Native Expo Native Base Blockchain / Smart Contract Backend Hardhat Solidity Etherscan API Pinata IPFS Image Processing / Machine Learning Backend MediaPipe for ML Pillow / PIL Python Flask Ethereum Operations WalletConnect Ropsten Ethereum Testnet ERC-721 NFT standard contract 🚧 Challenges we ran into Because there aren’t many fully-featured Web3 mobile apps on the market for both iOS and Android, it was difficult to find resources pertaining to how we could both utilize a wallet, create smart contracts, and more. In addition, a lot of custom configuration was required in order to get the app up and running. None of our team members had any exper"
      }
    ]
  },
  {
    "file_path": "./devposts/mlh-fiesta.html",
    "project_id": "mlh-fiesta",
    "title": "MLH fiesta",
    "tagline": "Hackathon even at which we learned a vast amount of tools and resources in our ambitious journey to code the time keeper's chrono capsule.",
    "hackathon": "",
    "built_with": [
      "c",
      "css",
      "html",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/264/802/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Approach for Mock Design Inspiration Chronotrigger What it does Allows user to access website to input message and time to which they will receive the message in the future along with phone number for notification messaging. How we built it We had wanted to implement a communicative back and front end via flask api and twilio api. We had initially approached cockroach DB to no avail on serverless db and had to use local db in testing. Challenges we ran into Cockroach DB was feeling a little antsy and new tool usage was difficult to handle. Accomplishments that we're proud of A very enjoyable hackathon to learn about new tools and products especially the CTF Snyk. We are proud of having a very solid front end. What we learned Multi-Tools Built With c css html python Try it out GitHub Repo saucypilot.github.io quivun.tech Submitted to UNT NSBEHack 2022 Created by I worked on the front-end portion of the Software design challenge. I was suppose to implement the C file into the website but we didn't have enough time. Irian Durian Worked on the back end c code. Taking user input and the timer. Assumed 1 year is a second to display the functioning in the demo. Heet1001 Patel Alexander Johnson Joshua Chong"
      }
    ]
  },
  {
    "file_path": "./devposts/mix-it-up.html",
    "project_id": "mix-it-up",
    "title": "Mix it Up!",
    "tagline": "There’s an entire world of deliciousness in our pantry, but we don’t know what we don’t know. Plug in what’s left in your fridge and any nation and get a recipe. Hope you mix it up with Mix It Up!",
    "hackathon": "",
    "built_with": [
      "css",
      "gpt3",
      "html",
      "javascript",
      "openai",
      "ruby-on-rails"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "## Inspiration We were inspired by the feelings or emotions food provides and incorporating it with the significant cultural value it holds. For those who might want to recreate their hometown foods but live in a foreign area and have only ingredients of their current location, Mix it Up! can provide similar food items at home with the given ingredients. For those who want to explore other parts of the world through cuisine, Mix it Up! may be a connection factor for one to further get to know or find interest in a foreign cuisine. Or simply, Mix it Up! can be a unique and fun recipe generator that helps eliminate housing overdue food items in your pantry. ## What it does Our web matches users with a foreign cuisine recipe based on their ingredients they input and the foreign location they input in order to connect them with that cuisine no matter where they are in the world. This encourages users to mix their food choices up! ## How we built it After a collaborative brainstorming process on executing the idea and establishing structure, the frontend was built using HTML and CSS, while the backend is built with Ruby and OpenAI’s GPT3 api. The whole application is powered by Ruby on Rails which makes it easier to manage views, data flow, and stylesheets. We extensively used Git to work collaboratively, defined tasks amongst each other, and used the Git repository as up to 30+ commits from all users. ## Challenges we ran into Some challenges we faced were connecting the Open Ai prompt service on Ruby back into the html file as well as integrating front and back end after merging rails with different ancestors. ## Accomplishments that we're proud of While we were fortunately able to have many small and large accomplishments, we are especially proud of the integration of GPT3 api with Ruby and our work in fine tuning prompts to produce the appropriate results. There was a lot of challenge especially because most of our teammates were unfamiliar with Ruby, so accomplishin"
      }
    ]
  },
  {
    "file_path": "./devposts/ml-puzzle-solver.html",
    "project_id": "ml-puzzle-solver",
    "title": "ML Puzzle Solver",
    "tagline": "Hate solving puzzles? Let machine learning do it for you! With our trained TensorFlow model created in Python, solving thousands of puzzles in no time is a breeze for the average data enjoyer.",
    "hackathon": "",
    "built_with": [
      "cnn",
      "deep-learning",
      "jupyter",
      "keras",
      "neural-network",
      "numpy",
      "python",
      "sparse-categorical-crossentropy",
      "tensorflow",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Why solve puzzles when your computer can solve them for you? Jigsaw puzzles are always fun to solve. But you know what's even better? Having a machine learning algorithm to solve it for you! Our machine learning model does just that, leaving you with beautifully solved puzzles. What it does Our model will take in 128x128 images that are scrambled into 2x2 puzzles. Our model will predict the correct locations, or indices, of the pieces, and it will then output a string that indicates the correct indices of the puzzle pieces based on the input. These indices can be used to view the original, unscrambled image. How we built it After extracting each puzzle piece from the original image, we pass each of them through the model, which is a neural network . The model will extract the features and learn the useful image features for us. In this case, edge and corner features are the most useful for finding the correct puzzle configuration. Since these features emerge within the first few layers of a neural network, we chose a shallow neural network for efficiency and simplicity. We wanted to train the model with symmetrical weighting on each image tile, so we used time distributed layers, which perform the same transform to each array in a mult-dimensional array. We also padded our input image to preserve edge information . After that, we flattened the final layer to merge the feature vectors. Then, we passed this vector through a feed-forward network, then we reshape it into a matrix of 4x4 (we need 4 vectors to predict the 4 scores for each position, which is a 4x4 matrix). Since this is a multi-class classification problem, we used sparse-categorial-crossentropy for our loss function. The optimizer that we utilized for our neural nets is Adam. When building our neural nets, we used the relu activation function, and for the last layer, we used a softmax to choose a definitive prediction. Challenges and Roadblocks When loading and training the model, we had memory limitatio"
      }
    ]
  },
  {
    "file_path": "./devposts/moretreatsfor-us.html",
    "project_id": "moretreatsfor-us",
    "title": "moretreatsfor.us",
    "tagline": "Get more treats this Halloween 🎃",
    "hackathon": "",
    "built_with": [
      "canva",
      "express.js",
      "github",
      "gitpod",
      "google-cloud",
      "mapbox",
      "mongodb",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Costume Hack” Category",
      "Best use of Linode Cloud Created by I worked on the entire front-end of this project",
      "Hack-O-LanternWinnerBest use of Linode Cloud",
      "We learnt full-stack development with MERN for the first time.",
      "We learnt UI/UX and it’s importance while participating in the “Best Costume Hack” Category.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/722/028/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 ✨Inspiration✨ We discovered a problem which is trick-or-treaters aren’t able to find houses that participate in Halloween trick-or-treating, as a result they have to be content with lesser treats. Similarly, some homeowners spend time and effort buying sweets and decorating their house for Halloween, but nobody shows up for trick or treating. moretreatsfor.us attempts to solve this by providing users with a map application where they can register their house with just few clicks and get trick-or-treaters. ❓What it does❓ As a home-owner, moretreatsfor.us allows you to register on our site, place a jack-o-lantern (pin) on your house location, select a few options — like the convenient timings to receive trick-or-treaters, types of candy you offer (for purposes of dietary restrictions), whether you have any pets (to avoid scaring trick or treaters at your door) and more notes. As a trick-or-treater, you can view the different houses that are trick-or-treating in your neighbourhood along with what timings they want to welcome you, whether they have any pets, whether their candy types suit your dietary restrictions etc. Trick-or-treaters can use our map to plan out their trick-or-treating route in advance and receive more treats. 🏗How we built it🏗 We used the MERN stack (MongoDB, Express, React, Node) and Linode, Google Cloud, GoDaddy, GitPod and Canva to build moretreatsfor.us. 🟢Use Of Linode Cloud - https://cloud.linode.com/linodes/31410609/ 🟢 We utilized Linode for its hosting and data storage. Linode is one of the top IaaS providers and is incredibly easy to use. Besides, we had a great experience using Linode for a previous hack, and the free Linode credit from MLH for us to learn and build on Linode was the cherry on the cake! Linode is fast, flexible, and reliable, and we truly enjoyed using it, and we can say that Linode truly took our hack to the next level. 🟡Use Of Google Cloud🟡 We used Google Cloud Source Repositories, a Google Cloud product. This weeken"
      }
    ]
  },
  {
    "file_path": "./devposts/modo-mentor-matching.html",
    "project_id": "modo-mentor-matching",
    "title": "Impact Mentor Hub",
    "tagline": "Unlock Your Passion. Match with a Mentor. Build Something Real.",
    "hackathon": "",
    "built_with": [
      "ai",
      "css",
      "html",
      "javascript",
      "mongodb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/360/296/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 🌟 Impact Mentor Hub 🧠 Inspiration Impact Mentor Hub is inspired by the sustaining power of mentorship we've personally experienced—mentors have profoundly changed lives, including helping me gain admission to Stanford. Recognizing the impactful mentor network among Stanford students and alumni and beyond, we envisioned a digital platform dedicated to bringing these life-changing opportunities directly to underprivileged youth, thereby maximizing our social impact. 🚀 What it does Impact Mentor Hub is an AI-supported nonprofit platform connecting underprivileged middle and high school students with dedicated mentors, like those from Stanford. By assessing students' unique strengths, aspirations, and community contexts, our platform generates tailored project ideas focused on STEM, social entrepreneurship, and community empowerment. Leveraging advanced AI tools, we facilitate engaging mentorship experiences at scale, enabling personalized connections that inspire and empower youth. 🛠️ How we built it Our platform integrates cutting-edge AI tools: AI : Offers personalized and advanced project recommendations tailored to each student’s profile. MongoDB : Provides robust, scalable data storage ensuring efficient and secure management of user information. 11Labs : Enables realistic, AI-driven mentor interactions, allowing students to experience mentorship conversations virtually before engaging with real mentors. 🚧 Challenges we ran into A major challenge was accurately tailoring AI-driven project suggestions to reflect the genuine interests and environments of underprivileged youth. Extensive iterative testing and careful consideration of our positioning as an NGO or for-profit were crucial. Additionally, seamlessly integrating multiple AI solutions required rigorous coordination to ensure a cohesive, intuitive experience accessible to students from diverse backgrounds. 🎉 Accomplishments that we're proud of We're proud of successfully digitizing an established m"
      }
    ]
  },
  {
    "file_path": "./devposts/monkeysign.html",
    "project_id": "monkeysign",
    "title": "MonkeySign",
    "tagline": "Education for typing? What about American Sign Language (ASL)? It's not just inclusive, but also a fun application! MonkeySign teaches you ASL by practicing in real time through webcam!",
    "hackathon": "",
    "built_with": [
      "fast-api",
      "flask",
      "javascript",
      "pip",
      "python",
      "react",
      "socket.io",
      "tensorflow",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Citrus Hack 2023WinnerBest Tracks Hack \"New Frontiers\"",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/478/582/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 MonkeySign: The ASL Learning Arcade Game In our pursuit of expanding our skill set and exploring new territories, our team embarked on an ambitious project that combined machine learning, frontend development, and American Sign Language (ASL). Despite the challenges we faced, our passion and enthusiasm for the idea fueled our drive to successfully implement this unique and engaging concept! Project Overview MonkeySign is an innovative, game-like platform designed to teach American Sign Language (ASL) in a fun and interactive manner. Inspired by MonkeyType, a popular touch-typing training tool, we sought to create a similarly engaging experience for ASL learners, emphasizing education and social good. Core Features MonkeySign utilizes real-time hand gesture detection to recognize ASL letters signed by the user. As the user successfully signs each letter, they progress through the game, enhancing their ASL skills in an enjoyable and captivating environment. Technical Details Frontend We built the frontend using Vite and TailwindCSS, ensuring a smooth and responsive user interface. Backend Our backend leverages Flask and socket.io for seamless communication between the frontend and the machine learning model. Detection Algorithms To accurately detect and recognize ASL letters, we employed Handtrack.js for hand detection and a custom Convolutional Neural Network (CNN) model, specifically trained on ASL data for letter recognition. Challenges & Solutions Throughout the development process, we encountered several obstacles, including: Raspberry Pi Camera issues: Initially, our project involved using a Raspberry Pi Camera, which malfunctioned during the hackathon. We pivoted our idea to create a more engaging arcade-like experience instead. Model training difficulties: Our team spent 12 hours attempting to train a single object detection model. Eventually, we opted to use two separate models, one for hand detection and another for letter recognition. Bounding b"
      }
    ]
  },
  {
    "file_path": "./devposts/moody-6pgw91.html",
    "project_id": "moody-6pgw91",
    "title": "Moody",
    "tagline": "Good mental health is more than just the absence of mental illness. Visit Moody to leave your worries and anxieties behind.",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "html",
      "imovie",
      "intellij-idea",
      "procreate",
      "react",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The color theme and the music are inspired by a video game called Omori where the main character faces depression and goes on adventures with his friends to fight his inner demons. \nOur website aims at improving the mental state of our users, and it encourages users who experience similar mental health issues to relieve their anxiousness and leave it on the pages with us What it does We have 3 main features for our website. \nOur feelings quiz offers a variety of questions to determine our user’s mood, specifically looking out for signs of depression or relating issues. \nThis information is recorded in our second feature, which is the Mood Trend. This feature showcases the user’s mood daily, monthly,...etc to see how one’s mood is changed over time\nHaving a journal log readily available for users when they log in offers them to write about their worries, and potentially leaves them in a better mood after they visit the site. How I built it We used Figma to design our website in the demo\nThen we implemented our website using HTML and CSS for our frontend look \nWe also tried using react.js for the backend components of our website\nThere was the usage of Procreate for animations and designs, and iMovie to put everything together for the demo video. Challenges I ran into Our team faced multiple adversities within the duration of this competition, in part because it was all of our first times joining a competition as such.\n Initially, our team started off with 4 team members, Tasnim (Tasnim#9773), Rajib (rajib.khan#0837), Satyam(satyam2003#7531), and I. We got along well and were able to discuss the important factors of the projects as well as agree on the division of the workload. Satyam and I were put on the frontend aspect of our project, which included designing prototypes, and building the HTML and CSS part of the website, while Tasnim and Rajib agreed on working on the backend and developing the UI for our website. We had occasional meetings with each ot"
      }
    ]
  },
  {
    "file_path": "./devposts/motion-puilbh.html",
    "project_id": "motion-puilbh",
    "title": "motion.",
    "tagline": "motion. - Building Real-Time Multiplayer Quizzes with Notion",
    "hackathon": "",
    "built_with": [
      "firebase",
      "javascript",
      "notion",
      "svelte",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Education Technology Hack - 2nd Created by Sandeep Kandrigi Abhishek More Retired Hackathon Enjoyer",
      "Best Education Technology Hack - 2nd Created by Sandeep Kandrigi Abhishek More Retired Hackathon En",
      "Build4GoodWinnerBest Education Technology Hack - 2nd",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/821/227/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Quiz View Quiz View with 2 Players Home Page containing notion pages Quiz View Quiz View with 2 Players Home Page containing notion pages Quiz View 1 2 3 4 Inspiration Recent studies have shown that online games are beneficial for students to learn different queries. Not only is it fun, but it helps students to learn more about their subjects. As, such we'd like to combine this knowledge as well as with a common tool that students around the world use to take notes - Notion . What it does In order to do this, we wanted to make a real time game that involved selection of topics from the student's Notion page. We utilized ChatGPT to generate a collection of questions for students to use to study their notes. In this way, we were able to gain full usage of all of the different topics in the student's notions. How we built it We utilized Svelte + TypeScript for the frontend, along with SvelteKit, Firebase, and Axios for the backend.\nWe utilized Firebase in order to enable real-time using its concurrency handling. Challenges we ran into Using the Notion API was pretty difficult because the documentation is not very succinct and it takes a while to find what you’re looking for. Also, some of the versions of the API gave us errors because the documentation had outdated versions. Interfacing SvelteKit with Firebase was also difficult as it was our first time using this stack for our backend. Accomplishments that we're proud of Being able to get the quiz function to work with Firebase and ChatGPT API is something we’re pretty proud of, since we only had 8 hours. What we learned We learned that the Notion API has a lot of possibilities if you put time into learning stuff like authentication and rich text scraping. We also learned how to use Firebase with SvelteKit. What's next for motion. Scale it larger and integrate sign in with Notion authentication, allowing students to use their own notions in motion. Built With firebase javascript notion svelte typescript Try it out Git"
      }
    ]
  },
  {
    "file_path": "./devposts/mpox-map.html",
    "project_id": "mpox-map",
    "title": "Mpox Map",
    "tagline": "Website for tracking the recent Mpox outbreak with tools for data visualization, viewing news on the topic and signing up for alerts regarding the spread of Mpox.",
    "hackathon": "",
    "built_with": [
      "css",
      "mapbox",
      "nextjs",
      "react",
      "tailwind",
      "thenewsapi",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Solo Hack Created by First Solo Hack I hope you enjoy it :) Alex Dubljevic",
      "Best Solo Hack Created by First Solo Hack I hope you enjoy it :) Alex Dubljevic",
      "Ignition Hacks 2024WinnerBest Solo Hack",
      "Winner",
      "First Solo Hack I hope you enjoy it :)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/992/265/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Newsletter Sign Up Landing Page Mapbox Interactive Map Mapbox Interactive Map 2 Live News on Mpox Newsletter Sign Up Landing Page Mapbox Interactive Map Mapbox Interactive Map 2 Live News on Mpox Newsletter Sign Up 1 2 3 4 5 6 Inspiration The inspiration behind MpoxMap stemmed from my experience during the COVID-19 pandemic, where I often used tracker tools to stay informed about the spread of the virus in Canada. These tools proved invaluable, providing real-time insights and helping me make informed decisions. When the novel Clade 1 Mpox outbreak began making headlines, I searched for a similar tool but found none. This gap in the market motivated me to create MpoxMap, a web app for monitoring Mpox. I wanted to develop a resource that not only keeps people informed but also has the potential to save lives by raising awareness about Mpox, how it spreads, and how it can be detected. As this is my first hackathon, and I’m participating solo, I set out to build something practical I could see myself and others using after the hackathon ends, and that's how I landed on making MpoxMap. What it does MpoxMap is a user-friendly web app designed to help users effortlessly monitor the spread of the Clade 1 Mpox outbreak. With an intuitive user experience, the app makes it simple for anyone to navigate its features. It includes an explainer section that educates users on what Mpox is, alongside an interactive 3D Mapbox-powered map that visualizes both current and historical cases worldwide. The map is continuously updated with the latest data from the CDC, WHO and UKHSA, ensuring users have access to the most up-to-date information. Additionally, MpoxMap features a real-time news section that pulls the latest articles on Mpox from TheNewsAPI, keeping users informed of any new developments. To further enhance its utility, the app offers a feature where users can sign up for personalized outbreak alerts, ensuring they receive timely notifications about new cases in their select"
      }
    ]
  },
  {
    "file_path": "./devposts/movie-finder-tb5s26.html",
    "project_id": "movie-finder-tb5s26",
    "title": "SHOWS4U",
    "tagline": "A unique app that allow users to get incredibly personalized movie recommendations. By entering a search phrase and filters,  a list of movies and tv shows from various websites will be returned.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/019/124/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home Page Home Page Home Page 1 2 Inspiration The inspiration for our project comes from the lack of tailored search fields when browsing streaming platforms. It is common to run into a situation where a search yields no results. The purpose of our Movie Finder site is to provide users with accurate movie suggestions. What it does Our Project web-scrapes data with Python and displays the given data to the flask site after referencing the IMDB API. Our aim is to provide accurate results that adhere to the user's search, this is accomplished through web-scraping. What it does Our Project provides users with a personalized list of movie recommendations when they enter a search phrase. Our aim is to quickly provide accurate results which can be accomplished through web-scraping. How we built it For our app, we used the Flask framework and Python to build the site. For the frontend of the site, we used HTML, JavaScript, and CSS to design the interface. In order to provide a accurate search of the user's input, we would scrape Google for URLs and then implement a further web-scrape of shows. This data would be passed to the html site where we used JavaScript to generate the appropriate tile elements. Challenges we ran into One of the biggest challenges we ran into is the accuracy of web-scraping, where some of our results have to be filtered out. The second challenge we encountered is creating a flask app and deploying it to Heroku. This included setting up a Heroku app that deploys Flask applications and designing the layout of the app. A technical challenge we faced is the implementation of the IMDB API, where the request limit is 100 per day. This meant that at the time of submission, the API would be out of daily requests. In order to overcome this, we saved information from IMDB locally. Accomplishments that we're proud of An accomplishment we are proud of is our implementation of web-scraping. It took multiple trials and errors to find an efficient solution to findi"
      }
    ]
  },
  {
    "file_path": "./devposts/moody-s5ojpe.html",
    "project_id": "moody-s5ojpe",
    "title": "Moody",
    "tagline": "Good mental health is more than just the absence of mental illness. Come and visit Moody to leave your worries and anxieties behind",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "html",
      "imovie",
      "procreate",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "- Soundcore Motion+ Winner Dream Big and Create More Cheers with AB InBev - Anker Wireless Charger",
      "Civic Track - Soundcore Motion+ Winner Dream Big and Create More Cheers with AB InBev - Anker Wirel",
      "HackCWRU 2022WinnerCivic Track - Soundcore Motion+WinnerDream Big and Create More Cheers with AB InBev - Anker Wireless Charger Bundle",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The color theme and the music are inspired by a video game called Omori where the main character faces depression and goes on adventures with his friends to fight his inner demons. \nOur website aims at improving the mental state of our users, and it encourages users who experience similar mental health issues to relieve their anxiousness and leave it on the pages with us What it does We have 3 main features for our website. \nOur feelings quiz offers a variety of questions to determine our user’s mood, specifically looking out for signs of depression or relating issues. \nThis information is recorded in our second feature, which is the Mood Trend. This feature showcases the user’s mood daily, monthly,...etc to see how one’s mood is changed over time\nHaving a journal log readily available for users when they log in offers them to write about their worries, and potentially leaves them in a better mood after they visit the site. How I built it We used Figma to design our website in the demo\nThen we implemented our website using HTML and CSS for our frontend look \nWe also tried using react.js for the backend components of our website\nThere was the usage of Procreate for animations and designs, and iMovie to put everything together for the demo video. Challenges I ran into Our team faced multiple adversities within the duration of this competition, in part because it was all of our first times joining a competition as such.\n Initially, our team started off with 4 team members, Tasnim (Tasnim#9773), Rajib (rajib.khan#0837), Satyam(satyam2003#7531), and I. We got along well and were able to discuss the important factors of the projects as well as agree on the division of the workload. Satyam and I were put on the frontend aspect of our project, which included designing prototypes, and building the HTML and CSS part of the website, while Tasnim and Rajib agreed on working on the backend and developing the UI for our website. We had occasional meetings with each ot"
      }
    ]
  },
  {
    "file_path": "./devposts/molecode.html",
    "project_id": "molecode",
    "title": "Molecode",
    "tagline": "A ML model with a 90% accuracy rate in protein prediction.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/571/898/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "99% accuracy! Protein sequencing at your fingertips About us 99% accuracy! Protein sequencing at your fingertips About us 99% accuracy! 1 2 3 4 💡 Inspiration Drug discovery is at the forefront of biomedical research . Discovering new drugs allows us to combat various diseases, improve patient outcomes, and extend human lifespan. For instance, for users with high cholesterol, there exist specialized enzymes found in certain microorganisms which can break down cholesterol through targeted reactions. Identifying these cholesterol-degrading microorganisms in the environment would greatly improve the quality of managing cholesterol-related conditions, abating the increased risk of diabetes, kidney failure, and liver dysfunction. However, traditional methods to identify enzymes targeting specific substrates are costly, involving equipment such as NMR spectrometers, chromatography, X-ray crystallography, and mass spectrometry. NMR spectrometers range from $35,000 to $150,000 to purchase, with analysis costing $17 to $50 per hour. Mass spectrometry rates range from $60 to $560. This is the inspiration behind our solution, Molecode, which uses machine learning to substantially cut these expenses. ✨ What it does Molecode is an integrated API to a ML model we developed, which allows users to rapidly analyse protein sequences remotely and predict protein functions, with a 90% accuracy rate in our trained dataset (recognizing cholesterol degrading proteins). Process Upload: Upload a file in FASTA format. Decode: MoleCode’s AI software analyzes the provided enzyme sequences. Discover: Receive results at 90% accuracy! 🛠 How we built it Backend : Flask, Python Frontend : ReactJS, HTML, CSS Machine Learning : TensorFlow, Keras Data Engineering : NumPy, BioPython 📊 Data understanding We used a training dataset of 1977 protein sequences protein sequences - 727 enzymes in the cholesterol oxidase (oxidoreductase) class and 1250 related enzymes that do not exhibit cholesterol degrading a"
      }
    ]
  },
  {
    "file_path": "./devposts/modguard.html",
    "project_id": "modguard",
    "title": "ModGuard",
    "tagline": "An ML-aided chrome extension that filters toxicicity and NSFW content.",
    "hackathon": "",
    "built_with": [
      "node.js",
      "react",
      "tailwindcss",
      "tensorflow",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/712/389/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ModGuard Censoring Explicit Content Our icon Main Logo ModGuard Chrome Extension in Light Theme ModGuard Chrome Extension in (the better) Dark Theme ModGuard Diagram ModGuard Censoring Explicit Content Our icon Main Logo ModGuard Chrome Extension in Light Theme ModGuard Chrome Extension in (the better) Dark Theme ModGuard Diagram ModGuard Censoring Explicit Content 1 2 3 4 5 6 7 💡Inspiration The internet is an enormous wealth of information that has completely changed the way we all live our lives. As the internet thrives and grows, all sorts of people post all kinds of media. This influx of data and exposure could be harmful, especially if the content is not-safe-for-work (NSFW) content like pornography and gore. Modguard aims to solve this by using machine learning models to block NSFW images that may show up when browsing, on social media, or a sketchy ad. ❓What it does Modguard is a Chrome extension that uses lightweight Machine Learning models to scan the website DOM and identify inappropriate images with a 90% accuracy rating. Users can: select the \"tolerance\" of the model by adjusting the slider (the higher the percentage the more content the model will block) choose the type of content blocking (either remove, blur, or grayscale) whitelist websites that shouldn't be affected by the extension choose a color theme ⚙️ How we built it We're using ReactJS, Nodejs, and Typescript for our front-end of the extension. The main program is primarily programmed in Typescript. \nFor blocking NSFW content, we are using Tensorflowjs which compiles a lightweight model stored on the client-side called MobileNet. To classify the images along with the dataset, we are using NSFWjs , a JS client-side library that puts images into 5 different categories: Neutral Drawing Porn Hentai Sexy Depending on the tolerance selected by the user, the confidence interval between the categories shrinks or enlarges.\nTo bundle our site and release it to the user, we are using Webpack.\nFor tests, "
      }
    ]
  },
  {
    "file_path": "./devposts/moivebot.html",
    "project_id": "moivebot",
    "title": "MoiveBot",
    "tagline": "A semantic similarity chatbot trained on movie dialogs",
    "hackathon": "",
    "built_with": [
      "flask",
      "python",
      "spacy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Finishing my first AI project and understanding the theory behind semantic similarity"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I wanted to learn how to build a chatbot, but my local IDE and environments weren't working so I decided to work on a project on Colab. I came across a chatbot tutorial for Colab, and decided to follow/learn it. What it does MovieBot is a chatbot but only replies to you with movie phrases How I built it Made with help from a tutorial , Google Colab, Flask, Spacy, Python, and SimpleNeighbors Challenges I ran into Understanding the theory and math behind semantic similarity and reading the documentation to use updated versions of code Accomplishments that I'm proud of Finishing my first AI project and understanding the theory behind semantic similarity What I learned The theory behind chatbots, NLP, word and sentence vectors, cleaning/arranging data, etc. What's next for MoiveBot Moviebot is fundamentally a chatbot. If we train the chatbot with customer service data, support data, etc. you automate customer support for your business. Making an API for you to add the chatbot onto your website would also be great. Built With flask python spacy Try it out GitHub Repo Submitted to BackyardHacks Created by Ryan Lam UWaterloo Physics"
      }
    ]
  },
  {
    "file_path": "./devposts/modem.html",
    "project_id": "modem",
    "title": "Modem",
    "tagline": "Made for the modern woman.",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/806/207/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Connect Page Modem's Homepage Real Talk Page Working It Page Community Page Connect Page Modem's Homepage Real Talk Page Working It Page Community Page Connect Page 1 2 3 4 5 6 Inspiration From our own experiences, we've realised that female empowerment is a much needed way to build bridges in this world. As Michelle Obama once said, \"There is no limit to what we, as women, can accomplish.\" Women from all walks of life face different struggles and we were inspired to create a platform for these women to share their stories, learn from others and have a safe space to connect. Through our prototype, communities of women can come to a safe and inclusive space to overcome life challenges together. What it does Our website aims to empower and motivate women to strive for success in their life and careers. How we built it All of us worked collaboratively on Figma to create a High Fidelity Prototype. Challenges we ran into Although we didn't have a large time difference, we found it hard to consistently communicate with each other due to our busy schedules. Thus, we only managed to start brainstorming ideas and working on the project a day before submission. Accomplishments that we're proud of Despite the challenges we faced, we surprisingly got along with each other very well which was the main reason why we managed to submit a High Fidelity Prototype of a website that we're proud of (in less than 8 hours!!). What we learned As a group, we learned how to install new plugins on Figma to make prototyping easier. What's next for Modem We would create a functional website using HTML, CSS, Javascript based on this prototype Create an \"Events\" page where the Modem community could organise events or special trinkets on International Womens Day (8 March) Built With figma Try it out www.figma.com Submitted to StarHacks II Created by I did the navigation bar, Homepage, \"Real Talk\" and \"Working It\" pages which was really fun as I love designing websites and these pages were the basi"
      }
    ]
  },
  {
    "file_path": "./devposts/mobius-e7jidz.html",
    "project_id": "mobius-e7jidz",
    "title": "Mobius",
    "tagline": "Mobile Device Automation Agents",
    "hackathon": "",
    "built_with": [
      "adb",
      "android-studio",
      "fastapi",
      "langchain",
      "langgraph",
      "llama",
      "openai",
      "python",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/472/733/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Mobile automation is still stuck in the dark ages of complex scripting frameworks like Appium , making it inaccessible to non-developers and tedious even for experienced engineers. While tools like Operator and BrowserUse exist for browser automation , there is no equivalent for mobile devices . We set out to build Mobius , an autonomous smartphone agent framework that can execute any task on a mobile device, scale to a fleet of agents, and provide a well-documented API for developers to build upon . What it does Mobius is an agent-driven, fleet-ready automation platform that enables developers to: Run AI-powered agents on mobile devices —\"Buy me a pizza,\" \"Set up my phone,\" or literally anything you’d rather not tap through yourself. Scale across a fleet of devices —Deploy hundreds of agents handling different workflows in parallel. Seamlessly integrate via APIs —Build powerful applications on top of our shockingly well-documented automation stack. With just a few lines of code, Mobius makes mobile automation effortless: pixel7 = create_emulator ( 'pixel7' ) Mobius = create_controller ( ) Mobius . do ( pixel7 , \"Check my messages for any new messages from Brian\" ) Mobius . close_all_emulators ( ) Example Use Cases: AI-driven mobile assistants – Voice-controlled agents that interact with apps autonomously. Software Testing & CI/CD – Run automated UI/UX tests with natural language. User Experience Research – Simulate and analyze real mobile interactions. Enterprise Mobile Automation – Automate complex workflows across multiple devices. Fleet-based Automation – Scale operations across hundreds of mobile instances. How we built it AI Agent Core: Built on VLM-powered reasoning using LangChain + LangGraph for autonomous task execution. Mobile Automation: Android Studio + ADB for real-device interaction and app control. Fleet Infrastructure: Scalable architecture for parallel execution across multiple agents. On-Device Execution: LLM inference runs local"
      }
    ]
  },
  {
    "file_path": "./devposts/monitoring-hybrid-vtol.html",
    "project_id": "monitoring-hybrid-vtol",
    "title": "Monitoring Hybrid VTol",
    "tagline": "This project is a creative adaptation of the current Vtol design for environmental monitoring and surveillance to protect ecosystems and mitigate climate change using implemented sensors.",
    "hackathon": "",
    "built_with": [
      "3dprinting",
      "ardupilot",
      "autodesk-fusion-360",
      "c",
      "coreldraw",
      "cura",
      "lasercutting",
      "python",
      "solidworks",
      "xflr5"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/847/589/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Vtol testing of Ailerons Quadcopter drone in the air Quadcopter on the ground Monitoring Hybrid VTol Vtol testing of Ailerons Quadcopter drone in the air Quadcopter on the ground Monitoring Hybrid VTol Vtol testing of Ailerons 1 2 3 4 5 Inspiration Our team consists of members from the Flylanders, NJIT's SAE Aero Design Team. Our team is inspisred by aero design, leading us to create a hybrid VTol What it does The hybrid VTol used for environmental monitoring and surveillance. Sensor on the  drone detects humidity, air quality, and temperature which can be used to fight climate change. Facial detection was added to the VTol in order to identity civilians in natural disasters. How we built it XFRL5 was used to determine the aerodynamics and stability of the wing and tail configuration. SolidWorks was used to model the parts for fuselage, wing, and tail while CorelDraw and Trotec was used to laser cut the parts. Cura was used to slice Cad files into g-code for 3d printing. Foam sheets was prepared to form the shape of wing and tail.  The accelerometer, compass, gps, esc were calibrated using a Quadcopter built from a kit while the Vtol frame was prepared. Once the frame of the vtol and Challenges we ran into We faced several problems calibrating the quadcopter. Several attempts where made to calibrate the quadcopter before it was able to fly. Accomplishments that we're proud of Creating a hybrid Vtol within 24 hours. What we learned How to calibrate a Quadcopter and bend foam without fracturing it. What's next for Hybrid VTol Monitoring The Drone can be trained to detect objects such as invasive or endangered species. Quadcopter test flying on NJIT campus Link: https://www.youtube.com/watch?v=b8yrwz9hja4 Built With 3dprinting ardupilot autodesk-fusion-360 c coreldraw cura lasercutting python solidworks xflr5 Submitted to MakeNJIT Hardware Hackathon 2024 Created by Arick Iglesias Hannah Tariq-Shuaib Neel Adwani yeet Michelle Arce"
      }
    ]
  },
  {
    "file_path": "./devposts/my-awesome-project-6xbylp.html",
    "project_id": "my-awesome-project-6xbylp",
    "title": "My Awesome Project",
    "tagline": "It's a project that indulges in copious amounts of awesomeness",
    "hackathon": "",
    "built_with": [
      "cobol"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How we built it asdffdsafdsa Challenges we ran into Accomplishments that we're proud of What we learned What's next for My Awesome Project Built With cobol Created by Naveen Iyer I am a human and I live on Earth Abhishek More Retired Hackathon Enjoyer"
      }
    ]
  },
  {
    "file_path": "./devposts/motional.html",
    "project_id": "motional",
    "title": "Motional",
    "tagline": "\"Motion is All You Need\". Motional uses state-of-the-art motion capture technology to enable users to play games in radically new ways using machine learning.",
    "hackathon": "",
    "built_with": [
      "json",
      "mediapipe",
      "mongodb",
      "open-cv",
      "pygame",
      "pysimplegui",
      "python",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Gaming Related Hack Created by Jay Zhou Steven Gong Ayush Garg",
      "(Cradle) Best Gaming Related Hack Created by Jay Zhou Steven Gong Ayush Garg",
      "Hack the Valley 7Winner(Cradle) Best Gaming Related Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/253/382/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 💡Inspiration Gaming is often associated with sitting for long periods of time in front of a computer screen, which can have negative physical effects. In recent years, consoles such as the Kinect and Wii have been created to encourage physical fitness through games such as \"Just Dance\". However, these consoles are simply incompatible with many of the computer and arcade games that we love and cherish. ❓What it does We came up with Motional at HackTheValley wanting to create a technological solution that pushes the boundaries of what we’re used to and what we can expect. Our product, Motional, delivers on that by introducing a new, cost-efficient, and platform-agnostic solution to universally interact with video games through motion capture, and reimagining the gaming experience. Using state-of-the-art machine learning models, Motional can detect over 500 features on the human body (468 facial features, 21 hand features, and 33 body features) and use these features as control inputs to any video game. Motional operates in 3 modes: using hand gestures, face gestures, or full-body gestures. We ship certain games out-of-the-box such as Flappy Bird and Snake, with predefined gesture-to-key mappings, so you can play the game directly with the click of a button. For many of these games, jumping in real-life (body gesture) /opening the mouth (face gesture) will be mapped to pressing the \"space-bar\"/\"up\" button. However, the true power of Motional comes with customization. Every simple possible pose can be trained and clustered to provide a custom command. Motional will also play a role in creating a more inclusive gaming space for people with accessibility needs, who might not physically be able to operate a keyboard dexterously. 🤔 How we built it First, a camera feed is taken through Python OpenCV. We then use Google's Mediapipe models to estimate the positions of the features of our subject. To learn a new gesture, we first take a capture of the gesture and stor"
      }
    ]
  },
  {
    "file_path": "./devposts/monalisa-nft.html",
    "project_id": "monalisa-nft",
    "title": "MonaLisa NFT",
    "tagline": "MonaLisa NFT serves as a DeFi platform solution providing not only selling, buying, and exchange services, but also secure peer-to-peer digital asset lending.",
    "hackathon": "",
    "built_with": [
      "metamask",
      "moralis",
      "next",
      "react",
      "solidity",
      "testnet"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Challenge Prize Packages Created by I worked on the back-end",
      "Inclusive Data 2022WinnerChallenge Prize Packages",
      "We built our first smart contract and NFT marketplace!",
      "Introduce sidechain to secondary transactions to reduce user costs such as live gas prices",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/040/458/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Non-fungible tokens (NFTs) are a red-hot asset class in crypto. From the budding NFT creator to the collector, the growing economy NFTs have pioneered cannot be ignored. Problem Statement According to SkyQuest Technology, the Global NFT Market was valued at USD 15.70 Billion in 2021, and it is expected to reach USD 122.43 Billion by 2028, with a compound annual growth rate (CAGR) of 34.10 % during the forecast period of 2022 - 2028. Current service providers exist either marketplaces like OpenSea, Rarible, and Minty.Art, as well as P2P lending intermediaries such as Arcade & NFTfi. Yet, the recent recession has emphasized current systematic risks faced by both segments: Liquidity Risk One of the greatest impediments to NFTs is the lack of liquidity. As a non-fungible asset, there is no guarantee of a consistent demand for artwork. This is further exaggerated when the only way to receive ROI is through selling the NFT. Volatility Risk Reliance on cryptocurrency comes with inherent risks. As currency fluctuations rock, so do the valuations of NFTs. This is further compounded by external factors such as: Collection Scarcity and uniqueness Sudden Fluctuations due to popularity What it does MonaLisa NFT serves as a one-stop-shop solution for NFT market participants, with goals to equip your next door neighbor with the ability to not only sell, buy, and exchange digital assets with ease of mind, but also securely participate in peer-to-peer digital asset lending. How we built it We built this project using React and Next.js for the front end, solidity for creating smart contracts, Moralis to build our dApp with authentication to web3 wallet Metamask, and testnet for testing. Challenges we ran into Our team came to learn about decentralized finance, so we had to review and synthesize a lot of new information and understand new concepts in a short amount of time. Accomplishments that we're proud of We built our first smart contract and NFT marketplace! What we l"
      }
    ]
  },
  {
    "file_path": "./devposts/mommyvital.html",
    "project_id": "mommyvital",
    "title": "Gestational Care",
    "tagline": "Transforming Women's Health by Improving Pregnancy Outcomes!",
    "hackathon": "",
    "built_with": [
      "chakra",
      "node.js",
      "opencv",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/583/173/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "\"Gestational Care\" designs - Add New Workout modal About the Disease Some Problem Areas Doctor's Statement Tech Stack \"Gestational Care\" designs - Homepage \"Gestational Care\" designs - Start Workout page \"Gestational Care\" designs - Add New Glucose Reading modal \"Gestational Care\" designs - Add New Workout modal About the Disease Some Problem Areas Doctor's Statement Tech Stack \"Gestational Care\" designs - Homepage \"Gestational Care\" designs - Start Workout page \"Gestational Care\" designs - Add New Glucose Reading modal \"Gestational Care\" designs - Add New Workout modal 1 2 3 4 5 6 7 8 9 10 💡Inspiration Our team has always harbored a deep interest in leveraging technology to benefit societal health and well-being. When we delved into the complexities faced by women with gestational diabetes, it was a revelation. These strong, resilient women face a myriad of health challenges daily, including long-term risks to their own health and their baby’s. Understanding their plight made us ponder - what if there was a way to harness technology to offer them a simplified solution? This thought gave birth to GestationalCare, our ambitious project that seeks to transform women's health by improving pregnancy outcomes. The aim is clear: create a seamless digital tool to combat gestational diabetes, to empower these women, and `ensure their and their baby’s wellbeing. Dr. Musleh's insights especially stood out - the hurdles in compliance with logging blood sugar values. We felt the urgency and need to make this crucial process simpler, thereby improving prognosis significantly. 🤖 What it does GestationalCare offers a twofold solution: Blood Sugar Monitoring: Allows users to effortlessly log and monitor their blood sugar values. This real-time data helps healthcare professionals to keep a watchful eye and make informed decisions regarding the patient’s health.\nStaying Active: Through our internally hosted workout tool, we guide users through safe and effective exercises tailored fo"
      }
    ]
  },
  {
    "file_path": "./devposts/moneybank.html",
    "project_id": "moneybank",
    "title": "MoneyBank",
    "tagline": "An international identity verification platform that uses AI for KYC & AML enrollment and verification reducing processing time from weeks to minutes and better fraud prevention",
    "hackathon": "",
    "built_with": [
      "africa's-talking",
      "bootstrap",
      "css",
      "fsi-sandbox",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/952/565/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "MoneyBank Homepage Online Payment 2FA MoneyBank Application MoneyBank Application MoneyBank Registration MoneyBank Homepage Online Payment 2FA MoneyBank Application MoneyBank Application MoneyBank Registration MoneyBank Homepage 1 2 3 4 5 Inspiration We got the inspiration from personal experiences when dealing with online payments and identity verification. The stress involved in applying for KYC & AML on platforms as a means of user verification against fraud prompted us to innovate and find better ways to tackle the problem and the recent boom in Artificial Intelligence systems gave us a platform to achieve this goal. What it does Our solution uses Artificial Intelligence to determine if user documents used for KYC & AML enlistment are authentic and belongs to the claimed user, ensuring whoever makes a transaction is the real owner by comparing selfie to government-issued ID, further processing of user documents and verification of enrolled users as opposed to the traditional method of manual verification. We will also be implementing a 2FA verification systems for online merchants to take advantage of so they know the person they are dealing with is legitimate as a form of reducing online payment fraud. How we built it Since we are building for the web client, we made use of HTML, CSS, JavaScript, Bootstrap for the web Interface where users will interact with from time to time. While all the backend verification and processing along with the AI technologies were done with Python. Challenges we ran into We ran into initial challenges setting up the fsi-sandbox API but luckily the Python module reduced our workload and helped us accomplish our task. We also had problems with our UI arrangement but we scaled through in the end. Accomplishments that we're proud of We are proud that we are able to use our skills to help build solutions for better payment, fraud prevention and identity verification services. What we learned We learnt how to work with the fsi-sandbox a"
      }
    ]
  },
  {
    "file_path": "./devposts/mma-highlighter.html",
    "project_id": "mma-highlighter",
    "title": "MMA Highlighter",
    "tagline": "AI-powered MMA commentator delivers real-time play-by-play, analyzing every strike and move, enhancing fan experience with smart insights and live predictions.",
    "hackathon": "",
    "built_with": [
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by the need to enhance MMA viewing experiences with real-time, insightful commentary, making fights more engaging for both casual and hardcore fans. AI offers a perfect solution to capture complex fight dynamics and deliver smart, on-the-spot analysis. What it does MMA Highlighter uses AI to provide real-time commentary, analyzing strikes, moves, and submissions with precision. It also predicts fight outcomes and delivers key insights as the match unfolds. How we built it We used machine learning models trained on past MMA fights, leveraging natural language processing to generate real-time commentary. The system was built using Python, TensorFlow, and a custom-built data pipeline for fight analysis. Challenges we ran into We faced difficulties in accurately capturing the nuances of MMA, particularly with predicting the timing of moves. Training the AI to handle the unpredictability of fights and delivering meaningful commentary was also a challenge. Accomplishments that we're proud of We successfully built a real-time AI system that can break down fights and provide accurate, engaging commentary. Our model's ability to adapt to unpredictable fight dynamics is a significant achievement. What we learned We learned a great deal about the complexity of sports analysis and the importance of real-time data processing. Training AI to handle unpredictable, fast-paced environments like MMA fights was a major learning curve. What's next for MMA Highlighter We plan to improve the AI’s accuracy and expand its capabilities to other sports. Additionally, we aim to integrate fan interaction features, allowing viewers to ask questions and get instant insights from the AI commentator. Built With javascript python Submitted to Cerebral Beach Hacks – LA Tech Week 2024 Kickoff Hackathon Created by Mushtaq Mk Kartik Pandey AI innovator driven to tackle impossible challenges, bridging innovation, impact, and inclusion to create transformative solutions. Andr"
      }
    ]
  },
  {
    "file_path": "./devposts/munch-meals.html",
    "project_id": "munch-meals",
    "title": "Munch Meals",
    "tagline": "Eat more, save more",
    "hackathon": "",
    "built_with": [
      "figma",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The GoldenHack 4.0WinnerTop 5 Business Solutions",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/241/389/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration There are many places in the world that struggle to put food on the table. 35.5 Million tons of food get wasted every year, and that's just Canada alone. This is why we built Munch Meals. Munch Meals is a platform that allows restaurants to post their leftover food for users looking for something to eat. This allows restaurants to profit while consumers can benefit from gaining delicious food for a much cheaper price. How we built it We used Figma, React, Javascript, and Google APIs to integrate features such as maps into our application What we learned -Learned how to use interactions on Figma Projects almost always take longer than expected Learned how to use APIs such as Google Maps What's next for Munch Meals We'll implement a more diverse dietary restrictions option for more variety of consumers Built With figma javascript react Try it out GitHub Repo Submitted to The GoldenHack 4.0 Winner Top 5 Business Solutions Created by Worked on the pitch video and the programming functionalities Sean Wang I worked on the website design and interface. I also worked on creating the pitch video. E11ieK Kim Prasa . Bradley Herrera Contreras"
      }
    ]
  },
  {
    "file_path": "./devposts/my-website-t2rfh3.html",
    "project_id": "my-website-t2rfh3",
    "title": "My Website!",
    "tagline": "Website about me.",
    "hackathon": "",
    "built_with": [
      "css",
      "html"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "I tried my hand at web development, and I am proud of all the things I learned during this hackathon. I had absolutely no background in web development going into this hackathon, and I feel as though I have learned a ton. Hope you enjoy my website! Built With css html Try it out jacksonlippert.tech Submitted to DeltaHacks 8 Created by Jackson Lippert"
      }
    ]
  },
  {
    "file_path": "./devposts/mr-finder.html",
    "project_id": "mr-finder",
    "title": "MR.Finder",
    "tagline": "Your personal lost and found assistant powered by XR",
    "hackathon": "",
    "built_with": [
      "adobe-creative-suite",
      "aivideo",
      "figma",
      "miro",
      "premiere",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/238/396/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "wip- ui/ux prototype wip- building blocks wip- cognitive 3d SDK GIF cognitive 3D analytics wip- ui/ux prototype wip- building blocks wip- cognitive 3d SDK GIF cognitive 3D analytics 1 2 3 4 5 6 7 Inspiration Losing essential items is a universal frustration—whether it’s searching for your keys in the morning, managing a shared household inventory, or helping hotels and rental properties keep track of guest essentials. The lack of efficient and intuitive solutions inspired us to create Mr. Finder. By combining spatial memory reinforcement with cutting-edge XR technology, we aim to transform how people organize their spaces and locate lost items, bringing simplicity and peace of mind to everyday life. What it does Mr. Finder is a mixed-reality (MR) application that helps users locate misplaced objects by creating a spatially tagged inventory within a mapped environment.\nOrganize Your Space: Users take pictures of objects, categorize them, and tag their locations in a virtual representation of their environment.\nFind Items Instantly: Use voice commands or a virtual keyboard to search for items. The app guides users with immersive virtual markers and arrows anchored to real-world spaces.\nHotel/Host Use Case: For shared spaces, such as hotels or rental properties, hosts can pre-tag items (e.g., remote controls, toiletries, kitchen supplies) to simplify guest interactions and ensure inventory accountability. How we built it Technology Stack:\nUnity with MRTK (Mixed Reality Toolkit): For creating an immersive mixed-reality environment and integrating advanced interactions.\nMeta Quest All-in-One XR SDK: Leveraged extensively for passthrough capabilities, voice commands, spatial mapping, and real-time interactions.\nSLAM (Simultaneous Localization and Mapping): Used to create a precise virtual map of the room and anchor objects to real-world locations.\nWit.ai Voice SDK: Enabled intuitive voice-based commands for searching, adding, and managing objects within the app. Developme"
      }
    ]
  },
  {
    "file_path": "./devposts/motion-6ztw47.html",
    "project_id": "motion-6ztw47",
    "title": "Motion",
    "tagline": "Wellness Within Reach - Increasing Efficiency and Accessibility",
    "hackathon": "",
    "built_with": [
      "javascript",
      "movenet",
      "neuralnetworks",
      "openai",
      "python",
      "pytorch",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/632/939/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Value Proposition Title Technologies Value Proposition Title Technologies Value Proposition 1 2 3 Motion's Creation: Bringing Precision to Yoga Inspiration While exploring potential ideas, MoveNet caught our attention with its capabilities for accurately tracking human movement. We recognized an opportunity: to provide wellness within reach for all through real-time feedback. Motion aspires to make wellness accessible for all. By breaking down multiple barriers, Motion allows new segmentations to receive personalized training feedback without the cost of hiring a personal trainer. Future updates to the application will ensure that anyone, irrespective of language, economic, age, or location status, can benefit. Implementation We integrated a camera on our platform that effectively captures joint movements using MoveNet. To understand and analyze these movements, we utilized TensorFlow and PyTorch in our backend. Our approach involved two primary steps: Pose Prediction: Training a machine learning model to identify the specific pose a user attempts. Pose Correction: Training a subsequent model to detect inaccuracies in the user's pose. If a user's pose is deemed incorrect, our system uses OpenAI's GPT API to generate unique and personalized feedback, guiding them towards the correct form. Challenges & Insights Gathering diverse and representative training data posed a significant challenge. Recognizing that individuals have varying arm lengths, different distances from the camera, and diverse orientations, we aimed to make our system universally applicable. Although MoveNet expertly captures joint data in diverse scenarios, our initial model's training revealed a need for broader data. This realization led us to consider the myriad ways users might interact with our application, ensuring our model had a rich learning environment. Built With javascript movenet neuralnetworks openai python pytorch react tensorflow Try it out GitHub Repo Submitted to HackHarvard 2023 Cr"
      }
    ]
  },
  {
    "file_path": "./devposts/musify-6m2q7z.html",
    "project_id": "musify-6m2q7z",
    "title": "Musify",
    "tagline": "Music for all your moods... \nCheers you up, calms you down helps you relax",
    "hackathon": "",
    "built_with": [
      "express.js",
      "html"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/770/336/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Past Songs When you are angry... Main page... Past Songs When you are angry... Main page... Past Songs 1 2 3 4 Inspiration I always listen to music when I work... I need it to focus calm down and relax. This website will give you songs for all your moods based on your Spotify account details What it does It looks at your Spotify data and gives you song options based on what mood you choose. Angry gives you calming songs, Depressed gives you Happy songs... How we built it We used Expressjs and Html to build our remarkable state of the art website Challenges we ran into We couldn't make the API call and after hours of troubleshooting, it finally worked! Accomplishments that we're proud of We are proud of connecting the Frontend to the Backend. It took us a while but we did it. What we learned We learned how to make API calls to different APIs and receive the data. What's next for Musify We will display past songs, and use a live feed of your face to get your emotions instead of you choosing your emotions Built With express.js html Try it out GitHub Repo Submitted to Presto Hacks Created by Aravindkrishna Arivudainambi Ikshit Gupta"
      }
    ]
  },
  {
    "file_path": "./devposts/mush-up.html",
    "project_id": "mush-up",
    "title": "[C01] MUSH UP",
    "tagline": "Jump up from the soils through whirling debrees into the bright sky. Move alone or together. Help or betray eachother. Can you beat the record?",
    "hackathon": "",
    "built_with": [
      "blender",
      "horizon",
      "meta",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Horizon Worlds Category by Meta - Runner Up Created by David Dünnebier What you can imagine is what",
      "SensAI Hack - CologneWinnerHorizon Worlds Category by Meta - Runner Up",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/684/190/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration We were inspired by joyful vertical games like Doodle Jump, Mario, and the minimalist beauty of Monument Valley — but wanted to reimagine that upward-jumping experience in a mushroom-shaped world filled with playful interactions and hidden meaning. We imagined a world once full of vibrant mushroom life, now withering due to pollution. Players climb through mushrooms, trees, and cloudy skies to reach the SunShroom (the mushroom angel) and save the MushWorld — not just to win, but to bring life back by reaching the purest mushroom at the top. The game is designed to feel lighthearted and communal, yet carries a gentle narrative about recovery, curiosity, and interconnected effort — whether alone or with others. What it does MushUp is a multiplayer jump-up game for Mobile, VR, and PC, built in Meta Horizon Worlds. Players begin on the ground of a once-thriving mushroom world and must leap upward through layered environments — mushrooms, trees, and clouds — to reach the legendary Sunshroom, a glowing mushroom angel said to hold the power to heal the world. On their journey, players can ride snails, bounce off ladybugs, float with balloons and hot-air balloons — but must beware of aggressive birds that try to knock them down. The faster and higher you reach the Sunshroom, the higher your score — and the more you contribute to restoring the MushWorld. You can play solo or with friends, uncover hidden areas, or simply enjoy bouncing through the skies.\nEverything starts with one jump. How we built it We built everything from scratch in Horizon Worlds within 2 days.\nOur team of 2 developers and 2 designers collaborated closely on: World-building & environment design Scripting jump mechanics, NPC behaviors, and scoring logic Custom 3D asset creation for Mushroom, Tree, leaves, hot balloon, balloon, bird, ladybugs, final Sunshroom Avatar interactions, feedback systems Recording voice-over, sound effects, and trailer editing Challenges we ran into Designing a ve"
      }
    ]
  },
  {
    "file_path": "./devposts/munited.html",
    "project_id": "munited",
    "title": "Munited",
    "tagline": "a website for a music nonprofit",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/768/797/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration i love music, and i want there to a be a nonprofit that provides resources to more students who like music. What it does its a website that gives info on this nonprofit How we built it using languages Challenges we ran into formatting errors Accomplishments that we're proud of it looks sleek What we learned javascript and boostrap What's next for Munited even more interactiveness for users Built With bootstrap css html javascript Try it out replit.com docs.google.com Submitted to HackJA December 2021 Created by I worked on this front end website with Html, css, javascript, and boostrap. julia huang hackathon enthusiast and coder"
      }
    ]
  },
  {
    "file_path": "./devposts/myinsurance.html",
    "project_id": "myinsurance",
    "title": "MyInsurance",
    "tagline": "Connecting insurance clients with insurance representatives",
    "hackathon": "",
    "built_with": [
      "css3",
      "django",
      "html5",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First time making a full-stack web app using Django (literally learned it in the morning)",
      "Completing the first hackathon (Michael)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/506/464/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 MyInsurance - TOHacks 2021 Inspiration The frustration of staying on the phone for hours trying to book an appointment is felt by almost everyone. Eliminating this barrier is the first step towards improving the customer experience in the insurance industry, and MyInsurance was designed with that in mind. What it does MyInsurance is a booking web application in which customers can find, and talk to the best insurance brokers in their area. Meetings are scheduled with a click of a button and customers can reach a broker within minutes of registering. How we built it We had 3 backend databases where 1 centralized database interacted with the 2 other databases We got objects in the database matching our requirements to be displayed by using Django sessions We used form-like interfaces to allow users to work and interact with the data We built a UI/UX after having the backend and databases working Challenges we ran into Getting our databases to work together Navigating the Django workflow Getting our database to have pre-existing data set in it when starting the program Getting frontend to work with backend and backend to work with the databases Debugging and understanding Django error messages Accomplishments that we're proud of First time making a full-stack web app using Django (literally learned it in the morning) First time working with databases and SQLite3 Making a web app that is dynamic and interacts with our databases Linking various databases together Getting better at bootstrap and git Completing the first hackathon (Michael) What we learned We learned how to use the Django framework to make a web app We learned how to work and use a database (specifically SQLite3) We learned how to have multiple web pages, route different paths, and have dynamic forms on the same page What's next for MyInsurance Adding a chat feature between the client (customer) and the representative Add a rescheduling feature so clients or the representative and reschedule and cancel"
      }
    ]
  },
  {
    "file_path": "./devposts/myridepal.html",
    "project_id": "myridepal",
    "title": "myRidePal",
    "tagline": "Tired of expensive gas prices and overpriced Ubers? MyRidePal is the perfect solution for you! You can match with other people to carpool, so you can save money and reduce your carbon footprint.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DivHacks 2022: GreenscreenWinnerBest “Climate Change” Hack",
      "Winner",
      "I worked on Logo Design and UX/UI design. It was my first hackathon and I learned a ton!",
      "I worked on prototyping our app on Figma. This was my first hackathon and I enjoyed it a lot!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/236/611/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration When we were brainstorming ideas for our project, we started talking about how expensive Uber and gas prices are. Then, that was when the idea came to us. We realized we could make a carpooling app the matches people going the same destination. This way, people can save money and reduce their carbon footprint. What it does You can make requests for rides, and if your on the way for someone, then they can reach out to you and offer a ride. How we built it We used SwiftUI and Xcode to develop the front end functionalities of our app. Some of the front end functionalities include the profile page, a page that displayed other people’s ride requests, and a pop up form to submit your own ride requests. In addition, we used Firebase cloud as our backend and created a schema for the request object. The schema included several elements, including the users current location, where they are trying to go, and what time they want to leave. Challenges we ran into One challenge we ran into was brainstorming. For most of us, it was our first time in a hackathon, and brainstorming was especially difficult. It by 5pm the first day, we still didn't have an idea. It was really frustrating and concerning, because we questioned whether we would even have time to finish a project. Fortunately, the idea just came to us, and everything was a much smoother process. We realized that we shouldn't stress too much about our project, and just go with the flow. Everything eventually came together, and it gives us a lot more confidence going forward for future hackathons. What's next for myRidePal Right now, the app is made so that you can offer rides to anyone. However, we believe that people can feel uncomfortable carpooling with random people. We want to avoid that concern by catering the app to college students. Basically, you would only be able to help to see ride requests from other students who go to the same college as you. This is more practical because college students are usu"
      }
    ]
  },
  {
    "file_path": "./devposts/n-a-amfwyr.html",
    "project_id": "n-a-amfwyr",
    "title": "The Green Project!",
    "tagline": "Our program aims assist individuals in finding out about their countries climate and how they can help prevent rising temperatures.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "matlab",
      "pandas",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/995/715/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "The Green Coders The Green Coders The Green Coders 1 2 Inspiration All of our homelands and families have been drastically affect by the monster known as climate change. The Green Coders want to spread awareness about the potent negative effects and solutions to global warming. What it does Our program uses non-linear regression to predict future temperatures for given country and year. The program then gives potential solutions for the average person to deter climate change in their region. How we built it We found data about average historical climate temperatures for various countries from the University of East Anglia. When then used non-linear regression to predict future temperatures for a given country at a given year. Challenges we ran into Struggled to find accurate and reputable climate data. We also struggled to create an accurate model for non-linear regression. Accomplishments that we're proud of We created an aesthetically pleasing website to display our data and program. What we learned We learned about trends in data and how fast its effects are increasing. On top of this, we learned about solutions to slow down the process of climate change. What's next for The Green Project! We will continue to work on projects to spread awareness about climate change and create solutions. Built With css html javascript matlab pandas python Try it out GitHub Repo Submitted to TOHacks 2022 Created by Adam Begagic Varun Sahni Kwanada 89 Florian Kasperbauer"
      }
    ]
  },
  {
    "file_path": "./devposts/myhealthcehr.html",
    "project_id": "myhealthcehr",
    "title": "MyHealthcEHR",
    "tagline": "Have you ever accessed your health records digitally? I know I haven't because it doesn't exist! Until now...",
    "hackathon": "",
    "built_with": [
      "cohere",
      "java",
      "javascript",
      "mysql",
      "postman",
      "react",
      "springboot"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/473/047/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Account Details Pharmacy Information Clinical Reports Immunization Records Lab Test Login Page Account Details Pharmacy Information Clinical Reports Immunization Records Lab Test Login Page Account Details 1 2 3 4 5 6 Inspiration One of the main requirements that patients look for in their healthcare providers is clear and effective communication about information such as their medical conditions, treatment options, and potential side effects. One of the places where such information is stored is on a patient’s health record. An electronic health record (EHR) is a secure and private lifetime record of your health history. It gives your healthcare team, including family doctors, nurses, emergency room clinicians, and specialists, real-time access to your relevant medical information, so they can provide the best care for you. As a patient, you - or your substitute decision-maker - have the right to access a copy of your personal health information. However, according to eHealthOntario, patients do not have digital access to their EHR as relevant information is decentralized. This means that in order for a patient to access their information, they will need to contact various organizations individually. What it does Our platform aims to revolutionize healthcare by centralizing patients' electronic health records, enabling them to access their medical information in one place, saving time, reducing costs, and improving healthcare quality. Currently, patients have to contact multiple organizations individually to access their EHR, but with our platform, this process becomes more streamlined and efficient. How we built it Our team built a digital dashboard for accessing electronic health records (EHRs) using MySQL for the database, Spring Boot for the backend, and React for the frontend. MySQL was chosen for its ability to manage large volumes of data, while Spring Boot provided features for enterprise-level development. React's component-based architecture was leveraged"
      }
    ]
  },
  {
    "file_path": "./devposts/myrecipepal.html",
    "project_id": "myrecipepal",
    "title": "MyRecipePal",
    "tagline": "Unlock your inner chef skills!",
    "hackathon": "",
    "built_with": [
      "chakraui",
      "cockroachdb",
      "express.js",
      "javascript",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "track"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/223/631/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home page of the website Inspiration As university students, we all understand that one of the biggest struggles of living by yourself is cooking food. We wanted to make it easy to find and craft new recipes, while still eating healthy. What it does With MyRecipePal, we make it easy for you to find new recipes to try. By filtering using your preferences, allergies, and cooking time, it's ensured that you will always find the right recipe for you. MyRecipePal allows you to eat healthier, save time, and improve your cooking skills all at the same time. How we built it We used React, JavaScript, ChakraUI, and Bootstrap for the frontend. For the backend. we used  CockroachDB and Express, Challenges we ran into Before hacking started, one of our teammates felt sick and had to go home. Without him, a lot of our planning and ideas had to be delayed and reinvisioned. He was a big part of keeping our team together and energized throughout the night, so we were all discouraged from him leaving. Accomplishments that we're proud of Instead of giving up, we took the loss of a teammate with even more determination to win. We utilized our resources, such as discord for communication, to help us continue moving forward with our project. As a result, we still managed to go beyond our expectations and make considerable progress on our project What we learned Some of the skills we learned included using a new, serverless database, experimenting with a different css framework, and how branches and pull requests can improve your project. Aside from tech-related skills, we’ve learned how to be flexible and push through challenges. It’s very rare that things will go according to plan. As long as you’re flexible and determined to do what it takes to move forward, you will be successful. What's next for MyRecipePal In the future, we hope to add: Accounts/login system Forums for people to talk about recipes and health A tracker that keeps track of your meals, calorie intake, etc Built With c"
      }
    ]
  },
  {
    "file_path": "./devposts/mycancer.html",
    "project_id": "mycancer",
    "title": "Cancare",
    "tagline": "An app containing all of the information a patient will ever need throughout their cancer journey.",
    "hackathon": "",
    "built_with": [
      "axios",
      "css3",
      "deso",
      "glidepages",
      "html5",
      "javascript",
      "materialui",
      "react",
      "tables"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Popular Choice Hack Winner Best Use of DeSo Created by Frontend and using DeSo",
      "HealthHacks Presented By PennApps x Wharton Undergraduate Healthcare ClubWinnerPopular Choice HackWinnerBest Use of DeSo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/876/185/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Dashboard Dashboard 1 2 3 4 5 6 7 8 💡Inspiration More likely than not, many of us will have a brush with cancer either ourselves or a loved one in our lifetime. The American Cancer Society states that in 2022, there will be an estimated 1.9 million new cancer cases diagnosed and 609,360 cancer deaths in the United States. Our teammate Hailey's mother and both grandmothers were both diagnosed with cancer, and another teammate, Kanha, had both grandparents diagnosed with cancer as well. Once the diagnosis comes, there are thousands of thoughts running through the patient’s mind, and there are many things to take care of. On top of this, the patient has to deal with keeping track of all the information you get along the way during your cancer journey. In Hailey's mom’s case, there was a lot of paperwork involved, a lot of calling different doctor offices for results, copies of results, and more. After all that, years later, Hailey’s mom can’t remember off the top of her head when her surgery was, who her doctors were, or even the important dates involving her cancer. So when she goes to a new doctor, she has to dig up and call around for all of the information. This is not a unique situation. Each year in the United States, more than 1.6 million people are diagnosed with cancer and struggle with this same issue. Cancer patients have nowhere to store all of their information, resulting in disorganization and stress. This is where our inspiration comes from. We believe an app is needed to keep track of everything related to your own personal cancer journey. It's a place where everything is saved, and if you beat cancer and still need your medical history information for whatever reason, it's all right there and easily accessible. ⚙️ What it does The app will essentially contain all of the information a patient will ever need throughout their cancer journey. It will track the patient's entire journey, from the moment they are diagnosed, through the course of treatments, a"
      }
    ]
  },
  {
    "file_path": "./devposts/nani.html",
    "project_id": "nani",
    "title": "What's with the narrator?",
    "tagline": "You follow the Narrator to explore a text-based world, but... you are repeatedly killed. Every death and reset gives you more clues: collect enough before the end to make a choice you won't regret.",
    "hackathon": "",
    "built_with": [
      "eclipse",
      "java"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/836/394/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Oh? What does the Narrator know? Omg a tree! (Ignore the person) It's a shame I don't know how to delete/refresh the console in the middle of a program Oh? What does the Narrator know? Omg a tree! (Ignore the person) It's a shame I don't know how to delete/refresh the console in the middle of a program Oh? What does the Narrator know? 1 2 3 4 Inspiration The three members of our team all liked to play games, and we especially liked indie games that reached beyond the cliche. The inspiration for What's with the narrator? comes from games that have a twist on a classic trope such as Slay the Princess -- which features an unreliable narrator that causes mistrust in the player -- and The Princess Gayme -- where the hero is an ordinary woman that the princess falls in love with. All of these games were highly influential in our decision to make What's with the narrator? . What it does Users can run the game and follow the narrator through multiple scenes that allow them to choose between a couple of options. Those options will lead them to reach either the end of the game or their repeated death. This game is unusually harsh towards the player, often ending in death rather than survival, however, with every death, the game also resets and repeats. How we built it Using the Eclipse IDE, we coded the game using functions within the Java library to allow for multiple branching of different storylines to unfold (all members are beginners in Java coding). Challenges we ran into Collaborating between all members of the group on a single piece of code was rather difficult. As novice coders, we had a multitude of issues trying out different software, such as Unreal Engine, Unity, and Github that allowed for collaboration. Also, keeping track of where the logic of the game was leading was difficult as well. Accomplishments that we're proud of Being able to delegate tasks and help support each other in each of our time of troubles. What's next for What's with the narrator? We hope"
      }
    ]
  },
  {
    "file_path": "./devposts/neibur.html",
    "project_id": "neibur",
    "title": "NeiBur",
    "tagline": "Like a good NeiBur, Zip codes are here!\nWe appeal all local environment to uplift + empower neighborhood to communicate their skills, requests, and sales directly to virtual market for and by locals!",
    "hackathon": "",
    "built_with": [
      "api",
      "css",
      "figma",
      "firebase",
      "html",
      "midjourney",
      "next.js",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/293/673/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo! Landing Page Interface / Alert / Services page Logo! Landing Page Interface / Alert / Services page Logo! 1 2 3 Inspiration We wanted to provided avenues for communities to come together with their skills, knowledge, queries, and emergencies that only local individuals would understand. Not all large supermarkets and wide scaled big services can fit the individualistic needs and normally cause frustration gradually in absence of said opportunities. What it does The user would put in their location via Zip Code and an interactive page would denote relevant locations, alerts, and services that the community has posted in a clean, easy to use, interact. How we built it Design : Figma, Midjourney\nFront End : Html, next.js, css\nBack End : Firebase hosting and database Challenges we ran into Deprecation of various tedious issues halted the progress in learning full stack development. Accomplishments that we're proud of We developed and pulled through a functional design that is demo ready (to an extent!). Having fun working through various tutorials, attending workshops, and tossing the adorable plushie. What we learned The complexities and interactions between all components is dependent on versions and we learned that utilizing tools that mitigate the time sink required would have been optimal to do at the start. What's next for NeiBur Scalability implementation and functional deployment. Built With api css figma firebase html midjourney next.js sql Try it out GitHub Repo Submitted to HackUTD IX Created by Joshua Chong Hoai Dinh Christian S Ethan D hackathon enthusiast specializing in NLP/LLMs"
      }
    ]
  },
  {
    "file_path": "./devposts/mytherapy-space.html",
    "project_id": "mytherapy-space",
    "title": "MyTherapy.Space",
    "tagline": "A platform to help patients connect with their therapists during COVID-times",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css3",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Best Domain Registered with Domain",
      "First Place Winner Best Domain Registered with Domain",
      "Hackabull 2021WinnerFirst PlaceWinnerBest Domain Registered with Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/431/753/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "NOTE: Our domain for the domain name challenge is mytherapy.space\nWe weren't able to register the domain because domain.com wasn't working. Stephen (from MLH) said in the help-desk discord channel that we could still complete in the challenge Inspiration We took the idea from this harsh time during the pandemic. Many people are in need of mental and wellness support. We decided to build an application that can connect patients to their therapist and allow them to do daily wellness/mental health check-ins What it does Our websites allow patients to submit daily check-ins/information to their therapist. The patient and therapist can then see the information submitted by the patient. The therapist will also be able to analyze the patient's data and provide tips/tricks/advice to said patient How we built it We built it using HTML, CSS, JavaScript, Python, Flask, and Bootstrap Challenges we ran into Figuring out how to send data back and forth from the frontend to the backend was the hardest challenge that occurred because the frontend and backend used 2 completely different programming languages Getting the website to continuous update itself so the user interface was dynamic (when the person entered information, they could instantly see that data processed and displayed) Accomplishments that we're proud of Getting the website to be dynamic Getting a fully functional UI for the patient dashboard What we learned Got better at using Flask (sessions, app.route, etc.) Learned how to store/send/receive information with Flask Graphing a graph What's next for MyTherapy.Space Build a better UI for the therapist dashboard Add customizable questions that the therapist can set Built With bootstrap css3 flask html5 javascript python Try it out GitHub Repo Submitted to Hackabull 2021 Winner First Place Winner Best Domain Registered with Domain.com Created by Ryan Lam UWaterloo Physics Jax Wang uwo 24' intermediate FE"
      }
    ]
  },
  {
    "file_path": "./devposts/nagaguard.html",
    "project_id": "nagaguard",
    "title": "NagaGuard",
    "tagline": "We aim to help local clinics and hospitals by optimizing the clinical coding process. 🏥",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "figma",
      "flask",
      "gemini",
      "javascript",
      "mysql",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Startup Created by I worked on the front end for this project",
      "Bearhack 2024WinnerBest Startup",
      "Our project reduces management time to just seconds by AI transcribing clinical codes.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/866/650/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Doctor Login App Logo Doctor/Patient Login Doctor Login App Logo Doctor/Patient Login Doctor Login 1 2 3 4 💡 Inspiration Local clinics and hospitals devote almost 50% of resources and several hours daily to data management. 💥 What it does Our project reduces management time to just seconds by AI transcribing clinical codes. 🛠️ How we built it Integrated Gemini AI in ReactJS front-end Saved patient/doctor data via MySQL Flask/Python for the backend 🧗‍♀️ Challenges we ran into MySQL database was tedious to set up Had to format several sections for each medical record 🏆 Accomplishments that we're proud of Transcribed records into clinical code using only ChatGPT Instantly present readable clinical notes to patient Figured out MySQL in 6 hours 📚 What we learned Choose a tech stack that works on everyone's machines before starting Stick to one goal before fusing goals within a 24 hour span If software setup takes too much time, try alternate stacks 💭 What's next for NagaGuard Integrate AI medical assistant for on-demand patient side Partner with clinics and hospitals to expedite clinical coding process Built With bootstrap figma flask gemini javascript mysql python react Try it out GitHub Repo Submitted to Bearhack 2024 Winner Best Startup Created by I worked on the front end for this project. I implemented Bootstrap and CSS for styling and conducted research for the color theme and background idea for the program name and mascot Aurelisa Juan Vouloir, c'est pouvoir. I worked on the frontend to provide an engaging UI/UX of the application. I utilized Bootstrap along with CSS in designing and draw some elements to support the UI/UX.  Those includes the mascot, logo, headers, and etc. Aurelia Sindhu 아이스 아메리카노 ☕️ I worked on both the front end and backend. I set up our database with MySQL to keep track of medical records and patient data and used Flask to connect our backend to the front end. I set up the front end with React components for functionality. Ethan Santos Rian "
      }
    ]
  },
  {
    "file_path": "./devposts/news-scraper.html",
    "project_id": "news-scraper",
    "title": "News Scraper",
    "tagline": "Usually when a person searches a topic on Google, the results are personalized, which may result in misinformation. Therefore, we present all information regarding the topic through a Chrome Extension",
    "hackathon": "",
    "built_with": [
      "javascript",
      "material-ui",
      "newsapi",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/347/626/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "News Scraper Logo News Scraper Logo News Scraper Logo 1 2 Inspiration We were inspired by the documentary, The Social Dilemma, and current political events... What it does It aims to provide different political news sources from the information the user has googled. How we built it Javascript, CSS, HTML, Node.js, React, Material-ui, News-API Challenges I ran into We were not able to connect the google search to updating the list of links. Accomplishments that I'm proud of We are proud about making chrome extensions, extract what the user searched on google, and how much we did in one day. What I learned We learned about the files that make up chrome extensions, web development, and working with APIs to scrape & process data. What's next for News Scraper We plan to implement a notification after a search has been completed and connecting the google search and scraped data to what needs to be displayed. Built With javascript material-ui newsapi node.js react Try it out GitHub Repo Submitted to CruzHacks 2021 Created by Chinmay Gowdru Tony Yang Ivan Diep DanteBrundage"
      }
    ]
  },
  {
    "file_path": "./devposts/nexuswrap.html",
    "project_id": "nexuswrap",
    "title": "NexusWrap",
    "tagline": "Streamlining efficiency with conditional wrapping based on inter-ledger protocol:Shaping the future of blockchain transactions",
    "hackathon": "",
    "built_with": [
      "api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Challenges we ran into: As it was the first time for most of us, we faced hurdles in the ideation."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration:\nOur team aimed to address the challenge of rethinking the facilitation of seamless and secure transfer of digital assets across different blockchain networks through token interoperability. What it does:\nOur project addresses the challenge by striking a balance between these two transaction flows to improve flexibility in transaction modes and create opportunities for integration with public blockchains through dual modes and conditional token wrapping. How we built it:\nOur project uses cross-chain bridging with several key features, namely the use of Dual-Mode Operations, Automated Market Makers, Support for Interledger Protocols, XRP Ledger, and Security and Compliance. Challenges we ran into:\nAs it was the first time for most of us, we faced hurdles in the ideation. Accomplishments that we are proud of:\nWe worked together to research and ideate, coming up with a solution to the challenge. What we learned:\nIncreased our knowledge in fintech through the research phase. Built With api Try it out drive.google.com Created by Siyi Xu :)"
      }
    ]
  },
  {
    "file_path": "./devposts/napkinmatic-ai3d.html",
    "project_id": "napkinmatic-ai3d",
    "title": "Napkinmatic AI3D",
    "tagline": "Turns your napkin sketch automatically into something AI magical - from masterpiece paintings to 3D models and beyond!",
    "hackathon": "",
    "built_with": [
      "android",
      "c#",
      "css",
      "ios",
      "javascript",
      "lamp",
      "modelviewer",
      "realityscript",
      "revenuecat",
      "three.js",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/808/566/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "A screenshot showing sketch to image with slider and the AI3D generated model Napkinmatic AI3D icon logo A screenshot showing sketch to image with slider and the AI3D generated model Napkinmatic AI3D icon logo 1 2 3 4 5 6 7 8 ***** After some intense of R+D iterations with multiple SIGGRAPH pubs, indie dev depression and recharge, metamorphosis of sketches and ideas etc, com.ai3d.napkinmatic aka Napkinmatic AI3D is now finally on the App Store and Google Play! ***** Inspiration Everyone doodles on napkins — in cafés, classrooms, airports, and meetings. It’s a universal act of casual creativity. But what if those doodles didn’t stay trapped on paper? What if they could instantly transform into: a masterpiece painting , a 3D model you can rotate, export, or print, a website or an app (coming soon - vibe code on a napkin!), or even a video projected on a Times Square billboard ? Napkinmatic was born from this question: turn everyday sketches into extraordinary creations. It reimagines what AI, AR, and transparent interfaces can do when grounded in the simplest act — drawing on a napkin. What it does Napkinmatic is an iOS + Android app that transforms napkin sketches into magical outputs using AI + 3D + AR. Core Features: Sketch Capture: Take a photo of your napkin doodle or upload from your gallery. Command Plane Overlay: Napkinmatic augments your sketch with an interactive UI directly on top of it. AI Transformations: /image2painting → masterpiece version of your doodle /image2mesh → interactive 3D model (pop-out-of-paper reveal) /image2video → animated billboard-style video Sharing & Virality: Every creation generates a permalink . Users earn Coins for unique views of their permalink, rewarding them for sharing. Viral sharing = organic growth + creative rewards. Monetization via RevenueCat: Buy Napkin Credits , which convert into Coins . Example costs: 5 coins for paintings, 90 coins for 3D. Hybrid model: casual users buy coins, power users subscribe for monthly bund"
      }
    ]
  },
  {
    "file_path": "./devposts/neuro-journal.html",
    "project_id": "neuro-journal",
    "title": "NeuroJournal",
    "tagline": "Journal to write on stress. Natural language processing to detect the words and chatbot to support the user.",
    "hackathon": "",
    "built_with": [
      "brainflow",
      "chatterbot",
      "muse-lsl",
      "pyqt5",
      "python",
      "sklearn",
      "streamlit",
      "tensorflow",
      "tensorflow-bert"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/097/632/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "How the app generally works Screenshot of our app Data pipeline of the stress sentiment analysis model How the app generally works Screenshot of our app Data pipeline of the stress sentiment analysis model How the app generally works 1 2 3 4 About the project [BRIEF] NeuroJournal has been working on a stress detection application which incorporates users’ brainwaves (EEG).The user journals a stressful event, which is siphoned through natural language processing (NLP). After associating the waveform with the experience of stress, this can be used to suggest a remedy or further involve a professional. Currently, the app can collect user input (text), determine stress level and make relevant suggestions to the user. [CODE ARCHITECTURE] We mostly programmed in VS Code while utilizing Python as the main language. PyQt5 boilerplates were used to record EEG data from Muse and openBCI hardware, which was further processed using the EEGrunt library. Our web app was built on Streamlit. It includes a journaling (user input) page, an About Us page, and an embedded Chatterbot. The libraries used for NLP were tensorflow, pandas, numpy, sklearn, nltk, tensorflow-bert, matplotlib, seaborn, Re, string, logging. We trained the BERT sentiment analysis model using logistic regression, SVM, random forest and neural networks techniques on the Dreaddit dataset. To train the model in BERT, we predicted 15% of the tokens in the training data, which were randomly picked. [PRODUCT] Seed funding will be used towards: Research and Commercialization: We hope to turn this into a research initiative by collecting more EEG datasets and working with startups and clinicians to design healthcare plans for those who have high anxiety/stress. Community: This could be used as a mental health service or a way to build a community to share experiences of other individual’s journals. Inspiration The biggest barrier to crisis response is feeling helpless even if you open up and say something it's not going t"
      }
    ]
  },
  {
    "file_path": "./devposts/nibble-y970t4.html",
    "project_id": "nibble-y970t4",
    "title": "Nibble",
    "tagline": "Find the perfect food for you!",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "css",
      "figma",
      "flask",
      "google-geocoding",
      "google-maps",
      "html",
      "postgresql",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "🌐 Best Domain Name from Domain.com"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/008/184/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "sample profile Create Account Dietary Restrictions Find a restaurant Calorie Counter sample profile Create Account Dietary Restrictions Find a restaurant Calorie Counter sample profile 1 2 3 4 5 6 Inspiration Food insecurity is a common issue, especially amongst college students. Many of them have allergies or dietary restrictions, and this makes it harder for them to find perfect meals. According to a study by Temple University's Hope Center for College, Community, and Justice, 45% of college students surveyed deal with food insecurity. This statistic depicts how difficult it is for students to satisfy their basic need to eat. And students with dietary restrictions face even more problems, especially since college dining halls often don't have many food options for them. This inspired us to create Nibble, which is website that will help students to find the perfect place to eat, according to their dietary restriction(s). What it does Our website, Nibble, helps students get easy access to the food they need. Once the user comes to our website, they will have the option to create an account or login. If they want to create an account, they'll need to fill in their personal info (name, email, etc). Then, they will be asked about their dietary restrictions, if they have any, and their profile will be created. Once the user has an account, they can browse for places to eat, such as restaurants, cafe, etc. The Google Maps API implemented will get the user's location, and scout for nearby restaurants, which best fits with their dietary restrictions. The user can also see the ratings and reviews for the restaurants provided. These ratings are specific to the dietary restriction of the user, setting Nibble apart from other food review apps since ratings are calculated from reviews across all users with that specific dietary restriction. Furthermore, the user can keep track of their daily calorie intake, using the calorie counter. We hope our website will give more options/t"
      }
    ]
  },
  {
    "file_path": "./devposts/newsflix.html",
    "project_id": "newsflix",
    "title": "Newsflix",
    "tagline": "Removing the bias from media, ensuring that young readers have access to holistic, reliable information regarding current world issues.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "flask",
      "javascript",
      "openai",
      "postman",
      "python",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/974/735/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Our inspiration behind this project stemmed from our own experience with social media and the consequences it can have on young impressionable youth. So often, kids and teens are oblivious to misinformation and bias that exists in the media. With Newsflix, we were committed to building equitable learning opportunities , creating a platform that could provide inclusive and deeper understandings. What it does Newsflix is an interactive, curated web application designed to broaden users' political perspectives. Our unique personalized approach ensures accessibility for our intended audience, promoting nuanced learning across all ages. Users begin by selecting an age level, which sets the application's literacy level. A live news catalog page then allows users to browse trending political topics. After choosing multiple articles from various news outlets, the application generates a comprehensive analysis, highlighting the political bias of the articles and providing a newly generated unbiased summary. How we built it On the frontend, we built Newsflix using React.js and styled it using Tailwind CSS for a dynamic and appealing user interface. On the backend, we integrated Python's Beautiful Soup package to collect real-time news article data from current web pages. The parsed information was then analyzed by an AI algorithm powered by OpenAI to assess political metrics and generate an unbiased summary. Finally, this information was connected to our frontend for deployment to users. Challenges we ran into ChatGPT's inability to browse links on the internet presented a significant challenge during development. Our article search algorithm initially depended on ChatGPT to read articles via URL links. When testing this API within our program, we discovered restrictions on the requests we could make. This forced us to make a critical change to our data collection algorithm. In response, we implemented a web scraping algorithm to filter specific data, wh"
      }
    ]
  },
  {
    "file_path": "./devposts/nemo-1sfhwg.html",
    "project_id": "nemo-1sfhwg",
    "title": "NEMO",
    "tagline": "Have you ever struggled to figure out what the HACK to say in an email? You aren't alone, and this problem is a recent phenomenon as the internet enables a higher risk of miscommunication vs. inperson",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "deso",
      "google-cloud",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/322/589/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Code for DeSo's Blockchain tech. We are on DeSo's Diamond platform! It shows a teacher's updates. Code for DeSo's Blockchain tech. We are on DeSo's Diamond platform! It shows a teacher's updates. 1 2 3 4 5 🗣️Inspiration Unfortunately, it is too familiar that teachers and students don’t see eye to eye, and this is due to the educational system's lack of priority on teaching the nuances of interpersonal relationships. This sees that students don’t have the skills to represent themselves even as an adult. Teachers are there to help the students, but often it doesn't feel this way. We believe we need to educate people about the art of email. Nevertheless, our solution considers the potential for change on both ends of the communication. We decided the most significant tension between the two is Unknown Expectations and Unclear Feedback. Thus we are honored to introduce Never Emailed More Optimally: NEMO. 📧What it does We propose an attentive, interactive walkthrough of writing a professional business email utilizing a questionnaire, natural language processing, and templates. We ensure the subject line is accurate, a formal greeting lists the problem, and proposes a solution. If you believe you've already mastered the art of email, I invite you to try our challenge mode and test your skill. We hope this can relieve the stress caused by frequent misunderstandings. Secondly, on the teacher side, we want to use web 3 to allow every student access to the syllabus while confirming the teacher sent it, a student received it, and no one can change it. ⌨️How we built it We used a variety of technologies to create our project. For our syllabus confirmer and checker, we decided to use DeSo . ☕️Challenges we ran into Every member of our team struggled in different ways from various distractions. This was our first time using DeSo , but we were able to learn a lot and creatively use DeSo 's Diamond platform to serve as a way to store class announcements! 🪙Accomplishments that we're"
      }
    ]
  },
  {
    "file_path": "./devposts/new-horizons-u38bom.html",
    "project_id": "new-horizons-u38bom",
    "title": "New Horizons",
    "tagline": "Here is the New Horizons app bridging the gap, turning these challenges into navigable experiences, ensuring that every step toward a new life is informed, seamless, and filled with possibilities.",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration This initiative was inspired by a strong desire to bring attention to the complex and frequently difficult path that immigrants take. We wanted to create an instructive and compassionate experience that would develop knowledge and appreciation for the different hardships and achievements faced by immigrants globally, while also acknowledging the sensitivity of the subject. What it does We did a lot of study on the immigrant experience, consulting academic papers, videos, and personal experiences to make sure the information was authentic and accurate. grasp the complex facets of immigration, such as cultural adjustment, administrative challenges, and the psychological effects of leaving one's native country, required a thorough grasp of this study phase. How we built it The decision to develop \"Journey of Belonging\" with C# and Unity was influenced by a number of things, including C#'s adaptability as a programming language and Unity's strong foundation for developing interactive and eye-catching applications. This is a summary of how the development process using Unity and C#. Challenges we ran into It was very difficult to walk the thin line between respectable representation and gamification. Frequent focus group feedback sessions ensured that the app's design and content were kept instructive without diminishing the seriousness of the immigrant experience. Accomplishments that we're proud of During thIS hackathon, our team set out on a singular and inspirational journey, and we are incredibly happy of the creative progress we have made. We took on the task of creating an app that delves into the domains of empathy, learning, and social impact in addition to enjoyment. We took the risk of addressing a delicate subject and turned it into an engaging and instructive activity. Through the application of technology, we have developed a tool that educates as well as amuses users, encouraging a closer bond between them and the experience of being an immigra"
      }
    ]
  },
  {
    "file_path": "./devposts/navi-tuogv9.html",
    "project_id": "navi-tuogv9",
    "title": "Navi",
    "tagline": "Navi provids quailty & complex Computer-use data for foundation model Labs",
    "hackathon": "",
    "built_with": [
      "figma",
      "nextjs",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/739/030/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration During a previous internship, we realized how difficult it is for AI labs to source high-quality training data for CUA (Computer Use Agents) . Collecting this type of behavioral data is expensive, time-consuming, and often fragmented, leaving many promising research ideas under-resourced. What it does Navi is a gamified platform for gathering supervised training data on real-world computer usage. Users are given entertaining, goal-oriented tasks — for example, “Add an item to your Amazon cart and proceed to checkout.” While completing these tasks, they allow Navi to securely capture on-screen activity such as mouse clicks, navigation flows, and (where permitted) keystrokes. All data is validated for accuracy and quality , then anonymized and delivered to organizations developing productivity assistants, next-generation AI systems, and CUA (Computer Use Agents) . How we built it We developed a Next.js frontend that handles task management, data ingestion, validation, and secure storage. The platform’s architecture makes it easy to extend features like task marketplaces, leaderboards, and client dashboards. Accomplishments that we’re proud of We’re proud that Navi bridges a significant gap for the AI and CUA communities: it empowers labs and companies to train the next generation of Computer Use Agents with richer, more authentic data while giving individuals an opportunity to contribute — and benefit — from their everyday computer use. What we learned We discovered an enormous and growing demand for unique, high-fidelity training data , especially for human-computer interaction and CUA development . Supply hasn’t kept up with that demand, and projects like Navi can help close that gap by aligning user incentives with research needs. What’s next for Navi Our next step is to expand into specialized datasets — from productivity workflows to niche applications like creative tools, developer environments, and educational software — helping to accelerate "
      }
    ]
  },
  {
    "file_path": "./devposts/networkia.html",
    "project_id": "networkia",
    "title": "EventSocial",
    "tagline": "Networkia – compete your way to getting more business cards than your boss at any event. It's smalltalks, but with points, challenges, and way less awkward.",
    "hackathon": "",
    "built_with": [
      "python",
      "pytorch",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/208/816/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration A team member here was a STEM director at the City of Brampton, and he witnessed “COVID kids” who missed out on the social skills needed for in-person events. He noticed this gap in communication skills, especially when it came to event networking. We also saw a lot of people at hackathons who were too shy to approach big tech companies, even though they had the potential to make great connections. We thought, “What if networking could be less awkward and more fun?” And just like that, Networkia was born. What it does Networkia turns networking into a competitive, game-like experience. Participants at events earn points by completing challenges, meeting new people, and unlocking achievements. It’s designed to make connections less about awkward small talk and more about meaningful interactions that drive real relationships. Think of it like a networking game where everyone wins—except the shy ones. How we built it We built Networkia using a combination of PyTorch, Unity, FastAPI, Pydantic, Pickle, and MongoDB. PyTorch was used for machine learning to help identify key features that drive meaningful interactions, Unity powered the immersive game experience, and FastAPI + Pydantic handled the backend to keep everything running smoothly. Pickle was our trusty sidekick for storing embeddings, while MongoDB managed the data and user interactions. It was a mix of AI, gaming, and a lot of caffeine. Challenges we ran into The main challenge was getting the PyTorch model to work properly for analyzing interactions and making real-time recommendations. Unity was tricky, as building an interactive game that wasn’t just a glorified PowerPoint presentation proved to be… well, a challenge. And don’t get us started on Pickle. Storing embeddings felt like trying to fit a square peg into a round hole—except the peg was a neural network and the hole was the database. Accomplishments that we're proud of We’re pretty proud of making networking actually fun and effective. Wh"
      }
    ]
  },
  {
    "file_path": "./devposts/neura.html",
    "project_id": "neura",
    "title": "Neura",
    "tagline": "Revolutionary preparation and conducive interview experience for neurodivergent people.",
    "hackathon": "",
    "built_with": [
      "cnn",
      "css",
      "flask",
      "html",
      "lstm",
      "natural-language-processing",
      "particle.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/685/178/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Neura Interview platform Text sentimental analysis Video sentimental analysis Texts are summarized and questions are generated using AI Audio sentimental analysis Result of sentiment analysis Neura Interview platform Text sentimental analysis Video sentimental analysis Texts are summarized and questions are generated using AI Audio sentimental analysis Result of sentiment analysis Neura Interview platform 1 2 3 4 5 6 7 makeUC Video Link https://youtu.be/5YOVkBYmONg Inspiration Neurodiversity is a form of diversity that has numerous benefits in the workplace. People with neurocognitive disabilities have unique talents, views, and skills that can be very useful in a variety of workplaces. Employers are increasingly acknowledging these advantages and developing hiring initiatives aimed at attracting neurodiverse staff. While these initiatives are more popular in larger firms, they have proven to be useful for businesses of all sizes across a wide range of industries. Hiring neurodiverse employees can give firms a competitive advantage that results in concrete financial and workplace culture benefits. What it does Neura is a revolutionary learning platform for neurodivergent people which furthermore provides a conducive interview experience. This platform employs artificial intelligence to summarises texts, highlight salient ideas, and generate questions. Moreover, It is also an interviewing platform where employers can conduct three different forms of interviews namely, text, audio, and video interview. All three sorts evaluate the textual, vocal, and facial emotional score respectively. This score can be used to ask questions that would make an interviewee comfortable. Additionally, the interviewee can see his sentimental analysis score to improve his performance further. How we built it Neura is built on a Flask micro-framework. It uses open-source pre-trained Machine Learning models. Natural Language Processing is used to summarise the text and to generate the quest"
      }
    ]
  },
  {
    "file_path": "./devposts/nobuai.html",
    "project_id": "nobuai",
    "title": "NabuAI",
    "tagline": "Have you ever found yourself drowning in a sea of research papers, desperately trying to organize 20+ citations while piecing together your thesis? Check our NabuAI to streamline the process!",
    "hackathon": "",
    "built_with": [
      "aryn",
      "firebase",
      "flask",
      "gpt",
      "nextjs",
      "python",
      "react",
      "singlestore",
      "sycamore"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best use of Sycamore (Aryn) Created by I designed a basic template and flow in Figma, worked with N",
      "SB Hacks XIWinnerBest use of Sycamore (Aryn)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/208/833/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "library home page chat page thesis decomposition dashboard citations library home page chat page thesis decomposition dashboard citations library 1 2 3 4 5 6 7 Have you ever found yourself drowning in a sea of research papers, desperately trying to organize 20+ citations while piecing together your thesis? Let me introduce NabuAI Named after the Babylonian god of literacy, we are an AI-powered tool designed to revolutionize how students and researchers interact with academic material. Think of it as your personal organizer for writing papers. Here’s how it works: Know what you want to write about but don't know where to find sources? You start by typing your thesis or even a rough idea into a chatbox. For example, “Public speaking and its impact on performance.” Instantly, our AI uses semantic decomposition through Gen AI to pick research papers or online articles that relate to your thesis. It breaks down the ideas into concepts - \"public speaking,\" \"performance,\" \"stress response,\" etc. If you want to search specifically for studies specifically about public speaking and performance, you can use our library to do so. We have a database of over 250 million scholarly works to search from, so you can select any article you’re interested in, and add it to your collection. See a title that interests you? Rather than trying to read through the jargon in the paper's abstract or scanning 30+ pages of text, these papers will stay in Singlestore’s vector database to be automatically processed in the background by Aryn’s API to analyze the paper and generate a summarized report using GPT4o. We have both a textual and graphical summary, allowing you to pick and choose the most relevant sources for you. Example use cases \"I remember reading this statistic about GPA and public speaking ability, which paper was that in?\" \"Find me a paper published within the last two months that is about public speaking\" \"Find other works by the same author\" \"How do these two studies compare in "
      }
    ]
  },
  {
    "file_path": "./devposts/northstar-6cz8km.html",
    "project_id": "northstar-6cz8km",
    "title": "NorthStar",
    "tagline": "NorthStar helps you choose the safest route through Toronto by showing crime hotspots and risk-score locations with real data, whether you’re walking, biking, or driving.",
    "hackathon": "",
    "built_with": [
      "googlestreetviewapi",
      "mapbox",
      "next.js",
      "node.js",
      "react.js",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/498/473/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Google maps street view with risk rating Bar statistical view with dark mode Dotmap view with light mode Google maps street view with risk rating Bar statistical view with dark mode Dotmap view with light mode Google maps street view with risk rating 1 2 3 4 🌟Inspiration Whether you're a local resident or visiting a new city, being aware of high-risk areas can mean the difference between feeling secure and facing real danger. That's where NorthStar comes in. 🔧What it does and how we built it NorthStar uses a risk-scoring algorithm that guides users around cities. While other mapping software stress on speed, NorthStar prioritizes safety by offering smarter navigation decisions powered by real crime data. The idea of this risk-scoring algorithm was inspired by a 2019 urban crime research paper on spatial analysis methods in neighborhoods ( https://www.mdpi.com/2220-9964/8/1/51 ). With this research, we assigned weighted influence zones to eight types of crimes (including shootings, assaults, robberies, etc.) and built a radius-based system that calculates a hazard score (from 0-100) at any location based on surrounding crime proximity and severity. With Mapbox GL JS, we integrated our risk-scoring output into a custom web map, allowing users to view previous crimes in heatmaps with Google Maps Street View API. These safety routes are updated based on the selected travel mode (walking, biking, driving) and specific crime types that can be turned on or off by the user. 🚩Challenges we ran into and what we learned One of the biggest challenges we faced was learning how to implement the heatmaps and the risk-scoring algorithm. Most of our team had little to no prior experience with data analysis, spatial data, or mapping tools, so we had to spend a significant amount of time learning, researching and building as we went. We learned that with time, we were able to be patient, collaborate, and teach each other new tools and concepts on the fly. 🎯Accomplishments that we're p"
      }
    ]
  },
  {
    "file_path": "./devposts/neuroveil-the-twin-mind-interface.html",
    "project_id": "neuroveil-the-twin-mind-interface",
    "title": "Neuroveil: The Twin Mind Interface",
    "tagline": "Synchronize brainwaves to treat mental disease and generate cymatic art",
    "hackathon": "",
    "built_with": [
      "3d",
      "arduino",
      "django",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Qualcomm Technologies with AI, Presented by Qualcomm Created by I worked on interpretin",
      "MIT Reality Hack 2025WinnerBest Use of Qualcomm Technologies with AI, Presented by Qualcomm",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/238/082/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Our inspiration originates with the Dream Machine from the 60s, a simple flickering light causing profound visual effects, and the plethora of research after it showing health improvements, neuron regeneration, and treatments of mental disease. What it does Neuroveil synchronizes brainwaves between participants, allowing them to converge to a shared brainstate, and control that brainstate to elicit certain effects. How we built it HACK HACK HACK! 3D printing, embedded systems, webserver master/client relationships, Apple vision pro monitoring systems, and more Challenges we ran into The Qualcomm RB3 Gen 2 was designed with a pipeline for realtime AI inference on video and other multimedia data types. However, our application involved EEG readings from the OpenBCI Cyton. We had to develop a custom model instead of the ones available on the Qualcomm SDK, and figure out a way to install the packages for our model so that it ran on the Qualcomm hardware. Accomplishments that we're proud of WE SYNCHRONIZED BRAINS BAYBEEEEEE What we learned 😌💫🕊️🧠🤍 What's next for Neuroveil: The Twin Mind Interface More than two people synchronized at the same time. A dimly lit room; it is cylindrical. there are concrete panels in a circle in the middle. There are 12 people laying on the ground. They are connected. Interlinked. Wires spill like oil from their heads. They all point to the middle of the room. In the middle of the room is a large metal cylinder. There is a hum of machinery in the distance. What they summon they do not know. An eye unknowingly twitches. The humming grows louder. There is a real goofy guy in there too. He has a cart. Oysters on the cart. The wires knowingly twitch. Built With 3d arduino django python Try it out GitHub Repo Submitted to MIT Reality Hack 2025 Winner Best Use of Qualcomm Technologies with AI, Presented by Qualcomm Created by I worked on interpreting the EEG data, Sending it over Wifi via websocket to an ESP32, and subjecting my bra"
      }
    ]
  },
  {
    "file_path": "./devposts/newfit.html",
    "project_id": "newfit",
    "title": "NewFit",
    "tagline": "Fitness and productivity, and NFTs",
    "hackathon": "",
    "built_with": [
      "filecoin",
      "google-cloud",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/781/913/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Connect to Github App Github Fitbit Connect to Fitbit NFT APIs Generate NFT Mint NFT Connect to Github App Github Fitbit Connect to Fitbit NFT APIs Generate NFT Mint NFT Connect to Github 1 2 3 4 5 6 7 8 9 10 Inspiration Programmers are commonly portrayed as anti-social, boring creatures who sit at their desks all day. Every loves NFTs! What it does NewFit helps you reach your fitness and productivity goals through NFTs, Github, and Fitbit. obtains your fitness goals and stats via your Fitbit app. monitors Github activity to measure your productivity as a developer generates an NFT from your data. How we built it GCP Serverless functions OAuth2 for Github and Fitbit authentication Github and Fitbit APIs for data React Native for the frontend Filecoin for NFT storage MongoDB for data storage Challenges we ran into There were errors in the Expo documentation for Github redirect URLs. Took a while to figure that out and get the OAuth to work. Accomplishments that we're proud of We built a fully functional prototype What we learned OAuth FitBit app works without a Fitbit What's next for NewFit Gamify. Pair users with similar fitness and productivity goals for weekly challenges. Winner gets a boost, which they can show it off with their NFT. Use NFTs to unlock challenges or powerups. Built With filecoin google-cloud react-native Try it out GitHub Repo Submitted to YouthHacks See You Later, Hackulator Created by I worked on UI/UX Kanha Korgaonkar MLH Top 50 | Frontend & Jamstack Developer | 18x Hackathon Winner Muntaser Syed Ebtesam Haque"
      }
    ]
  },
  {
    "file_path": "./devposts/no-strings-attached-zxslgy.html",
    "project_id": "no-strings-attached-zxslgy",
    "title": "No Strings Attached",
    "tagline": "A fun game to play with a friend, no strings attached.",
    "hackathon": "",
    "built_with": [
      "canvas",
      "css",
      "html",
      "javascript",
      "qdollar",
      "socket.io",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Game Hack Winner Wolfram Award Letter Created by I mainly worked on the back-end, implementing game",
      "[HACKUMASS] Third Prize Winner [HACKUMASS] Best Game Hack Winner Wolfram Award Letter Created by I",
      "Winner [HACKUMASS] Best Game Hack Winner Wolfram Award Letter Created by I mainly worked on the bac",
      "HackUMass XIWinner[HACKUMASS] Third PrizeWinner[HACKUMASS] Best Game HackWinnerWolfram Award Letter",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/667/571/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The host's screen Hello from the team that made No Strings Attached! 24 hours in! Debugging info from a mobile device The host's screen Hello from the team that made No Strings Attached! 24 hours in! Debugging info from a mobile device The host's screen 1 2 3 4 Inspiration Technology is amazing. The ability to explore countless web pages and message someone across the globe is right at our fingertips. In spite of the constant buzz of technology, a subtle yet significant issue persists: loneliness. It's a paradox of our times — a world more interconnected than ever, yet tinged with a pervasive sense of isolation. Enter “No Strings Attached”, our hackathon creation. Our project aims to harness technology to foster connections and combat social isolation. Drawing inspiration from interactive games like Kahoot, our objective was to craft a social gaming experience where multiple players could actively participate using their smartphones to engage with content displayed on a central screen. What it does \"No Strings Attached\" is an engaging co-op game designed for two players. In this unique experience, participants take on the role of puppeteers, wielding control over their puppets through the intuitive interface of their mobile devices. The gameplay involves manipulating the movement of the puppets by skillfully tilting their phones and interacting with in-game objects using gestures in the air. In order to clear all of the challenges, it is imperative that players coordinate their efforts and communicate their intentions. How we built it To accurately monitor the orientation and position of each mobile device, we used the THREE.js library, utilizing quaternions as a robust mathematical representation of orientation that avoids singularities. Using these quaternions, we transformed data obtained from the gyroscope and accelerometer—originally relative measurements—into absolute measurements based on a predefined set of axes established during a calibration period. The p"
      }
    ]
  },
  {
    "file_path": "./devposts/nerds-wgzxn6.html",
    "project_id": "nerds-wgzxn6",
    "title": "Toots",
    "tagline": "Be a toot or a tootee",
    "hackathon": "",
    "built_with": [
      "adobe",
      "figma",
      "notion"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Notion: Anker Speaker Created by John Mo :D Weston Jenner Paul Kim Chrispbz",
      "Product@TAMU Ideathon 2025WinnerBest Use of Notion: Anker Speaker",
      "Focused on clean UI/UX to support both first-time and returning users.",
      "Remote collaboration during the second day made brainstorming and alignment slower, but we adapted quickly.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/376/553/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Colour Palette App Icon Screenshot 1 - Start Page Screenshot 2 - Profile Kanban Board - Notion Colour Palette App Icon Screenshot 1 - Start Page Screenshot 2 - Profile Kanban Board - Notion Colour Palette 1 2 3 4 5 6 🧠 Toots:  Your Student Tutor Matchmaker Inspiration We built Toots to bridge this gap: Empower students to earn money or give back by tutoring. Help tutees find instant support from trusted peers. Make study room use smarter and social. What it does Toots is a campus-focused web app that allows students to: Act as both a tutor (toot) and a tutee, with an open marketplace for tutoring requests. Post or browse tutoring sessions, choosing whether to offer help for free or for a fee. Book study rooms in campus buildings and see who else is studying there. Join open sessions and collaborate with students studying the same subject. Rate peers after each session with an Uber-style system: reflected as \"Toot\" (tutor) and \"Tootee\" scores displayed on user profiles. How we built it We used Figma to design and prototype the entire application. Created 30 screens with interactive flows simulating real app functionality. Focused on clean UI/UX to support both first-time and returning users. Crafted role-based navigation to support both tutor and tutee actions seamlessly. Challenges we ran into Designing for a dual-role experience meant to balance two user journeys while keeping the app intuitive. Limited time required prioritizing features—we had to cut certain ideas to keep the experience fluid. Remote collaboration during the second day made brainstorming and alignment slower, but we adapted quickly. Accomplishments that we're proud of Seamless dual-role logic and interface Efficient booking system with group visibility Interactive prototype with full navigation and logic simulated in Figma Profile + rating system to keep users accountable and engaged What we learned Less is more: simplicity wins in product design. Designing for two personas in one app is challeng"
      }
    ]
  },
  {
    "file_path": "./devposts/node-package-checker.html",
    "project_id": "node-package-checker",
    "title": "Eye of Packages",
    "tagline": "Are you aware of NPM packages you use? This tool will help you figure it out",
    "hackathon": "",
    "built_with": [
      "javascript",
      "netlify",
      "node.js",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH Fellowship Orientation Hackathon - Fall 2022WinnerTop Software Engineering Project",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/236/318/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "How we built the big eye Node Package Checker What eye of the package helps you do How we built the big eye Node Package Checker What eye of the package helps you do How we built the big eye 1 2 3 4 Team Details: Aziz Abdullaev: [ https://azizabdullaev.site ; https://github.com/azyzz228 ] Emeka Mba: [ https://www.emekathegreat.vercel.app ; https://github.com/emekathegreat1 ] Both of us are 22.Fall.8 Pod members Inspiration 🐧 Many developers make use of the plethora packages that exist in the third party package ecosystem on their various projects. However, managing these packages can become cumbersome, tiring and at worst make one's project vulnerable to attacks. We built this project to help developers manage their packages better to help seamless and malware-less development. What it does 🥷🏾 The sole and primary aim of Eye of Packages is to help you track and manage your Node project's NPM packages and dependencies. Eye of Packages presents data on Github stats, last updated date, and the links to Github repo and issues for the package. It is aimed to help you identify potential incompatibilities as well as security threats that can come the obsolete packages. The name eye of the package originated from the phrase \"keep an eye\" which is used to signify that one is tracking or monitoring something. Which means that with our node package tracker you can keep an eye on all the packages and/or dependencies you used in building your project. This will be beneficial for both the author of the project, the maintainer, contributors and the users. How we built it ❤️ This application was built with: React Js Tailwind css Node Js Javascript Challenges we ran into 🐞 There were lots of challenges on our way, but our primary challenge was in the assembly of the projects various endpoints and making them work together seamlessly. After we settled on the idea, we separated the work according to everyone's skills. Aziz was primarily working on the Backend-end, while Emeka set up i"
      }
    ]
  },
  {
    "file_path": "./devposts/oasis-fts2zp.html",
    "project_id": "oasis-fts2zp",
    "title": "Oasis",
    "tagline": "A mental health website that addresses user's anxiety and mental health issues and provides support.",
    "hackathon": "",
    "built_with": [
      "ai",
      "bootstrap",
      "c#",
      "css3",
      "html5",
      "javascript",
      "machine-learning",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "PioneerHacks IVWinnerWolframAlpha",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/422/918/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "OpenCV demo Home page Media suggestions Questionnaire page Products page OpenCV demo Home page Media suggestions Questionnaire page Products page OpenCV demo 1 2 3 4 5 PLEASE READ THE README FILE FOR INFORMATION ABOUT THE WEBSITE Problem: What is the problem you are addressing, why is it significant?\nDue to Covid-19 and the increasing stress on adults and children across the world, more and more people are falling victim to mental health depression. As a result, more and more people are unhappy and unsatisfied with life which leads to serious issues. Entering highschool, we saw that many of our peers, including ourselves, had gotten more anxious when talking to classmates due to the isolation of the pandemic. Solution: What is the idea of your project, how original is the solution?\nOur idea is to implement an ingenious website called Oasis which assesses the mental health of the individual with several different products integrated. Using OpenCv, we made a smile detector that encourages users to smile more, improving their overall day. We also used Opencv to encourage individuals in a computer setting to stop touching their face through a ringing sound. Using a Machine Learning model, we also predicted the rise in future depression rates to raise caution to individuals and raise awareness. In addition to these solutions, we also have a mental health survey which utilizes a variety of factors in depression to figure out what type of help the person needs. In conclusion, the increase in the dependency of technology has impacted millions of children. With more and more children being stuck to their screen, there is a significant decrease in social interaction and an increase in depression. As a result,  our website will reach out to the younger generation and help them achieve a happier mood or a better outlook on life. Implementation: How well done is the implementation? Is the design easy to use, clean, and bug free?\nWe implemented a website to allow users to sift th"
      }
    ]
  },
  {
    "file_path": "./devposts/nocapad.html",
    "project_id": "nocapad",
    "title": "NoCapAd",
    "tagline": "Find your personalized credit card!",
    "hackathon": "",
    "built_with": [
      "flask",
      "openai",
      "python",
      "react",
      "tailwind",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMU Datathon 2024WinnerCapital One Challenge 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/129/492/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Recommendation UI Analytics page Home page Recommendation UI Analytics page Home page Recommendation UI 1 2 3 4 Inspiration Kareem has done a lot of personal research on the benefits/drawbacks of various credit cards, and he thought he would share his knowledge with people who haven't invested as much time in learning about personal finance. We wanted to build an app that could make the journey toward financial literacy as painless as possible. Currently, recommenders need certain information from you to gauge your preferences; we believe this is very subjective and sometime people my not know what they want. They may think that a certain category, like travel, will save them a lot of money when in reality it doesn't. This is why we wanted to look instead at transaction history and see how, based on the customers current usage, what credit card would be best for them. What it does Given the user's financial history, our web app researches and provides recommendations on several credit cards that provide the most utility. Note that the recommendations may not be mutually exclusive: using multiple cards in conjunction could provide more value across different categories of spending. In addition, our interface also displays the average monetary value of each card to allow for easy visual comparisons between the recommendations. This also give users options, if they do not feel comfortable holding multiple credit cards they can still see which benefits them the most. How we built it We developed a simple frontend UI in React with Tailwind CSS. We developed our backend REST API with Flask. We developed our application's core business logic using the OpenAI chat completions API along with its structured outputs (a.k.a. grammar-constrained decoding) functionality. Structured outputs is a new API feature that takes a JSON schema as input and ensures that the LLM's output is 100% adherent to the provided schema. This feature was very important, because we needed to be confid"
      }
    ]
  },
  {
    "file_path": "./devposts/nostalg-ai.html",
    "project_id": "nostalg-ai",
    "title": "Nostalg.ai",
    "tagline": "Instant Nostalgia, Eternal Memories.",
    "hackathon": "",
    "built_with": [
      "chakra-ui",
      "cohere",
      "css",
      "github",
      "openai",
      "react",
      "streamlit",
      "verbwire"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/738/688/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Create Page Tech Stack Diagram Home Page Record Page Create Page Tech Stack Diagram Home Page Record Page Create Page 1 2 3 4 5 🌟 Inspiration Our journey with Nostalg.ai began with a burning desire – a desire to effortlessly journey back in time, reliving the moments that make us who we are. We wanted to tackle two common problems: the hassle of searching through an endless sea of memories and the heartache of losing them as old social media platforms fade into the abyss. 💡 What it Does Get ready to embark on an electrifying journey through your past with Nostalg.ai! 🚀 Here's the magic it brings to your fingertips: Search Memory by Text and Image: Find your treasured memories effortlessly using text or even images! 📸✨ Mint NFTs of Memories: Turn your priceless moments into Starknet NFTs, forever etched in the sands of time. 🪙🎉 Semantically Search Through Memories: Cohere Vector Embeddingsadds a touch of magic, allowing you to search through tagged memories, including photos and videos. 🔍🧙‍♂️ Chat with Memories: Immerse yourself in conversations with your memories, reliving the past through dynamic interactions. 🗣️💬 🛠️ How We Built It We harnessed the power of cutting-edge technologies to bring Nostalg.ai to life: Cohere Embeddings: For semantic search through tagged memories (photos and videos). Cohere Chat with RAG: Enabling interactive conversations with your memories. Verbwire: The magic behind minting NFTs of your most cherished moments. React: Providing a user-friendly and vibrant frontend. OpenAI GPT-4 Vision: Unveiling the hidden stories behind your images and videos. 🌆📚 🚀 Challenges We Conquered Our journey was not without its fair share of challenges. We battled the complexities of integrating multiple technologies while ensuring a silky-smooth user experience. Handling vast memory datasets and optimizing real-time interactions pushed us to our limits. But we emerged victorious! 🏆 Proud Accomplishments Our proudest achievement? Crafting a platform that seam"
      }
    ]
  },
  {
    "file_path": "./devposts/noted-qytkow.html",
    "project_id": "noted-qytkow",
    "title": "Noted",
    "tagline": "Noted provides a way to take organized notes on mobile devices using a folder structure and an algorithm to search for terms and create flashcards.",
    "hackathon": "",
    "built_with": [
      "android",
      "react-native",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/796/930/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "View of inital folder view View of inital folder view View of inital folder view 1 2 Inspiration For one of my classes at school, I need to take fairly extensive notes with many definitions, and I felt that there was no good way to organize them, leading me to be inspired and created Noted to tackle the problem of unorganized notes. What it does Noted has a folder structure that allows for taking structured notes on mobile devices, as well as having a flashcard feature to review definitions. How we built it Noted is built using React Native and Typescript and uses Android Studio and its emulators to test and run code. Challenges we ran into There were problems with ensuring consistency of data and saving data across page loads, as well as some layout issues with CSS. Accomplishments that we're proud of I'm proud of being able to finish one of my first projects ever on React Native, since many of my previous projects had issues with the code as well as the Android SDK. What we learned I learned more techniques for dealing with React Native such as Expo vector icons, ScrollViews, and recursive elements. What's next for Noted I hope to implement a live Markdown editor (i.e. renders Markdown in the editor as you type) to create a more visually convenient editor, as well as extending the flashcard feature. Built With android react-native typescript Try it out GitHub Repo Submitted to HappyHacks V Created by Redger Xu"
      }
    ]
  },
  {
    "file_path": "./devposts/notematic.html",
    "project_id": "notematic",
    "title": "Notematic",
    "tagline": "Notematic is committed to revolutionizing the way you study and learn. By harnessing the power of AI, NLP, and user-friendly tech, we aim to empower individuals to unlock their learning potential.",
    "hackathon": "",
    "built_with": [
      "api",
      "bootstrap",
      "canva",
      "chatgpt",
      "css",
      "css3",
      "github",
      "html",
      "html5",
      "javascript",
      "node.js",
      "php",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/553/180/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Contact Page Home Page About Page AI-Generated Flashcards Page Quiz (AI Checker) Page Contact Page Home Page About Page AI-Generated Flashcards Page Quiz (AI Checker) Page Contact Page 1 2 3 4 5 6 Inspiration The education sector is underserved. Most schools around the world focus on broad-based learning, where teachers teach the same way to all kids in the classroom regardless of each individual's specific needs. There is currently not really a focus on individual learning and making sure each person is caught up and understands the material. This is a problem because students all learn at different paces and learn better with different methods. Since we are high schoolers and college students ourselves, we have experienced this phenomenon first-hand, especially in harder classes like physics and history. Therefore, we created a versatile tool, Notematic, that will help resolve this issue. What Notematic does With ChatGPT API, our application utilizes state-of-the-art natural language processing (NLP) to provide you with intelligent and contextually accurate study material. We generate multiple notecards using AI based on any user-inputted keyword topics for students to study and/or review. We also provide a quiz function that evaluates the students’ answers and the AI can correct them dynamically. How we built Notematic We integrated ChatGPT API into a user-friendly, responsive web application using front-end languages HTML, CSS, Bootstrap, Canva, JavaScript and back-end Node.js in order to provide a seamless experience for our student customers. Challenges we ran into We found that some JavaScript functions were producing bugs, so it took some time to debug. Prompting for ChatGPT was also difficult because ChatGPT sometimes responds inaccurately to complex prompts. We solved this by improving our parsing of question-answer pairs. Accomplishments that we're proud of/benefits of our app We are happy to finish building Notematic's front and back-end, which is easy t"
      }
    ]
  },
  {
    "file_path": "./devposts/not-the-new-york-times.html",
    "project_id": "not-the-new-york-times",
    "title": "Not The New York Times",
    "tagline": "Delivering \"fake\" news like never before—satirical, witty, and at your doorstep",
    "hackathon": "",
    "built_with": [
      "cloudflare",
      "fastapi",
      "flask",
      "nextjs",
      "node.js",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/172/217/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The proliferation of fake news has become a global phenomenon, influencing public opinion and shaping narratives in unexpected ways. We wanted to shed light on this issue by illustrating how simple it can be to generate satirical content from real news articles. By doing so, we aim to provoke thought and entertain while raising awareness about the power of AI and its potential misuse. What It Does Not The New York Times takes real news articles and transforms them into satirical pieces. The AI-driven pipeline ensures that satire retains the essence of the original while injecting humor, exaggeration, and irony to deliver a fresh perspective. How We Built It News Scraping: Leveraging RSS feeds, we gather real-time news articles using Python-based web scraping tools integrated with FastAPI . Satirical Conversion: Using VoiceFlow , the news content undergoes a transformation process to rewrite it into satire, complete with quirky and humorous twists. Frontend Display: Finally, we use Next.js for a polished, interactive web display of the satirical articles. Challenges We Ran Into Our most significant hurdle was navigating VoiceFlow , a tool we had never used before. We faced issues with variable conflicts that slowed down the workflow and required multiple debugging sessions. Additionally, integrating Cloudflare Workers AI with our existing stack posed some initial roadblocks, requiring creative problem-solving. What We Learned Mastered the intricacies of VoiceFlow , including managing complex flows and variable dependencies. Discovered how to harness Cloudflare Workers AI for real-time data processing and transformation. Strengthened our skills in API integration and frontend-backend communication. What's Next for Not The New York Times Our immediate goal is to streamline workflows to enhance the satirical content's quality and speed of delivery. Beyond that, we aim to: Expand content types to include video and audio satire. Introduce user-generated sa"
      }
    ]
  },
  {
    "file_path": "./devposts/nightlight-64g8wc.html",
    "project_id": "nightlight-64g8wc",
    "title": "nightlight",
    "tagline": "Our service, nightlight, is devoted to improving the transportation security of users all around the world! So, embark with us on this journey to being your light in the night.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Connectivity Hack by HRT Winner People's Choice Award Created by",
      "Best Connectivity Hack by HRT Winner People's Choice Award Created by",
      "Hack with Us - TechNova 2022WinnerBest Connectivity Hack by HRTWinnerPeople's Choice Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/204/218/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "we vow to be your light in the night! we vow to be your light in the night! we vow to be your light in the night! 1 2 Inspiration 💡 The inspiration behind ‘nightlight’ stemmed from an issue that all of us have experienced; fear at night. As teenage girls, we repeatedly dread taking transportation systems, like the TTC, alone. We often come across anecdotal posts shared by other women on social media that recount their horrific experiences on public transit. An experience shared by a 20-year-old woman on TikTok “I was literally taking the bus home after getting some drinks with my friends when this guy pulled out his phone and started filming me [...] This is not any woman’s fault, but be careful because there are some people who will take advantage of any one they see.” With this problem in mind, our team decided to create an application that would act as one’s “light in the night” in order to reduce the risk of harassment that females, minorities and people in general experience on public transport. What it does In an attempt to improve physical security and to champion women, our responsive web application informs the user on potential risk factors at bus stops, train and subway stations! As a user, simply… Enter your starting location and destination Select a public transit route View updated reports about each public transit station written by other public transit users Make reports about public transit stations, as needed, and notify authorities Share your location with friends and family Follow the indicated route Contribute and collaborate! We develop a community of women empowering women, by allowing users to report any suspicious activity or incidents that they have either seen or experienced using public transport. E.g, harassment, sexual assault, invasion of privacy By standing together in solidarity, public transit has never been safer! How we built it We used Figma to design our web application in order to showcase the potential interactive elements we "
      }
    ]
  },
  {
    "file_path": "./devposts/nopanic-io.html",
    "project_id": "nopanic-io",
    "title": "nopanic.io",
    "tagline": "Nopanic.io aims to provide contextual information in order to help contain the COVID19 outbreak. This web app provides guidelines based on the user's location to help them navigate the outbreak.",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "google-cloud",
      "google-maps",
      "html5",
      "javascript",
      "json",
      "matplotlib",
      "numpy",
      "pandas",
      "scikit-learn",
      "xarray"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place Overall Winner Wolfram Alpha Award Winner Lighthouse Labs Scholarship Winner YoungLeaders",
      "Winner Lighthouse Labs Scholarship Winner YoungLeaders Most Promising Hack Created by Worked on the",
      "MariHacks 2020Winner1st Place OverallWinnerWolfram Alpha AwardWinnerLighthouse Labs ScholarshipWinnerYoungLeaders Most Promising Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/951/521/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Amidst the ongoing COVID19 outbreak, we felt a tool was needed to provide quality and fact-based - but also contextual - information in order to help mitigate the fear factor associated with such events. We wanted to offer this solution in a dashboard-type web application, all the while making it visually appealing and staying far from the bright reds and blacks, which are usually more fear-inducing than calming. What it does Nopanic.io offers many features. First of all, the user is able to see the different COVID19 outbreaks around the world for the present, the past, and even 7 days in the future using a machine learning model to predict the future number of cases. Although getting the big picture is always useful, we wanted to provide the user with a way to know if they have to adapt their lifestyle depending on their region's situation. Thus, by entering their location in the search bar, the user is able to see the number of cases in their region and, based on this number, is given safety guidelines and useful hotlines. For example, if the number of cases in an area is under 100, the user is told to proceed normally but to adopt good sanitary discipline. However, if the number of cases exceeds 1,000, the user better avoid using public transit and stay at home until the outbreak calms down. How we built it We extracted our data from the John Hopkins University public COVID19 open-source dataset made available on Github using pandas. We then transformed this dataset into daily sub-sections and exported them into .geojson files in order to be able to visualize them on Google Maps. This transformed data was then uploaded to a Google Cloud Storage Bucket. At the same time, we also built a machine learning model using linear regression, predicting the potential number of infected victims within the next week across all regions of the world. The frontend was built using the Flask python framework, which loaded a map after sending a request to the Googl"
      }
    ]
  },
  {
    "file_path": "./devposts/noteboard-site.html",
    "project_id": "noteboard-site",
    "title": "noteboard.site",
    "tagline": "offline encrypted threaded conversations",
    "hackathon": "",
    "built_with": [
      "bolt",
      "ionos",
      "netlify"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/591/556/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 📝 Collaborative Notes - Serverless Real-Time Note Board - ONE SHOT APP! 🚀 What it does Collaborative Notes is a revolutionary note-taking platform that enables real-time collaboration without any server infrastructure. Users can create, edit, and organize notes together simply by sharing a URL - no accounts, no databases, no complexity. ✨ Key Features 🔗 URL-Based Storage : All data is encrypted and stored directly in the URL, making sharing as simple as copying a link 👥 Real-Time Collaboration : Multiple users can collaborate simultaneously with automatic updates every 2 seconds 🎯 Dual View Modes : Pin Board : Pinterest-style masonry layout for quick note browsing Tree View : Hierarchical display showing conversation threads and note relationships 🔒 Privacy-First : Client-side encryption ensures your notes remain secure ⚡ Zero Infrastructure : No servers, databases, or user accounts required 📱 Responsive Design : Works seamlessly across desktop, tablet, and mobile devices 🛠️ How we built it Frontend Technologies: React 18 with TypeScript for robust component architecture Tailwind CSS for beautiful, responsive styling Lucide React for consistent iconography Vite for lightning-fast development and optimized builds Core Innovations: Custom URL Storage System : Developed a sophisticated URL parameter-based storage engine that handles data serialization, encryption, and size optimization Real-Time Sync Engine : Implemented polling-based synchronization that detects URL changes and updates the UI seamlessly Client-Side Encryption : Built a lightweight XOR-based encryption system for casual privacy protection Tree Data Structure : Created algorithms for building and maintaining hierarchical note relationships Architecture Highlights: Modular Component Design : Each feature is isolated into reusable components State Management : Efficient React hooks-based state management with automatic persistence Search & Filter System : Real-time search across note content and use"
      }
    ]
  },
  {
    "file_path": "./devposts/not-another-driver.html",
    "project_id": "not-another-driver",
    "title": "Not Another Driver",
    "tagline": "Through the algorithmic analysis of driving footage and telematics, Not Another Driver turns bad driving habits into good ones through personalized, incentivized, graded driving reports.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css3",
      "express.js",
      "google-cloud",
      "html5",
      "javascript",
      "node.js",
      "numpy",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Lifestyle Improvement Hack for Drivers powered by Ford Created by I wrote the majority of the scrip",
      "Ford Challenge: Best Lifestyle Improvement Hack for Drivers powered by Ford Created by I wrote the",
      "TAMUhack 2022WinnerFord Challenge: Best Lifestyle Improvement Hack for Drivers powered by Ford",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/815/079/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The page for specific reports. This shows a color-coded score, suggestions, and appropriate navigation UI. GIF A video of the image analysis component of the app in action. It uses OpenCV and image analysis to identify unsafe driving behavior. This image quantitatively models the rapid, unsafe brake shown in the previous video through a rapid increase in car-related pixel usage. GIF This video shows the image analysis tool in action again, this time in a safe driving environment. This graph correlates to the previous image. The slow changes and small values show a safe driving distance with no major unsafe brakeage. GIF A GIF showing the app in action. The homepage of the app. The main menu page of the app. The driving page of the app. Users will see this page while the app collects driving data. The reports homepage of the app. The page for specific reports. This shows a color-coded score, suggestions, and appropriate navigation UI. GIF A video of the image analysis component of the app in action. It uses OpenCV and image analysis to identify unsafe driving behavior. This image quantitatively models the rapid, unsafe brake shown in the previous video through a rapid increase in car-related pixel usage. GIF This video shows the image analysis tool in action again, this time in a safe driving environment. This graph correlates to the previous image. The slow changes and small values show a safe driving distance with no major unsafe brakeage. GIF A GIF showing the app in action. The homepage of the app. The main menu page of the app. The driving page of the app. Users will see this page while the app collects driving data. The reports homepage of the app. The page for specific reports. This shows a color-coded score, suggestions, and appropriate navigation UI. 1 2 3 4 5 6 7 8 9 10 11 Inspiration Car accidents seem to be an unavoidable part of life. A grim reality that leaves many harmed, both temporarily and permanently. However, car accidents are not necessarily unav"
      }
    ]
  },
  {
    "file_path": "./devposts/nutrivision-tmulga.html",
    "project_id": "nutrivision-tmulga",
    "title": "NutriVision",
    "tagline": "Secure and accessible app that makes use of computer vision, in order to identify illnesses in people from remote areas and connect them with appropriate organisations to receive treatment.",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/620/323/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Submitted to CatalystXAI Created by dlathyun Yim alyssaongyx Ong"
      }
    ]
  },
  {
    "file_path": "./devposts/nutriscan-d06z4p.html",
    "project_id": "nutriscan-d06z4p",
    "title": "NutriScan",
    "tagline": "A revolutionary iOS app designed to empower individuals (particularly seniors) to take control of their health by easily monitoring their daily nutritional intake.",
    "hackathon": "",
    "built_with": [
      "apininjas",
      "firebase",
      "google-cloud",
      "nutritionapi",
      "python",
      "swift",
      "swiftui",
      "visionai",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/718/024/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Daily Limits Page Landing Page Login Page Home Page Camera Page Camera Classification Page Nutrition Facts Page Warning Page Updated Home Page Profile Page Statistics Page Daily Limits Page Landing Page Login Page Home Page Camera Page Camera Classification Page Nutrition Facts Page Warning Page Updated Home Page Profile Page Statistics Page Daily Limits Page 1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration My grandfather was recently diagnosed with kidney failure, and many of our teammates have grandparents who have diabetes and high cholesterol levels. We've all faced difficulties regarding regulating different nutritional elements, and it gets tedious and frustrating too easily. If you've ever used a calorie or macro tracker, you'll know what we're talking about! Manually inputting nutritional facts or having to search them up is a huge reason why most of us stopped using the trackers. Our solution? NutriScan, an iOS app that provides a convenient way for anyone to easily keep track of their daily nutritional intake. What it does NutriScan tracks the daily intake of important nutrients, such as cholesterol, sugar, and carbohydrates, so that those who need to restrict their diets are able to be more aware of what they are eating. Upon logging in or registering, the user can easily access their suggested daily intake ranges for different nutritional values. You can take photos of your food, and NutriScan will classify it and calculate its nutritional facts. Then, we'll help you record the food for the day and update a daily summary of your nutritional intake! Stay vigilant though! We'll give warnings if any category is above or below its suggested range to promote a healthy and sustainable lifestyle for their distinct needs. As a fun way to encourage people to stay on top of everything, we calculate a monthly score of how well they aligned with the suggested nutritional ranges! How we built it The architecture and front-end of our iOS app was programmed using SwiftUI and "
      }
    ]
  },
  {
    "file_path": "./devposts/obsidion.html",
    "project_id": "obsidion",
    "title": "Obsidion",
    "tagline": "An All-in-one platform for your finances. Master your path towards Financial Success",
    "hackathon": "",
    "built_with": [
      "css3",
      "decision-trees",
      "express.js",
      "flask",
      "heroku",
      "html5",
      "javascript",
      "linear-regression",
      "logistic-regression",
      "machine-learning",
      "mongodb",
      "node.js",
      "python",
      "react-native",
      "sass"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/085/355/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Domain Name - Obsidion.tech (Registered) Inspiration Obsidion is latin for investment. 78% of the north american population live paycheck to paycheck and have very poor money management skills. We wanted to create a tool for the average joe that will enable them to be in control of their finances and be able to achieve financial freedom. What it does The app can track all kinds of finance related stuff ranging from transaction, expenses, income, investments, credit history etc. The app will be able to sync all that data from the user's bank. It also has a feature that uses machine learning to track spending habits of the user and prompts them necessary money management tips. There's also a section called 'Did you know' which includes fundamental finance information regarding many things that the user might have not known. This will help the user be more familiar with the commonly used terms and money management rules How We built it For the back-end, We first created a REST API using express and mongoDb. For the mobile app, we used react native and some other packages such as bootstrap etc. We also created a web api using python and flask that uses \nmachine learning (linear regression, logistic regression and decision tree) to display current and future visual representations of their spending habits. For the did you know section, we used Uipath to webscrape information regarding finance fundamentals. Challenges We ran into One of the biggest challenge was coming to a mutual agreement regarding the project idea. After brainstorming for a few hours and wasting some time, we finally decided to pursue this project. Setting up the rest API was a bit of a challenge since we had to make sure the user data is secure and the login and authentication routes are protected.  It also a challenge to make the schema of the database the same as the input data from the app. Furthermore, a problem that arose when we were uploading our machine learning web api to he"
      }
    ]
  },
  {
    "file_path": "./devposts/offnet.html",
    "project_id": "offnet",
    "title": "OffNet",
    "tagline": "The easiest way to track and manage your computer screen time.",
    "hackathon": "",
    "built_with": [
      "css",
      "dart",
      "firebase",
      "flutter",
      "html",
      "javascript",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The easiest way to track and manage your computer screen time."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/609/699/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Humans spend more and more time in front of their screens, but they do that at the expense of enjoying the world around them. That problem inspired us to create an app that will help you track your screen time because without doing that, you can miss an event in the real world, which could cause you a lot of regrets in the future. For example, one of our team members recently went to Colorado but missed his opportunity to take pictures of tall mountains and steep, beautiful canyons because he was getting distracted by his phone. This type of story can happen to anyone, so it is important to address the problem of overexposure to technology. We are determined to help our users enjoy their non-digital life, while also completing their tasks on the computer. What it does Our product allows the user to set his own screen time limits, track the time he spends on his computer, and view important and accurate data about his activity. Our app doesn’t need the user to interfere with it while he or she is working, all the user needs to do is run the app in the background and start working. The app will take care of everything else. The statistics the user will get at the end of his work session will assist him in developing a better schedule for his future sessions. How we built it We built this app using Flutter, Web, Python, and Firebase. Flutter's efficiency and compatibility prompted us to use the framework for our companion app. Also, since manual recording is relatively taxing, we made an OpenCV system where it would track the individual's face. Firebase would record statistics like hours of screen time and the number of breaks and show it on the companion app. Challenges we ran into Our app relied a lot on the ability of our code to detect faces, but the machine learning algorithm that was responsible for that was at times inconsistent. Because the angle at which the camera sees the user’s face changes, at some moments, the app could think that th"
      }
    ]
  },
  {
    "file_path": "./devposts/office-space-optimization.html",
    "project_id": "office-space-optimization",
    "title": "Office Space Optimization",
    "tagline": "A simple application designed to arrange clients in an office space according to their preference for sharing floors with certain teams.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Our team set out to tackle the CBRE challenge in order to help the company organize their clients within an office space. We were interested in this challenge because it gave us the opportunity to try our hand at designing an algorithm to determine the most compatible office layout with only a small amount of data. Although our project is unfinished, this is definitely something we would like to finish in the future. Built With css3 html5 javascript Try it out GitHub Repo Submitted to TAMUhack 2023 Created by wytata Cade Shahir Ali"
      }
    ]
  },
  {
    "file_path": "./devposts/ok-9hwiye.html",
    "project_id": "ok-9hwiye",
    "title": "CarZam",
    "tagline": "Extremely accurate and fast vehicle-related audio processing software",
    "hackathon": "",
    "built_with": [
      "3js",
      "fastapi",
      "google-cloud",
      "material-ui",
      "pydub",
      "python",
      "pytorch",
      "raspberry-pi",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hackaburg 2022WinnerThe Sound of Propulsion - by Infineon",
      "# First Convolution Block with Relu and Batch Norm.",
      "# Second Convolution Block",
      "# Third Convolution Block",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/027/754/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Visualization of the hidden-layer codeblock CarZam, just like Shazam, but for cars ;) Information visualization Complete life cycle of an audio file Vertical blocks represent silence, while horizontal ones represent some frequences missing Visualization of the hidden-layer codeblock CarZam, just like Shazam, but for cars ;) Information visualization Complete life cycle of an audio file Vertical blocks represent silence, while horizontal ones represent some frequences missing Visualization of the hidden-layer codeblock 1 2 3 4 5 In the era of analytics, data explosion and IT 2.0, cameras, sensors and photoelectric barriers have been massively used to collect the most powerful currency of 21st century - data. One specific type of information though, has been especially neglected, and that is auditory information! Inspired by one of Hackaburg 2022s sponsors, Infineon, my friends and I have started discussing the unlimited source of information that is a \"sound\". After all, depending on the frequency and quantity of channels of the file, one second of an audio can be anything from a meaningless bleep to billions of sine waves intermeshed together to create a gold mine for anyone willing to invest the time to decipher their meaning. From the beginning of the hackathon, our goal was to display how rich the auditory information really is, and we believed the monotonous vehicle noises were perfect for that. Even before the Hackathon, we had a clear plan and even some proof, about what sort of information could be extracted from something as innocent as a car driving by: The speed and acceleration of the vehicle (derivatives of loudness contour) The shape and size of the vehicle (especially when the audio is being recorded from inside) The engine type of the vehicle (the source of most noise) The type of road and weather (the 2nd source of most noise, tire impact) The relative position from the microphone, and as such, complete echolocation of environment if provided enough "
      }
    ]
  },
  {
    "file_path": "./devposts/okedoke-karaoke.html",
    "project_id": "okedoke-karaoke",
    "title": "Okedoke Karaoke",
    "tagline": "Separate vocals, bass, and drums in real time!",
    "hackathon": "",
    "built_with": [
      "demucs",
      "opencv",
      "pyqt",
      "python",
      "ytdl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/089/133/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Devil Is a Lie Devil Is a Lie Devil Is a Lie 1 2 What it does We created a desktop application that separates vocals, bass, and drums from a song uploaded on YouTube, then plays the song and video in real time. Additional features include synced song lyrics, a search bar with autocomplete, and track option selection. How we built it When a song is chosen by the user, the audio is downloaded from YouTube and split into chunks. These chunks are asynchronously split into vocal, bass, and drum tracks using the demucs source separation model API. These tracks are played overlapping each other, with the user being given the option to exclude specific tracks.\nWe programmed a frontend GUI using PyQt to handle user input as well as lyric and video output. For user input, we implemented autocomplete by forwarding their text to YouTube’s search API and converting the chosen search to the YouTube link. We then download the audio from YouTube and handle audio output as mentioned above. Video output is handled using OpenCV, which gathers frames from the video that sync to the current audio position, then displays it to the screen. Lyrics are gathered from the syncedlyrics API, and are synced with the video and audio with the same method. Challenges we ran into The biggest challenge we faced was making our model process audio in real-time. This required us to pre-process our audio by cutting it into chunks, then asynchronously split the audio with our model. However, running python code asynchronously was another challenge we faced. This required research into multithreading and multiprocessing. The implementation we chose was to run each task in different child processes so that they could run simultaneously. What's next for Okedoke Karaoke The most major thing to work on is improving the performance of our application by reducing lag on the video display and improving the overlap between audio chunks. Additionally, we plan to work on adding more operating system accessibility, a"
      }
    ]
  },
  {
    "file_path": "./devposts/onionalyze.html",
    "project_id": "onionalyze",
    "title": "Onionalyze",
    "tagline": "Scan, Analyse, and Savour — Onionalyze your way to healthy eating!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "cloud-vision-api",
      "css",
      "figma",
      "firebase",
      "flask",
      "gcp",
      "html",
      "java",
      "javascript",
      "jquery",
      "node.js",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Google Cloud Created by Pratyay Banerjee I share memes more than I code :p // Smurfing",
      "Hack the HillWinnerBest Use of Google Cloud",
      "Best use of Google Cloud ☁️",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/407/397/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF High-Fidelity Design (figma) GIF High-Fidelity Design (figma) 1 2 3 4 5 Inspiration 💡 Are you tired of scanning ingredient lists to avoid certain foods? Do you ever come across a new fruit at the market but have no idea what to cook with it? Are you curious about the nutritional value of an apple? We've been there too, and that's why we created this app. These problems are nothing new and affect everyone, from people with reduced mobility to the lazy ones who just don't want to read the whole package. Our inspiration for this app came from the growing demand for quick and easy access to information about food and nutrition. We recognized the need for a tool that could provide users with accurate and useful information about food and nutrition, all in one convenient place, and that's exactly what we created. What it does 🤔 The app that we created here is a real game-changer when it comes to food and nutrition. With just a snap of your camera, you can take a picture of any food item, and the app will recognize what it is, providing you with a wealth of information. Not only does it give you the name of the food item, but it also gives you the option to find recipes using that food item, so you can explore new and exciting ways to enjoy your meals. If you're trying to keep track of your health and nutrition, this app is a fantastic tool to have. With its access to powerful APIs, you can easily access the nutritional values of the food you've captured, helping you make informed decisions about what you're eating. Additionally, the app can scan an ingredients list and alert the user if it contains a food item they're allergic to or trying to avoid, making it a must-have for individuals with food allergies or specific dietary requirements. Signing in with your Google account makes it even more seamless and efficient. This app is a must-have for anyone who is serious about their health, nutrition, and exploring new and exciting foods. How we built it 🦾 Frontend: HTML, "
      }
    ]
  },
  {
    "file_path": "./devposts/omnom-hg16v3.html",
    "project_id": "omnom-hg16v3",
    "title": "OmNom",
    "tagline": "OmNom is your late night food savior, autonomously navigating a variety of outdoor and indoor environments across campus to bring back your cravings just in time for you to finish your PSET.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "clip",
      "dpt",
      "fast-api",
      "google-maps-places-api",
      "jetson-nano-c++",
      "lasercutting",
      "matplot-lib-v0.dev",
      "metal",
      "next.js",
      "open-cv",
      "open-route-service",
      "openai-api",
      "python",
      "react",
      "roboclaw",
      "soldering",
      "tailwindcss",
      "typescript",
      "vercel",
      "vit",
      "vite.js",
      "websockets-api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Creative Hack (Pioneer DJ DDJ-FLX4 Pack per team member) Created by front and back end of the",
      "TreeHacks 2025WinnerMost Creative Hack (Pioneer DJ DDJ-FLX4 Pack per team member)",
      "If present, recognizes/tracks target object",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/274/322/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "mid building process ipad control state machine screenshot a fraction of our custom laser cut parts frontend web app food ordering simulation app depth mapping mapping and object classification electrical wiring early building process full body robot shot mid building process ipad control state machine screenshot a fraction of our custom laser cut parts frontend web app food ordering simulation app depth mapping mapping and object classification electrical wiring early building process full body robot shot mid building process 1 2 3 4 5 6 7 8 9 10 11 Inspiration Stanford students are always busy late into the night cramming for PSETs while playing too much poker. You're craving a late night snack, but it's a little too cold, and Late Night is a little too far away. If only you could get food without walking across campus and waiting in line... Meet OmNom , a 6ft tall robot that fetches your food for you. We were inspired by Om Nom from the popular mobile game Cut The Rope. Like in the game, you have to cut a rope to get your food from OmNom . What it does OmNom is a 6ft tall robot that fetches food for you. He can navigate both outdoors and indoors. OmNom can find the front door, get in line, and even use self-order booths on your behalf. All you have to do is go to OmNom's website, and put in your order in natural language. OmNom then autonomously traverses across campus to Late Night, navigates inside, places your order for you, and brings back your food. How we built it OmNom was not easy to build, and our journey took us across almost the entire tech stack... Mechanical design Fabrication Om nom was built from scratch, with no pre existing assemblies or electronics used. A lot of Om nom is built from laser cut sheet metal, and we made 10 different sheet metal lasercut parts (22 total on the robot). Om nom's drivetrain uses 6\" wheels and repurposes a moving dolly. It has single loop chain wraps on each side 5 degree of freedom arm Om nom uses a kevlar rope driven"
      }
    ]
  },
  {
    "file_path": "./devposts/okailora-ai.html",
    "project_id": "okailora-ai",
    "title": "OkaiLoRa.ai",
    "tagline": "OKaiLora.ai is the Shopify of ML for healthcare tasks.\nOur platform offers training, testing, and sharing for state-of-the-art healthcare tasks.",
    "hackathon": "",
    "built_with": [
      "kotlin",
      "nextjs",
      "pytorch",
      "react",
      "springboot",
      "swagger",
      "vibes"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Track training metrics in real-time, no code, no setup!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/499/241/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In the medical AI space, clinicians and researchers often sit on high-value datasets but lack the tools and the time to turn them into actionable machine learning models. The current paradigm involves outsourcing to middlemen, which are ML engineers, who are far removed from the data collection and intent. Yet, even when the models are trained, they need to remain proprietary due to patient data privacy issues, which stop medical healthcare professionals from sharing their data, and enabling wide-spread sharing of their training pipeline. We wanted to flip that model: what if any medical professional could train and deploy state-of-the-art Vision Transformer (ViTs) models themselves, in minutes, no code required?\nWhat if, instead of sharing data, they could encode their hundreds of GB of data into low-level representation model adapters (LoRa adapters), which could be added for fast-shareable inference? What it does OKaiLoRa.ai is a no-code platform that simplifies healthcare model training, fine-tuning, and model sharing platform which allows medical professionals to: Upload image data for classification, segmentation, generation, or object detection, within our deployment server. Select from a curated set of pre-trained models, which encompass the mainstream medical healthcare tasks, such as image classification, image segmentation, bounding box detection and generation. Train lightweight LoRa adapters on limited hardware (even with just 6GB VRAM)! Track training metrics in real-time, no code, no setup! Share inference-ready models via secure Tailscale-powered links which point to the LoRa weight  and fine-tuned weight checkpoints, keeping patient private data secure. How we built it Frontend : Built in React, the UI supports drag-and-drop data uploads, dynamic sliders for model configuration, and real-time progress displays for accuracies, loss, and epoch. Backend : Powered by SpringBoot in Kotlin, we provide a robust REST API layer with the following"
      }
    ]
  },
  {
    "file_path": "./devposts/onehome-5t097e.html",
    "project_id": "onehome-5t097e",
    "title": "OneHome",
    "tagline": "Connecting homeless people with homes.",
    "hackathon": "",
    "built_with": [
      "heroku",
      "html",
      "java",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "One home is a web application designed to assist people in need, aimed at the homeless in particular, in finding the closest resources to them any where on the globe.\nOur app communicates with Google Map API to list the closest shelters near the given address. Beyond that, we wanted to give shelter owners a platform to signal to the community the status of their inventory: if there are any vacant beds left, if they provide food services, medical assistance and access to clothes banks. To do that, shelter owners can sign up for a free profile, verify their shelter by providing an ID (like an electricity bill) and create an updated profile on the application. We also provided the ability for any person to create a profile and to reserve a place in a shelter as a guest or as an already registered user. In the future, we would want to work with an organization that provide free ride shares to people in need such as Red Nose. Built With heroku html java javascript react Try it out GitHub Repo Submitted to Hack the Northeast: Beyond Created by Hamza Kaced Belle Hagan 2nd year Computer Science student urjeet shrestha Josh Fried"
      }
    ]
  },
  {
    "file_path": "./devposts/online-made-easy.html",
    "project_id": "online-made-easy",
    "title": "Online Made Easy",
    "tagline": "Online learning is hard for many students. But with the perfect tools in your hands, you can make your life much easier. Introducing Online Made Easy",
    "hackathon": "",
    "built_with": [
      "css3",
      "html",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winners Created by I worked alone in this project",
      "Second Place Winners Created by I worked alone in this project",
      "IBY Hacks+ 2021WinnerSecond Place Winners",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/588/409/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 What it does An app made to improve your experience online by grouping useful studying tools, resources and techniques as smaller widgets in a beautifully designed layout. There is a great variety of apps, such as a pomodoro timer, a meditation app, and many more! Challenges I ran into My CSS skills were quite rusty when I started this project. Creating a good-looking widget layout was the biggest challenge I face when working on the app. Accomplishments that I'm proud of I am proud of the design layout, which looks stunning and modern in my opinion. What I learned Grid and flexbox CSS. Improved my knowledge and skills in React. What's next for Online Made Easy A mobile app, and a \"Widget Store\" Built With css3 html javascript react Try it out freakboy123.github.io Submitted to IBY Hacks+ 2021 Winner Second Place Winners Created by I worked alone in this project. I made the widget layout with React, and prepared the pitch video. Aly Shariff"
      }
    ]
  },
  {
    "file_path": "./devposts/optimist.html",
    "project_id": "optimist",
    "title": "Optimist",
    "tagline": "Grammarly for prompt engineering",
    "hackathon": "",
    "built_with": [
      "love?",
      "openai",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/481/872/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 A tool to help you write better prompts, ask it to improve your prompt in some direction and it will help you do that and compare the results In the future, it will tell you what is wrong with your existing prompts and auto evaluate them. Built With love? openai react Try it out optimist.varied.ai www.loom.com Submitted to AI SF Created by Caused levan stress Rahul Tarak InkOut"
      }
    ]
  },
  {
    "file_path": "./devposts/ok-spmfva.html",
    "project_id": "ok-spmfva",
    "title": "Data Friend",
    "tagline": "Collaborative Filtering algorithm for Binary, Positive-only Data, fletched into a beautiful data vizualisation software to underline more human-like feature recognition",
    "hackathon": "",
    "built_with": [
      "css",
      "d3.js",
      "html",
      "javascript",
      "materialui",
      "pandas",
      "python",
      "react",
      "scipy",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "of the best and do the job perfectly, the humans tend to struggle with understanding the actual rea"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/915/168/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Video Walkrthough of our app Screenshot of our application Data represented in an experimental different view GIF Video Walkrthough of our app Screenshot of our application Data represented in an experimental different view GIF Video Walkrthough of our app 1 2 3 Inspiration As a team with a ton of experience in the field of data-science, we could all relate to the black-box problem that comes with various feature-extraction/clustering/ML algorithms. While the algorithms are really best of the best and do the job perfectly, the humans tend to struggle with understanding the actual reason why the final result works to begin with. A similar feeling arises with E-Commerce and advertising, where while the advertising algorithm seemingly maximizes the revenue, the user never feels like his interessets are being understood properly. With that problem in mind, we sat down to create something that presents ML/Statistical analysis about data in a human-friendly way. That's how the idea about \"Data Friend\" was born. What it does The tool \"Data Friend\" was designed with the goal in mind to make feature extraction and spotting connections between seemingly unrelated datapoints as humanly easy as possible. The final product closely resembles our goal, with the visualisation software making a lot of seemingly unrelated data pop into logical groups, that can then be further analysed both by software and by a human. Even if human interraction is not welcome by the client, the profiling software still tries to replace and improve upon the human-like suggesting patterns that might lead to overall higher client retention due to client's feeling more welcome and cared for, at least while shopping for those specific shops How we built it The project is divided into two central parts - one built with Python's scientific computing library SciPy, and the other one with the known frameworks like MaterialUI and most importantly Vite for the lightning fast visualisations. The parts were bu"
      }
    ]
  },
  {
    "file_path": "./devposts/optimaloc.html",
    "project_id": "optimaloc",
    "title": "MediLoc",
    "tagline": "Nutrition centers remain the foremost solution to stunted growth in Indonesia, but identifying the optimal locations for these centers for maximum outreach in an area is difficult. Enter MediLoc!",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "css",
      "flask",
      "html",
      "javascript",
      "marshmallow",
      "mysql",
      "numpy",
      "pandas",
      "primeng",
      "python",
      "scikit-learn",
      "sqlalchemy",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/183/992/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Designed UI (using figma.com) Designed UI (using figma.com) Designed UI (using figma.com) 1 2 Inspiration Stunted growth is considered to be one of Indonesia’s largest health concerns, affecting one in every three children across Indonesia. This condition arises from lack of access to proper nutrition and surprisingly was one of Indonesia’s least-known health issues. It was not until very recently that the government started realizing the permanent damage that stunting causes towards children’s physical and cognitive capacities and began accelerating programs in 2018 to combat this issue.\nThese programs mostly comprise of setting up nutrition centers in rural areas that provide basic immunization, breastfeeding, dietary diversity, drinking water and sanitation, etc. However, as the government plans to scale up these programs to hundreds of more districts (planning to reach 514 districts and cities by 2021), the issue of limited resources arises. The government can only build a certain number of centers in an area, and so a critical question emerges: “What are the optimal locations for these nutrition centers for maximum outreach in an area?” This is where MediLoc comes in. What it does MediLoc is a web app built for the government and healthcare organizations to identify the optimal locations for a given number of nutrition centers in a district/area. Upon opening the web app, the user is shown a map and prompted to input the locations of the target villages on the map and their corresponding populations of children with stunted growth. The user will also be prompted to input how many centers are to be built in this area, as well as how many healthcare workers are to work in this area. After inputting all this data, the user clicks “RUN,” which runs a k-means clustering algorithm that optimally finds the locations for these centers in the area. In the web app, the locations of these centers are displayed; the villages will be color-coded according to the centers fro"
      }
    ]
  },
  {
    "file_path": "./devposts/open-trading.html",
    "project_id": "open-trading",
    "title": "The OpenTradeLab",
    "tagline": "Bold, Accessible, Ethical. An open-sourced algorithmic trading platform tapping into 150 billion/month market, moving towards transparency while aligning financial success with responsible investing.",
    "hackathon": "",
    "built_with": [
      "ai",
      "app-engine",
      "c++",
      "flask",
      "gemini",
      "google-cloud",
      "llm",
      "machine-learning",
      "python",
      "react-js",
      "single-store",
      "stock-market-data",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/088/950/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Realtime processing far left, Near-time LLM and contextualization in middle, compiling and execution on the right. Our glorious tech-stack Our stock portfolio monitor Dark Mode :) Our integrated notebook Prediction modeling example built with non-continuous data Real-time updating correlation visualization between different stocks (Can append data to edges for increased context) essentially a mapper Realtime processing far left, Near-time LLM and contextualization in middle, compiling and execution on the right. Our glorious tech-stack Our stock portfolio monitor Dark Mode :) Our integrated notebook Prediction modeling example built with non-continuous data Real-time updating correlation visualization between different stocks (Can append data to edges for increased context) essentially a mapper Realtime processing far left, Near-time LLM and contextualization in middle, compiling and execution on the right. 1 2 3 4 5 6 7 8 9 Inspiration Our project aims to democratize algorithmic trading and the data associated with it to capture a 150 billion dollar a month trade volume and aim it towards transparency and purpose. Our project is a culmination of the technical depth and breadth of a new step forward in technology. We really wanted to open up the centralized and ever exclusive profession of algorithmic trading, giving the average retail trader the same tools and data as billion dollar companies. Empowering curiosity and innovation through open sourced data and tools. What it does Our project is an brokerage platform that hosts compute, data APIs, processing tools, algorithms,  and data-stream. A mix of the usability of Robinhood with the decentralized community building of technical people like Kaggle. We transform strategies and ideas that require a huge amount of capital and expertise, and hand it to the every-day retail investor. When customers upload code, our platform allows them to test their ideas out on paper trades, and when they are confident enough, we hos"
      }
    ]
  },
  {
    "file_path": "./devposts/open-ed.html",
    "project_id": "open-ed",
    "title": "OpenED",
    "tagline": "Enabling students to voice their opinions.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/939/800/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Enabling students to voice their opinions What is OpenED? OpenED is a school-wide web app that serves as a platform for students to voice their opinions anonymously so that schools will take their ideas and opinions into consideration for their events and activities. These features are extremely helpful for students that may be too uncomfortable to voice their opinions, and it gives them the opportunity to have an impact on their school environment. What Inspired us to do this? An increasing percentage of high school students are withholding their opinions due to the fear of being judged by others or offending others. Without students' input on learning techniques, events, and activities, they won’t know what students want. Features Submit a suggestion Suggestion feature for students to share their ideas to improve or create better clubs and learning environments. Vote for suggestions A voting feature that students can use to vote on school events, clubs, and activities suggested by students. Rate teachers A feedback feature to give comments on improvement for teachers, staff, clubs, and school activities. Built With css html javascript Try it out opened.tech GitHub Repo Submitted to Hack the Valley 4 Created by Param Thakkar Justin Lau Computer Engineering @ UWaterloo"
      }
    ]
  },
  {
    "file_path": "./devposts/optiver-team-19.html",
    "project_id": "optiver-team-19",
    "title": "Optiver Team 19",
    "tagline": "We are developing a market making algorithm that will make a lot of profit!",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hackaTUM 2022WinnerOptiver",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration inspired by profit Built With python Submitted to hackaTUM 2022 Winner Optiver Created by Justus Beck Ibad Rather"
      }
    ]
  },
  {
    "file_path": "./devposts/optimist-6c3tn7.html",
    "project_id": "optimist-6c3tn7",
    "title": "Optimist",
    "tagline": "Grammarly for prompt engineering",
    "hackathon": "",
    "built_with": [
      "love?",
      "openai",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/482/089/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 A tool to help you write better prompts, ask it to improve your prompt in some direction and it will help you do that and compare the results In the future, it will tell you what is wrong with your existing prompts and auto evaluate them. Built With love? openai react Try it out optimist.varied.ai www.loom.com Submitted to HackAIthon by Craft Ventures Created by Caused levan stress Rahul Tarak InkOut"
      }
    ]
  },
  {
    "file_path": "./devposts/one-home.html",
    "project_id": "one-home",
    "title": "One Home",
    "tagline": "One Home is a web app designed to assist the homeless in finding the closest shelter. Using google map api, One Home lists the closest shelters with the services offered at that shelter",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "java",
      "javascript",
      "react",
      "react-bootstrap",
      "spring"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/353/641/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "registration page homepage Google Map API listing shelters in Montreal registration page homepage Google Map API listing shelters in Montreal registration page 1 2 3 4 Inspiration: Homeless people in our cities and how they were impacted by COVID-19 What it does: One home is a web application designed to assist people in need, aimed at the homeless in particular, in finding the closest resources to them any where on the globe.\nOur app communicates with Google Maps API to list the closest shelters near the given address. \nBeyond that, we wanted to give shelter owners a platform to signal to the community the status of their inventory: if there are any vacant beds left, if they provide food services, medical assistance and access to clothes banks. To do that, shelter owners can sign up for a free profile, verify their shelter by providing an ID (like an electricity bill) and create an updated profile on the application. \nWe also provided the ability for any person to create a profile and to reserve a place in a shelter as a guest or as an already registered user. In the future, we would want to work with an organization that provide free ride shares to people in need such as Red Nose. How I built it: Using React as a javascript framework and Spring as a java framework to communicate with our user database and Google Maps API Challenges I ran into: Trying to get only shelters listed from google map Accomplishments that I'm proud of: I am proud of the project, it is something I actually believe in and would want to make into an actual product What I learned: how to use React, MySQL What's next for One Home: We all agree on finishing this project together as a team beyond this hackathon and hopefully we will deploy with a mobile app interface soon. Built With css html5 java javascript react react-bootstrap spring Try it out onehome.space GitHub Repo Submitted to Hack the Northeast: Beyond Created by I worked on the frontend using React.js as well as a google maps API. ur"
      }
    ]
  },
  {
    "file_path": "./devposts/outsiide.html",
    "project_id": "outsiide",
    "title": "Outsiide",
    "tagline": "Informing you about outdoor gatherings in your local community.",
    "hackathon": "",
    "built_with": [
      "bubble",
      "css",
      "html",
      "javascript",
      "opendb",
      "openlayers2",
      "qoom"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/645/789/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Bubble - viewing a specific discussion and its replies Front page of Outsiide, showing map with marker+description placed on San Francisco (Qoom framework) Secondary page of Outsiide, if the user wishes to add a marker on the map through submitting a form (Qoom framework) Bubble - discussion forum for Outsiide (discussions based on event location) Bubble - adding new events using a form Bubble - viewing current events on a map Bubble - viewing a specific discussion and its replies Front page of Outsiide, showing map with marker+description placed on San Francisco (Qoom framework) Secondary page of Outsiide, if the user wishes to add a marker on the map through submitting a form (Qoom framework) Bubble - discussion forum for Outsiide (discussions based on event location) Bubble - adding new events using a form Bubble - viewing current events on a map Bubble - viewing a specific discussion and its replies 1 2 3 4 5 6 7 Inspiration Having been in quarantine for the past two years, we've seen a large decline in outdoors-related activities and a lack of social interaction between fellow peers. From a survey of 60 students, over 75% of classmates said that they were more isolated now than they were before the pandemic. Additionally, nearly 90% of them didn't go outside for exercise. We found, after investigation, that the main part of this problem is a lack of awareness about where outdoor gatherings are. There isn't a suitable compilation of all outdoor-related activities that individuals can look to on a regular basis, which leads to this cycle of decreased social interaction. Going back in person this year, we've felt the struggles of the pandemic and want to figure out a way to increase social interaction between individuals, promoting mental health either through exercise or just mental wellness talks outside. From an NYU study, only half of all students exercise weekly; we face a major health crisis as physical education is not stressed in modern-day society. What i"
      }
    ]
  },
  {
    "file_path": "./devposts/optimizing-bicycle-infrastructure.html",
    "project_id": "optimizing-bicycle-infrastructure",
    "title": "Optimizing bicycle infrastructure – Košice 2.0",
    "tagline": "Algorithm for finding the best possible cycling route within fixed bugets. The optimal path connects the most people with the chosen infrastructure in Košice.",
    "hackathon": "",
    "built_with": [
      "cython",
      "google-colab",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We are inspired to pursue this vision because we believe that it has the potential to create real change in our communities. By making our cities more walkable and bikeable, we can reduce traffic congestion and air pollution, improve public health by encouraging people to walk or bike instead of driving, and increase social interaction by creating more public spaces where people can gather and connect. What it does The goal of this project is to identify the best location for a new cycling path in a city that brings points of interest closer to as many people as possible while staying within a constrained budget, thus saving money to a city. How we built it We used Python and Google Colab. We also used Cython with GCC compiler for the most performance-critical part of our project. Challenges we ran into We encountered several challenges such as how to process data, evaluate a potential cycle route, and optimize it as well as ensure good performance of our code. Accomplishments that we're proud of We are proud of the fact that our project has the potential to make a real difference in people's lives by promoting healthier, more sustainable forms of transportation. What we learned We enhanced our skills in teamworking, problem solving and data processing. What's next for Optimizing bicycle infrastructure Next feature that should be added is the evaluation of the cycling routes for their plausibility. Built With cython google-colab python Try it out drive.google.com Submitted to Hack Kosice 2023 Created by I worked on a function for cycle route scoring, performance enhancement using Cython, UI, and a portion of data processing. Vítězslav Lužný Matěj Vais Maroš Bratko 0ntos 90ku1"
      }
    ]
  },
  {
    "file_path": "./devposts/oneshot-social.html",
    "project_id": "oneshot-social",
    "title": "OneShot Vision",
    "tagline": "Facial Detection and Intelligence Glasses for Networking Events.",
    "hackathon": "",
    "built_with": [
      "machine-learning",
      "neural-networks",
      "opencv",
      "python",
      "raspberry-pi",
      "twilio",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Unique Hack Created by Naman Singh Founder of MassApply, Software Engineering Intern at Reddit",
      "VTHacks IXWinnerMost Unique Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/855/130/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration As anxious coders deprived of typical social interaction, networking events are our worst nightmare. We wanted to hack a way for us to instantly learn about the people we're meeting and break the ice as fast as possible. What it does OneShot Vision uses our own one-shot face detection machine-learning algorithm, and our custom-built raspberry pi glasses to recognize and match a face to our database in real-time. We then pull up their LinkedIn information to appear on a small OLED screen in front of your eyes. How we built it We built a headset that consists of a raspberry pi, a pair of glasses, an OLED screen, and a camera to process a feed of live image data. Using hard cascade image detection we’re able to isolate the face, and send it into our own ML model for one-shot facial detection. We utilized siamese neural networks to make the one-shot face detection algorithm. Once a contact’s face is recognized, we query our DB for the contact’s information and return it back to our raspberry pi glasses, which gets displayed on the wearer’s small non-obtrusive OLED screen. And since there’s only limited space on the screen, we’re also sending the user a text message using Twilio’s API to provide a full profile overview of the person you’re meeting. Challenges we ran into One unique constraint for this problem, is that we needed our facial recognition to work with a single sample per person. This is because for networking events, you will typically have access to only the profile pictures of attendees. This added a lot of difficulty since most facial identification models rely on thousands of images. So this led us to implement a siamese neural network for one-shot facial recognition. Accomplishments that we're proud of Overcoming the single image sample size per person is an extremely challenging Machine Learning problem, so we are impressed with ourselves that we've built a feasible implementation of One-Shot facial detection in the short time fram"
      }
    ]
  },
  {
    "file_path": "./devposts/ourworld.html",
    "project_id": "ourworld",
    "title": "OurWorld",
    "tagline": "OurWorld is an app designed to help everyone explore our world. Thanks to posts in either text or video format, users can interact with them and briefly learn about various topics.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "javascript",
      "react",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/619/442/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration I am afraid that in the future, I will lose my desire of learning. Prior to making the project, I had read an article about people being less curious as they grew older. Therefore, I thought of an app that would promote and ease learning for everybody! What it does It is an app built to develop curiosity and improve our general knowledge thanks to posts made by the community. Either in text or video format, these posts are made to be concise. Due to limited time in our day, it can be hard to learn new things. Therefore, brevity is key. How we built it Javascript, using the React Native framework to build cross-platform mobile apps and Expo-CLI Challenges we ran into Finding a way to store our posts, as I didn't develop any backend for this app. I ran into few technical problems with running simulators on my computer. It was my real first time building a mobile app (I had already built one, following a tutorial). Accomplishments that we're proud of Making a good-looking layout and adding posts to the app. Finishing the app in time without any bugs. What we learned Using React Native and Expo-CLI more effectively. I also improved my skills using git and GitHub. I learned how to some React Native components as well as modules related to that framework. What's next for OurWorld First, improving the functionality of the app to make it publishable by coding all the features promised. Second, making a backend for the app to store posts and user information. Built With expo.io javascript react react-native Try it out GitHub Repo Submitted to XHacks 2021 Created by I built the entire frontend of the app. I was the only member of my team, so I was responsible for everything. Aly Shariff"
      }
    ]
  },
  {
    "file_path": "./devposts/organ4health.html",
    "project_id": "organ4health",
    "title": "Organ4Health",
    "tagline": "We are a three-person team whose goal is to bridge the gap between health and the public by emphasizing transparency. Discord is a major player in social media and so our team decided to create a bot.",
    "hackathon": "",
    "built_with": [
      "heroku",
      "nextcord",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The Wolfram Award Created by Worked on the coding logic for the commands, collaborated with team me",
      "RU Hacks 2022: DigitalWinnerThe Wolfram Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/927/804/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Feature to locate the blood bank or hospitals when clicked List of available commands Blood bank search funciton Organ search by organ type Feature to locate the blood bank or hospitals when clicked List of available commands Blood bank search funciton Organ search by organ type Feature to locate the blood bank or hospitals when clicked 1 2 3 4 5 Inspiration Our team decided to develop a discord bot while serving a meaningful purpose in society, and so one of our developers discussed about a situation in their country where it was hard to find an organ donor at times of need. With this in mind, our team had decided that this idea can be implemented onto a discord bot while doing a meaningful contribution to the society. What it does The purpose of our bot is to develop a database that stores data of organ donors including blood donors, where our  users can access this information and enter their personal health constitutions, once the arguments are entered into the bot, it will then filter out the data according the arguments, thus providing a potential candidate. How we built it Our developers had used nextcord  library to connect to the Discord API and connected the application with a lightweight sqlite database which had mock data of potential donor samples as per user query . We used Python as our main programming language. Challenges we ran into A challenge we have ran into while making our discord bot was that everyone in the group had little experience in developing a discord bot and so learning how to code a discord bot in a very small time limit was very challenging.\nWhile developing the bot various bugs appeared such as repeated results and different functions have not appeared when summoned. This was also our first time developing an asynchronous application and this was our practical experience in asynchronous programming beyond tutorials and labs. Also all three of us were in very different time zones, so coordination was hard to establish but kudos to "
      }
    ]
  },
  {
    "file_path": "./devposts/paimless.html",
    "project_id": "paimless",
    "title": "pAIMLess (#18)",
    "tagline": "pAIMLess allows people with no experience with neural networks to quickly train and deploy them.",
    "hackathon": "",
    "built_with": [
      "numpy",
      "pandas",
      "python",
      "tensorflow",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/233/110/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Making AI models is hard, and even harder when you don't know how to use machine learning libraries. Even though these libraries are meant to make the process easier, sometimes its just confusing and overall annoying trying to make a machine learning model. This can take days, to even weeks to perfect, and it may take a large chunk of time out of a side project that doesn't have the model as its main priority. What it does pAIMLess is a lightweight application that allows users to quickly create and deploy neural networks. You basically give it a csv to train and tweak some settings of the machine learning model, and the program automatically trains the model. You can also host it on a server handcoded by us, and send requests to it. How we built it We used Tensorflow with Python, processed data with pandas, created a httpserver, and the interface is with tkinter. Challenges we ran into We had many, many Git merge errors. Not everyone in our group knew much about neural networks, so they had to learn a bit. However, by the end, it turned out fine as we pulled through. Accomplishments that we're proud of We were able to make a working prototype of a no-code neural network builder that seemed daunting at first. It is actually really cool how you can send requests to the api/server that we hosted the model on. What we learned We learned skills for collaboration on Git, and more about AI in general. We also learned about csv reading and httpsserver making. What's next for pAIMLess Adding more customization (more types of layers), more templates, and sharing templates. Built With numpy pandas python tensorflow tkinter Try it out GitHub Repo Submitted to Los Altos Hacks VI Created by I worked on making the model's training, the templates, and creating the deployment server. Andrew Fan I helped to write the functions used for reading and parsing CSVs. Then I worked on developing our pitch and our demo video. Max Yang I worked on the basic skeleton code that we "
      }
    ]
  },
  {
    "file_path": "./devposts/orca.html",
    "project_id": "orca",
    "title": "ORCA",
    "tagline": "\"A teens Best Friend\"",
    "hackathon": "",
    "built_with": [
      ".net"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "\"A teens Best Friend\""
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/282/611/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 What's next for ORCA V 2.0 with alarms and many more exiting features that will help you be in-touch with your work. Built With .net Submitted to Hackerupt Created by Rahul Tarak"
      }
    ]
  },
  {
    "file_path": "./devposts/pac-head.html",
    "project_id": "pac-head",
    "title": "Pac-Head",
    "tagline": "The More Politically Correct Version of Pac-Man",
    "hackathon": "",
    "built_with": [
      "canvas",
      "css3",
      "html5",
      "javascript",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Video Game Remix Created by Anita Yip Product owner, project manager, retired hackathon-er",
      "Best Video Game Remix Created by Anita Yip Product owner, project manager, retired hackathon-er",
      "Hack-Cade 2WinnerBest Video Game Remix",
      "It was my first time figuring out collision detection on canvas!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I created this in honor of Pac-Man's 40th Anniversary this year 2022. When being PC is valued, I decided to rename Pac-Man to Pac-Head and allow for using your head physically to play this game. What it does You can play the class version of Pac-Man on PC using the arrow keys. In the Post-COVID version, you can help our hero navigate the maze and eat/collect all the yellow dots by physically moving your head around the screen. How we built it HTML, CSS, JavaScript, and HTML Canvas! Python / OpenCV for tracking head. Challenges we ran into There was only so much time to do it all! Accomplishments that we're proud of Made a working version of a beloved game! What we learned It was my first time figuring out collision detection on canvas! What's next for Pac-Head More PC versions! Built With canvas css3 html5 javascript opencv python Try it out GitHub Repo thepcversionofpacman.tech Submitted to Hack-Cade 2 Winner Best Video Game Remix Created by Anita Yip Product owner, project manager, retired hackathon-er"
      }
    ]
  },
  {
    "file_path": "./devposts/outfit-social-app.html",
    "project_id": "outfit-social-app",
    "title": "Outfit Social App",
    "tagline": "Say goodbye to the stress of figuring out what to wear based on the forecast! With Outfit Social App, you can get personalized outfit recommendations tailored to the weather conditions in your area.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "firebase",
      "openmeteo",
      "react",
      "tailwindcss",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Auth0 Created by I was responsible for seamlessly connecting users' browsers with the O",
      "HackBattle: Mobile vs WebWinnerBest Use of Auth0",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/453/776/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Upload your fits Dark mode (1) Dark mode (2) Clothing suggestions Upload your fits Dark mode (1) Dark mode (2) Clothing suggestions Upload your fits 1 2 3 4 5 Inspiration We wanted to create an app that would make it easier for people to choose what to wear for the weather, so they can save their brain power for more important things. We were also inspired by the story of Albert Einstein, who is said to have bought several variations of the same suit so that he wouldn't have to waste time deciding what to wear each morning. Outfit Social saves you this time, so you can focus on more important things in your life! What it does Outfit Social is an app that suggests outfits based on the weather in your area, so you can be both comfortable and stylish without having to put in a lot of effort. The app uses logical algorithms to provide personalized recommendations, taking into account factors such as your style preferences and body type. You can also share photos of your outfits, discover new styles, and connect with other users who share your fashion interests. How we built it We built Outfit Social using a combination of React, Firebase, and Auth0. We also integrated the OpenMeteo API to provide accurate and up-to-date weather information. Furthermore, we used Vite, Google Cloud Hosting and various tools to future-proof our project. For the design, we used TailwindCSS to create a modern and responsive user interface. Challenges we ran into One of the biggest challenges we faced was creating accurate and personalized outfit recommendations that would meet the needs of different users. We also had to ensure that the app was secure and user-friendly. Accomplishments that we're proud of We're proud of the algorithms we developed to provide personalized outfit suggestions and the user interface we created using TailwindCSS. We're also happy with the integration of the OpenMeteo API, which provides accurate and reliable weather information. What we learned Through building O"
      }
    ]
  },
  {
    "file_path": "./devposts/pacepal.html",
    "project_id": "pacepal",
    "title": "Pacepal",
    "tagline": "Pacepal is an app that encourages jogging by allowing showing you different places to jog to depending on your preferences and desired distance. The app also allows you to meet up with fellow joggers.",
    "hackathon": "",
    "built_with": [
      "google-maps",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "This project was build with react native and the google maps api.  We were inspired to create this app after repeatedly hearing about the high obesity rates in America. Built With google-maps react-native Try it out GitHub Repo Submitted to MSET health hackathon Created by Capital E___ Ashish Ramanan \"Python\" \"Java\" \"GDscript\" \"Html\" \"CSS\" \"JavaScript\" \"React\" \"React Native\" davnotdev Zhong"
      }
    ]
  },
  {
    "file_path": "./devposts/orbis-kb9218.html",
    "project_id": "orbis-kb9218",
    "title": "Orbis",
    "tagline": "Orbis is an online community where users can prioritize their productivity and well-being with their peers.",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "figma",
      "html",
      "javascript",
      "mongodb",
      "node.js",
      "react",
      "socket.io",
      "webrtc"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Courageous Hack #3 Created by I was the full-stack developer for the team",
      "TechTogether BostonWinnerMost Courageous Hack #3",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/699/808/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Before & After Login Kanban Board Wireframe Before & After Login Kanban Board Wireframe Before & After Login 1 2 3 4 Inspiration During the pandemic, a lot of online communities like LifeAt.io and Study Stream have surfaced for students studying in the pandemic. Needless to say, they have become quite popular over the past few months and going viral on TikTok. As students and recent grads, we understand why working with your peers boosts our productivity. Although these platforms are very helpful, there isn't a platform for students to create private study sessions specifically for their peers that also prioritize their mental well-being together. What it does Orbis is an online community for users to create public and private study sessions to encourage interactivity and productivity all at the same time. Within these sessions, users can activate the Pomodoro timer to prioritize breaks with their peers. During such breaks, users can access the motivation corner, where they can scroll through inspirational study content instead of scrolling through social media's which will  lead to procrastination. How we built it Front-end: React, HTML, CSS, and Bootstrap was used to build the front-end of the application. WebRTC was used for Peer to Peer video connections. Back-end: MongoDB, NodeJS, and ExpressJS were used for the back end. Socket.io was used for maintaining chat rooms. Challenges we ran into While we faced several challenges (such as overlapping flex layouts and connecting the different elements of the project together). Some challenges we faced in the back-end was having to deal with cross origin request errors when sending request from the react front-end to the node js backend,  figuring out how to authenticate websocket connections, integrating WebRTC with React in the front-end, and creating multiple chat rooms that users can sign into. The team decided to use Google and YouTube to assist them with the issues. Accomplishments that we're proud of The team is"
      }
    ]
  },
  {
    "file_path": "./devposts/orb-5dvm4b.html",
    "project_id": "orb-5dvm4b",
    "title": "Orb",
    "tagline": "A platform and community for the next generation of empowered women in the workplace. This is Orb.",
    "hackathon": "",
    "built_with": [
      "css",
      "glitch",
      "html"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "How a Hackathon works - considering these were our first Hackathons!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/475/726/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration When we were brainstorming for our project, we realized that there was a problem that wasn't spoken up enough about. This was women in the workforce. We had an interest in 360-degree videos, which later then introduced us to the name Orb. What it does Our solution is to provide a safe community where women can report on their experiences of harassment in the workplace. We provide a woman's perspective in an office, and we collect statistics survey-based data. How we built it Orb was built by our developers, Beth and Kawtar using HTML, and CSS on Glitch. Challenges we ran into Most of us were new to Hackathons, and time managing was definitely a challenge for all of us. Knowing that most of us were halfway across the world (wow), we had to deal with different timezones and hours lost. We also needed to find a way to know that our users retained whatever was said in the video. With that, we created a survey that allows us to see the effectiveness of our solution by allowing our users to give their experience and what they have learned. Accomplishments that we're proud of Getting the project out! Our presentation! The idea in general! We believe that our solution will really make an impact on the lives of working women! What we learned Time management New technical terms How a Hackathon works - considering these were our first Hackathons! What's next for Orb We hope you enjoy our MVP. Orb would like to further our service by enhancing our website and covering more pressing topics. We would like to implement our solution to a variety of workplaces and not just the office! We plan to reach as far as hospitals! We also plan to add a feature where you can sign in, which then lets you join the forum where you can connect with other women and uplift each other! We plan to expand our outreach and allow our website to function more conveniently for people. \nThank you so much!!! Orb Team Built With css glitch html Try it out orb-.glitch.me Submitted to Superposition"
      }
    ]
  },
  {
    "file_path": "./devposts/paragon-385hzx.html",
    "project_id": "paragon-385hzx",
    "title": "paragon",
    "tagline": "providing meaning in this distracting world",
    "hackathon": "",
    "built_with": [
      "flutter",
      "gemini"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/131/784/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "paragon Built With flutter gemini Try it out paragon-guide.web.app Created by Oskar Kraak"
      }
    ]
  },
  {
    "file_path": "./devposts/panda-wheels.html",
    "project_id": "panda-wheels",
    "title": "Panda Wheels",
    "tagline": "Build VR, in VR. Panda Wheels is an application for prototyping VR experiences within a VR environment, emphasizing no-code tools for interaction design and object behavior mechanics.",
    "hackathon": "",
    "built_with": [
      "c#",
      "oculus",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MIT Reality Hack 2023WinnerMixed Reality",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/346/091/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Interaction menus Panda Wheels promo image Interaction menus Panda Wheels promo image Interaction menus 1 2 3 Inspiration We are a team of tool-builders, and we were inspired by the idea of creating an experience that would give the hackathon judges an opportunity to become hackers themselves for a few minutes. What it does Panda Wheels is a new take on a VR prototyping application. It lets users rapidly build interactive VR experiences while inside a VR environment, enabling them to become fully immersed in the design process by eliminating the need to constantly don and remove a headset. Unlike other VR sandbox tools, Panda Wheels has a robust WYSIWYG editor for behavioral logic and interaction design. Codeless option panels make creating new objects, defining their behavior, and simulating that behavior as easy as clicking a few buttons. Not only do users get an immediate understanding of live object mechanics, but they are also actually able to adjust these mechanics in situ. How we built it We built Panda Wheels in Unity from scratch, basically only using existing functions and mostly writing our own custom functions in C#. We split up the work across team members and held regular brainstorming sessions to clearly define the end user experience we wanted to create. There were many lively debates about the best ways to implement certain functionality, how to make the object logic settings as intuitive for the user as possible, and whether or not the best illustrative use case for this tool would be watching someone build their own version of Beat Saber. Challenges we ran into As in any hackathon, we ran into a wide variety of challenges at MIT Reality Hack 2023 - the first of which was coming up with an idea! We changed our concept entirely between day 1 and day 2, and one big difficulty was distilling and crystallizing our vision for the final product as well as restricting the scope to something we thought was possible to build within our remaining time. Anoth"
      }
    ]
  },
  {
    "file_path": "./devposts/pantry-protector.html",
    "project_id": "pantry-protector",
    "title": "Pantry Protector",
    "tagline": "With a secret password, you can keep your pantry safe from any intruders.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "breadboard",
      "c",
      "hot-glue",
      "popsicle-sticks"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Sometimes, our roommates try to take our food, so we want some sort of protection for it. What it does With a secret clap password, only you can get into your pantry, successfully protecting your food from anyone trying to get in. How we built it Using a sound sensor, an arduino, and a motor, the sensor detects a specific pattern and activates a motor to unlock a pantry. Challenges we ran into brooo so many. soooo many. we went through around 7 different project designs before deciding to land on this one. although this project design and execution was pretty simple, the other designs were not as such. Scope creeps and pipe dreams plagued our week-of-hardware until we decided to lock in on ol' faithful. Accomplishments that we're proud of We're thankful to have gained experience with a variety of arduino parts and learned how to deal with electrical voltage projects. ## What we learned What's next for Pantry Protector Making it more robust/not with popsicle sticks. Built With arduino breadboard c hot-glue popsicle-sticks Submitted to TAMUhack 2025 Created by Vedant Soni winterberrylavender Lam IshaanBansal2006 Bansal"
      }
    ]
  },
  {
    "file_path": "./devposts/parkwork.html",
    "project_id": "parkwork",
    "title": "ParkWork",
    "tagline": "Get rewarded for exercising! With ParkWork, you can earn points by working out. Simply just scan the QR Code at designated fitpits and complete the exercise to start earning points.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "ios",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/791/908/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration America is contains one of the highest amounts of people with obesity. In order to fix this problem, we wanted to implement fitness with something that will motivate a person : prizes. This combination of reward and physical activity will be done through Park Walk. What it does Park Walk uses the built in camera to scan QR Codes. When a QR Code is scanned at designated fit-pits, a physical activity is displayed in groups of 10 (ex. 10 pushups, 10 sit ups). After doing 10 iterations of the given exercise, 10 points will be granted to your overall score. As your score increases, you can cash them in for prizes. How I built it We built it using Swift for iOS on Xcode. Challenges I ran into We ran into challenges with detecting QR codes and certain aspects of the apps such as using the Apple Maps API to assign locations to fit pits. Accomplishments that I'm proud of We are proud of our app's ability to detect information from QR Codes. What I learned We learned the basics of iOS app development. We also became adept at basic UI design and aesthetic appeal. What's next for ParkWork We hope to improve our app by implementing user accounts and customized music to play during a session at a Fitbit. \nWe also want to add a leaderboard for friends to compete with each other and attempt to surpass one another. Built With css3 html5 ios swift xcode Try it out rnuv.github.io GitHub Repo Submitted to HackSB 2019 Created by Arnav Nayak"
      }
    ]
  },
  {
    "file_path": "./devposts/parampower.html",
    "project_id": "parampower",
    "title": "Parampower",
    "tagline": "Empowering the Paralyzed 💪♿",
    "hackathon": "",
    "built_with": [
      "docker",
      "figma",
      "firebase",
      "gcp",
      "github",
      "jax",
      "keras",
      "mui",
      "numpy",
      "python",
      "react",
      "react-native",
      "s2t",
      "tailwind",
      "tensorflow",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Figma by Figma Figma has been a critical collaborative tool during our hackathon",
      "Creative Hack by Meta When we first approached the problem of redesigning an interface for paralyze",
      "Track: Inclusion Created by Built the entire web application, integrated the ML model, and helped w",
      "HackNYU 2022WinnerTrack: Inclusion",
      "Keep track of patient requests",
      "Inclusion Track",
      "Best Use of Figma by Figma",
      "Best Creative Hack by Meta",
      "Machine Learning for tracking patient’s head and speech recognition",
      "Best Use of Google Cloud",
      "GitHub was used to collaborate, push code, get feedback, and keep track of our code throughout the hackathon.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/854/005/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration 💡 If you had to pick one, would you rather lose motor control of your hands or lose sensations of your legs? While it is certainly a hard question, we are surrounded by individuals who suffer from paralysis and cannot move either limb. There are approximately 5.4 million Americans suffering from paralyzing conditions such as Quadriplegia, Cerebral Palsy, or ALS. Despite occupying a large proportion of society, paralyzed patients’ everyday problems solved by caretakers and patients often face difficulties in communicating with their Caretaker when they are in the need of help. Tools used by Stephen Hawking for communication work great but are not affordable for the average patient. We believe that software and hardware can be combined in ways to enable paralyzed patients to gain the same superpowers and agency that rest of us do. Upon thinking, we realized that the interface with which we interact with technology (mainly touch) is incapable of serving the needs of the paralyzed. With an aim to invent an interface leveraging the abilities of the paralyzed, we built Parampower ✨ What it does 🤔 Parampower is a system comprising of a web application, which will be used by the paralyzed patient, and a mobile application that is tailored for the needs of the caretaker. The web application uses highly sensitive Head Tracking Machine Learning algorithms to change the position of the cursor according to the paralyzed patients’ head movements. Our research informed us that a majority of paralyzed patients can and there already exists head-tracking cameras specifically designed for paralyzed patients. Our web application is feature-rich with functionalities such as: notify the nurse for help notify the nurse about a meal request to be taken to the restroom toggle lights in room voice recognition messaging system the game Wordle! Our mobile application is the perfect solution for the caretaker: Keep track of patient requests Monitor patient vitals How we built "
      }
    ]
  },
  {
    "file_path": "./devposts/patientsimai.html",
    "project_id": "patientsimai",
    "title": "PatientSimAI",
    "tagline": "PatientSimAI is a web app that simulates human patient interactions using GPT4, to train clinical reasoning, improve medical education, and build skills for practical application.",
    "hackathon": "",
    "built_with": [
      "clerk",
      "css",
      "deepgram",
      "drizzle",
      "gpt4",
      "neon",
      "next.js",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Health Prize We focused on the \"service accessibility\" aspect of the Health track, and created a to",
      "Interactive Media PatientSimAI falls under the category of AI education and use speech-to-text to m",
      "Hack for Social Good Winner Hacker's Choice Award Created by Chloe Wang Chinat Yu My name is Chinat",
      "Best Hack for Social Good Winner Hacker's Choice Award Created by Chloe Wang Chinat Yu My name is C",
      "We focused on the \"service accessibility\" aspect of the Health track, and created a tool that can b",
      "HackDavis 2024WinnerBest Hack for Social GoodWinnerHacker's Choice Award",
      "👨‍⚕️ Best Health Prize",
      "🗣️ Best Interactive Media",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/867/870/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo and Cover Slide 💡 Inspiration Medical students aren't getting the training they want and need to feel confident in interacting with patients. We've spoken to a PhD student at the Stanford School of Medicine who teaches many students currently struggling with this issue, not just here in the USA, but also in various countries around the world (like Chile, Ireland, Singapore, and Brazil) where students lack the same access to patients and practice. ✏️ What it does PatientSimAI is a web app that simulates patient interactions using AI and GPT4, to train clinical reasoning , improve medical education , and build skills for practical application . We built a platform where professors can input parameters around which AI can craft a conversation, utilize the scenarios we have crafted, and provide a lesson for students. 🛠️ How we built it Technology Integration: We combined AI with GPT-4 to simulate authentic patient interactions, enhancing the educational modules in our web app. Development Journey: We began with a basic prototype to test the AI’s conversational capabilities and iteratively refined both the user experience and functionality based on feedback. Collaboration: We engaged with medical professionals extensively to ensure the scenarios we created were accurate and educational. 🚧 Challenges we ran into Text-to-Speech Integration: We faced significant challenges integrating effective text-to-speech capabilities, which were essential for realistic patient interactions. Deployment Setbacks: Deploying the application on a scalable server was tough and caused delays in our testing and feedback phases. Managing Time: Balancing the complexity of the project within our deadlines was a substantial challenge. Creating/Deleting Data: Fetching and adding new courses caused a significant amount of failed API requests in the server. 🏆 Accomplishments that we're proud of Successful Launch: Despite the hurdles, we successfully launched the app, providing a functional and e"
      }
    ]
  },
  {
    "file_path": "./devposts/pathosense.html",
    "project_id": "pathosense",
    "title": "Pathosense",
    "tagline": "Bring emotion into technology!",
    "hackathon": "",
    "built_with": [
      "amplifier",
      "filter",
      "hardware",
      "keras",
      "machine-learning",
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Created by helped build AI model to process EEG signals and detect emotional stress readings",
      "Interactive Media Track Winner Created by helped build AI model to process EEG signals and detect e",
      "HackMIT 2023WinnerInteractive Media Track Winner",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "[Description removed to protect originality of idea] Built With amplifier filter hardware keras machine-learning python scikit-learn Submitted to HackMIT 2023 Winner Interactive Media Track Winner Created by helped build AI model to process EEG signals and detect emotional stress readings with high accuracy. Our goal was to use EEG + AI + VR to create interactive experiences in gaming, sports, and broader entertainment. as3448@scarletmail.rutgers.edu Akhil Sharma Serena Shih Stephen Chang (949)-439-7158 stephen0.0chang@gmail.com Amazon Intern & brand ambassador Olivia Zheng"
      }
    ]
  },
  {
    "file_path": "./devposts/parkaway.html",
    "project_id": "parkaway",
    "title": "parkAway",
    "tagline": "find peace for your vehicle parking!",
    "hackathon": "",
    "built_with": [
      "express.js",
      "node.js",
      "postmanapi",
      "react.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Creative Use of Twilio Created by I worked on the font-end it was my first time using React",
      "Give Back Hacks 3WinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/313/845/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration We discussed the idea of \"Giving back to the community\" and came to the conclusion to make something that can make people's life easy so they can stop thinking of vehicle parking. The idea was to implement something to help people by other people. What it does It's a parking service where clients can post parking lots for rent. And users/customers can send a request to make a deal/contract. It's a kind of Airbnb for parking lots. How we built it We built the app using the following languages, and framework React.js Express.js Node.js MongoDB Bootstrap Twilio Challenges we ran into Learning new skills to implement the project. It was a bit challenging to work with API integration specifically while doing it for the first time as well as building the login for using Twilio. We also had a hard time resolving the merge conflicts in GitHub twice. Accomplishments that we're proud of We are proud to learn about APIs and new frameworks. Specifically, we have learned that in a very short time. What we learned Learnt how to effectively use APIs in an app and use the additional functionality. And most importantly how to integrate APIs What's next for parkAway We are planning to add location-based listings. And add a feature for payments (payment gateway). Built With express.js node.js postmanapi react.js Try it out GitHub Repo Submitted to Give Back Hacks 3 Winner Most Creative Use of Twilio Created by I worked on the font-end it was my first time using React.js, Nodejs, Express.js etc. which was little intimidating, but the good thing is that I learned a lot. Om Dalwadi Kartik Patel Nothing much..! Satyam Singh"
      }
    ]
  },
  {
    "file_path": "./devposts/pear-piano.html",
    "project_id": "pear-piano",
    "title": "PearPiano",
    "tagline": "AR composing tool, bringing music to life, not just to your ears but to your eyes 🎶",
    "hackathon": "",
    "built_with": [
      "blender",
      "c#",
      "oculus-gear-vr",
      "openai",
      "unity",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2023 Finalist Created by I worked in Unity/C# for VR features like hand-tracking, co",
      "Hack the North 2023WinnerHack the North 2023 Finalist",
      "Calibrating and configuring hand tracking on the Oculus Quest",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/590/387/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Drag-and-drop your notes for instant edits. A musician's best friend. Record your spontaneous compositions. Ask Pear any music-related questions! Interact with the AR piano. Drag-and-drop your notes for instant edits. A musician's best friend. Record your spontaneous compositions. Ask Pear any music-related questions! Interact with the AR piano. Drag-and-drop your notes for instant edits. 1 2 3 4 5 6 Bringing your music to life, not just to your ears but to your eyes 🎶 Inspiration 🍐 Composing music through scribbling notes or drag-and-dropping from MuseScore couldn't be more tedious. As pianists ourselves, we know the struggle of trying to bring our impromptu improvisation sessions to life without forgetting what we just played or having to record ourselves and write out the notes one by one. What it does 🎹 Introducing PearPiano, a cute little pear that helps you pair the notes to your thoughts. As a musician's best friend, Pear guides pianists through an augmented simulation of a piano where played notes are directly translated into a recording and stored for future use. Pear can read both single notes and chords played on the virtual piano, allowing playback of your music with cascading tiles for full immersion. Seek musical guidance from Pear by asking, \"What is the key signature of C-major?\" or \"Tell me the notes of the E-major diminished 7th chord.\" To fine tune your compositions, use \"Edit mode,\" where musicians can rewind the clip and drag-and-drop notes for instant changes. How we built it 🔧 Using Unity Game Engine and the Oculus Quest, musicians can airplay their music on an augmented piano for real-time music composition. We used OpenAI's Whisper for voice dictation and C# for all game-development scripts. The AR environment is entirely designed and generated using the Unity UI Toolkit, allowing our engineers to realize an immersive yet functional musical corner. Challenges we ran into 🏁 Calibrating and configuring hand tracking on the Oculus Quest Reducin"
      }
    ]
  },
  {
    "file_path": "./devposts/parivartan-car-security-simplified.html",
    "project_id": "parivartan-car-security-simplified",
    "title": "Parivartan : Car Security Simplified",
    "tagline": "Problems related to car security are a major hassle in countries filled with hussle like India. So we at Parivartan provide people with luxury car security at an affordable price using Raspberry Pi.",
    "hackathon": "",
    "built_with": [
      "dl-scanner",
      "fingerprint-scanner",
      "motion-sensor",
      "python",
      "raspberry-pi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Code HackWise 2021 CrowdHacks Ideathon'21 Created by Programmer, Head of Presentation, Chief Video",
      "NextStep Hacks 2021 IncluTech Hack Winner Best Code HackWise 2021 CrowdHacks Ideathon'21 Created by",
      "Third Place NextStep Hacks 2021 IncluTech Hack Winner Best Code HackWise 2021 CrowdHacks Ideathon'2",
      "Quantahacks 2021WinnerThird Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/369/748/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Our Model! Problem Scenario: Underage Driving Problem Scenario: Car thefts Our Solution: Parivartan! What are we aiming for? Tech Used Block Diagram of System Flowchart: DRIVE Function Functions: Enrolling of Fingerprint Flowchart: ENROLL Function Flowchart: Motion Senser About Components: Smart Card Reader About Components: Fingerprint Module About Components: Motion/Passive Infrared Sensor About Components: GSM Module Our Model! Problem Scenario: Underage Driving Problem Scenario: Car thefts Our Solution: Parivartan! What are we aiming for? Tech Used Block Diagram of System Flowchart: DRIVE Function Functions: Enrolling of Fingerprint Flowchart: ENROLL Function Flowchart: Motion Senser About Components: Smart Card Reader About Components: Fingerprint Module About Components: Motion/Passive Infrared Sensor About Components: GSM Module Our Model! 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 Inspiration Seeing constant news regarding car thefts, accidents related to underage driving made us feel an urge to create a project that provides car security in a very simple yet effective manner. India is a country with a lot of 'unordered' road systems, so large car security systems or even cars with security features become inefficient. So we were inspired to create something small and cheap which can provide luxury car security to the Indian middle classes. What it does Parivartan is aimed towards combating car thefts and to avoid underage driving. Using Raspberry Pi and Python , along with high class security features like fingerprint sensors and smart DLs readers, we have made an easy-to-install and extremely secure security feature to help in providing top tier car security to the consumers.​ Using top-notch security features like fingerprint sensors linked with smart DLs and QR codes, we provide an additional effective wall of security and safety. User's car is only started in case the correct DL-fingerprint combination is applied. In case, if the user's smart DL is missing,"
      }
    ]
  },
  {
    "file_path": "./devposts/pathsense-athy2r.html",
    "project_id": "pathsense-athy2r",
    "title": "PathSense",
    "tagline": "Empowering Vision Through Voice. Revolutionizing indoor mobility with real-time, adaptive AI-enabled guidance for seamless navigation in complex spaces.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "cohere",
      "convex",
      "detectron2",
      "dpt",
      "git",
      "gpt-4",
      "groq",
      "javascript",
      "json",
      "jwt",
      "kubernetes",
      "mappedin",
      "ngrok",
      "node.js",
      "opencv",
      "postman",
      "python",
      "pytorch",
      "react",
      "rest-api",
      "tailwind-css",
      "tapo-cameras",
      "tensorflow",
      "typescript",
      "unreal-engine",
      "vercel",
      "voiceflow",
      "whisper",
      "yolo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2024 Finalists Winner Cohere: Best Use of Cohere Created by Ameya Jadhav jacobr12 Ru",
      "Hack the North 2024WinnerHack the North 2024 FinalistsWinnerCohere: Best Use of Cohere",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/025/731/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "route generated after a voiceflow convo route generated after a voiceflow convo route generated after a voiceflow convo 1 2 Inspiration Our journey with PathSense began with a deeply personal connection. Several of us have visually impaired family members, and we've witnessed firsthand the challenges they face navigating indoor spaces. We realized that while outdoor navigation has seen remarkable advancements, indoor environments remained a complex puzzle for the visually impaired. This gap in assistive technology sparked our imagination. We saw an opportunity to harness the power of AI, computer vision, and indoor mapping to create a solution that could profoundly impact lives. We envisioned a tool that would act as a constant companion, providing real-time guidance and environmental awareness in complex indoor settings, ultimately enhancing independence and mobility for visually impaired individuals. What it does PathSense, our voice-centric indoor navigation assistant, is designed to be a game-changer for visually impaired individuals. At its heart, our system aims to enhance mobility and independence by providing accessible, spoken navigation guidance in indoor spaces. Our solution offers the following key features: Voice-Controlled Interaction: Hands-free operation through intuitive voice commands. Real-Time Object Detection: Continuous scanning and identification of objects and obstacles. Scene Description: Verbal descriptions of the surrounding environment to build mental maps. Precise Indoor Routing: Turn-by-turn navigation within buildings using indoor mapping technology. Contextual Information: Relevant details about nearby points of interest. Adaptive Guidance: Real-time updates based on user movement and environmental changes. What sets PathSense apart is its adaptive nature. Our system continuously updates its guidance based on the user's movement and any changes in the environment, ensuring real-time accuracy. This dynamic approach allows for a more na"
      }
    ]
  },
  {
    "file_path": "./devposts/pastry-artist.html",
    "project_id": "pastry-artist",
    "title": "Pastry Artist",
    "tagline": "From Sugar Painting to Pastry Making, \nFrom the Tradition to Your Creation,\nPastry Artists Are You Ready?",
    "hackathon": "",
    "built_with": [
      "ai",
      "blender",
      "c#",
      "photoshop",
      "premiere",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We first brainstormed about different ideas and found that"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/210/764/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sketch about the Process of Making Pastry Artist - Title User Interface 1 in the Final APK User Interface 2 in the Final APK User Interface 3 in the Final APK User Experience 1 -in the Final APK User Experience 2 in the Final APK Beginning User Interface in the Video Sugar Cooking Sugar Drawing Tests Sketch about the Process of Making Pastry Artist - Title User Interface 1 in the Final APK User Interface 2 in the Final APK User Interface 3 in the Final APK User Experience 1 -in the Final APK User Experience 2 in the Final APK Beginning User Interface in the Video Sugar Cooking Sugar Drawing Tests Sketch about the Process of Making 1 2 3 4 5 6 7 8 9 10 11 Inspiration Chinese Intangible Culture Heritage \"Tang Hua\" (meaning \"Sugar Drawing\"). What it does Pastry Artist is a mixed-reality app that aims to guide beginners in making pastry. Its functions include drawing, painting, and building with physical liquid materials, such as sugar, chocolate, and flour guided by mixed-reality tutorials and real-time tracing guides. How we built it We first brainstormed about different ideas and found that Self-learning tools that can help people using physical materials are lacking. \nMixed reality is an ideal tool in spatially providing step-by-step tutorials to guide users in learning the process and controlling the liquid of materials, especially for beginners — A light, fun, and creative way to guide self-learning in making pastry can raise users' interest, and play a great effect in inheriting some cultural customs, such as sugar drawing - Chinese intangible cultural heritage. Our team of three members brought together diverse skills:\nShujing Shen - product experience, research, and documentation.\nJiachen Zeng - project organization, animation, and video production.\nSowilo Xiong - Unity development and UI design. We collaboratively discussed the core concept of the project and developed the software using Unity, ultimately building it on the Oculus Quest 3 platform. Challenges "
      }
    ]
  },
  {
    "file_path": "./devposts/paw-pal.html",
    "project_id": "paw-pal",
    "title": "PawPal",
    "tagline": "Together, we bring our Paws home.",
    "hackathon": "",
    "built_with": [
      "api",
      "figma",
      "google-maps",
      "html"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for Life of Kai Created by Linh-dan Nguyen BaoTran Tran Chen Liu Michelle L",
      "Best Hack for Life of Kai Created by Linh-dan Nguyen BaoTran Tran Chen Liu Michelle L",
      "HackDavis 2024WinnerBest Hack for Life of Kai",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/867/641/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by Amber Alerts and wanted to implement and improve the lost pet finding process while encouraging community interactions. Currently, ‘The Life of Kai’ relies on a manually made map that the organization creates when a pet is lost. New sightings of the lost pet are manually added to the map while community members are encouraged to utilize other applications to help locate their lost pets. For HackDavis, we wanted to combine all of these steps and processes into one convenient application, PawPal. What it does PawPal is a mobile application that utilizes community efforts to help locate lost pets. The user is able to create profiles of their pets and is able to interact with other app users through discussion posts and community forums. When a lost pet is reported, other users are alerted nearby are alerted and encouraged to report any sightings. How we built it We build our project using Figma for the mobile interface. We incorporated ‘The Life of Kai’s’ existing color scheme of yellow and teal from their website to uphold the organization’s brand. HTML was used to code the backend with the geo-locater and time stamp marker. A Google Maps API was used along with multiple API libraries, like Directions API and Geocoding API, to create routes and implement map functions. Challenges we ran into Implementing the Google Cloud API was very confusing for me since the time marker function and geocode function required additional libraries that I was not aware of. I also had to worry about key restrictions while still allowing the API to work. \nOriginally, I wanted to use Python to simulate the process of creating a user profile. However over time, I realized that I did not know how to combine Python and Figma into one cohesive application. We ultimately compromised by creating a Figma representation of a user profile.\nWhen designing the Figma interface, we wanted to include several features that we did not explicitly know how to implement, like"
      }
    ]
  },
  {
    "file_path": "./devposts/penetrateai.html",
    "project_id": "penetrateai",
    "title": "PenetrateAI",
    "tagline": "Cybersecurity has never been easier and safer with PenetrateAI.",
    "hackathon": "",
    "built_with": [
      "docker",
      "flask",
      "huggingface",
      "langchain",
      "next.js",
      "openai",
      "react",
      "shadcdn",
      "tailwind",
      "tavily",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by Devin AI. We also wanted to build something that would help out in the field of cybersec. What it does PenetrateAI helps the user keep their website safe by pen testing their website to find vulnerabilities. How we built it We used a stack of Next.js, Tailwind and React for the Frontend. We used flask, docker and websockets for the backend. We used the websocket server to communicate between the docker image and the client. The core of our app was the GPT 3.5 LLM, we used Tavily API as a tool for our LLM so that it could access the web, we also connected the LLM to a CLI tool so that it could send commands. We also used some Lang Chain tools to further improve our LLM. Finally, we used a HuggingFace BERT model for queries. Challenges we ran into Some of the challenges we ran into were was that it was very difficult to configure docker to work for our purposes. It was also difficult to communicate between the proxy server and the docker image, as we had many errors while attempting the connection. It was very difficult to establish a connection because the two devices kept connecting to different access ports. Accomplishments that we're proud of Learning about the ins and outs of everything in Lang-Chain. Used GPT 3.5 to generate information. What we learned We learned a lot about Lang-Chaing as it was one of the most core technologies in our application. We also learned a lot about docker and docker images. We also learned a bit about networking because What's next for PenetrateAI We are planning on using a better LLM such as GPT-4 to build our app around. We are also planning on getting our own access port so that we don't need to use a mobile hotspot to be able to communicate between two devices. Built With docker flask huggingface langchain next.js openai react shadcdn tailwind tavily websockets Try it out GitHub Repo Submitted to Los Altos Hacks 8 Created by Easwar Gnana Hari Sekar Yash Singh Shrey Vishen"
      }
    ]
  },
  {
    "file_path": "./devposts/petpal-wk2bzg.html",
    "project_id": "petpal-wk2bzg",
    "title": "PetPal",
    "tagline": "A Pet-Friendly setup to keep your pets company in luggage",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c++",
      "flutter",
      "python",
      "restapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/580/122/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Last Morning, I got an email regarding a petition about how some animals die in the aircraft's cargo hold. To fix that, we developed PetPal! What it does It is a device that allows the passengers to interact with their pets in the airliner's cargo hold and also provides them with the ability to feed them remotely! How we built it Using Arduino, Servo, Python, Webcam, OpenCV, Rest API, Flutter Challenges we ran into JSON Fetching Accomplishments that we're proud of We successfully integrated our Flutter API with a flask API to get real-time updates from our hardware. What we learned To start off with devpost submissions right at the start of the event. What's next for PetPal The weekend was the beginning of what we hope will be a long and innovative journey. The next immediate steps would be making our API more secure and adding more functionality - specifically to the voice recording and playing. We also want the owners to be able to see a video stream of their pet in real-time and so will setup a Jitsi server to do this. Our electronics can be made better and more compact, something we will be working on as well! Built With arduino c++ flutter python restapi Try it out GitHub Repo GitHub Repo Submitted to R. U. Hacking? Hackathon 2021 Created by Designed and built the UI in flutter and integrated it with the API rishabh java Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/pawlert.html",
    "project_id": "pawlert",
    "title": "Pawlert",
    "tagline": "Keep your dog cool and safe! Pawlert watches over them in real-time!",
    "hackathon": "",
    "built_with": [
      "ai",
      "api",
      "aqicn",
      "cloudflare",
      "cloudflare-c3",
      "cloudflare-workers",
      "cloudflare-workers-ai",
      "css",
      "figma",
      "github",
      "google-maps",
      "html",
      "javascript",
      "json"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "(MLH Opt-in) Best AI Application Built with Cloudflare Created by I worked as UI/UX designer, speci",
      "ElleHacks 2024Winner(MLH Opt-in) Best AI Application Built with Cloudflare",
      "Secondary Feature: Nearby Location Recommendation",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/777/808/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sign up process First page Main page Main two features UI and prompts are changed based on the weather and dog's condition Sign up process First page Main page Main two features UI and prompts are changed based on the weather and dog's condition Sign up process 1 2 3 4 5 6 Inspiration As much as Summer brings us joy and optimistic energy, its weather conditions put us at higher risk of heat-related illnesses, Heat Stroke, being the most serious of them all. During the brainstorming process, a dog owner from our team brought up how common it is for heat stroke to happen to dogs. Small details like having a heavy coat of hair or more intense exercise can all contribute to worsening the situation, making the cool-down process more difficult for a dog As we looked further into the specific issue, we were kind of surprised at just how frequent and life-threatening heat strokes are to dogs, yet not so much attention and help is available to dog owners at hand. This idea led us to create a solution that can assist dog owners in the best and simplest ways possible in protecting their dogs from heat strokes. What it does Paired up with a smart tracking collar, Pawlert is a tracking system that help owners spot potential risk of heat stroke that may occur to their dog, based on real-time data the collar and app gathers. Primary Feature #1: Keep your dog in check at all times. Purpose: Spot signs of potential overheating behaviour if there’s increase in dog’s body temperature and heart rate. Live data of their body temperature and heart rate gets sent onto the mobile app Safety tag of Normal / Caution / Fatal notify users when the numbers are out of the safe “Normal” zone Primary Feature #2: Weather Guide Purpose: Suggestions made to minimize dog’s exposure to hot conditions Based on the location of the user, this feature suggests whether it’s safe weather, in terms of temperature and humidity, for dogs to go out Colour coded in 4 levels, Safe / Caution / Risky / Dangerous to "
      }
    ]
  },
  {
    "file_path": "./devposts/petme-xg07r8.html",
    "project_id": "petme-xg07r8",
    "title": "PetMe",
    "tagline": "A platform that encourages people to adopt rather than buy pets in their community. Use Augmented Reality to view these animals in 3D.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "flask",
      "hedera",
      "python",
      "react",
      "solidity",
      "swiftui",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of CockroachDB WildHacks II Created by Brayton Lordianto Nischal Shakya Asim Nepal Chantal Pino",
      "Best use of CockroachDB WildHacks II Created by Brayton Lordianto Nischal Shakya Asim Nepal Chantal",
      "Hack With A CrewWinnerBest use of CockroachDB",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/137/396/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "updated ios UI second view DIAGRAM OF APP twilio confirmation (during testing) crab 3D model bird 3D model SOLIDITY updated ios UI updated ios UI second view DIAGRAM OF APP twilio confirmation (during testing) crab 3D model bird 3D model SOLIDITY updated ios UI updated ios UI second view 1 2 3 4 5 6 7 8 💡 Inspiration💡 We believe that animals all over the world deserve to have a warm, loving home. It is our mission that we promote and connect people to animals by creating a community of love and care. Each year, it's estimated that more than one million adoptable dogs and cats are euthanized in the United States, simply because too many pets come into shelters and too few people consider adoption when looking for a pet. We believe that we, as a community, can help lead this cause and help prevent cases of euthanization. ⚙️ What it does ⚙️ Animal providers can upload animal information. There are many people like these who found injured/lost animals and hope for others to adopt them. They can use recommended third-party apps like PhotoCatch to convert video to 3D models in seconds. \nUsers looking for animals to adopt can view a list of animals available, and can use the iOS app to view the animal in 3D Augmented Reality (AR) to see if the animal is a good fit.\nIf users do decide to adopt these “unwanted” animals, they get a code to redeem NFTs. They will be messaged by our app through iMessage on their code. \nUsers are therefore incentivized to adopt these animals. \nWe get these NFTs from Non-Profit Organizations that want to contribute to our cause. 🏗️ How We built it 🏗️ The front end for the web app was done in Tailwind and React , while the storage of information was used in both a CockroachDB database (user information) and in the blockchain using Solidity and Hedera (adoption information). The iOS app was done in SwiftUI and RealityKit + ARKit . Uploaded 3D images get stored on our Echo3D account and are fetched from Echo3D in the iOS app. 🟣 Twilio 🟣 We used Twil"
      }
    ]
  },
  {
    "file_path": "./devposts/pathway-9ne2sq.html",
    "project_id": "pathway-9ne2sq",
    "title": "Pathway",
    "tagline": "Pathway is an AI tool which helps students pick their university courses based on their interests. The UofT website is scraped and the AI creates the most suitable course list.",
    "hackathon": "",
    "built_with": [
      "css",
      "python",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration With a huge selection of courses, picking courses has always been tough. While planning for third- and fourth-year courses, we had trouble narrowing our interests to select the right course list. What it does Pathway scrapes the UofT course list website and gathers information from users regarding their interests. The AI then selects the most suitable courses based on the specified interests of the user. How we built it We built a Next.js web app using typescript. For web scraping, we used Beautiful Soup and the OpenAI API to help select courses based on user prompts. Challenges we ran into Dependencies and Package.json errors, we had to switch from Vite to Next. Syncing up the backend logic with the front-end logic. Accomplishments that we're proud of Having a visually appealing front end and functional backend with accurate algorithms for course selection. What we learned New frameworks and technologies. What's next for Pathway Improve the time efficiency of the scraping process and make our website more accessible by providing helpful popups/guidelines and expand our product to more than just U of T. We hope to be a useful tool for all students in university. Built With css python typescript Try it out GitHub Repo Submitted to Deerhacks IV 2025 Created by Worked on the Python backend and assisted with frontend integration. Matthew Falcone Michal Buczek Ambitious developer passionate about learning and creating. Siddharth Iyer Alexander Gu hackathons are fun."
      }
    ]
  },
  {
    "file_path": "./devposts/picket.html",
    "project_id": "picket",
    "title": "Picket",
    "tagline": "Where waste isn't wasted.",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "google-cloud",
      "google-vision-api",
      "html5",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/632/015/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration According the the United States EPA , the U.S. creates approximately 250 million tons of waste each year. For Canada , this is 31 million tons and for India this is 62 million tons . Not much of this waste is being recycled the correct way. Seeing this hazardous problem in our society, we decided to take action and create Picket. We wholly believe that humans have the capacity to come together, recycle their waste, and create a cleaner environment. We built Picket as a method to engage society in it's environmental affairs in the simplest way. What it does Picket allows the user to upload pictures of waste to the Picket website. Once our website receives the picture, it uses a machine learning model to correctly classify what type of waste the picture contains in 1 of 6 categories (Glass, Metal, Plastic, E-Waste, Paper, Organic). After it identifies what type of waste it is. It notifies the user to place that specific type of plastic into that categories' bin. How we built it We first used Flask to set up our server, and collaborated using VSCode's live share extension. We then added our google vision api to use as a machine learning model. We then grabbed the labels from the model and classified our test images with those labels. Challenges we ran into The first problem we ran into was installing numpy and some other useful libraries. Luckily we were able to fix this by restarting our live share. The next problem we were facing was that our google vision api was not accepting our image for some reason. We were able to fix this by looking of the documentation for some the os library we used. The next problem was that we had to change the names of some of our categories because google was not recognizing cardboard as cardboard as we intended so we had to filter out the labels given by the vision model. Accomplishments that we're proud of We're proud of our wesbite's UI design and functionality, and that we were able to implement a working google vision ap"
      }
    ]
  },
  {
    "file_path": "./devposts/phishalert.html",
    "project_id": "phishalert",
    "title": "PhishAlert",
    "tagline": "Tired of phishing? Let our browser extension handle it!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "flask",
      "html",
      "javascript",
      "jupyter",
      "python",
      "summernote"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/742/372/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our ML algorithm correctly identifies emails that are not phishing attempts. Click our extension icon in your menu bar to open the text window. Our algorithm flags emails suspected of being phishing attempts and highlights keywords. Our ML algorithm correctly identifies emails that are not phishing attempts. Click our extension icon in your menu bar to open the text window. Our algorithm flags emails suspected of being phishing attempts and highlights keywords. Our ML algorithm correctly identifies emails that are not phishing attempts. 1 2 3 4 Inspiration Phishing attacks are up 900% in the past few years alone, and companies are expected to lose $10.5 trillion due to cyberattacks annually. This is a widespread problem that needs a quick, easy-to-use solution. Introducing PhishAlert, a Google Chrome extension designed to help users detect potential phishing attacks. What it does PhishAlert is a simple, easy-to-use extension that only has two moving parts: a textbox for inputting text and a button to analyze the text. When a user comes across a text they believe could be suspicious or asks for their information, they can paste the text into our extension, and it will perform machine learning analysis to determine the likelihood of it being a phishing attack. If the text is marked as likely to be a phishing attack, our extension will also highlight pieces of text that are known to be common words used in phishing attacks. How we built it We built this extension using vanilla HTML, CSS, and JavaScript frontend languages. We used JQuery with SummerNote to create a rich-text editor and Bootstrap for straightforward styling. On the backend, we have a C-Support Vector Classification model pre-trained with Scikit-Learn on a dataset pulled from Kaggle here . We also used Jupyter Notebooks to perform tests on the model during the training process. We exposed this model to the frontend via endpoints on a REST API created using Python and Flask. Challenges we ran into This was"
      }
    ]
  },
  {
    "file_path": "./devposts/phish-net-qsvk3c.html",
    "project_id": "phish-net-qsvk3c",
    "title": "Phish-Net",
    "tagline": "Protect yourself with our new Chrome extension: Phish-Net! This protects users and intakes data that cybersecurity teams can analyze for future developments.",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "html",
      "javascript",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/633/823/datas/medium.GIF",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 Inspiration During our internships, there were many times when employees failed phishing tests or got compromised by phishing scams. Therefore, we wanted to create an application that can minimize the risk of scams and show stats for people to know what to look out for. What it does Our application is a Chrome extension that detects which emails are phishing emails within your inbox, highlights them, and generates a long-term statistics page of what type of phishing emails came in as well as the percentage of phishing emails caught. How we built it We built our extension using Node.js, Express, HTML, CSS, and JavaScript. Challenges we ran into Some of the challenges we ran into were formatting the stats page, finding the right type of API for Gmail, and the OpenAI API being slow. Accomplishments that we're proud of We are proud that we created this Chrome extension as we did not have much experience in API-related projects. What we learned We learned the use of API and AI through this hackathon. What's next for Phish-Net In the future, we would like to implement faster calls/results as well as the extension being able to auto-detect all the phishing emails without having to push a button, other than to see the stats page. Built With css express.js html javascript node.js Try it out GitHub Repo GitHub Repo Submitted to HackTX 2023 Created by I worked on the design aspect, including the logo and layout of the stats page as well as front end with Josh. Lizzy Yoon I worked on the front-end with Lizzy. We worked on styling the statistics page and connecting it to our backend. Joshua John abaustinva Abraham Christos Joseph"
      }
    ]
  },
  {
    "file_path": "./devposts/pictionary-plunge-c4kz0g.html",
    "project_id": "pictionary-plunge-c4kz0g",
    "title": "Pictionary Plunge",
    "tagline": "A website built with Taipy that uses a recurrent neural network and MATLAB to classify images and process images.",
    "hackathon": "",
    "built_with": [
      "matlab",
      "python",
      "taipy",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of MATLAB Created by Ziyang Chen Lex Kilpatrick AJ Komolafe",
      "TAMU Datathon 2023WinnerBest Use of MATLAB",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/644/169/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "After prediction Before prediction After prediction Before prediction After prediction 1 2 Inspiration The reason for us building a front-end interface is that we were fascinated by Taipy's potential and wanted to gain some experience using it. We saw Google's \"Quick, draw\" and were inspired to create an image classification app. What it does Upload an image using the core Taipy component. The image will be preprocessed by MATLAB, turning it to grayscale and resizing it to the desired width and height. A guess is then made by our RNN, which is displayed on the website accordingly. How we built it We built it using Taipy, MATLAB, and a Tensorflow RNN. Taipy was used to build the UI. It allows for the uploading of an image and the displaying of that image and its prediction. MATLAB was implemented for image processing purposes and was vital for preparing images to be guessed at by our model. MATLAB's engine Python API contained image processing, converting uploaded images to grayscale, as well as resizing them for the model's needs. Lastly, a RNN trained with Tensorflow makes predictions about what it thinks the image might be. So give it a try! Just draw an image in MS Paint, upload it to the Taipy website, and watch the magic unfold. Challenges we ran into The first challenge we ran in to was creating a Taipy custom component. Our vision for the project was originally to mimic that of Google's \"Quick draw\", which features a canvas that users may create strokes on while their neural network makes guesses. Unfortunately, creating a custom canvas component proved to be quite time consuming and more advanced, and so we were forced to move away from that idea. Additionally, configuring tensorflow to train a RNN using a GPU was very challenging, as tensorflow stopped native support for such in windows. Thus a whole lot of time was spent configuring WSL, and training models with our CPUs. Accomplishments that we're proud of We are proud to have worked so hard and come up w"
      }
    ]
  },
  {
    "file_path": "./devposts/phishnet-combatant.html",
    "project_id": "phishnet-combatant",
    "title": "PhishNet-Combatant",
    "tagline": "PhishNet-Combatant is your one stop phishing email detector! Simply forward an email you want checked, and watch as PhishNet provides you with all the information you'll ever need!",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "huggingface",
      "imaplib",
      "ipqualityscore",
      "javascript",
      "node.js",
      "python",
      "react",
      "smtp"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Second Place for the Sandia Challenge Created by I fine-tuned DistillBERT",
      "TAMUhack XWinnerSecond Place for the Sandia Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/737/557/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Response to the forwarded email PhishNet-Combatant Logo GIF Scrolling through the website Forwarding the email Response to the forwarded email PhishNet-Combatant Logo GIF Scrolling through the website Forwarding the email Response to the forwarded email 1 2 3 4 5 The Problem and our Purpose Due to the ever present popularity of social media apps and the recent innovations in generative AI, phishing emails have become increasingly more sophisticated and difficult to detect. According to CNBC, from the fourth quarter of 2022 to November 2023, there was a 1265% increase in malicious phishing emails (see here ). To combat this, our team developed PhishNet-Combatant, a tool which aids in determining whether or not an email sent is a phishing email by providing PhishNet's built-in machine learning classification model, link analysis, and email domain analysis services. Using our Project Interfacing with PhishNet-Combatant is simple. Just forward an email which you suspect might be phishing to phishnetcombatant@gmail.com and wait a few seconds for a reply. Methodologies PhishNet’s custom AI classification model. To create PhishNet’s custom AI model we deploy transfer learning by fine-tuning DistillBERT, an older (2019) smaller (250 million parameter) model which was created to make improvements on the previously existing BERT model. The dataset we used consisted of 18,600 emails, 39% of which were phishing emails. The model was trained in Google’s Colab on a T4 GPU and it took 1 hour. We rely heavily on a notebook released by DIMA806 on Kaggle, a senior data scientist in Denmark. The Colab can be found on our repository, and at the top DIMA806 is cited. Link Analysis. To find links in each forwarded email we deploy RegEx, along with the library URLExtract. Once links are extracted, we process them with ipqualityscore’s API for determining link legitimacy. It returns JSON describing many different attributes per each link, which we cut down and organize in a digestible form"
      }
    ]
  },
  {
    "file_path": "./devposts/picket-nacou0.html",
    "project_id": "picket-nacou0",
    "title": "Picket",
    "tagline": "Unifying against tech giants with the world's first digital picket line.",
    "hackathon": "",
    "built_with": [
      "chrome",
      "css3",
      "html5",
      "javascript",
      "react",
      "supabase"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Unifying against tech giants with the world's first digital picket line."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/194/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 We are proud to introduce Picket, the world’s first tool to enable users to coordinate website boycotts and stand up against tech monoliths. We are all aware that tech companies exploit our privacy and sell our personal data without notice . We know that they utilize algorithms intent on inducing controversy and addiction . And we know that they constantly rely on exploitative labor, both domestically (think Amazon warehouses ) and internationally . There’s a disheartening tone of helplessness when discussing the actions and policies of these multinational conglomerates. Their services are embedded into our daily routines, so simply deciding not to use them is unfeasible. And making a stir online fails to bring change because we stand alone behind our devices, far from a mobilized front. We can’t fight injustice when we feel utterly defeated by these tech Goliaths. BUT ALL IS NOT LOST. Our solution is inspired by labor organizers. Just as millions of users are locked into a tech juggernaut’s services, many specialized blue collar workers have no option but to work for a regional monopsony. Yet these workers find power in numbers. Labor unions equalize the playing field, transforming lone workers deemed replaceable into an unbreakable, powerful unit with a seat at the table. These unions encourage the populace to “not cross the picket line,” not only mobilizing affected laborers but the community as a whole. Inspired by this, we built the first digital picket line . With the click of a button, anyone can join a coordinated collective of users determined to push back against unethical tech. Picket firewalls companies with predatory practices until they participate in negotiations to revert these policies. While a user may pass through to the site (as is, at times, necessary) there is a heavy emphasis on not crossing the picket line. Alternative sites are recommended and the user can view a full explanation of the boycott’s purpose. The aim is to boost the friction"
      }
    ]
  },
  {
    "file_path": "./devposts/pictionary-plunge-in-pytorch.html",
    "project_id": "pictionary-plunge-in-pytorch",
    "title": "Pictionary Plunge in PyTorch",
    "tagline": "Have a doodle but no one can quite make out what it's supposed to be? No worries, our neural network built with PyTorch can figure out even the messiest of scribbles through the power of ML!",
    "hackathon": "",
    "built_with": [
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Having worked with PyTorch before with image data, this Pictionary challenge was one we were immediately gravitating towards upon the reveal of TD2023's challenges for its challenging aspect and opportunity to exercise some serious ML skills. What it does Our PyTorch model takes in inputs of .ndjson files of different drawing and outputs predictions of what the doodle is classified as. How we built it We utilized PyTorch's transfer learning capabilities to use a pre-trained VGG neural network and applied it to our data, along with some layer modifications to fit our needs. Challenges we ran into Our data was not easy to work with since it was in the form of JSON objects, so we worked hard to change each drawing to image data so that it was something our model could have fed in and learn from. Accomplishments that we're proud of We were able to achieve a decent accuracy in multiclass prediction, which is something we all haven't exercised vey often in our courses or other work. What we learned PyTorch image processing for model input and advanced multiclass prediction techniques were some skills we are proudly walking away with to use in future work and projects. What's next for Pictionary Plunge in PyTorch More data hopefully for better accuracy! Built With python pytorch Try it out GitHub Repo Submitted to TAMU Datathon 2023 Created by Sophia Lazcano Ethan Greiffenstein stseeda Simon Sprouse"
      }
    ]
  },
  {
    "file_path": "./devposts/pictionary-plunger-challenge.html",
    "project_id": "pictionary-plunger-challenge",
    "title": "Pictionary Plunger Challenge",
    "tagline": "As a person makes strokes for a drawing, our machine learning model will make classifications and predictions on what that person is drawing!",
    "hackathon": "",
    "built_with": [
      "cuda",
      "google-cloud",
      "pillow",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/644/149/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The inspiration for the Pictionary Plunge came directly from Google's Quick! Draw challenge that was released in 2016. It was a unique representation of how machine learning can decipher human creativity in real-time. We were inspired to take this idea and push it further, aiming to improve accuracy and expand the application to diverse datasets. What it does Pictionary Plunge is a machine learning-based challenge where users draw doodles, and in real-time, our model classifies and predicts what the drawing represents. As the user sketches, the system captures each stroke and processes the data, offering instantaneous feedback to the user about the guessed object or concept. It's an interactive way for users to challenge the system's recognition capabilities and, at the same time, understand the intricate workings of machine learning models in the domain of image recognition. How we built it Our approach was methodical and divided into well-structured steps: Data Processing : We began by obtaining the dataset from the Google Cloud platform and processed the raw stroke maps into binary image maps. Model Building : A convolutional neural network (CNN) was employed to handle the image data. We interspersed convolutional layers with Max/Mean Pooling 2D. After this, we flattened the data to feed it into LSTM and hidden layers. These layers utilized batch normalization, activation functions, and culminated in a softmax categorization layer. Model Evaluation : We pitted our trained model against industry standards like MobileNet, ResNet, and VGG. Optimization : Hyperparameters were tweaked, dropout was added, and regularization techniques were employed to optimize the model's performance. Transfer Learning : We saved the weights of our trained model and adjusted the learning rate for future applications. This set the stage for the model to learn from new datasets while retaining its foundational knowledge. Challenges we ran into Like all ambitious projects, we "
      }
    ]
  },
  {
    "file_path": "./devposts/peer-pressure-l1eha7.html",
    "project_id": "peer-pressure-l1eha7",
    "title": "PeerPressure",
    "tagline": "Fast, Scalable, Redundant P2P File Sharing",
    "hackathon": "",
    "built_with": [
      "express.js",
      "javascript",
      "node.js",
      "redis",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the Hill IIWinnerCiena Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/049/276/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Heatbeat Upload File Explorer CLI Whiteboard Progress 1/2 Whiteboard Progress 2/2 Upload File - Option 1 Upload File - Option 2 Download File Download Chunk Add Node Remove Node Heatbeat Upload File Explorer CLI Whiteboard Progress 1/2 Whiteboard Progress 2/2 Upload File - Option 1 Upload File - Option 2 Download File Download Chunk Add Node Remove Node Heatbeat 1 2 3 4 5 6 7 8 9 10 11 12 13 🌟 Inspiration Ciena's challenge really stood out to us due to the specific requirements for the project. Our team briefly knew about P2P networks, but we wanted to learn more. We built Peer Pressure to dive deeper into P2P networks and develop our own architecture for sharing. 🚀 🔍 What it does Users can connect directly to one of the Nodes to request files. 📂 Users can use our NextJS frontend to upload and search for files. 🔎 Once users upload a file, it is split up and replicated across different Nodes. 🌐 If a Node goes down, it redistributes the chunks to ensure there are at least two copies of each chunk. 🛠️ 🛠️ How we built it We started by brainstorming the architecture on the whiteboard. We referenced torrents and hashes to determine the arrangement of our Nodes. With our plan, we built our app using NodeJS and Express . Our Tracker and Worker Nodes communicate via a REST API. Worker Nodes retrieve data from each other using sockets. 🔌 The Tracker keeps track of the status and location of different file chunks, including their hashes. The requesting Node then becomes a new source of chunks for other Nodes. One of our methods for accessing data is directly via a Node. After connecting to a Node, the user can request files directly from other Nodes. The other method is our NextJS frontend which communicates to our Tracker and Node via REST API. By containerizing everything, we can easily scale Nodes. 📈 It's easier to see the gallery images rather than read the text 🖼️ 🚧 Challenges we ran into Designing the architecture was a very big challenge. Even after writing it out, we f"
      }
    ]
  },
  {
    "file_path": "./devposts/picture-picture-perfect.html",
    "project_id": "picture-picture-perfect",
    "title": "Picture Picture Perfect",
    "tagline": "A machine learning model that reorients scrambled images.",
    "hackathon": "",
    "built_with": [
      "keras",
      "numpy",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/248/322/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "After Picture Picture Perfect Before Picture Picture Perfect After Picture Picture Perfect Before Picture Picture Perfect After Picture Picture Perfect 1 2 Inspiration We wanted to do something that truly challenged our programming and Data Science skills. We decided to attempt the puzzle solver challenge. We were interested by computer vision, and wanted to see if we could solve an advanced computer vision problem. What it does The assignment requires a machine learning algorithm to unscramble a given image. A given image has been split into four even pieces, each piece rearranged, and the image reassembled. After the model’s training, it returns a string with the solution containing the correct placement of the pieces to solve the image. How we built it We used Python, Numpy, TensorFlow, and Keras in order to build this project. We built the main orientation system using a using a Convolutional Neural Network Machine Learning model. We took in training data from the given data and from popular online datasets of scrambled and unscrambled images. Challenges we ran into One of the most complicated challenges we faced is that there were not enough unscrambled images to train our model off of. Our model was incorrectly classifying many images because it was receiving so many scrambled input images. We resolved this issue be taking a sample dataset online and training out model on it. This allowed for the model to become much more accurate. Accomplishments that we're proud of As noted above, there were many unforeseen challenges in both the iterative development of our machine learning model and the implementation for scrambled photos. On the night before the submission was due, our team troubleshooted a number of challenging unforeseen problems in order to submit the deliverable before the project deadline. Seeing the program run successfully after the long uphill climb was immensely gratifying. What we learned Our team learned about digital image processing concepts "
      }
    ]
  },
  {
    "file_path": "./devposts/piktocache.html",
    "project_id": "piktocache",
    "title": "Piktocache",
    "tagline": "Piktocache is a browser based chat, where people can leave behind or discover messages, drawings well as have location based chatroom encounters with strangers.",
    "hackathon": "",
    "built_with": [
      "axios",
      "css",
      "firebase",
      "firestore",
      "html",
      "ipify",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/588/406/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Cache chat with sample messages Logo / Product Banner Main menu of Piktocache Cache chat with sample messages Logo / Product Banner Main menu of Piktocache Cache chat with sample messages 1 2 3 Piktocache 💬 Created during UWaterloo's 2023 Hack the North Event, we took it upon ourselves to create a unique social experience in urban spaces where users are under the same IP address. Inspired by our nostalgia for Nintendo's DS Piktochat feature and the unique quality of geocaching, we combined these experiences to reshape how people can interact in urban spaces. How does Piktocache work? 🤔 Piktocache is a browser-based chat, where people can leave behind or discover messages as well as have brief encounters with strangers. It also contains the ability to both send messages as well as drawings into the chat. Being a niche topic, our website is geared towards a specific user base that is interested in digital geocaching or even the return of a Nintendo Piktochat-esque chatroom. In trying to foster low-risk social encounters in a world where individuals become more socially isolated, this is a new way to interact with strangers and provide a way to socialize anonymously in a public space! Other than searching for those online on the website at the same time, users can also leave behind messages, which allows for the ability for users to join networks and be able to find messages left behind from previous chatters passing by. This means that users can either engage in the search for messages left behind, leave their own clues and messages, and in doing so also leave behind a digital artifact for others to find. Built With axios css firebase firestore html ipify javascript react Submitted to Hack the North 2023 Created by I worked on using react and axios  to call the ipify api to get a users ip address. This I then used to filter all the messages in the database to only display ones that are from that ip. Jayden Brooks Digital Doohickeys | YorkU cs Developed the chat based "
      }
    ]
  },
  {
    "file_path": "./devposts/pigeon-jhu7og.html",
    "project_id": "pigeon-jhu7og",
    "title": "Pigeon",
    "tagline": "This is a nostalgic and memory-evoking social media communication app.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "caligraphyr",
      "cohere",
      "dalle",
      "flask",
      "html",
      "javascript",
      "preline",
      "python",
      "react",
      "selenium",
      "sql",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/738/488/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The inspiration behind our nostalgic communication software stems from a deep appreciation for the beauty of bygone eras and a desire to infuse modern communication with a touch of the past. We aim to evoke a sense of nostalgia, transporting users back to a time when handwritten letters and unique speaking styles were the norm. By offering personalized, handwritten messaging options and diverse historical language expressions, we seek to create a platform that not only facilitates communication but also enables users to relive the charm and sentimentality of yesteryears. This venture is driven by a passion for preserving the timeless aspects of human connection in an increasingly digital world. What it does Pigeon is a nostalgic and memory-evoking social media communication app. Users can send messages in a personalized, handwritten style, adding a touch of individuality to their communications. Additionally, we offer a variety of expressions in different historical speaking styles for users to choose from when sending messages, bringing back memories of past eras. Users also have the option to send handwritten-style postcards to the person they are chatting with. How we built it Backend: Python, Flask, SQL, Selenium Web Scrape\nFrontend: Created React App with Tailwindcss and Preline (Tailwindcss UI Library).\nUtilities: For our font creation we used Caligraphyr ( https://www.calligraphr.com/en/ ), for custom user fonts. AI API: Dalle3 is used to generate our Postcard images. Cohere is used to rephrase user input and convert it into 7 different styles of old English to modern English Challenges we ran into We struggled the most with syncing our backend and frontend. We did not fully connect our main endpoints until last minute.\nAlso with the implementation of Auth0 authentication. \nGenerating font because Caligraphyr has no API support, so we had to use Selenium to download font pdf and upload font pdf. Another challenge was storing and converting the"
      }
    ]
  },
  {
    "file_path": "./devposts/pimco.html",
    "project_id": "pimco",
    "title": "Pimco+",
    "tagline": "A financial assistance tool with options and activities for all ages aimed at improving the users' financial literacy, and informing them on topics they should consider when making important decisions",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "html",
      "javascript",
      "jquery"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were directly inspired by Pimco and the services that they provide their clients. What it does It provides information on various financial topics such as investing and retirement planning to inform the user on essential financial information that will aid them in making better financial decisions and improving their overall financial literacy. How we built it We began by making a LucidChart diagram to plan the layout and flow of our website as well as help us stay on track. We made the website using HTML and CSS for the front end with some javascript for the back end. Challenges we ran into The primary issue that we ran into was formatting our website and properly implementing HTML and CSS in order to make the website legible and user-friendly. We also had some problems with implementing our backend code onto the website. Accomplishments that we're proud of We are proud of the appearance and functionality of our website as we are both new to web development. What we learned We learned a tremendous amount of information regarding web design and how to properly and effectively use HTML and CSS to make a platform that is user-friendly. What's next for Pimco+ We will continue to improve the UI and design of the website to make it look more professional and credible. We also want to improve the activities provided to the user, so that they can better learn about this important financial information. Built With bootstrap css html javascript jquery Try it out GitHub Repo Submitted to TAMUhack 2023 Created by Yasir Yilmazcoban nicolas-m-romero Romero"
      }
    ]
  },
  {
    "file_path": "./devposts/pillpal-laj5bk.html",
    "project_id": "pillpal-laj5bk",
    "title": "PillPal",
    "tagline": "The best web-based product to prevent medication harm.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "express.js",
      "mongodb",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/766/082/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our team wanted to create software that not only made people's lives easier but played an active part in saving it. Our team wanted to find a way to ensure that people who are prescribed medication know how, when, and why they’re taking it. This applies especially to elderly people, who are often given many different medications and are at high risk of misunderstanding doctors or forgetting information. What it does Our product PillPal is a web application that holds all of a patient’s diagnoses, treatment plans, and medications in a single easy-to-use place. This allows a patient to take charge of their health and ensure they're on the right path to recovery. How we built it The front end of the app was built with Next.Js and Bootstrap. The back end was built out with Node.Js and Express.js. The database used to store medication information was created with MongoDB atlas, and connected to express via an API. Challenges we ran into Our team had trouble finding a suitable API that would provide information about diseases and the medication used to treat them. This resulted in us creating our own database with an API to connect it to the website. Given that our team did not have experience doing this, it put a considerable time constraint on us and we ended up working to the last minute. Accomplishments that we're proud of We are proud that we were able to develop an easy-to-understand format for our website that we're confident any patient would be able to understand. What we learned We learned a consider amount about learning to work with mongoDB to create local databases and link them to our web apps. Additionally, our team became more aware of the true scale of the number of medication error injuries in the United States, and the lack of a comprehensive solution to this problem. What's next for PillPal We would like to see our product expand to include more areas of a patient's medical history, as well as an SMS or other notification service to remind "
      }
    ]
  },
  {
    "file_path": "./devposts/placeholder-jsx57d.html",
    "project_id": "placeholder-jsx57d",
    "title": "Resumate",
    "tagline": "Introducing Resumate—like Grammarly for resumes.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "nuxt",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/226/234/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration A resume is something that we will all have to make, some time or another. It plays a major role in determining future opportunities. A weak resume could lead to an automatic no, but a great one will lead to success. Many companies use ATS, or applicant tracking system. It's used to scan resumes and see whether they are worthy of consideration/interviews. So, our service uses AI trained on great resumes to help you get approved by both the ATS and your employers. What it does Resumate guides you through the tough task of creating a resume. You start off by picking one of four modern resume templates. Then you enter in your information such as your name, location, school, relevant work experience or any projects that you are proud of. This information then gets automatically displayed on the template you chose. As you enter in the bullet points for your experience, Resumate will give you feedback and tell you how well your bullet points are. Lacking bullet points will be boxed in red and there will be helpful suggestions to improve your lacking bullet points. There will be a score displayed for how well your resume is out of 100. Finally, you will be able to download the resume you created as a PDF. How we built it We built it using Vue for the frontend and we used Cohere's API to generate feedback for the bullet points and an overall score for the resume. Challenges we ran into One challenge we ran into was trying to collaborate on the same files at the same time as other teammates. This made it hard to merge changes, and we had to take extra care into making sure that there were no problems with integration. We originally had the translator to workplace-appropriate language as one of our main features, but it had to be scrapped because of difficulties. Accomplishments that we're proud of One accomplishment we are proud of is successfully integrating the Cohere API in our project. For two of our team members, this was the first time learning how "
      }
    ]
  },
  {
    "file_path": "./devposts/placeholder-hatmfc.html",
    "project_id": "placeholder-hatmfc",
    "title": "Stride",
    "tagline": "Faster, easier package delivery, built for and empowered by local community.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "github",
      "google-cloud",
      "javascript",
      "node.js",
      "react",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/565/926/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration We're all familiar with UberEats and DoorDash—time is a precious, precious commodity, and rapid delivery allows us to keep up with the bustle of a modern, busy world. Although food delivery receives acceleration, local parcel delivery doesn't: Canada Post doesn't offer same-day shipping, even for businesses that could be right next door to you! In practice, nearly all packages pass through distribution centers. While it is efficient for load balancing packages being shipped across long distances, it makes little sense for local delivery. A dedicated service for local delivery would offset the heaviest load-balancing issues traditional shipping services face, while making same-day shipping much more of a commonplace. Allowing the general population to participate as couriers would give current delivery drivers, such as those for UberEats and Uber, more work opportunities during off-peak hours. Industry giants like Amazon may have recognized the power of localized delivery, but unfortunately, such services often remain out of reach for the average business. Stride's aim is to bridge this gap, democratizing efficient and prompt local parcel delivery. There's a sharp rise in demand for faster delivery ecosystem, and our service ensures no business needs to be left behind. What it does Stride is a shipping API suite and software infrastructure designed to be integrated with e-commerce enterprises. The service expedites businesses' ability to achieve high-speed local delivery, making same-day shipping for the majority a more feasible standard. With the Stride API at the helm of the sales in an e-commerce site, determining whether a delivery should be local or long-distance becomes a seamless process. For larger retailers, at checkout, Stride pinpoints the most suitable fulfillment center for each customer's needs to ensure optimal distribution strategy. Shipping costs are calculated based on distance; shipping routes are set up as"
      }
    ]
  },
  {
    "file_path": "./devposts/placeholder-ufa527.html",
    "project_id": "placeholder-ufa527",
    "title": "Medic-Reliable",
    "tagline": "A web3 app that stores medical records on the blockchain for more reliable health tracking.",
    "hackathon": "",
    "built_with": [
      "codepen",
      "mongodb",
      "python",
      "zeeve"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "A web3 app that stores medical records on the blockchain for more reliable health tracking."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/029/652/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "the file that was uploaded on zeeve the file that was uploaded on zeeve the file that was uploaded on zeeve 1 2 Inspiration We feel that we need more security and reliability to the data of health and medical records online. We were inspired by Zeeve's medical records and health tracking problem statement, and wanted to make more reliably stored medical records. What it does A web3 app that stores medical records on the blockchain, accumulates the data anonymously, and displays a representation of the said data. By using the blockchain, the data is more reliable. How we built it We used MongoDB for the authentication system. We used the Zeeve python to upload the file on the blockchain. Challenges we ran into It was really difficult to finish what we wanted to do in the small-time given. Accomplishments that we're proud of We are glad we got to use Zeeve. However, we wish we had more time using it. What we learned We learned that the Zeeve API was effective at connecting to IPFS. This was the code we used to upload a file on Zeeve. we learned that it was super simple to use the Zeeve API to upload and get files on the blockchain. # upload a file def upload ( file , filename , auth ) : url = \"https://app.zeeve.io/zdfs-api/api/v1/file/upload\" payload = { 'files' : f \"file\" , 'name' : f \"filename\" , 'isDirectory' : 'false' } files = [ ] headers = { 'Authorization' : f \"Bearer {auth}\" } response = requests . request ( \"POST\" , url , headers = headers , data = payload , files = files ) print ( response . text ) What's next for Placeholder We need to work on the UI of the project and complete its core features. It would also be good to use smart contracts in the future to make more reliable. Built With codepen mongodb python zeeve Try it out GitHub Repo Submitted to BlockET Created by pruthviraj jadhav Brayton Lordianto"
      }
    ]
  },
  {
    "file_path": "./devposts/pixelate-you.html",
    "project_id": "pixelate-you",
    "title": "Pixelate you",
    "tagline": "Ever wondered how the world looks when pixelated? Here you go!!",
    "hackathon": "",
    "built_with": [
      "ar"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I was able to make my first ever instagram filter"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/790/658/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "See the pixelated me :))) See the pixelated me :))) See the pixelated me :))) 1 2 Inspiration I have been seeing crazy filters that turn a basic image into something completely different and i always wanted to make one by myself. What it does So this little instagram filter I made turns everything you see into pixels. You can also import images , they are pixelated too. How we built it This was built using this app called Spark AR Accomplishments that we're proud of I was able to make my first ever instagram filter Built With ar Submitted to Local Hack Day: Build Day 2 Created by Aakanksha Rangdal"
      }
    ]
  },
  {
    "file_path": "./devposts/planted-scm8wb.html",
    "project_id": "planted-scm8wb",
    "title": "Planted",
    "tagline": "Introducing Planted: Use AI tools to monitor and optimize plant care. Trade plants as NFTs on a secure blockchain market. Merge nature with technology and grow your digital plant economy with Planted.",
    "hackathon": "",
    "built_with": [
      "ai",
      "bockchain",
      "computer",
      "fine-tune",
      "gcp",
      "gpt4o",
      "ipfs",
      "llm",
      "next.js",
      "node.js",
      "polkadot",
      "satistical-analysis",
      "smart-contract",
      "unique",
      "vision"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/976/415/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration The inspiration for Planted came from our shared love for gardening and technology. We saw an opportunity to merge these passions to create a unique platform that not only helps people take better care of their plants but also allows them to trade plants as valuable digital assets. By combining AI and blockchain technology, we aimed to innovate the way people interact with and perceive plant care. What it does Planted utilizes advanced AI tools such as computer vision and statistical analysis to monitor plant growth and provide personalized care recommendations. Users can track the health and progress of their plants through our intuitive interface. Additionally, Planted enables users to trade their plants as NFTs on a secure blockchain marketplace, transforming their gardening hobby into a potential digital investment. How we built it We built Planted using a combination of modern technologies. Our AI tools for plant care analysis were developed using Python and TensorFlow, enabling us to implement computer vision for plant health monitoring. The user interface was designed with React, ensuring a seamless and interactive experience. For the blockchain marketplace, we utilized Ethereum and smart contracts to securely manage NFT transactions. Throughout the development process, we used agile methodologies to iterate and improve our platform continuously. Challenges we ran into One of the significant challenges we faced was integrating the AI tools with the user interface in a way that was both functional and user-friendly. Ensuring the accuracy of our AI models for plant care recommendations also required extensive training and testing. Additionally, developing a secure and efficient blockchain marketplace presented its own set of technical hurdles, particularly in implementing smart contracts and ensuring transaction security. Accomplishments that we're proud of We're proud of successfully creating a platform that merges advanced AI and blockchain "
      }
    ]
  },
  {
    "file_path": "./devposts/plan2plant.html",
    "project_id": "plan2plant",
    "title": "Plan2Plant",
    "tagline": "A mobile app that aims to bridge the gap between planning and planting by enabling users to efficiently compare the characteristics, intrinsic value, and economic yield of each tree species.",
    "hackathon": "",
    "built_with": [
      "canva",
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Design Created by Jessica Dong Michelle L",
      "HackDavis 2023WinnerBest Design",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/558/439/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "We were inspired by the i-Tree website and TreeDavis's mission. Our mobile app, Plan2Plant, was designed to create an accessible, public tool for homeowners to learn about the most suitable tree(s) to plant in their individual spaces. Our team looked at the i-Tree tool to understand its strengths, and weaknesses, and draw key insights from our analysis. We then created sketches of potential ideas and used card sorting to further narrow down the features of the app. We went through an accelerated sprint process when designing our prototypes that ensured the most valuable features were part of the final design. Our biggest challenge was time constraints, which compromised our design decisions for our prototype. We are most proud of the different choices we give our users to achieve their goals. Research is always the strongest foundation of your product. As we ideated and drafted our ideas, the data we collected through research provided us a strong clarity of what our users desired. Learned how to manage our time within the given time frame to produce a design that provided a solution to our problem statement. -Flesh out the typing system so individuals can type their thoughts and have a voice AI read it out with included closed captions. Finalize the plant page. Built With canva figma Try it out www.figma.com Submitted to HackDavis 2023 Winner Best Design Created by Jessica Dong Michelle L. Juliana Viado UX designer with a focus on the business value of creating solutions and immersive experiences"
      }
    ]
  },
  {
    "file_path": "./devposts/pizza-mamma-mia-analysis.html",
    "project_id": "pizza-mamma-mia-analysis",
    "title": "Pizza Mamma Mia Analysis",
    "tagline": "This project uses data mining to improve day-to-day operations at Pizza Mamma Mia. We were tasked with determining which factors increase profitability for the company.",
    "hackathon": "",
    "built_with": [
      "celonis",
      "pql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/700/223/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We chose to complete this project because it was beginner-friendly. Since our team is not as familiar with data science, this was an important factor in choosing our project. What it does Our project provides an in-depth analysis of Pizza Mamma Mia's day-to-day costs and revenue. We use factors such as customer type and cost factors to determine ways to improve customer satisfaction. How we built it The project was built using the Celonis Data Environment in which we were able to upload spreadsheets of Pizza Mamma Mia's pizza transaction history. From there, we used data science to represent the information in graphics including a pie chart and an OPAL table. Challenges we ran into One challenge that we ran into was determining how to use the key performance indicators. This prevented us from being able to easily create charts. We were able to overcome this challenge with the help of a Celonis representative. Accomplishments that we're proud of We are proud of our final graphic as it connects all the components of the data given. The user is able to test different variables to see their impact on the other dependent variables. What we learned We learned a lot about data mining and how to graphically represent data. For example, we learned which type of graph works best for specific variables. We also learned PQL, which is a publisher query language. What's next for Pizza Mamma Mia Analysis Our next step would be to create more graphics in order to test the correlation between variables from different spreadsheets. We would also like to implement the changes we suggested and determine whether or not they actually help. Writeup This project uses data mining to improve day-to-day operations at Pizza Mamma Mia. We were tasked with determining which factors, such as customer type and cost factor, increase profitability for the company. The following information is what we have gathered.\nIn the workspace that was created, it was insightful to see the different"
      }
    ]
  },
  {
    "file_path": "./devposts/planetpal-8cua0f.html",
    "project_id": "planetpal-8cua0f",
    "title": "PlanetPal",
    "tagline": "Your personal sustainable shopping companion powered by NLP, AI, and Blockchain. Helping the 2.14 billion e-commerce shoppers around the world shop greener while getting rewarded for it! 🌎",
    "hackathon": "",
    "built_with": [
      "chrome",
      "css3",
      "extension",
      "gpt4",
      "html5",
      "javascript",
      "openai",
      "postman",
      "svelte",
      "taskade",
      "typescript",
      "voiceflow",
      "wolfromalpha"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/479/692/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡 Inspiration We all want to be sustainable, but it can be challenging. Two major barriers are the time-consuming research required to find sustainable products and the lack of incentives for people to shop sustainably. Our team aimed to overcome these obstacles at TurtleHacks for not just us, but the 2.14 billion e-commerce shoppers around the world. 🤖 What It Does Say hello to the future of sustainable shopping with PlanetPal - the tool that helps you find the perfect product for both you and the planet, and rewards you for it! With one click, the extension pop-up automatically fetches and displays product information, eliminating the need for additional research. PlanetPal also incentivizes eco-friendly purchases with credits from sponsors who want to offset their carbon footprint. 👨‍💻 How We Built It We used JavaScript to implement the extension's logic and search product webpages for information such as ingredients, manufacturer, packaging, and other relevant details. HTML and CSS were used to design the extension's pop-up interface where users can see the product's extracted information and sustainability evaluation score. Finally, we employed OpenAI to evaluate the product based on a specified set of parameters to generate an overall sustainability score. 🤯 Challenges We Faced We faced challenges in scraping web data due to inconsistencies in the different layouts and field IDs. We also encountered issues with the OpenAI API keys, which reset without notice, leading to needless debugging. 😎 Accomplishments We're Proud Of Through our work on PlanetPal, we were able to build an extension that has the potential to make a significant impact on sustainability. We're proud of the fact that we were able to create a tool that not only makes it easier for consumers to make environmentally conscious purchasing decisions, but also incentivizes them to do so. Additionally, we were able to successfully integrate the OpenAI API, which allowed us to evaluate the sustain"
      }
    ]
  },
  {
    "file_path": "./devposts/platemate.html",
    "project_id": "platemate",
    "title": "PlateMate",
    "tagline": "Find new restaurants, find new friends",
    "hackathon": "",
    "built_with": [
      "cohere",
      "express.js",
      "figma",
      "firebase",
      "github",
      "google-cloud",
      "google-maps",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Co:Here - Best Build With Co:Here Challenge Created by I built the Express",
      "UofTHacks XWinnerCo:Here - Best Build With Co:Here Challenge",
      "This was the first hackathon for two of our team members",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/351/611/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chat page Sign up page Log in page Homepage User recommendations page Restaurant recommendations page Profile page Chat page Sign up page Log in page Homepage User recommendations page Restaurant recommendations page Profile page Chat page 1 2 3 4 5 6 7 8 9 10 💡 Inspiration Meeting new people is an excellent way to broaden your horizons and discover different cuisines. Dining with others is a wonderful opportunity to build connections and form new friendships. In fact, eating alone is one of the primary causes of unhappiness, second only to mental illness and financial problems. Therefore, it is essential to make an effort to find someone to share meals with. By trying new cuisines with new people and exploring new neighbourhoods, you can make new connections while enjoying delicious food. ❓ What it does PlateMate is a unique networking platform that connects individuals in close proximity and provides the setup of an impromptu meeting over some great food! It enables individuals to explore new cuisines and new individuals by using Cohere to process human-written text and discern an individual’s preferences, interests, and other attributes. This data is then aggregated to optimize a matching algorithm that pairs users. Along with a matchmaking feature, PlateMate utilizes Google APIs to highlight nearby restaurant options that fit into users’ budgets. The app’s recommendations consider a user’s budget to help regulate spending habits and make managing finances easier. PlateMate takes into account many factors to ensure that users have an enjoyable and reliable experience on the platform. 🚀 Exploration PlateMate provides opportunities for exploration by expanding social circles with interesting individuals with different life experiences and backgrounds. You are matched to other nearby users with similar cuisine preferences but differing interests. Restaurant suggestions are also provided based on your characteristics and your match’s characteristics. This provides in"
      }
    ]
  },
  {
    "file_path": "./devposts/pizzeria-mamma-mia-process-analysis.html",
    "project_id": "pizzeria-mamma-mia-process-analysis",
    "title": "Giovanni's Great Pizzeria Pickle: A Celonis Implementation",
    "tagline": "The pizza delivery business is unforgiving at times. Deadlines constantly have to be met in order to satisfy your hungry customers. With a plethora of variables at hand, we sought to solve the issue.",
    "hackathon": "",
    "built_with": [
      "celonis",
      "csv",
      "numpy",
      "pandas",
      "python",
      "seaborn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/703/873/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Celonis provided us with incredible tools in order to analyze the processes behind Giovanni's operation. We sought to determine which factors were responsible for the drop in efficiency behind certain process variants, and how it affected the business. What it does This project primarily analyzes the automation level of the most frequent process variants and how they affect customer satisfaction and profit: two main factors that are metrics of success for a business. How we built it We built the main interactive process analysis using a Celonis applet. The primary correlations were also made with the built-in Celonis tools; other influential data was visualized through Python's Seaborn library, and our use of Python helped us develop additional .csv files with a bit of coding and pre-processed data. Challenges we ran into We hypothesized plenty, looking for factors influencing the decrease in satisfaction and profit; however, we had to discard them as the visualizations provided little to no evidence for these hypotheses. This made the process of looking for proper evidence tedious but allowed for our final evidence to be essential. Accomplishments that we're proud of We found a correlation between variables that were difficult to analyze and required processing; we are extremely proud of our unique conclusions, which would help Giovanni improve his business and gain an upper hand over the competition. What we learned As the analysis we did was very detailed and would look packed in this textbox, we created separate documents as detailed reports of what we learned and concluded. Process Analysis Report Recommendations for Giovanni The main thing we learned was the usefulness of Celonis tools in visualizing processes to improve business efficiency. We never really thought that there can be that many variations in a business' process, and hence realized that if the inconsistencies in these variations are fixed then the number of business efficiency leaks c"
      }
    ]
  },
  {
    "file_path": "./devposts/plantup.html",
    "project_id": "plantup",
    "title": "PlantUp",
    "tagline": "Saving the world one plant at a time.",
    "hackathon": "",
    "built_with": [
      "figma",
      "http:requests",
      "json-server",
      "react",
      "react-router-dom",
      "tailwind-css",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "Backyard Hacks IIIWinnerBest Domain Name from Domain.comWinnerMost Creative Use of Twilio",
      "🌐 Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/055/824/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Congratulations Page! Home Page Search Page Search Page Profile Dashboard Timeline - Start Timeline - Finished Congratulations Page! Home Page Search Page Search Page Profile Dashboard Timeline - Start Timeline - Finished Congratulations Page! 1 2 3 4 5 6 7 8 💡 Inspiration Taking care of plants is like taking care of children- you need water, food, sunlight and love; without these, they die :(. Yet, despite being so fragile, plants are often forgotten on window sills or in the backyard, where people (especially coders) forget to visit. What if there was a platform that serves as a one-stop destination for all of your plant needs? We recognized from the get-go that there are several reasons why people neglect their plants: Taking care of plants can be a pretty low priority. If you aren’t a plant fanatic, having to water the lawn that you never asked for can be the least of your concerns. If you don’t want to be known as that one person on the street with a yellow lawn, we’ve got your back! There is a goal: seeing how your plant goes from seed to stalk can be very very rewarding, and what if you could see a montage of it growing up slowly? We made gardening fun, and we hope to be the reason that some of you get out of your house and give plants a chance! 🔍What it does At its core, PlantUp is a platform that is meant to make gardening an exciting experience- and we have plenty of features that help realize this. Search Page: users are able to search up the plant that they intend on planting in our search catalogue. Once they find the match, the user has the option to add it to their dashboard. Dashboard: the dashboard is the collection of plants that a user is currently taking care of. Once having selected a plant from the dashboard, they are brought to the Plant Profile. Plant Profile: This is where all the progress is saved! Users will be reminded daily to take care of their plants whether this is watering, or moving their plants into the sun! These reminders are sen"
      }
    ]
  },
  {
    "file_path": "./devposts/plan-t.html",
    "project_id": "plan-t",
    "title": "Plan-T",
    "tagline": "We hope to inform all planters, gardeners, and farmers of the most optimal planting and growing strategies to avoid potential plant diseases and provide an efficient and free way to diagnose plants.",
    "hackathon": "",
    "built_with": [
      "css3",
      "googlefonts",
      "html5",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall: Google Nest Hub (2nd gen) Created by I worked on creating the PlantNet",
      "First Place Overall: Google Nest Hub (2nd gen) Created by I worked on creating the PlantNet",
      "Pixelhacks VIWinnerFirst Place Overall: Google Nest Hub (2nd gen)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/885/357/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "PlantNet Model Architecture Description Home Page Plant Care Tips Upload Plant Picture PlantNet Model Test Accuracy PlantNet Model Training and Validation Accuracy and Loss PlantNet Model Architecture PlantNet Model Architecture Description Home Page Plant Care Tips Upload Plant Picture PlantNet Model Test Accuracy PlantNet Model Training and Validation Accuracy and Loss PlantNet Model Architecture PlantNet Model Architecture 1 2 3 4 5 6 7 8 9 Inspiration Early treatment and prevention leads to healthy plants. Healthy plants lead to healthy people, animals, and a healthy planet. We want to help our planet become healthier. Also, my grandparents were rural farmers who were not well informed of the best ways to take care of plants and prevent plant diseases. What it does Our simple and efficient instructions and tips help you and your fellow planters plan the best times and ways to water your plants so that they are healthy and robust. We also help diagnose any of your currently affected plants so you can receive an initial diagnosis needed for further treatment. How we built it HTML, CSS, REPLIT, GOOGLE FONTS, Python Challenges we ran into Syncing up different styles and formats for each HTML page into one CSS page can result in code errors.\nIncreasing the accuracy of the CNN Accomplishments that we're proud of We finished this website in less than 5-6 hours. What we learned To work fast and come up with ideas fast. What's next for Plan-T To provide more tips for plant care and classify more types of diseases.\nImprove the accuracy of the CNN model What is the purpose?\nTo help planters plan the best times and ways to water your plants so that they are healthy and robust so animals and humans can get a healthy diet. We also help diagnose any of your currently affected plants so you can receive an initial diagnosis needed for further treatment using our PlantNet CNN trained to identify whether a plant is Healthy, Powdery, or Rusty. PlantNet diagnoses pictures of plants "
      }
    ]
  },
  {
    "file_path": "./devposts/player5.html",
    "project_id": "player5",
    "title": "player5",
    "tagline": "Add a fifth player to your dev team to automate the tedious aspects of the hackathon development process.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "nextjs",
      "puppeteer",
      "redis",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/789/091/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "tasks page main menu statistics page issues page tasks page main menu statistics page issues page tasks page 1 2 3 4 5 Player5 - The Ultimate Hackathon OS GitHub Repository: Player5 - The Ultimate Hackathon OS Generated: 9/28/2025 Inspiration We've all been there: the frantic initial setup, the struggle to keep documentation fresh, the panic of deployment, all while the clock ticks down in a hackathon. It's a cruel irony that in a high-pressure, creative sprint, so much precious time is often spent on administrative overhead rather than innovative creation. This deep-seated frustration, exacerbated by countless hours wrestling with boilerplate and fragmented team workflows, sparked the vision for Player5. We dared to imagine a world where the mundane vanished, where developers could focus purely on the creative spark of hacking, liberated from the tedious and empowered to build truly amazing projects. Player5 was born from the desire to turn that vision into a tangible reality, streamlining every aspect of the hackathon journey. What It Does Player5 transforms the chaotic sprint of a hackathon into a streamlined, highly productive flow, offering a comprehensive development platform that automates the most time-consuming tasks. Imagine a team member simply typing p5 init , and within moments, their entire project is scaffolded, connected to a real-time analytics dashboard, and ready for collaborative development. From there, the platform intelligently generates polished Devpost submissions and up-to-date READMEs with p5 devpost gen and p5 readme sync , pulling insights directly from the codebase and Git history. Crucially, Player5 provides a centralized hub for project management with its web dashboard, accessible via a unique {owner}.{repo}.player5.vercel.app subdomain, allowing teams to effortlessly track bugs, manage tasks, and monitor project health in real-time, all while freeing them to focus on what truly matters: building revolutionary solutions. How We Built"
      }
    ]
  },
  {
    "file_path": "./devposts/pleasant-pixels.html",
    "project_id": "pleasant-pixels",
    "title": "Pleasant Pixels",
    "tagline": "Pleasant Pixels is a program that allows you to be more productive by setting up the mood for study, work, etc.",
    "hackathon": "",
    "built_with": [
      "c#"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/994/425/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Main menu Inspiration What inspired me was the lo-fi beats to study to channel.  I wanted more variety in the scenes so I created this program. What it does This program lets you choose beautiful animated scenes to display and then a set of music to go with it. You can also turn on rain ambiance and turn off the music if you'd prefer a more relaxing vibe. There is also a clock which you can enable to keep track of time with while you're studying. How we built it I built this application with C# and GDScript using the Godot Engine. Challenges we ran into I had a hard time finding wallpapers that were free for personal/commercial use. I created one of the animated wallpapers but finding the rest of them was hard. Accomplishments that I'm proud of I'm proud of all the sprites that I made and the overall creativity of the project. What we learned I learned how to take advantage of free assets to finish a project in a short timeframe. What's next for Pleasant Pixels Continue adding music and scenes according to the feedback given.  Hopefully more original artwork. Built With c# Try it out GitHub Repo sameerr.itch.io Submitted to LateNightHacks Created by I programmed the whole game, and created the user interface and thought of the idea of creating this program. Sameer Rahmani"
      }
    ]
  },
  {
    "file_path": "./devposts/platonic-solids-experience.html",
    "project_id": "platonic-solids-experience",
    "title": "Platonic Solids Experience",
    "tagline": "Touch-discover Polygons, Vertices, Edges and more of Platonic Solids",
    "hackathon": "",
    "built_with": [
      "3dsmax",
      "android",
      "areality3d",
      "ios",
      "magical-graph-paper",
      "qcar",
      "realityscript",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Apps for Class Winners Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)",
      "Apps for ClassWinnerApps for Class Winners",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/219/598/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 The Platonic Solids Experience Discover the properties of platonic solids (convex polyhedra with congruent faces of polygons with the same number of faces meeting at each vertex) in a magical and intuitive 3D spatial way using augment reality! First, make sure you have the magic graph paper from the PolyhedrAR website at http://print.polyhedrAR.com in front of you on a screen or printed. Then point your phone or tablet (running this app) at it! Select your Platonic Solid to see its properties. Touch to count faces, edges and vertices. Operate Kepler’s Mysterium Cosmographicum to see which polyhedron fits inside which, and how the distances of the planets are related. Coming soon - Derivations and Symmetry groups and more cute tricks! Note: you need special paper to operate magic! Please print the magical 3D augmented reality graph paper at: http://print.polyhedrAR.com — made by @yosun - the girl who built GREPhysics.NET Made by a physicist, the app includes all features in existing 3D apps teaching polyhedra, as well as a clearly-presented “magical” element inspired by classical mathematics instruction: understand the Platonic solids spatially to fit them together to deduce various planetary radii from the sun. The app is designed for use both at home and in the classroom, fitting for both self-study and any curriculum covering polyhedra. The app is accessible for all ages - from simple counting vertices, edges and unfolding faces to advance concepts for higher education, such as vector calculus derivations of formulae and symmetry groups. Extra fun comes with the nostalgic elements of magic realism on hybrid-reality graph paper, facilitating spatially-connected 3D geometry that “comes alive” interactively. Built With 3dsmax android areality3d ios magical-graph-paper qcar realityscript unity Try it out Google Play Store Submitted to Apps for Class Winner Apps for Class Winners Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)"
      }
    ]
  },
  {
    "file_path": "./devposts/pluh-stic-clean-up-crew.html",
    "project_id": "pluh-stic-clean-up-crew",
    "title": "Pluh-stic Clean Up Crew",
    "tagline": "Our project predicts ocean currents and future trash accumulation. Using data and ocean modeling, we help cleanup efforts target key areas, raising awareness about global warming and plastic pollution",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "leaflet.js",
      "math",
      "numpy",
      "panda",
      "python",
      "scikit-learn",
      "terminal"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We noticed tons of plastic being dumped into the open, killing the oceans full of life. We want to not only develop technology but also act as a call to action. The purpose is to raise awareness for global warming and pollution, in an attempt to save the environment. With this project, we can give our generation a sense of purpose while also fixing our planet for the future of humanity. What it does We use datasets from link to find the general information on ocean currents. Based on the ocean currents, the model predicts where the trash is likely to end up (where the currents end up in a circular motion). We also used link data set for the international ports. The user inputs the data, time, and starting location that they want to find the nearest trash patches. Based in the user input, our application will find the nearest port that the user can start in and the nearest cluster of trash the user can help pick up. How we built it Starting off with the datasets, we preprocessed it so the model can compute the data with no problems. Then, due to the Earth being a curve, all the distances we had were calculated using the haversine formula. We detected the accumulation range, which was ocean current accumulation near the port selected, but if we couldn’t find any due to a lack of datasets and processing power, we chose the closest ocean current. We then used 2 models, CNN for spatial data and LSTM for temporal data. We trained it 2 times and used the test data for the third fold. At the end, we concatenated the two models to print out the trash latitude and longitude. We then saved the learning model so we could add it to the webpage. Data is taken from the html webpage, the map and date, and goes through python code running through the model and outputting the port, trash, and distance between each. Challenges we ran into One of the first big problems we ran into was that our computers couldn't handle the data we were working with. As a result, we had a lo"
      }
    ]
  },
  {
    "file_path": "./devposts/polish.html",
    "project_id": "polish",
    "title": "Polish",
    "tagline": "Trained to polish your writing, our product is here to provide a safe and fast tool to support you throughout your day, using AI to provide sentence improvement and completion to users, on device.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gcp",
      "javascript",
      "python",
      "tensorflowjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Domain Name from Domain",
      "Cal Hacks 9.0Winner[MLH] Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/257/738/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "In:You belong at Calhacks Out:Come join a CalHacks community! Come join a group Input: Polishing your writing     Output:Polishing your writing a better way. Our lovely loading screen: the progress bar indicates launch speed In: Polishing your writing  Out: Polishing your words can be a lot easier for writers. Full Screen: the statement below the loading bar will be finished with AI generated content once the model is ready, as a warmup Accessibility: with a strong emphasis on accessibility, the text can be enlarged. Here we see the generation coming from In:You belong at Calhacks Out:Come join a CalHacks community! Come join a group Input: Polishing your writing     Output:Polishing your writing a better way. Our lovely loading screen: the progress bar indicates launch speed In: Polishing your writing  Out: Polishing your words can be a lot easier for writers. Full Screen: the statement below the loading bar will be finished with AI generated content once the model is ready, as a warmup Accessibility: with a strong emphasis on accessibility, the text can be enlarged. Here we see the generation coming from In:You belong at Calhacks Out:Come join a CalHacks community! Come join a group 1 2 3 4 5 6 7 Inspiration As busy hakerrs hackers, spelling, sentence structure, or grammar are seldom luxuries that we have time to indulge. We decided to face our writing demons for one last time. The result? Polish. In providing a closed-sourced alternative for many of the same mechanical functions as other text processing algorithms such as Grammarly, we can simultaneously provide instant feedback while protecting information and increasing user transparency. With increasing reliance on and availability of technology, cyber security is more important now than ever before; we hackers need a reliable, intuitive interface which that can protect our data and save us time. We keep Polish running local on the user's device, which allows our users to maintain control over their own data, "
      }
    ]
  },
  {
    "file_path": "./devposts/plutus-b7egl0.html",
    "project_id": "plutus-b7egl0",
    "title": "Plutus",
    "tagline": "Let's help to improve teenagers' financial literacy!",
    "hackathon": "",
    "built_with": [
      "django",
      "mongodb",
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Investment Hack Created by Chantal Pino Renz Vital Lib Joshua Martinito",
      "Second Overall Winner Best Investment Hack Created by Chantal Pino Renz Vital Lib Joshua Martinito",
      "FinHack 2WinnerSecond OverallWinnerBest Investment Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/316/926/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Monthly Expenses Tracker Authentication Page Landing Page Drag and drop about needs and wants Quiz about finance Compound Interest Visualization Wish List Monthly Expenses Tracker Authentication Page Landing Page Drag and drop about needs and wants Quiz about finance Compound Interest Visualization Wish List Monthly Expenses Tracker 1 2 3 4 5 6 7 8 Inspiration Financial literacy amongst teeangers is one of the problems they most encounter when transitioning to adulthood. Interactivity and making these subjects into something engaging helps us reach our target audience and helps teens to get introduced to these concepts. What it does It’s a webapp with two components, the learning activities that helps teens learn financial concepts and the SARIMA-powered expense predictor that helps them manage their finances. How we built it We used Django to structure our webapp and to serve our templates and Scikit-learn to train our SARIMA expense predictor and stored our data in mongodb. Challenges we ran into This was the first time we had ever used django as a the skeleton of our project so we had problems adjusting to the new framework. This was also our first implementing a SARIMA( Seasonal Autoregressive Integrated Moving Average) that forecasted and predicted your balance based on the data that you provide so we also had to study the concept thoroughly. Wifi issues also came up, but we grew stronger for it and worked together to solve last minute issues! Accomplishments that we're proud of We're proud that we got to collaborate so seamlessly and that we learnt new concepts as a team! What we learned How to use Django and how to implement a SARIMA based model in scikit-learn. What's Next for Plutus We want to improve the UI/UX, add more activities to help teens improve their financial literacy and to fine-tune the model we already have. Built With django mongodb python scikit-learn Try it out GitHub Repo Submitted to FinHack 2 Winner Second Overall Winner Best Investment H"
      }
    ]
  },
  {
    "file_path": "./devposts/plate-o.html",
    "project_id": "plate-o",
    "title": "Plate-O",
    "tagline": "Revolutionize your takeout habits — get financially savvy meal choices and ideal restaurant picks with an AI that seamlessly learns from your every order.",
    "hackathon": "",
    "built_with": [
      "atlas",
      "defang",
      "docker",
      "fastapi",
      "json",
      "llama",
      "math",
      "mongodb",
      "python",
      "tune"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      ": Best Financial Hack (Sponsored by Capital One) Created by nicole pardal Gene Yang WesleyBLDC Dela",
      "Financial Hack (Sponsored by Capital One) Created by nicole pardal Gene Yang WesleyBLDC Dela Cruz V",
      "Track: Best Financial Hack (Sponsored by Capital One) Created by nicole pardal Gene Yang WesleyBLDC",
      "PennApps XXVWinnerTrack: Best Financial Hack (Sponsored by Capital One)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/037/968/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Smart Delivery Recommendation App Imagined Signin Info Smart Delivery Recommendation App Imagined Signin Info 1 2 3 4 Inspiration Behind Plate-O 🍽️ The inspiration for Plate-O comes from the intersection of convenience, financial responsibility, and the joy of discovering new meals. We all love ordering takeout, but there’s often that nagging question: “Can I really afford to order out again?” For many, budgeting around food choices can be stressful and time-consuming, yet essential for maintaining a healthy balance between indulgence and financial well-being. 🍔💡 Our goal with Plate-O was to create a seamless solution that alleviates this burden while still giving users the excitement of variety and novelty in their meals. We wanted to bridge the gap between smart personal finance and the spontaneity of food discovery, making it easier for people to enjoy new restaurants without worrying about breaking the bank. 🍕✨ What makes Plate-O truly special is its ability to learn from your habits and preferences, ensuring each recommendation is not only financially responsible but tailored to your unique tastes. By combining AI, personal finance insights, and your love for good food, we created a tool that makes managing your takeout spending effortless, leaving you more time to enjoy the experience. Bon Appétit! 📊🍽️ How We Built Plate-O 🛠️ At the core of Plate-O is its AI-driven recommendation engine, designed to balance two crucial factors: your financial well-being and your culinary preferences. Here’s how we made it happen:\nBackend: We used FastAPI to build a robust system for handling the user’s financial data, preferences, and restaurant options. By integrating the Capital One API, Plate-O can analyze your income, expenses, and savings to calculate an ideal takeout budget—maximizing enjoyment while minimizing financial strain. 💵📈 Frontend : Next.js powers our intuitive user interface. Users input their budget, and with just a few clicks, they get a surprise restaurant "
      }
    ]
  },
  {
    "file_path": "./devposts/podcastgpt.html",
    "project_id": "podcastgpt",
    "title": "PodcastGPT by 14Labs",
    "tagline": "Podcasts Customized for Your Interests",
    "hackathon": "",
    "built_with": [
      "llamaindex",
      "openai",
      "python",
      "tavily"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DevDay Releases x MultiOn API HackathonWinnerSecond Place",
      "Aiming to blend the best of written and audio content into personalized podcasts.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/676/887/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Growing popularity of podcasts as a medium for content consumption. Aiming to blend the best of written and audio content into personalized podcasts. What it does PodcastGPT allows users to create personalized podcasts.\nFeatures include: Selection of a celebrity host. Customizable podcast duration and genre. Option to input personal news articles or use an in-built news search. Podcasts mimic host mannerisms. Ability to upload podcasts to YouTube. How we built it OpenAI Assistants API for podcast agent configuration. LlamaIndex and Tavily Search for news aggregation. Custom YouTube integration for podcast uploads. ElevenLabs for celebrity voice recreation. Challenges we ran into Managing the context window for large article inputs. Ensuring deterministic news retrieval via Tavily Search. Accomplishments that we're proud of Integrated OpenAI API, LlamaIndex, Tavily Search, ElevenLabs, and YouTube, achieving seamless functionality. Mastered ElevenLabs' voice recreation, adding unique celebrity voices to podcasts. Developed a method for efficient article condensation, addressing AI context window limits. Enabled reliable and relevant news retrieval through Tavily Search. What we learned Learned to navigate and mitigate agent limitations, particularly in content processing. Understood the subtleties of voice technology for creating engaging audio content. Recognized the importance of user-driven customization in content platforms. What's next for PodcastGPT Introduction of customized voices and self-created hosts. Integration with Spotify for podcast sharing. Expanding content ingestion capabilities (e.g., YouTube videos, PDFs). Built With llamaindex openai python tavily Try it out GitHub Repo Submitted to DevDay Releases x MultiOn API Hackathon Winner Second Place Created by Zacchaeus Chok Backend engineer at Series C Fintech. Varun Swaminathan Aayush Mathur SWE at Series A Fintech Gabriel Yang"
      }
    ]
  },
  {
    "file_path": "./devposts/poli-search.html",
    "project_id": "poli-search",
    "title": "Poli Search",
    "tagline": "Find info and similarity to politicians.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "flask",
      "google-civic-information",
      "html",
      "open-fec",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/266/710/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Example politician search Home Page Survey Example politician search Home Page Survey Example politician search 1 2 3 4 Inspiration Our team has all recently come of voting age, and we are of the collective opinion that deciding who to vote for is an arduous task. What it Does Take a quick survey about your political stances, submit a politician for comparison, and watch the magic happen! A similarity score will be calculated and basic info will be returned. This will allow you to make a more informed decision when it comes to voting day. How We Built it Using Google Civic and Open FEC APIs we request information on politicians. We then list a short bio using a Wikipedia scraper. For flask, we used a template linked here . Challenges We Encountered Importing images Utilizing Google APIs flask in general learning new languages in 24 hours (HTML, CSS)\n## What we learned\nWe learned about using flask to implement HTML and CSS to create a functional website. (All searches must be of politicians serving the 45040 zip code) Built With bootstrap css flask google-civic-information html open-fec python Try it out GitHub Repo Submitted to MakeUC Created by Nathan Grilliot Soham Das Daniel Vennemeyer Eli Fouts"
      }
    ]
  },
  {
    "file_path": "./devposts/predict-risk-of-covid19.html",
    "project_id": "predict-risk-of-covid19",
    "title": "Predict Risk of Covid19",
    "tagline": "91% accurate model to determine level of risk of Covid based on user's physical details so visit to doctors can be planned and people don't panic.",
    "hackathon": "",
    "built_with": [
      "c50",
      "r",
      "shiny"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Presently there has been a large panic among people regarding COVID-19 and there has been a huge problem with the treatment of a large number of people in hospitals. Some of the patients tend to show early signs and go voluntarily to get the covid test done but it leads to a huge number of people visiting hospitals wherein the hospital's capacity is not able to accommodate the number of people visiting it. In order to streamline the process of delivering healthcare, we propose a method that identifies the risk for a person in terms of having COVID-19 based on their demographics. What it does We developed an accurate machine learning model that can be used to predict the level of risk of a person based on age, race, gender, date of exposure, and pre-existing illness to inform them whether to go for a checkup to the doctor or not and not panic in case any primary symptoms are shown. Model details C5.0 machine learning model 2 fold cross-validation trained over COVID-19_Case_Surveillance_Public_Use_Data Accuracy : 90.60% How I built it Checks for a risk factor for a particular user of having specific age, gender, race, and medical condition - 4 levels of risk factor are given: 0 - No risk (shouldn't visit a doctor), 1 - minimal risk, 2 - moderate risk (should plan on visiting doctor within a week if illness pertains), 3 - High Risk (Should visit a doctor immediately) Based on the risk factor, the user can either visit the doctor or stay at home to avoid infections.\nWe also identified the attributes that were mostly used for making a prediction. In other terms, the risk of having COVID-19 is dependent primarily on the following factors: Attribute Usage for making prediction 100.00% medcond_yn 100.00% age_group80+ Years 94.78%    age_group70 - 79 Years\n-12.73% cdc_report_dt 9.75% age_group60 - 69 Years 6.52% age_group50 - 59 Years 4.72% Race.and.ethnicity..combined.Asian, Non-Hispanic 4.47% age_group40 - 49 Years 3.49% Race.and.ethnicity..combined.Unknown 2.9"
      }
    ]
  },
  {
    "file_path": "./devposts/power-steering-system-for-solar-sail-boat.html",
    "project_id": "power-steering-system-for-solar-sail-boat",
    "title": "Power steering system for Solar sail boat",
    "tagline": "Sailboat",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/949/093/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 What it does We wrote prototype code for a system that allows a user to steer a Sonar-class boat using either a sip'n'puff system or a joystick. You can switch the mode using a hardware switch mounted on the board. Depending on which controller you choose, the code either converts pressure to velocity or X position of the joystick to velocity. This enables people with limited mobility to steer the boat. Required hardware: Arduino Board, Stepper motor, Pressure sensor, Switch, Jumpers TODOs: Bluetooth communication between sensors Add sensors that will be used (not known yet) TODO Hardware: Two cells to sense the tension Stepper motor Driver Bluetooth transimtters Try it out docs.google.com GitHub Repo Created by Adrianna Wojtyna Hyejun Youn Austin Veseliza"
      }
    ]
  },
  {
    "file_path": "./devposts/polypace.html",
    "project_id": "polypace",
    "title": "PolyPace",
    "tagline": "A VR, full body motion capture game that helps you stay active through adventures in a fantasy world.",
    "hackathon": "",
    "built_with": [
      "blender",
      "opencv",
      "openxr",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Motion tracking via OpenCV and OpenXR"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/234/875/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration In a world where young adults are increasingly sedentary, spending more time on devices than moving their bodies, we saw an opportunity. The fitness industry's traditional models—expensive gyms and rigid class schedules—are failing an entire generation. We discovered that 42% of people experience appearance-based anxiety about working out, and 72% crave the flexibility from online fitness apps as opposed to traditional gyms. PolyPace was created with a simple thought in mind: What if we could make exercise feel like play? What it does 🏃PolyPace is a first-person VR game that transforms exercise into an immersive, enjoyable experience. By gamifying physical activity, we've created a solution that allows users to work out comfortably at home, on their own schedule, without the intimidation of traditional fitness environments. Users can have their motions translate into real-time actions in-game and progress through a series of obstacles, getting exercise, experiencing stunning visuals and listening to our wonderful custom soundtrack (thanks Baseless!) along the way. At the end of each level, users can track their progress to see how many calories they've burned to help them continue their fitness journey. How we built it Motion tracking via OpenCV and OpenXR MetaQuest 3 for immersive VR experience Custom front-end designed in Blender Unity integration for seamless game development Challenges we ran into 🌼Our team grappled with technical and logistical hurdles during PolyPace's development. Relearning Unity's latest updates, resolving complex motion tracking depth calculation errors, and managing the project amidst a packed hackathon schedule tested our adaptability. Despite these challenges, we remained committed to creating an innovative VR fitness experience. Accomplishments that we're proud of 🍃 We're most proud of creating a visually and technically impressive solution that could potentially help thousands of young adults overcome their bar"
      }
    ]
  },
  {
    "file_path": "./devposts/pompy.html",
    "project_id": "pompy",
    "title": "Pompi!",
    "tagline": "A fluffy friend for your quarantine to reduce all your loneliness and depression!",
    "hackathon": "",
    "built_with": [
      "firebase",
      "flask",
      "numpy",
      "opencv",
      "python",
      "swift",
      "swiftui",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "IOS Project (Sponsored by LocketCamera) Winner Best Use of Echo3D (Sponsored by Echo3D) Created by",
      "LocketCamera) Winner Best Use of Echo3D (Sponsored by Echo3D) Created by worked on all the AR front",
      "Best IOS Project (Sponsored by LocketCamera) Winner Best Use of Echo3D (Sponsored by Echo3D) Create",
      "HackHarvard 2022: Control, Alt, CreateWinnerBest IOS Project (Sponsored by LocketCamera)WinnerBest Use of Echo3D (Sponsored by Echo3D)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/255/497/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "screenshot GIF Pompy screenshot GIF Pompy screenshot 1 2 3 4 5 6 💡 Inspiration💡 Our team is saddened by the fact that so many people think that COVID-19 is obsolete when the virus is still very much relevant and impactful to us. We recognize that there are still a lot of people around the world that are quarantining—which can be a very depressing situation to be in. We wanted to create some way for people in quarantine, now or in the future, to help them stay healthy both physically and mentally; and to do so in a fun way! ⚙️ What it does ⚙️ We have a full-range of features. Users are welcomed by our virtual avatar, Pompy! Pompy is meant to be a virtual friend for users during quarantine. Users can view Pompy in 3D to see it with them in real-time and interact with Pompy. Users can also view a live recent data map that shows the relevance of COVID-19 even at this time. Users can also take a photo of their food to see the number of calories they eat to stay healthy during quarantine. Users can also escape their reality by entering a different landscape in 3D. Lastly, users can view a roadmap of next steps in their journey to get through their quarantine, and to speak to Pompy. 🏗️ How we built it 🏗️ 🟣 Echo3D 🟣 We used Echo3D to store the 3D models we render. Each rendering of Pompy in 3D and each landscape is a different animation that our team created in a 3D rendering software, Cinema 4D. We realized that, as the app progresses, we can find difficulty in storing all the 3D models locally. By using Echo3D, we download only the 3D models that we need, thus optimizing memory and smooth runtime. We can see Echo3D being much more useful as the animations that we create increase. 🔴 An Augmented Metaverse in Swift 🔴 We used Swift as the main component of our app, and used it to power our Augmented Reality views (ARViewControllers), our photo views (UIPickerControllers), and our speech recognition models (AVFoundation). To bring our 3D models to Augmented Reality, we used A"
      }
    ]
  },
  {
    "file_path": "./devposts/portfolio-website-1ovr36.html",
    "project_id": "portfolio-website-1ovr36",
    "title": "Gigachad Giraffes Portfolio Template",
    "tagline": "A portfolio website template with a professional and sleek aesthetic. This template allows you to showcase who you are personally and professionally while leaving a long-lasting impact on users.",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/001/468/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Hobbies Page GIF Landing Page Projects Hobbies Page GIF Landing Page Projects Hobbies Page 1 2 3 4 Inspiration We wanted to create a minimalist, but dynamic portfolio. We looked at online portfolios and resumes and we took bits and pieces from each with our biggest inspiration being LinkedIn. We didn't want our portfolio to be too crowded and we wanted everything to be viewable at once so we cut back on interactive elements like carousels and tabs. What it does The portfolio application we built can be run as a flask application. It displays the various experience, education, and other things that a person feels is particularly important. There is a way to contact them at the top and the application is heavily customizable and row after row of experiences, projects and more can be added. How we built it We used Flask, JavaScript, HTML/CSS. We used online resources to show us how to get certain features and we also used the Openweathermap API to display local weather data. We live in various different time zones so we couldn't all work on it at the same time, so we made a groupchat, providing each other descriptions of what we planned on working on and notificiations of our PRs. These were either merged by teammates, or if the teammates were on their phone and couldn't merge, merged by the ones who made the Pull request. Challenges we ran into None of us had experience with flask and were pretty rusty when it came to our front-end skills. We learned as we went through the project and used outside sources to learn more about the languages we were using. CSS and styling were also something we had a hard time discussing and finalizing but in the end, we came up with a very pleasing aesthetic we are proud to display. Git was also an issue as some team members were unfamiliar with git so pushing, pulling, and merging was quite a challenge. Accomplishments that we're proud of We are proud of the features and effort we put into this project as well as how great we worked to"
      }
    ]
  },
  {
    "file_path": "./devposts/prepaired.html",
    "project_id": "prepaired",
    "title": "PrepAIred",
    "tagline": "AI-powered Interview Coach: Master your responses, ace your interview.",
    "hackathon": "",
    "built_with": [
      "chatgpt",
      "llama",
      "loveable",
      "mongodb",
      "mongoose",
      "node.js",
      "ollama",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/251/058/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Interview Page Main Page Interview Page Main Page Interview Page 1 2 PrepAIred Inspiration Internship hunting season is stressful, and we all felt pressure to prepare for interviews. We wished we had a way to experience real mock interviews before facing actual recruiters. Additionally, having an interview buddy or a structured way to practice would have made the process much smoother. That's why we built PrepAIred : a tool designed to simulate real interviews , provide instant feedback, and track progress over time. What it does PrepAIred simulates real interview experiences using an AI-driven interviewer that asks dynamic, industry-specific questions. Users can: Engage in mock interviews with AI, receiving real-time feedback. Practice behavioral questions based on their field. Customize interviews by selecting the job role. Speech-to-text processing for a hands-free, conversational experience. Get AI-generated feedback on responses, including clarity, and conciseness. Score tracking to monitor improvement over time. User authentication to save past performance and track progress. How we built it Frontend : Developed using React for a clean and interactive UI, and with react-speech-recognition for speech-to-text . Backend : Built with Node.js to handle communication with Ollama . AI Model : Utilized Llama 3 (latest) to generate realistic interview questions and feedback. Database: Stores user scores and progress history in MongoDB for tracking improvements. Challenges we ran into Setting up MongoDB: Ensuring proper database connections and structuring data efficiently. Authentication: Implementing secure user login and session management. Score tracking: Designing a system that records user performance over multiple sessions. Prompt engineering responses : Ensuring AI-generated questions and feedback felt natural and job-relevant. Accomplishments that we're proud of Creating a realistic mock interview experience powered by AI. Successfully integrating speech-to-tex"
      }
    ]
  },
  {
    "file_path": "./devposts/precept.html",
    "project_id": "precept",
    "title": "Precept",
    "tagline": "This project combines state-of-the-art 3D rendering techniques, including NeRF (Neural Radiance Fields) and Gaussian Splatting, to create a highly detailed and interactive digital twin of a Seat car",
    "hackathon": "",
    "built_with": [
      "gemini",
      "mongodb",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/405/109/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "eeg seat in tokyo seat in barcelona seat 3d eeg seat in tokyo seat in barcelona seat 3d eeg 1 2 3 4 5 🧠 Precept: AI-Driven Experiential Platform Unlock subconscious decision-making and photorealistic 3D visualization -- together! 🚗🧠 Inspiration We're inspired by the belief that technology should feel both magical and deeply personal. On one hand, planning a reunion with friends scattered around the globe is often logistical drudgery -- what if your brain could choose the destination before you even say a word? On the other, the future of mobility demands seamless, personalized experiences -- from selecting eco‑friendly flights to virtually previewing local transport and vehicle options. By combining real‑time neural sensing with cutting‑edge neural rendering, Precept creates immersive experiences that mind‑meld with emotion, democratize high‑fidelity visualization, and reimagine mobility as a whole . 🔍 What It Does Precept consists of two integrated modules: SEAT Car Digital Twin We create a complete 3D virtual replica of a SEAT car that: Allows users to explore both the exterior and interior of the car in real-time with photorealistic quality Enables interactive viewing from any angle, with accurate lighting and reflection details Provides a foundation for applications in car customization, virtual showrooms, and engineering analysis Democratizes access to high-quality 3D car visualization without the need for traditional 3D modeling expertise EEG-Powered Travel Planner Live brainwave input via Muse Headband scores 10 AI‑curated cities for engagement, arousal, mindfulness. Top 3 destinations shown; users finalize their pick subconsciously. Friends repeat or vote in real time ; smart budget‑and‑harmony warnings keep everyone on board. Once chosen, Skyscanner integration surfaces optimal flights (greenest, cheapest, fastest). 🛠️ How We Built It Digital Twin Rendering Pipeline: Data Capture: Hundreds of multi-angle photos of the SEAT car (interior & exterior). COLMAP:"
      }
    ]
  },
  {
    "file_path": "./devposts/poptactoe-fairyfish.html",
    "project_id": "poptactoe-fairyfish",
    "title": "PopTacToe-FairyFish",
    "tagline": "Use stockfish to play **TicTacToe**.",
    "hackathon": "",
    "built_with": [
      "fairy-stockfish",
      "stockfish"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMU Datathon 2024WinnerPush Battle",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/128/015/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Github: PLEASE USE THE ‘td_submission’ directory to run our code as we have multiple directory and this is the most updated one! https://github.com/lucianchauvin/poptactoe-fish Inspiration We were given problem! What it does It uses a stockfish fork called Fairy-Stockfish to allow for custom models. We then implement PopTacToe in Fairy-Stockfish. How we built it with much pain. Accomplishments that we're proud of that anything works at all What we learned stockfish is weirdly readable. What's next for PopTacToe-FairyFish uhh the codebase is a mess so Us beating random people Here is it beating random people: 10.245.103.239 - - [10/Nov/2024 10:48:08] \"POST /start HTTP/1.1\" 200 -\n[5, 4]\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . W . .\n. . . . . . . .\nNone\n10.245.103.239 - - [10/Nov/2024 10:48:12] \"POST /move HTTP/1.1\" 200 -\n[3, 4]\n. . . . . W . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . B . . .\n. . . . . . . W\n. . . . . . . .\nNone\n10.245.103.239 - - [10/Nov/2024 10:48:16] \"POST /move HTTP/1.1\" 200 -\n[6, 4]\n. . . . . W . .\n. . . . . . . .\n. . . . . . . .\n. . . . B . . .\n. . . . . . . .\n. . . . B . . .\nW . . . . . W .\n. . . . . . . .\nNone\n10.245.103.239 - - [10/Nov/2024 10:48:20] \"POST /move HTTP/1.1\" 200 -\n10.245.103.239 - - [10/Nov/2024 10:50:18] \"GET / HTTP/1.1\" 200 -\nFalse\n10.245.103.239 - - [10/Nov/2024 10:50:18] \"POST /start HTTP/1.1\" 200 -\n[1, 5]\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . W . .\nNone\n10.245.103.239 - - [10/Nov/2024 10:50:22] \"POST /move HTTP/1.1\" 200 -\n[2, 7]\n. . . . . . W .\n. . . . . B . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . W . . .\n. . . . . . . .\nNone\n10.245.103.239 - - [10/Nov/2024 10:50:26] \"POST /move HTTP/1.1\" 200 -\n[2, 5]\n. . . . . . W .\n. . . . . B . .\n. . W . . . . B\n. . . . . . . .\n. . . . . . . .\n. . . . . . . .\n. . . . W . . .\n. "
      }
    ]
  },
  {
    "file_path": "./devposts/presssy.html",
    "project_id": "presssy",
    "title": "VenTalk",
    "tagline": "Need to vent about a bad day or just want someone to chat with? VenTalk pairs users with compatible needs in this unique wellness messaging app and quickly relieves everyday stressors.",
    "hackathon": "",
    "built_with": [
      "adobe-illustrator",
      "dandelion-api",
      "figma",
      "gcp",
      "javascript",
      "react-native",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack Western 7WinnerTELUS Leverage Technology to Manage/Improve any Mental Health Related Issue",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/291/665/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Back End Code VenTalk Main Page User Experience Flowchart UI Sketches and Brainstorming Back End Code VenTalk Main Page User Experience Flowchart UI Sketches and Brainstorming Back End Code 1 2 3 4 5 Inspiration The idea for VenTalk originated from an everyday stressor that everyone on our team could relate to; commuting alone to and from class during the school year. After a stressful work or school day, we want to let out all our feelings and thoughts, but do not want to alarm or disturb our loved ones. Releasing built-up emotional tension is a highly effective form of self-care, but many people stay quiet as not to become a burden on those around them. Over time, this takes a toll on one’s well being, so we decided to tackle this issue in a creative yet simple way. What it does VenTalk allows users to either chat with another user or request urgent mental health assistance. Based on their choice, they input how they are feeling on a mental health scale, or some topics they want to discuss with their paired user. The app searches for keywords and similarities to match 2 users who are looking to have a similar conversation. VenTalk is completely anonymous and thus guilt-free, and chats are permanently deleted once both users have left the conversation. This allows users to get any stressors from their day off their chest and rejuvenate their bodies and minds, while still connecting with others. How we built it We began with building a framework in React Native and using Figma to design a clean, user-friendly app layout. After this, we wrote an algorithm that could detect common words from the user inputs, and finally pair up two users in the queue to start messaging. Then we integrated, tested, and refined how the app worked. Challenges we ran into One of the biggest challenges we faced was learning how to interact with APIs and cloud programs. We had a lot of issues getting a reliable response from the web API we wanted to use, and a lot of requests just returned "
      }
    ]
  },
  {
    "file_path": "./devposts/possibility-website-the-possibility-engine.html",
    "project_id": "possibility-website-the-possibility-engine",
    "title": "Possibility.website - The Possibility Engine",
    "tagline": "Welcome to the endless realm of potential\n\nType anything. Discover everything. The only limit is your imagination.",
    "hackathon": "",
    "built_with": [
      "bolt",
      "ionos",
      "lucide-react",
      "netlify",
      "react",
      "tailwind",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/581/341/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Possibility Engine - Unlimited Potential Awaits Inspiration In a world filled with limitations and boundaries, we wanted to create something that celebrates the infinite nature of human creativity and imagination. Inspired by the legendary zombo.com and its message that \"anything is possible,\" we built the Possibility Engine for 2025 - a modern, interactive experience that transforms any idea into countless opportunities. The concept emerged from a simple question: \"What if we could help people see beyond their initial thoughts and discover the unlimited potential in every idea?\" We wanted to create a tool that doesn't just respond to input, but actively expands it into realms of possibility that users might never have considered. What it does The Possibility Engine is an interactive web application that takes any user input - whether it's a simple word, concept, dream, or vision - and generates an array of inspiring possibilities. The application: Transforms Ideas : Takes user input and applies creative templates to generate unique possibilities Inspires Action : Presents ideas in an engaging, visually stunning interface Encourages Exploration : Shows multiple perspectives on any given concept Sparks Creativity : Combines user input with inspirational words to create unexpected combinations Users simply type anything into the input field, and within moments, they're presented with a grid of possibilities that reframe their original idea in revolutionary, innovative, and inspiring ways. How we built it Technology Stack Frontend : React 18 with TypeScript for type safety and modern development Styling : Tailwind CSS for rapid, responsive design development Icons : Lucide React for beautiful, consistent iconography Build Tool : Vite for fast development and optimized production builds Deployment : Netlify for seamless hosting and continuous deployment Architecture & Features Real-time Generation : Uses React hooks (useState, useEffect) to generate possibilities "
      }
    ]
  },
  {
    "file_path": "./devposts/pocket-plots.html",
    "project_id": "pocket-plots",
    "title": "Pocket Plots",
    "tagline": "Making land ownership accessible and affordable to all",
    "hackathon": "",
    "built_with": [
      "checkbook",
      "convex",
      "gradio",
      "huggingface",
      "materialui",
      "natural-language-processing",
      "netlify",
      "nltk",
      "numpy",
      "pandas",
      "python",
      "react",
      "scikit-learn",
      "tailwind",
      "transformer"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Startup by YC, Runner-Ups Created by I worked on building & deploying (streamlit + gradio) the",
      "TreeHacks 2023WinnerBest Startup by YC, Runner-Ups",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/386/319/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Logo 1 2 3 4 5 6 7 💡 Inspiration Generation Z is all about renting - buying land is simply out of our budgets. But the tides are changing: with Pocket Plots, an entirely new generation can unlock the power of land ownership without a budget. Traditional land ownership goes like this: you find a property, spend weeks negotiating a price, and secure a loan. Then, you have to pay out agents, contractors, utilities, and more. Next, you have to go through legal documents, processing, and more. All while you are shelling out tens to hundreds of thousands of dollars. Yuck. Pocket Plots handles all of that for you. We, as a future LLC, buy up large parcels of land, stacking over 10 acres per purchase. Under the company name, we automatically generate internal contracts that outline a customer's rights to a certain portion of the land, defined by 4 coordinate points on a map. Each parcel is now divided into individual plots ranging from 1,000 to 10,000 sq ft, and only one person can own a contract to each plot to the plot. This is what makes us fundamentally novel: we simulate land ownership without needing to physically create deeds for every person. This skips all the costs and legal details of creating deeds and gives everyone the opportunity to land ownership. These contracts are 99 years and infinitely renewable, so when it's time to sell, you'll have buyers flocking to buy from you first. You can try out our app here: https://warm-cendol-1db56b.netlify.app/ (AI features are available locally. Please check our Github repo for more.) ⚙️What it does Buy land like it's ebay: We aren't just a business: we're a platform. Our technology allows for fast transactions, instant legal document generation, and resale of properties like it's the world's first ebay land marketplace. We've not just a business. We've got what it takes to launch your next biggest investment. Pocket as a new financial asset class... In fintech, the last boom has been in blockchain. But after FTX and"
      }
    ]
  },
  {
    "file_path": "./devposts/prices-petite.html",
    "project_id": "prices-petite",
    "title": "Prices Petite",
    "tagline": "A price tracker for any product",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "opencv",
      "python",
      "taipy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Taipy Created by I used BeautifulSoup to scrape product information in Python",
      "The GoldenHackWinnerBest Use of Taipy",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/614/911/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Our team was inspired to create this project because we noticed an underlying issue today that many people face these days; with the increasing complexity of online shopping, how do you make sure that when you’re buying a product you’re getting the best possible deal to get online? How do I find the cheapest option?. Recognizing the need to simplify the process of finding the best prices for products across various retailers, our team set out to develop a price tracker that checks prices from multiple sources, and lists out the cheapest options and where you can buy it from. What sets this project apart is the integration of computer vision technology, allowing users to search for products by showing images, making it more intuitive and user-friendly. This way, even if the user may not know what the product is exactly, they can use the computer vision model to find an appropriate comparison. We wanted to empower consumers to make informed decisions, save time, and money. Moreover, this project serves as an opportunity for me to learn and apply various skills, including web scraping and computer vision. What it does Our project uses web scraping to locate the cheapest prices for a given query, and displays: a table of each product: the vendor they're sold from: their price: a link to buy the product. The table is ordered from cheapest to most expensive to streamline the experience for the user. The user can input the query manually, or use a computer vision model that detects any visible objects in the camera and automatically selects a query. The model is trained from the google cloud. The user is able to filter which specific vendor they want to buy from. How we built it For the web scraping, we used Python and the libraries BeautifulSoup. We used a dictionary that organised the product information neatly, and then used the pandas library to create a dataframe that consolidated the information into a neat table. For the computer vision aspect, we "
      }
    ]
  },
  {
    "file_path": "./devposts/presentquick.html",
    "project_id": "presentquick",
    "title": "PresentQuick",
    "tagline": "An AI-based tool built for researchers, that uses NLP to summarize content and create instant Presentations from Research Papers and Long Articles",
    "hackathon": "",
    "built_with": [
      "flask",
      "natural-language-processing",
      "nltk",
      "python",
      "python-pptx",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/729/566/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Briefing a Research Paper or an Article into a compact presentation can be difficult, especially during conferences, where there are people from different domains who may or may not have the knowledge about your field. What it does PresentQuick is a tool that can convert a long article or research paper into a simple presentation, that makes it easier to understand. It uses NLP to analyze long pieces of content and recollects the most important sentences and breaks them down into slides. This web application can be used either for presenting something to the audience of even to get a simple understanding of a complex topic. How I built it Back-end: Natural Language Toolkit, Python-Flask Front-end: Python-PPTX Hosting: Replit Challenges I ran into Creating and designing presentations was a challenge at first, but then I found out the Python-PPTX library and learned how to use it during the course of this project. Accomplishments that we're proud of Being able to complete this project, learning about Natural Language Processing and Python-PPTX, and hosting it. What I learned I learned about NLP and Python-PPTX library. What's next for PresentQuick I'll be adding more presentation designs and work on the overlay problem with text. Built With flask natural-language-processing nltk python python-pptx replit Try it out GitHub Repo presentquick.neeltron.repl.co Submitted to TigerHacks 2021 Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/presentation-coach.html",
    "project_id": "presentation-coach",
    "title": "Presentation Coach!",
    "tagline": "Imagine you're doing a presentation, and you want to know if the audience is actually looking at your slides. Now, you can! Simply record your audience and gather retention analytics fast.",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/053/287/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Seeing HowdyHack's presentation What it does It tells you retention analytics from a recording of the presentation and the presentation file itself. How we built it Python, NextJS, OpenCV, and blood, sweat, and tears. Challenges we ran into Communication, time management, and accidentally sleeping too long. Accomplishments that we're proud of We're proud that we were able to learn NextJS in one night and get a working prototype of the web app of our dreams. What we learned Why time management is important and how to deal with git merge conflicts. What's next for Presentation Coach! We hope to add more speech analysis for the presenter as well as crowd volume analysis to determine whether the crowd is attentive or restless to make the web app overall more polished. Built With nextjs opencv python Try it out GitHub Repo Submitted to HowdyHack 2024 Created by Isaac Chacko"
      }
    ]
  },
  {
    "file_path": "./devposts/prism-7yfp2v.html",
    "project_id": "prism-7yfp2v",
    "title": "PRiSM",
    "tagline": "Too many tools, too much time, with PRiSM engineering is simplified",
    "hackathon": "",
    "built_with": [
      "fluxapi",
      "github",
      "next.js",
      "node.js",
      "octopartapi",
      "python",
      "simscaleapi",
      "tailwind",
      "typescript",
      "zooapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Prize Created by I built PRiSM, a Next",
      "Startup Track 1st Prize Created by I built PRiSM, a Next",
      "DevHacks S2WinnerStartup Track 1st Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/767/880/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Circuit Created and Simulated Command Window Code Section BOM Risk Analysis Testing Methods User Manual Generated: UI User Manual Generated: Export Circuit Created and Simulated Command Window Code Section BOM Risk Analysis Testing Methods User Manual Generated: UI User Manual Generated: Export Circuit Created and Simulated 1 2 3 4 5 6 7 8 9 Inspiration We were inspired by how difficult it still is to move from an idea to a working prototype in hardware. While software teams can rapidly spin up projects with a few commands, hardware teams must juggle fragmented workflows across circuit design, CAD modeling, simulations, BOM generation, and documentation. Our vision was to remove those barriers and build a system where a single prompt could generate an entire prototype, making hardware innovation as fast and accessible as software development. What it does PRiSM takes a user’s natural language prompt and automatically generates the critical components of a hardware project. It produces circuit diagrams with editable variables, CAD models with live previews and STEP downloads, CFD and stress simulations with metrics, fully generated working code, a real-time BOM with prices and suppliers, and detailed risk analysis, testing methods, and user manuals. Every time the user modifies the prompt or adjusts variables, the entire system recomputes so that the outputs always reflect the latest requirements. How we built it We built PRiSM with a Next.js frontend styled using Tailwind and shadcn/ui for a clean, responsive interface. The Command Prompt acts as the single source of truth, where any change triggers recomputation across all sections. On the backend, we integrated multiple APIs: Flux AI for circuits, Zoo API for CAD previews and STEP files, SimScale API for simulations, Octopart API for real-time BOM data, and Gemini API for risk analysis, testing methods, and documentation. To ensure reliability during the hackathon, we also implemented mock fallback routes so the p"
      }
    ]
  },
  {
    "file_path": "./devposts/printerpeddler.html",
    "project_id": "printerpeddler",
    "title": "PrinterPeddler - Team 6",
    "tagline": "Printer Peddler is a marketplace designed for sellers with 3d printers to host a printer to print parts on request for money, allowing the user to cooperate or make money off of their printer",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "python",
      "sqlalchemy",
      "velo",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Velo by Wix Created by Pranav Yerramaneni space cat Austin4705 Wu Sarvesh Madullapalli",
      "Los Altos Hacks VIWinnerBest Use of Velo by Wix",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/234/568/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Ordering Main Search Page Ordering Main Search Page Ordering 1 2 Here's is our website link (using Velo by Wix): https://py96982015.wixsite.com/printer-peddler Inspiration Our inspiration for this project came when we were discussing ideas. We noted how hard it was to work with 3d printed designs for hardware if you didn't have a printer while at the same time having a printer be way too expensive for small recreational use. We then came up with the idea of getting people to sell printer services online to not only give people that don't have printers an opportunity to get stuff printed but also an opportunity to cooperate with the cost. What it does Printer Peddler allows a user to view and search up 3d printers based on specified parameters. After they find a printer they like, they can place an order on that printer. That creates a ticket that the seller can see and approve/deny. Assuming the seller approves he can then give updates through the ticket until the buyer confirms that the part has arrived. How we built it Our project has a main frontend and a backend. The fronted was created on wix velo and routed using domain.com. We used custom js functions in order to work with the json files and update it accordingly.  We used Axios as a framework to better communicate with the backend. For the backend, we used Python with Flash and SQLAlchemy in order to build it out. We created a database between users, printers, and tickets and used a relational database to map between them. Challenges we ran into The main challenges we ran into while creating the project were DIsplaying the search properly on wix We had initially planned to use the wix.com storefront module to display all the data. However, we quickly realized that our Wix storefront was not able to be edited by code and so we had to design our own search page. Managing a relational database Our system required us to have a database of users and printers and tickets available. All printers and tickets require"
      }
    ]
  },
  {
    "file_path": "./devposts/pridenet.html",
    "project_id": "pridenet",
    "title": "PrideNet",
    "tagline": "A Progressive Web App to keep a Mental Health Check on the LGBTQIA Community",
    "hackathon": "",
    "built_with": [
      "dart",
      "flask",
      "flutter",
      "mysql",
      "python",
      "replit",
      "restapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration As per the CDC [1], LGBT youth are almost 5 times more likely to have attempted to commit suicide as compared to Heterosexual youth. To prevent that, it is necessary to have someone to talk to, or a community that supports them, or perhaps we can call it an unofficial \"helpline\". What it does It is a progressive web application that allows LGBTQ + Allies to connect with like-minded people (anonymously or openly, up to them) and provides them with an unofficial \"helpline\". Our application is built to facilitate volunteers too, who can join in during their free time and talk to those in need. How we built it We used Flutter for the front end, MySQL for storing data and Python with flask to develop the Rest API, that is working as the backend for this application. Challenges we ran into Fetching JSON Responses in Flutter. Accomplishments that we're proud of Finally being able to complete it! What we learned About API Integration in Flutter and developing Rest APIs with Flask. What's next for PrideNet We'll deploy it as soon as possible and try to have a full product ready! Citations [1] CDC. (2016). Sexual Identity, Sex of Sexual Contacts, and Health-Risk Behaviors Among Students in Grades 9-12: Youth Risk Behavior Surveillance. Atlanta, GA: U.S. Department of Health and Human Services. Built With dart flask flutter mysql python replit restapi Try it out GitHub Repo drive.google.com Submitted to Def Hacks Worldwide 3.0 PrideHacks Created by Neel Adwani yeet rishabh java"
      }
    ]
  },
  {
    "file_path": "./devposts/problama-llama.html",
    "project_id": "problama-llama",
    "title": "Problama Llama",
    "tagline": "Learn code, help llamas, have fun! For the woman developer. For the woman gamer. The story matters.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Diversity & Inclusion Hack Created by Drove project vision, co-created pitch, and coded game Anita",
      "Best Diversity & Inclusion Hack Created by Drove project vision, co-created pitch, and coded game A",
      "WaffleHacks 2022WinnerBest Diversity & Inclusion Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/010/787/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration When I was young, I remember cringing when I saw Tetra transform into Princess Zelda; the change was framed as an \"upgrade\" from an unremarkable brown pirate to a pale princess worth Herculean effort to save. Playing video games often meant I have to leave my identity at the door. Video games only knows one kind of Latina, and it's one mired in negative stereotypes. That's why I want to change this misconception that permeates in Latin culture and the misogynistic society we live in. Now in 2022 more women play video games than men yet women make up only 24% of game developers. As aspiring game developers, when we see women create video games, there's more of a focus on the storytelling, vibrant and welcoming graphics, and maybe even an altruistic goal. Our vision is that saving the world starts with kindness, empathy, openness, and intentionality with words - not with weapons. And sometimes that starts locally. What it does As a team of two strong women pursuing STEM majors looking to bring more women into the field, represent,  and practice what we preach, we created a game, Problama Llama, which teaches code in fun, easy, interactive way. First, we highlight a Latina woman as the protagonist helping her neighbor find and bring home a mischievous llama. We then immerse the player into Peruvian culture - often not explored in video games beyond gangsters, violence, and corruption. Players see phrases in Spanish, listen to cultural music, and learn more about domesticated llamas and daily life in South America. All the while, we showcase the power of the basic HTML, CSS, JavaScript to not only aid the storyline by visualizing what code can do, but we also give a glimpse of how the code is not as daunting when we break everything down to its most basic HTML component. How we built it We built this using HTML, CSS, and JavaScript. Instead of creating multiple HTML pages, we challenged ourselves to use JavaScript to manipulate the DOM and keep everythin"
      }
    ]
  },
  {
    "file_path": "./devposts/prismbot.html",
    "project_id": "prismbot",
    "title": "PrismBot",
    "tagline": "Get factual information grounded from reliable sources",
    "hackathon": "",
    "built_with": [
      "docker",
      "python",
      "streamlit",
      "vertex-ai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Google Cloud Created by James Liang Avid student exploring different aspects of technol",
      "hackHerWinnerBest Use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/802/844/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Redis Database General Questions Unrelated Question Data Loading - from Google's blog RAG - from Google's blog GCP APIs Redis Database General Questions Unrelated Question Data Loading - from Google's blog RAG - from Google's blog GCP APIs Redis Database 1 2 3 4 5 6 7 Inspiration There is a lot of disinformation and misinformation spread around the world, especially for under represented groups like LGBTQ2+. Transgender issues are in the spotlight now with news articles and laws. PrismBot is a chat bot that answers difficult questions grounded by reliable sources including Rainbow Health Ontario. It provides a source of truth in this world of misinformation. What it does Via the chat interface, users can ask any question they want. Questions are compared to our known database of reliable information to provided grounded answers. If the bot doesn't know, it will explicitly say rather than hallucinate. It cites sources from where it retrieved information so the user knows exactly where to look. There is also a \"Take me to safety!\" button on the left to let the user quickly leave the website. No user information is stored. How we built it Using Langchain, I was able to connect all the components together. To parse documents, I use PyPDF to read PDFs and extract the text. This text is split into manageable sizes and converted into embeddings using Vertex AI. Everything is then stored into the Redis database. Websites are processed in a similar way by extracting content before being split. The front-end is built using Streamlit. User queries are parsed and converted into embeddings. A similarity search is run against the Redis database to find relevant information. Using Gemeni Pro, the information is processed into user-friendly text before being presented. Using GitHub actions and Docker, the app was built to be deployed anywhere. Using Google Cloud Google Cloud Platform is one of the crucial pillars of this project. Using Vertex AI, I was able to get all the resources"
      }
    ]
  },
  {
    "file_path": "./devposts/privacy-concerns-related-to-covid-19-boundary-collapse.html",
    "project_id": "privacy-concerns-related-to-covid-19-boundary-collapse",
    "title": "Privacy Concerns Related to COVID-19 Boundary Collapse",
    "tagline": "We have designed, conducted, and analyzed a survey examining specific privacy concerns related to this boundary collapse during COVID-19.",
    "hackathon": "",
    "built_with": [
      "jmp",
      "qualtrics",
      "r"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration COVID-19 is causing boundary collapse for many of us -- our homes are now also our schools, our workplaces, our social event spaces, and much more. This boundary collapse is accelerated by technology, such as video meetings or course proctoring tools. What it does In this project, we have designed, conducted, and analyzed a survey examining specific privacy concerns related to this boundary collapse: what new privacy concerns do people have? What coping strategies are they using? Have they experienced any adverse consequences? How I built it We used Qualtrics to develop the survey, and R and JMP to analyze the survey results. Challenges I ran into Due to our time constraints, we only had time to collect data from 32 participants (30 of which completed the survey). Accomplishments that I'm proud of Our group managed to complete a stand-alone survey analysis project in just one weekend. What I learned We drew three primary conclusions: As the number of meeting attendees rise, the comfort level for turning on the camera decreases. People are more interested in hiding their faces than hiding their names in a meeting. People are more likely to hold back from participating when they know that the meeting is being recorded. What's next for Privacy Concerns Related to COVID-19 Boundary Collapse To obtain more conclusive results in the future, we could release this survey for a longer period of time to get more survey participants. Built With jmp qualtrics r Submitted to Technica 2020 Created by I developed research questions, analyzed data and presented findings. Kristen Hallas Undergraduate student at UTRGV Private user Kelsey Fulton Fariha Mohamed Radhika Patel Senior at the University of Maryland Janki Chaudhari Computer Science and Software Engineering student at University of Western Ontario asl3 Liu"
      }
    ]
  },
  {
    "file_path": "./devposts/proactive-health.html",
    "project_id": "proactive-health",
    "title": "Proactive Health",
    "tagline": "Hundreds of billions of dollars are lost due to administrative waste, lack of transparency, and uninformed decision making. We provide a solution for all three.",
    "hackathon": "",
    "built_with": [
      "modal",
      "openai",
      "python",
      "swift",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We have a member who works in Healthcare and deals with administrative problems every day, especially as they pertain to insurance and informed decision making What it does Aggregates health data for more informed decision making by your doctor and yourself How we built it Typescript + Next for Frontend, Python Backend hosted on Modal, Swift for IOS App, MongoDB for storage/vector-search, OpenAI for Embedding Generation Challenges we ran into Apple HealthKit is notorious for having a terrible API. We never used Mongo before. We never used Modal before. Accomplishments that we're proud of We learned how to make several different parts of our project work together and learned how to use tech that we've never used before. What we learned We learned how to use many different technologies in conjunction and learned how to get every part of our project off our project off localhost. Built With modal openai python swift typescript Try it out GitHub Repo Submitted to IvyHacks Created by Provided open source healthcare data, designed collections in mongo, set up real time updates with swift and apple watch victor su-ortiz the frontender Private user I wrote the backend server with Modal, abstracted away mongo functionalities for frontend calls, created and saved embeddings, made RAG for OpenAI GPT calls, and provided my health data for the demo. Tanzir Hasan"
      }
    ]
  },
  {
    "file_path": "./devposts/produce-sustainability.html",
    "project_id": "produce-sustainability",
    "title": "Produce Sustainability",
    "tagline": "A grocer`s partner for their journey to produce sustainability and fight against food waste!",
    "hackathon": "",
    "built_with": [
      "charts.js",
      "css",
      "express.js",
      "html",
      "javascript",
      "node.js",
      "postgresql",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/034/238/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Final design for website navicon logo First design for website home page Final design for website navicon logo First design for website home page Final design for website 1 2 3 4 5 Inspiration Have you ever walked into a convenience store and marveled at the vast collection of goods? Although convenience stores are convenient in the sense that they always seem to have what you need, there’s a big catch. About 30% of food in the US from supermarkets is thrown out due to mass supply, and this can have major environmental consequences. Food waste generates 11% of greenhouse gas emissions, and not to mention, food takes an insane amount of resources to grow and/or prepare. This is why we created Produce Sustainability, to help our grocers and shopkeepers in their fight against food waste. What it does Produce Sustainability is a website that utilizes a machine learning model to calculate how much perishable items a store is recommended to buy with a goal of minimizing food waste. We use past sales data to predict the demand for food at this specific convenience store. We also predict the amount a shopkeeper should buy for a specific food item, such as potatoes, to give more accurate results based on consumer demand. In addition, the machine learning model also takes data from other stores to help make more accurate predictions. How we built it This website was built using HTML, CSS, JavaScript, Express.js, Node.js, and PostgresSQL. Charts.js is also used to create a chart to visualize the data coming from the machine learning model. The model itself was made in-house using js without any APIs, and uses techniques such as polynomial regression, querying SQL databases, feature regularization, and gradient descent. Challenges Coming up with a viable solution to this problem was difficult, as it is a complex problem that has no real “correct” solution. Deciding where to get the data for predicting sales demand was also somewhat difficult if you consider the fact that some s"
      }
    ]
  },
  {
    "file_path": "./devposts/proffrating.html",
    "project_id": "proffrating",
    "title": "ProfMatch",
    "tagline": "Find your ideal professor by leveraging real data and your personal preferences.",
    "hackathon": "",
    "built_with": [
      "axios",
      "css",
      "database",
      "flask",
      "next.js",
      "pandas",
      "python",
      "sqlite",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HowdyHack 2023Winner2nd Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/582/561/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Recommendations Homepage Sign Up / Sign In Page Preferences Recommendations Homepage Sign Up / Sign In Page Preferences Recommendations 1 2 3 4 Our Mission: At ProfMatch, our mission is to empower students to take control of their education. We believe that accurate data from students about professors and courses can lead to better academic choices and improved learning experiences. What is it? Our user-friendly interface allows you to search for course names and report to you the professors best suited to your preferences for that course. Whether you're selecting your classes for the upcoming semester or just curious about your current instructors, finding the right information is a breeze. Our platform thrives on the feedback of students like you. We use AEFIS course evaluation data from students, published in a public and frequently updated Kaggle dataset, to give more thorough and objective feedback. Get an inside look into teaching styles, course content, grading criteria, and overall classroom experiences. Personalize ratings for each student based on preferences Users can dynamically change and get ratings specifically for them, versus one-size-fits-all ratings on other sites, based on subjective metrics (people more likely to use if they are extremely like or dislike a professor causing voluntary bias) How we built it Next.js React-based framework for the front-end web development. Tailwind CSS for easier implementation of styling, color, and design.\n-Axios library and Flask backend to communicate between front-end and data science and analytics.\n-Python scripts implementing data science life cycle- preprocessing, feature engineering and normalization, and development of an algorithm to recommend and rank professors based on how they match the preferences and priorities of each student.\n-Pandas data frame for organization and manipulation of data.\n-Sqlite3 database for planned storage of user preferences- not fully implemented yet. Challenges we ran into Dev"
      }
    ]
  },
  {
    "file_path": "./devposts/project-op4593jagmcb.html",
    "project_id": "project-op4593jagmcb",
    "title": "Motor Down",
    "tagline": "Our model ‘listens’ to motor data, selecting only key signals to track its health and load. This streamlined approach makes predictive maintenance efficient and reliable, saving time and resources.",
    "hackathon": "",
    "built_with": [
      "googlecollab",
      "matplot",
      "numpy",
      "pandas",
      "scipy",
      "sklearn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMU Datathon 2024WinnerBaker Hughes' Challenge 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/127/148/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Original Distribution vs Blended Distribution (Alpha: 0.5) Density Plots Original Data Distribution (Dataset 1) Downsampled Similar Distribution (Dataset 1) Downsampled Uniform Distribution (Dataset 1) Original Distribution vs Same Shape Distribution Density Plots Original Distribution vs Uniform Distribution Density Plots Original Distribution vs Blended Distribution (Alpha: 0.5) Density Plots Original Data Distribution (Dataset 1) Downsampled Similar Distribution (Dataset 1) Downsampled Uniform Distribution (Dataset 1) Original Distribution vs Same Shape Distribution Density Plots Original Distribution vs Uniform Distribution Density Plots Original Distribution vs Blended Distribution (Alpha: 0.5) Density Plots 1 2 3 4 5 6 Inspiration The need for smarter and more efficient monitoring of electric motors is what inspired this project. We saw an opportunity to apply data science, machine learning, and statistical analysis to improve predictive maintenance, and transform electric motor health and load proactively. What it does Our model uses data from sensors that track frequency and power to predict health degradation in electric motors by selecting 2500 key data to represent the entire dataset. These selected data points help represent the original dataset, and enable the precise and efficient operation of the condition monitoring system. How we built it We used the sensor data to create an output the original distribution as a comparable baseline. Next, we utilized a data selection algorithm to reduce the dataset size while persevering crucial information from the data. Finally, we plotted the sampled data in 2D scatter plots and 3D histograms to visualize and compare the distributions and density percentages of the original and sampled data. Challenges we ran into The greatest challenge we faced was trying to efficiently reduce the dataset from 500,000 points to 2,500 without losing any valuable information. We had to make sure that we captured a uniform distribu"
      }
    ]
  },
  {
    "file_path": "./devposts/project-lou.html",
    "project_id": "project-lou",
    "title": "Project Lou",
    "tagline": "Lou is an AI-powered assistant/people-search-engine that finds people, writes emails, follows up, and schedules meetings on your behalf—so you can focus on real connections, not repetitive tasks",
    "hackathon": "",
    "built_with": [
      "admin",
      "advanced",
      "ai",
      "aiohttp",
      "anthropic)",
      "anymailfinder",
      "api",
      "beautifulsoup4",
      "calendar",
      "claude",
      "cloud",
      "context",
      "discovery",
      "docker",
      "duckduckgo",
      "email",
      "environment",
      "environments",
      "fastmcp",
      "firebase",
      "firebase/firestore",
      "git",
      "gmail",
      "google",
      "integration",
      "key",
      "linkedin",
      "management",
      "mcp)",
      "model",
      "oauth2",
      "platform",
      "powershell",
      "protocol",
      "python",
      "python-dotenv",
      "rapidapi)",
      "requests",
      "sdk",
      "search",
      "sqlalchemy",
      "storage",
      "system",
      "tracking",
      "url/email",
      "uvicorn",
      "variables",
      "venv)",
      "virtual",
      "windows",
      "workspace"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Tracks context state across multiple sessions",
      "tracking"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/407/722/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "🧠 About the Project: Project Lou – Your AI-Powered Assistant Suite for everything Outreach via Modular Claude MCPs 🎯 Problem Statement Despite having state-of-the-art LLMs, we still waste enormous time on repetitive cognitive tasks: Searching for people or companies with vague info Writing personalized cold emails Managing multi-step follow-up logic Scheduling calendar events and parsing replies I wanted to solve this with a fully modular AI-powered agent that not only “thinks,” but also acts autonomously across the real web and productivity tools. Because to be honest outreach of many forms job search, sales, recruitment, involves a lot of manual and redundant work that can be automated plus with Claude desktop and MCP it becomes so simple just type in English a small prompt to give the base idea and let prompt engineered anthropic models do the work for you, especially in job search, personalization takes a lot of student’s time and it’s expensive to hire someone or get a service that does it for the student on their behalf, then comes the problem of transparency, sharing of confidential details, up-front costs.  Everyone needs it but no one wants to outsource it if they have a better option. With Claude desktop and MCP servers that becomes possible everything remains transparent user has full controls with a super minimalistic UI that when served on dockers can even be made available to mobile devices (imagine just sending a message to Claude desktop in cloud before sleeping and waking up to potentially tens of responses and scheduled meets on calendar just like delegating to a human) by cloud services via a web interface and this can be made commercial while keeping control to the user by charging for the API usage, compute and Claude powered people search engine. I have already received 40+ users in the waitlist I floated within 24hrs, that too passively. 🤖 What is Project Lou? Project Lou is a suite of specialized Claude-powered MCP servers (Model Context Prot"
      }
    ]
  },
  {
    "file_path": "./devposts/productivityplus.html",
    "project_id": "productivityplus",
    "title": "ProductivityPlus",
    "tagline": "With ProductivityPlus, you can have a huge assortment of cherry-picked unproductive apps that you can access with a press of a button.",
    "hackathon": "",
    "built_with": [
      "axios",
      "express.js",
      "firebase",
      "mongodb",
      "next.js",
      "procrastination",
      "react",
      "tailwind.css"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Unite Hack IIWinnerLED lightsWinnerkeyboardsWinnerarduino kits",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/580/468/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ProductivityPlus Inspiration We were inspired by the American work culture and how we wanted to reverse that. What it does It makes sure you stay unproductive and keep time for your mental health. How we built it React, next.js, express.js, tailwind.css, axios, firebase, mongol db Challenges we ran into Integrating backend routes into front end, and working with complex figma designs. Accomplishments that we're proud of We are proud that we made a leaderboard, we are proud of backend and MetaMask integration. What we learned We should plan our time more usefully and not do auth again. We also learned that not being productive is better than being productive. What's next for ProductivityPlus We make it essential to school systems. Built With axios express.js firebase mongodb next.js procrastination react tailwind.css Try it out GitHub Repo Submitted to Unite Hack II Winner LED lights Winner keyboards Winner arduino kits Created by I wrote the entire backend for this project and wrote middleware for integrating our frontend with our backend. Veerrohit Veeravadivel I worked on UI Design and frontend Aravindkrishna Arivudainambi Jahaanshah Sheikh Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python"
      }
    ]
  },
  {
    "file_path": "./devposts/prof-finder.html",
    "project_id": "prof-finder",
    "title": "Prof Finder",
    "tagline": "Are you a confused future Aggie? Use our website and become more knowledgeable about choosing the class that's right for you. Find the right professor and the right timings that work just for you!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/241/648/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Reviews about Prof Finder Home page of Prof Finder About us: States our purpose and features Class search section: Lists all classes and section for the class selected by drop-down and day selected Schedule builder: Puts specified classes into cards to help visualize schedule Grade Point Average distributer by teacher for courses The team Reviews about Prof Finder Home page of Prof Finder About us: States our purpose and features Class search section: Lists all classes and section for the class selected by drop-down and day selected Schedule builder: Puts specified classes into cards to help visualize schedule Grade Point Average distributer by teacher for courses The team Reviews about Prof Finder 1 2 3 4 5 6 7 Prologue We were the clueless freshmen at our NSC. The ones that had little to no knowledge about the classes that were offered here at A&M and the difficulty of the courses and the differences between the quality of professors. A website such as this would have been the perfect addition to improving the quality of our NSC and lowering our stress levels during this new time Description This app is tailor-made for incoming freshmen engineers to decide what schedule they want for their mandatory courses during their fall semester. It works to provide every piece of information that any incoming Aggie would need to become an academic weapon at the prestigious institution of Texas A&M. The How There is a lot that went into this project. Firstly, we created our own database by browsing through the different class sections that incoming freshmen engineering courses have on the Howdy Portal. Then, we needed to parse through this database to match the input from the student to the list. After this, we create cards that display the student's schedules - the sections and the information about the professor they chose. Finally, we created the rest of the website; the about, the home, and the graphs section. Our about included all the pertinent information relating to t"
      }
    ]
  },
  {
    "file_path": "./devposts/progressions.html",
    "project_id": "progressions",
    "title": "Progressions",
    "tagline": "Short story based on COVID-19 built using HTML",
    "hackathon": "",
    "built_with": [
      "html",
      "twine"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Almost a year into the pandemic, many people don't understand the emotional effects of seeing a loved one with COVID-19. What it does You navigate through the story using link and automatic timers. How I built it Using the Twine interactive fiction software Challenges I ran into Using the macro values and integrating html elements into the story Accomplishments that I'm proud of It has emotional value that I was aiming for What I learned Practice more What's next for Progressions Further story development with more features and actions Built With html twine Try it out naughty-hypatia-df5d73.netlify.app Submitted to Hackdemonium Created by Iman Umair-Qaiser UWaterloo CE '26"
      }
    ]
  },
  {
    "file_path": "./devposts/promptgpt.html",
    "project_id": "promptgpt",
    "title": "PromptGPT",
    "tagline": "Our app generates efficient prompts for one-shot results using a custom, finetuned, opensource Dolly v2 model with 3 billion parameters.",
    "hackathon": "",
    "built_with": [
      "databricks",
      "docker",
      "dolly-v2-3b",
      "fastapi",
      "flask",
      "google-cloud",
      "hugging-face",
      "langchain",
      "mongodb",
      "next.js",
      "peft",
      "pubsub",
      "python",
      "pytorch",
      "vertex-ai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/508/912/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Google Cloud Logs shows user's request and output PromptGPT regenerate prompt \"Instagram post about vacation\" Regenerated prompt for \"Youtube video about cats\" Regenerated prompt using promptGPT extension for \"Developing application for Databricks\" Google Cloud Logs shows user's request and output PromptGPT regenerate prompt \"Instagram post about vacation\" Regenerated prompt for \"Youtube video about cats\" Regenerated prompt using promptGPT extension for \"Developing application for Databricks\" Google Cloud Logs shows user's request and output 1 2 3 4 5 Inspiration Crafting effective prompts for ChatGPT has long been a challenge faced by users. Users often find themselves frustrated when attempting to achieve the desired text output from chatGPT, which even led to a community of users attempting to find the best prompt for one-shot answers. This inspires us to create PromptGPT in order to help the user find that desired output. What it does Imagine a content creator who needs assistance generating engaging article ideas. Instead of brainstorming and refining prompts through trial and error, PromptGPT allows them to input a single sentence and receive a prompt-engineered best practice suggestion for one-shot result. This enables the creator to save time and focus on crafting high-quality content with one simple instruction. \nPromptGPT can be used as a browser extension and can be access at in the website with OpenAI prompt to test out at https://promptllm.vercel.app/ How we built it We create a custom dataset with 50 rows of data using Expert Prompt Creator We used Hugging Face dataset and web scrape EasyPrompt Library Using datasets created in step 1 and step 2, we instruction-tuned the databricks/dolly-v2-3b model using the PEFT library to have the training in 4 bits in LORA on a single Nvidia Tesla A100 40 GB in 15 minutes. You can access the training notebook in Google Colab notebook We then serve the model in Google Cloud Vertex AI on one Nvidia Tesla T4 GPU for p"
      }
    ]
  },
  {
    "file_path": "./devposts/project-name-9ov6u0.html",
    "project_id": "project-name-9ov6u0",
    "title": "Defectors",
    "tagline": "Augmenting your data",
    "hackathon": "",
    "built_with": [
      "adobe-illustrator",
      "bootstrap",
      "dash",
      "figma",
      "invokeai",
      "label-studio",
      "pytorch",
      "streamlit",
      "tensorboard",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner - Reduce the Footprint Created by Mantas Kandratavičius Linda Weiß Daud Taj Tahmina Mojumder",
      "Track Winner - Reduce the Footprint Created by Mantas Kandratavičius Linda Weiß Daud Taj Tahmina Mo",
      "Hackaburg 2023WinnerTrack Winner - Reduce the Footprint",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/489/333/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Classification Defectors - Automate your data Generation structure based on DefectGAN Generated defects Web Dashboard Training Dashboard Classification Defectors - Automate your data Generation structure based on DefectGAN Generated defects Web Dashboard Training Dashboard Classification 1 2 3 4 5 6 Inspiration Automated defect inspection is critical for effective and efficient maintenance, repair, and sustainable production in advanced manufacturing. On the other hand, automated defect inspection is almost always constrained by the lack of defect samples, instead of working on detection, we fix the underlying issue by replicating the defect creation process! What it does While the goal remains to be able to identify anomalies as accurately and effectively as possible, it's not the detection itself that is the actual challenge. Our project has to be able to recreate every single possible damage type on golden-samples and then use that to generate a dataset of reasonable size for the actual detection training. In the current era of machine learning, training a model given the perfect data has become trivial, that's why detection is only the cherry on the anomaly-generation based cake. 🎂 Based on Stable Diffusion, we use the already pre-trained SD-in-painting models as a starting point. In-painting with Patchmatch is more than capable of removing important elements from a golden sample, which is the first step to both, defects through removal and defects through anomaly introduction to the image. If a defect can be put into the group of \"missing elements\" then the in-painting model does the job completely, removing a labeled element and then filling in with background information. If a defect can be put into the group of \"unwanted elements\" then the first step remains the same - first we 'fix' an image with a defect by removing the unwanted addition. With the element removed, and gold sample restored, we can then calculate the absolute difference between the restored "
      }
    ]
  },
  {
    "file_path": "./devposts/prostateninja.html",
    "project_id": "prostateninja",
    "title": "ProstateNinja",
    "tagline": "We are creating a website to help prostate cancer patients find nearby clinics with free experimental treatments.",
    "hackathon": "",
    "built_with": [
      "flask",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Problem/Need Addressed by Technology\nProstate cancer remains the second most common cause of cancer death in American men, with 200,000 new cases and 30,000 deaths in 2019 alone. Despite its prevalence, Cancer.gov reports that men do not seek the regular screenings or treatment, leading to unnecessary death and suffering for patients. I have seen firsthand the devastating impact of prostate cancer in breaking apart families and communities as I volunteer in urology wards and organize health workshops for prostate cancer patients. What struck me most from these experiences was a lack of information, isolation and disempowerment felt by patients throughout the treatment process. The creation of a virtual, personalized patient portal for prostate cancer patients would provide them an understanding of their disease and the importance of seeking screening and diagnostics while engaging them in their own health. Proposed Solution\nA new portal for prostate cancer patients to learn more about their illness, access resources, identify support groups, discover clinical trials, seek professional counseling and allow them to regain agency over their cancer. This portal will be accessible as a digital hub for patients and their families faced with a new diagnosis. This portal will be of particular help for underserved patients who may be unfamiliar with the basis of their condition and the concrete next steps they should take. It will also help alleviate the stigma around prostate cancer as local support groups can be organized through this portal and patients can see and connect with others like them. This innovation will accelerate innovation in prostate cancer research as it eliminates the oftentimes complicated method of connecting patients with clinical trials. This innovation may be monetized through charging clinical trial organizations and local providers for listings.\nWho is Your Competition?\nThe current state of information for prostate cancer patients is fragmented as"
      }
    ]
  },
  {
    "file_path": "./devposts/prompt-sf7drq.html",
    "project_id": "prompt-sf7drq",
    "title": "prompt+",
    "tagline": "supercharge your prompts: get every token's worth.",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "flask",
      "html",
      "javascript",
      "langchain",
      "openai",
      "python",
      "react",
      "spacy",
      "tiktoken"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall - 3rd Place Created by Jeet Bhatkar Swapnil Mittal Kavya Venkatesh MS CS @ Columbia | Georg",
      "Best Overall - 3rd Place Created by Jeet Bhatkar Swapnil Mittal Kavya Venkatesh MS CS @ Columbia |",
      "HackGT 11: Circus of InventionsWinnerBest Overall - 3rd Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/044/907/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 💡 Inspiration Have you ever realized you maxed out your tokens for the day while halfway to a big breakthrough interacting with an LLM? With the increasing adoption of large language models (LLMs) across industries, prompt engineering has become a critical yet untapped aspect of obtaining precise, contextual, and optimized outputs. However, most users struggle with crafting the optimal prompts to extract the best possible results from industry-leading models, thereby missing out on the optimal use of the capacity of tokens they can use in a ̄timeframe. This creates inefficiencies, inaccurate outputs, and a steep learning curve. This gap in prompt engineering and tokenization inspired us to develop prompt+ , an intuitive tool that optimizes LLM prompts and the tokens they utilize, enhancing the accuracy, relevance, and efficiency of responses for users across expertise levels. It enables users to bridge various contexts in novel LLM interactions, minimizing the tokens and time taken to carry over past data. 💿 What it does prompt+ is an AI-powered prompt optimization platform designed to help developers, researchers, and LLM users easily craft and refine prompts for large language models (LLMs). Using advanced NLP techniques, our tool: Optimizes Prompts: Provides real-time improvements for user-provided prompts to generate more relevant LLM responses using the least possible amount of tokens per query. Performs Task-Specific Optimization: Offers templates and optimization modes tailored to specific tasks, such as creative writing, technical queries, code generation, and summarization. Delivers Contextual Enhancements: Uses previous interactions and context to refine prompts dynamically, ensuring that the LLM maintains a coherent and relevant thread of conversation while minimizing time taken. Calculates Efficiency Metrics: Tracks metrics like model processing time, token usage, and response quality to help users understand the performance impact of their p"
      }
    ]
  },
  {
    "file_path": "./devposts/prospectsai.html",
    "project_id": "prospectsai",
    "title": "ProspectsAI",
    "tagline": "Level up your career with ProSpecsAI! Our AI chatbot, personalized learning paths, and mock interviews guarantee your dream job. Join now, transform your future! Seize opportunities today!",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "react",
      "textscipt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Second Overall Created by Lanning Zhang Meiyi Chen Chinat Yu My name is Chinat Yu",
      "HackBattle: React vs AngularWinnerSecond Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/548/245/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Resume Review Sign-In Our Solution Dashboard Learning Path Chat about any question Interview Report Resume Review Sign-In Our Solution Dashboard Learning Path Chat about any question Interview Report Resume Review 1 2 3 4 5 6 7 8 Inspiration As recent college graduates ourselves, we understand the challenges and hurdles that job seekers encounter during their transition from academia to the workforce. Inspired by our own experiences, we created ProSpecsAI to provide a comprehensive and supportive tool that equips fresh graduates with the skills and knowledge needed to excel in their job search and secure desirable job opportunities. Competitive Analysis We investigated more than a dozen AI job preparation-related products on the market. The following are some of the problems we found and the solutions we came up with. Shortage : Most of them cannot answer personalized questions, users can only choose to ask a certain number of set-up questions. Most of them do not have Resume Review, which is also a crucial part for college job seekers. Most of them have a limited number of companies and job types to choose from, usually they only focus on big companies and ignore the job seekers who need to practice skills with other companies. With the report the system directly presents in the isolated single user solution, users are not sure if the system’s scoring is accurate or not. What It Does ProSpecsAI is built using the latest technology stack, including the Next.js framework for a seamless user experience. Our platform incorporates cutting-edge AI algorithms to deliver valuable insights and personalized recommendations to users. Whether it's helping them identify the right career path, optimizing their resume to stand out, or preparing them for job interviews, ProSpecsAI offers a user-friendly and efficient solution to overcome the challenges of the job-seeking process. Our Solution : Provide a live AI Chatbot to answer any personalized questions from college job seekers"
      }
    ]
  },
  {
    "file_path": "./devposts/project-8ca0hrpog54x.html",
    "project_id": "project-8ca0hrpog54x",
    "title": "EmpathiCare",
    "tagline": "Evaluate a healthcare provider’s reaction to AI generated patient",
    "hackathon": "",
    "built_with": [
      "computervision",
      "healthcare",
      "hugging",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration\nIn the healthcare industry, professionals often confront emotionally charged situations demanding a delicate and empathetic response. The challenge lies in providing sufficient emotional training for healthcare providers. Our inspiration arises from the imperative need to bridge this gap by introducing a tool that simulates emotionally challenging scenarios, ultimately enhancing the emotional intelligence of healthcare providers. What it does\nOur tool immerses healthcare providers in emotionally difficult situations, scrutinizing their reactions to predefined prompts. Utilizing a pre-trained VGGNET19 model from Hugging Face, we implemented a facial expression classifier to discern the emotion and intensity conveyed by the healthcare provider. Additionally, by analyzing facial expressions and transcripts, we generate remarks on the response. The tool incorporates a time-series analysis, providing insights into the evolving emotional responses. Finally, the ChatGPT plugin is employed to present cohesive reports with charts and timestamps, highlighting instances when the healthcare provider's response may have been inappropriate. How we built it\nWe harnessed the power of the VGGNET19 model from Hugging Face for facial expression classification. Leveraging Intel's cloud infrastructure, we efficiently prototyped and trained our model. The tool adopts a time-series approach to capture the dynamic nature of emotional reactions, ensuring a comprehensive and accurate analysis. Challenges we ran into\nOur journey was marked by several challenges. Initial stages involved extensive research to identify a compelling and useful idea. We faced difficulties in selecting the most suitable model for face detection, and choosing the right model for initial detection posed an additional challenge. Accomplishments that we're proud of\nWe successfully developed a viable beta version of our emotional training tool. Our sense of accomplishment extends to the effective utilization"
      }
    ]
  },
  {
    "file_path": "./devposts/prompto-kcv361.html",
    "project_id": "prompto-kcv361",
    "title": "Prompto",
    "tagline": "Tinder and AI generative tools combine in Prompto. Describe the image you would like, and Prompto adapts as you swipe left or right on its generations, saving images in your personal library.",
    "hackathon": "",
    "built_with": [
      "flask",
      "modal-stable-diffusion",
      "python",
      "react-native",
      "replicate"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/594/196/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Prompto Generation Page Prompto Logo Prompto Generation Page Prompto Logo Prompto Generation Page 1 2 3 Inspiration How could we create AI accessible to digitally disadvantaged communities and increase digital literacy? That's why we developed Prompto. With AI that is simplified and a UI that is familiar, users don't need to be intimidated to intensively converse with AI. Human-AI interactions can be unserious and enjoyable, like a social media platform, while still utilizing the benefits of intelligent technology. What it does Prompto, an AI generative platform that creates images from a user’s prompt and allows users to swipe left to dislike or right to like a generated image, adapts to curate images more closely aligned with a user’s liking preferences. Inspired by the swipe feature of dating sites like Tinder coupled with AI image tools like Dall E, we created Prompto.\nYou begin by entering a base description for the image you’d like to see, like “show me two cats.” Prompto then generates five images using your input. You select any image of the five closest to your desired vision, and Prompto returns user input more tailored to the image you choose to guide you in making your search more specific. For example, if you selected the top left image, Prompto would return, “a couple of cats sitting on top of a wooden floor, a photorealistic painting by Hanns Katz, international gothic, handsome, symmetrical, dynamic pose,” which you could copy and paste into your next iteration of generating an image, which is a form of simplified prompt injection. How we built it The front-end was built using React Native via Expo. We used Modal Stable Diffusion combined with Replicate's Clip interrogator to create a robust content generation algorithm that dynamically adapts to user preferences through the experience. We used Flask to set up Web API to connect the algorithm and the mobile view. The algorithm and front-end are working independently but the glue is still in developme"
      }
    ]
  },
  {
    "file_path": "./devposts/punctuality.html",
    "project_id": "punctuality",
    "title": "Punctuality",
    "tagline": "Create and fill out quick attendance forms with ease.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "javascript",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Code for CauseWinnerBest for BISV DECA",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/695/068/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Punctuality Built With expo.io javascript react-native Try it out GitHub Repo Submitted to Code for Cause Winner Best for BISV DECA Created by Jerry Y Oliver Ma Ashish Ramanan \"Python\" \"Java\" \"GDscript\" \"Html\" \"CSS\" \"JavaScript\" \"React\" \"React Native\""
      }
    ]
  },
  {
    "file_path": "./devposts/pseudonote.html",
    "project_id": "pseudonote",
    "title": "PseudoNote",
    "tagline": "PseudoNote is a lightweight no frills word-processor where you can take notes reliably, for free, on the go, and at any time.",
    "hackathon": "",
    "built_with": [
      "css",
      "electron",
      "html",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/578/012/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Individual Files in Each Class Creation of Classes Individual Files in Each Class Creation of Classes Individual Files in Each Class 1 2 3 Inspiration We created PseudoNote with the intention of making word-processing software as accessible as possible. So, if anyone ever has a 10-year-old laptop and needs to take notes in class, and Google Docs refuses to load while Microsoft Word is not an affordable option, PseudoNote is there for the rescue. What it does PseudoNote is a compact, no frills word processor. We have kept support for the most essential features of word processors, such as auto-save, italics and bolding, lists, and image support. The most integral attribute of PseudoNote is that it is compact enough to run on the oldest systems, and is designed for quick note-taking when other features are unnecessary. How we built it We built PseudoNote in Electron framework. The languages we used is Node.js, HTML, and CSS. Challenges we ran into As inexperienced programmers, we ran into various technical problems while programming the app. Though we worked into the night, we managed to fix any bugs we encountered. Accomplishments that we're proud of Our team is proud of finishing with an app that fit expectations. We’ve created a simple-to-use, minimalist note-taking app with basic functions according to plan. We also had some fun in making a demo video, the summation of our accomplishment over the past few days of the hackathon. What we learned Throughout the entire process, we acquired a good grasp on the Electron framework, and how the different languages come together in creating the final app. Along the way, we gained some valuable experience in trouble-shooting. What’s next for PseudoNote We see our application supporting more essential features past our minimum viable product, such as document sharing. Our vision for the future of PseudoNote is for our users to feel as if they have no more features to be desired, and PseudoNote is the only note-taking applica"
      }
    ]
  },
  {
    "file_path": "./devposts/push-battle-ujm1ih.html",
    "project_id": "push-battle-ujm1ih",
    "title": "Push Battle",
    "tagline": "Push the Limits: This AI changes the game for ultimate Push Battle domination!",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/144/868/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Inspiration The inspiration for this project stems from the increasing interest in AI-driven game strategies and the exciting challenge of creating intelligent agents capable of competing at an expert level in dynamic environments. Push Battle presents a unique opportunity to test and improve AI techniques by combining elements of strategic decision-making, grid manipulation, and opponent prediction. What it does Push Battle is an AI competition featuring a two-player strategy game played on an 8x8 grid. Players place pieces on the board, pushing adjacent pieces away upon placement. The objective is to align three pieces in a row while navigating time constraints, valid move rules, and opponent strategies. The AI agent aims to make optimal moves to win the game while adapting to the opponent’s tactics and the constraints of the environment. How we built it We developed our AI agent using the provided API and starter code, focusing on optimizing decision-making algorithms. We explored various approaches to enhance the agent’s performance, including Minimax with Alpha-Beta Pruning, Monte Carlo Tree Search (MCTS), and Reinforcement Learning techniques. The AI evaluates the current game state, predicts the outcomes of possible moves, and selects the most strategic action based on both short-term tactics and long-term goals. To address the time limitations imposed by the competition, we implemented a Beam Monte Carlo approach that strikes a balance between exploration and computation time, ensuring decisions are made within the 5-second window. Challenges we ran into One of the primary challenges we faced was optimizing the agent’s decision-making within the tight 5-second time limit for each move. This required us to refine our algorithms for speed without sacrificing strategic depth. We also had to manage the trade-off between heuristic-based methods (fast but less precise) and more computationally expensive methods like MCTS (slower but more strategic). Balancing "
      }
    ]
  },
  {
    "file_path": "./devposts/proxima-1vpwlg.html",
    "project_id": "proxima-1vpwlg",
    "title": "Proxima",
    "tagline": "Your personal diagnosis buddy",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "ipynb",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/620/568/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration We were inspired by medical technologies. We wanted to find a way to provide accessible medical consultations from everywhere. What it does This application uses AI to diagnose the user's medical condition based on their symptoms and vitals. How we built it The UI was built using HTML and CSS. JS was used to add more useful and user-friendly features to the app. Machine learning databases and libraries were incorporated with Flask. Challenges we ran into We found it challenging to work with Flask, and incorporating the ML databases with HTML code. Accomplishments that we're proud of We are very proud of finishing the project. It was a great learning opportunity. What we learned We learned a lot of new Flask and JS feautres. What's next for Proxima We will try to improve the ML part of the project. Built With css html ipynb javascript Try it out GitHub Repo Submitted to XHacks 2021 Created by Worked on the front-end, design, and ML model Sean Wang I worked on the front-end and the UI of the project. Mariya Turetska"
      }
    ]
  },
  {
    "file_path": "./devposts/psyconnect-89wng0.html",
    "project_id": "psyconnect-89wng0",
    "title": "PsyConnect",
    "tagline": "Giving Access to Underrepresented Areas in Indonesia",
    "hackathon": "",
    "built_with": [
      "express.js",
      "javascript",
      "mern",
      "mongodb",
      "node.js",
      "react",
      "sass",
      "tailwind",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Garuda Hacks 3.0WinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/203/960/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "TRACK: Health \n1) How do we educate people on healthy living practices to prevent costly medical interventions in the future?\nOur app is essentially a video call app that connects users from all over Indonesia to therapists in Jakarta. According to the Health track info session, healthcare in Indonesia is unsurprisingly centralized in Java, specifically Jakarta. Mental health in general is an issue that's not addressed enough in Indonesia, so if there's a lack of mental health resources in Jakarta, there's certainly a scarcity of such resources elsewhere in the country. We believe that since a good amount of young Indonesians use their phones or laptops, this app can potentially help open up the mental health conversation across the country. 2) How do we provide health accessibility to ensure people get proper health regardless of location or socioeconomic status?\nThis app is intended to match users anywhere in Indonesia to therapists in Jakarta. We intended to have both a chat and video call feature using Twilio, but due to time constraints, we were only able to deliver video calls on the prototype. However, we do believe that regardless of the user's location, as long as they have internet, if the app is deployed somewhere they are able to connect and talk to a therapist 1:1. 3) How do we raise awareness, create conversations, and effective interventions on mental health?\nEven if one person uses the app, if they're able to connect to a mental health professional, that would certainly help push the user to a better life. The app, PsyConnect, is a mental health resource for anyone in Indonesia, a country where mental health conversations are still not prevalent even in its major cities. PsyConnect democratizes the resource to everyone regardless of their location or socioeconomic status. Inspiration Indonesia is a very centralized country with no exception for healthcare. Most of Indonesia's healthcare workers, centralize in java specifically in Jakarta. Less known "
      }
    ]
  },
  {
    "file_path": "./devposts/puzzle-solver-dk6f3p.html",
    "project_id": "puzzle-solver-dk6f3p",
    "title": "Puzzle Solver",
    "tagline": "Got a scrambled image that is conveniently split into 4 quadrants? We got your back in unscrambling with our half working ML Model!",
    "hackathon": "",
    "built_with": [
      "blood",
      "hint-of-tensorflow",
      "sprinkle-of-python",
      "sweat",
      "tears"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/248/311/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Initial Discovery At the start of our journey, we looked at the scrambled images and thought to ourselves: what if we hard code this? What if we just use our seam carving knowledge from CSCE 121 to solve this challenge? \"Its so easy\" they said. \"We will be done in 30 minutes\" they said. After 3 hours of work just to realize that seam carving is not the way to go as the background got in our way. We were not able to accurately compare the differences between two pixels and make conclusion. We started wracking our brains for other ideas. Lost in the Sauce At this point, we are not yet lost in the sauce. Our next idea was to use ML(yea yea yea, the intended way) to brute force recognize all the correct and incorrect images. For each image we are viewing, we rearrange the images in all 24 permutations and have the model output a confidence level for each of these outputs. Then, from those, the classification model selects the permutation with the highest confidence level as a the predicted image. Sauce is Lost Through this process, there was one part that was massively overlooked. The training and validation data were all combined into one folder, and for each model we cover some number of the images. Though due to the nature of the order of the files, the model was only repeatedly trained on some arrangements and not others. The model thus performs at ~95% accuracy in some arrangements but near 0 in others. After adding some random sampling of the images to the input datasets, we saw significant increases in the total accuracy across all tests. The highest prediction accuracy we received on a completely new testing set was 93.05%. Built With blood hint-of-tensorflow sprinkle-of-python sweat tears Try it out GitHub Repo Submitted to TAMU Datathon 2022 Created by I worked on the convolutional neural network that was able to unscramble the images with  93.5% accuracy. Anish Karthik CS Junior interested in AI Disc: anishfish#5103 Old Devpost Acc: anishfish Eric Yang Naveen"
      }
    ]
  },
  {
    "file_path": "./devposts/public-transport-connect.html",
    "project_id": "public-transport-connect",
    "title": "Travel Surfer",
    "tagline": "Work, Learn and Play on Public Transportation by Actively Evading Limited Internet Connectivity!",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "python",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hackaTUM 2022WinnerCity of Munich",
      "For the first time, we have created an app that (at least) we will use on a daily basis!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/303/866/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "App Overview App Overview App Overview 1 2 Inspiration The inspiration for this project came quite naturally - on our way to hackaTUM, we were chatting on WhatsApp about our ETAs and where we would meet, and of course this happened while some team members were in U-Bahn. When Aaron’s Internet dropped, and he couldn’t send any responses, it was infuriating, because if had he sent the message earlier, we could have arranged meeting up earlier. And it was even more infuriating, because it reminded us of all the many failed down- and upload attempts in the last years of studying at TUM. What it does The app is simple to use - it asks the user for his current station and his destination stop in the Munich public transport network (easily extensible for long distance travel or other cities) and shows the expected mobile data coverage on the given route. Users have the option to either look at the possible timeframes in which they can do different activities on their phone (for example live streaming), or to check out how big of a file they can download on which part of their way. How we built it Using \"Open Data Munich\" we gathered information about the public transportation network in general. Then, we collected real data about network quality all the way across a U-Bahn ride.\nAfter that we used polynomial regression functions to process the data, getting rid of outliers and with this we inferred the general pattern of network connectivity across a ride. We introduced and implemented simple but meaningful use cases to base our UI/UX design on.\nFinally, we coded the app using React Native and deployed it our our mobile phones with expo.io Challenges we ran into A simpler question would be - what challenges didn’t we run into? :D First of all, speed tests take up a lot of mobile data. We had to choose a fitting polling rate so that we don’t use up all of our monthly plans within a few minutes. We found that taking a measurement every 10 seconds (with 20MB of downloaded dat"
      }
    ]
  },
  {
    "file_path": "./devposts/protection-des-droits-de-la-jeunesse.html",
    "project_id": "protection-des-droits-de-la-jeunesse",
    "title": "Protection des droits de la Jeunesse",
    "tagline": "Fermer les yeux serait ignorer le futur de l’humanité.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "html5",
      "keras",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1er prix - 1st Prize Created by Rupeng Dou Rukun Dou Aly Shariff Jakob ",
      "BrébeufHx 5.0 (En ligne - Online)Winner1er prix - 1st Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/838/366/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Un courriel est envoyé lorsque vous votez une pétition. Le droit à la sécurité, la santé et l'éducation est universel. Il n'y a pas d'exception. Carte interactive qui montre les statistiques concernant différents pays. Galleries des pétitions écrits par ceux qui souhaitent contribuer au changement. Menu principal qui présente notre mission, motivation, objectif ainsi que l'enjeu sur la protection des droits des enfants. Formulaire pour la soumission des pétitions. Un courriel est envoyé lorsque vous votez une pétition. Le droit à la sécurité, la santé et l'éducation est universel. Il n'y a pas d'exception. Carte interactive qui montre les statistiques concernant différents pays. Galleries des pétitions écrits par ceux qui souhaitent contribuer au changement. Menu principal qui présente notre mission, motivation, objectif ainsi que l'enjeu sur la protection des droits des enfants. Formulaire pour la soumission des pétitions. Un courriel est envoyé lorsque vous votez une pétition. 1 2 3 4 5 6 7 Nos inspirations Les droits des humains sont absolus et universels. Les enfants ne font pas exception. Peu importe leur origine, leur culture ou leur ethnicité, tous les enfants ont le droit d’être en sécurité, d’aller à l’école, de recevoir une éducation convenable et de vivre heureusement. \nMalheureusement, des millions d’enfants chaque année sont victimes de violence et d’exploitation. Ces différentes formes de violence entravent au développement économique des communautés et des nations. En effet, ces pertes sont estimées mondialement à 7 trillions de dollars par année, soit 8 % du PIB mondial. Sur le plan individuel, le traumatisme psychologique impacte négativement leurs performances académiques et donc leurs avenirs. Les effets se font ressentir après plusieurs générations. \nLe monde est plein d’imperfection. Visons-nous peut-être trop haut ? Le monde égalitaire et juste dont nous rêvons n’est-il qu’un idéal ? Non. Il est certainement possible de faire mieux. Les fonctio"
      }
    ]
  },
  {
    "file_path": "./devposts/put-owb4qj.html",
    "project_id": "put-owb4qj",
    "title": "PUT",
    "tagline": "PUT is a self-hosted file sharing universe that maximizes upload efficiency, reliability, and security, providing the user with the most optimal and convenient client-side experience.",
    "hackathon": "",
    "built_with": [
      "golang",
      "javascript",
      "next.js",
      "python",
      "react",
      "tailwind",
      "terraform",
      "tus"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "3rd Place Prize Created by Araf A Uhhhhhhhhh Idk jeff lu she11fish she11fish Jason Cameron Heya! I'",
      "Hack the Valley 9Winner3rd Place Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/064/791/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our command line tool Our command line tool Our command line tool 1 2 3 4 5 6 Inspiration How many clicks does it take to upload a file to Google Drive? TEN CLICKS. How many clicks does it take for PUT? TWO (that's 1/5th the amount of clicks) . What it does Like the name, PUT is just as clean and concise. PUT is a storage universe designed for maximum upload efficiency, reliability, and security. Users can simply open our Chrome sidebar extension and drag files into it, or just click on any image and tap \"upload\". Our AI algorithm analyzes the file content and organizes files into appropriate folders. Users can easily access, share, and manage their files through our dashboard, chrome extension or CLI. How we built it We the TUS protocol for secure and reliable file uploads, Cloudflare workers for AI content analysis and sorting, React and Next.js for the dashboard and Chrome extension, Python for the back-end, and Terraform allow anyone to deploy the workers and s3 bucket used by the app to their own account. Challenges we ran into TUS. Let's prefix this by saying that one of us spent the first 18 hours of the hackathon on a golang backend then had to throw the code away due to a TUS protocol incompatibility. TUS, Cloudflare's AI suite and Chrome extension development were completely new to us and we've run into many difficulties relating to implementing and combining these technologies. Accomplishments that we're proud of We managed to take 36 hours and craft them into a product that each and every one of us would genuinely use. \nWe actually received 30 downloads of the CLI from people interested in it. What's next for PUT If given more time, we would make our platforms more interactive by utilizing AI and faster client-server communications. Built With golang javascript next.js python react tailwind terraform tus Try it out GitHub Repo GitHub Repo file.jasoncameron.dev Submitted to Hack the Valley 9 Winner 3rd Place Prize Created by Araf A Uhhhhhhhhh Idk jeff lu "
      }
    ]
  },
  {
    "file_path": "./devposts/push-battle.html",
    "project_id": "push-battle",
    "title": "Push Battle",
    "tagline": "Push Battle by PhoCurry",
    "hackathon": "",
    "built_with": [
      "monte",
      "neat",
      "neural",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/129/362/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Win for Blue Inspiration I liked machine learning, and we all wanted to experiment with different algorithms and models, so each of our teammates used a different method of solving the problem. What it does This plays a game of Push Battle, in which the model tries to win against other players by making optimal moves to achieve three pieces in a row. Every time a piece gets put next to another piece, it will push the piece back unless there is another piece behind it. This makes the game full of strategy and thinking ahead. How we built it We used heuristic-based approaches to combine if-else statements to generate solutions and optimal moves to get to 3 pieces in a row while fighting against other players. Challenges we ran into We ran into a lot of challenges getting our different models to work. For one, it was really difficult to get anything to work after training the models. We had a lot of errors with what was happening since the model kept trying to make invalid moves that wouldn't work in the game, leading to a forfeit. Accomplishments that we're proud of We are most proud that we managed to solve the puzzle. It took a lot of learning where we stepped out of our comfort zone and learned many new ideas and concepts we didn't even know existed. Because we got this experience, we got to learn a lot to become better problem solvers and coders. What we learned We learned how to use different models such as NEAT, Monte Carlo, different heuristic-based algorithms, and even neural networks to try to solve the problem. Even though we didn't end up using any of those methods to ultimately solve the challenge, getting through it was extremely fun since we got some new experience with things we don't usually get to work with. Hopefully, the next time we use these programs, it'll be better designed and put together. What's next for Push Battle Hopefully, Push Battle will improve in the future by actually using AI models and algorithms, making it more accurate than our c"
      }
    ]
  },
  {
    "file_path": "./devposts/qlearly.html",
    "project_id": "qlearly",
    "title": "qlearly",
    "tagline": "A QR Code and web-app duo which empowers consumers to make better water choices!",
    "hackathon": "",
    "built_with": [
      "figma",
      "webflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Web App Created by I worked on business research, fine tuning our « about the project » paragr",
      "Develop to Disrupt: World of Devs x CICSWinnerBest Web App",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/651/771/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration 🌎 The term “Global Water Crisis\" is scary and intimidating. From Netflix documentaries to National Geographic articles, the title of our future’s wicked problem is inescapable. Upon our research, we learned that virtual water, the water embodied in the production of products, accounts for 40% of global water consumption due to overproduction. Industries, over individuals, make up the majority of water consumption.  Although feeling powerless, we realized that individuals have the power of choice. Our team plans to disrupt the beverage industry by encouraging consumers to treat each dollar as a vote towards products that do good, and work with businesses towards the future they want to see. Our brand, qlearly , aims to enable the next generation of mindful citizens through web-enabled QR codes found on the drinks of local, water-responsible beverage companies, placing power back in the hands of individuals. What it does 📱 qlearly ’s product is a QR code designed by qlearly and printed onto select beverage containers by partner businesses. Users will buy these drinks, scan the code using their phone camera, and be brought to the qlearly web page where they enter their product number. The website will then show the amount of virtual water contained within the specific product, how that compares to the industry average, and the geographic location from which the water was consumed. This information is obtained through partnerships with the manufacturer and independent research. Next, the user is prompted to donate a percentage of their drink purchase to an initiative that contributes to water conservation or research. Once the user chooses an initiative, qlearly ’s servers will receive a notification that this specific code has been used. The user will be presented with a summary of their donation order and a personalized, exciting tally of how much money they have donated over a lifetime using qlearly . This data can be stored and sent to qlea"
      }
    ]
  },
  {
    "file_path": "./devposts/quantine.html",
    "project_id": "quantine",
    "title": "Quantine",
    "tagline": "Mobile app that helps people organize their stuff during the COVID-19 pandemic",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "express.js",
      "git",
      "heroku",
      "mongodb",
      "mongoose",
      "node.js",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I helped develop the frontend. It was my first time using React Native, and I learned a lot."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration As we can see around the world, many supermarkets are emptied because people are panic buying. Panic buying is a type of herd behavior, most common at disasters such as the COVID-19 pandemic. Our idea is to help people buy only what they need so they don't waste money and don't cause any shortages of essential items and being more organized. What it does Users can have inventories, which contain a set of items, added by the user. When someone creates a new inventory, he/she becomes the owner and has the ability to invite and kick others.When someone joins the owner's inventory, he/she becomes a member. Each user can create up to 2 inventories (to be the owner) and join up to 3 other inventories after getting invitation from other users (to be a member). The member can leave the inventory. Each item has type. The type can be either food and drinks or household products. The item also has the option to upload pictures of it and what amount of the items is in stock, as well as montly consumption amount and its history of the last months. How we built it We decided to make a mobile app that involves using React Native. As we are new to React Native, we used expo cli to make the things quickly. We used MongoDb for building the database, as well as mongoose js for object data modeling. The backend server, containing the REST api and all the bussiness logic is built with node js and express. Challenges we ran into Timezone Challenges Implementation At the frontend, we had some confusion on whether we should use class components or hooks but eventually we settled for hooks as there was a lot of useful hooks that we could use and the code is cleaner in general. We also had some cross platform issues with Android and iOS, with a lot of crashing in Android, and we fixed that by specifying the project to detect all the javascript and typescript files in app.json What we learned We learned to use Expo and React Native as well as integrating both frontend and backend."
      }
    ]
  },
  {
    "file_path": "./devposts/quick-alert-ohvfz1.html",
    "project_id": "quick-alert-ohvfz1",
    "title": "Quick Alert",
    "tagline": "Increasing community involvement by getting rid of the",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "at Aurora Library Hackathon 2020 Aurora Library Hackathon was a in person hackathon that happened i",
      "Won Third Place at Aurora Library Hackathon 2020"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/175/685/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Won Third Place at Aurora Library Hackathon 2020 Aurora Library Hackathon was a in person hackathon that happened in February. Inspiration Many times, there are potholes and graffiti that are unreported because people are driving by them or think it is too much of a hassle to report them. So, we made an app that gets rid of this hassle. What it does Quick Alert uses voice recognition and a Google Map to allow users to report potholes and other community problems while the user is driving. How I built it Android Studios and Google Maps. Try it out GitHub Repo Created by Mihir Kachroo"
      }
    ]
  },
  {
    "file_path": "./devposts/quarters.html",
    "project_id": "quarters",
    "title": "Quarters",
    "tagline": "Quarters make us one, cubes make things whole.",
    "hackathon": "",
    "built_with": [
      "blender",
      "c#",
      "handtracking",
      "meta",
      "mr",
      "photoshop",
      "unity",
      "xr"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Meta Track 2 - 1st Place Created by killian BAILLIF Jiachen Zeng www",
      "XR Creator Con – by immersive insidersWinnerMeta Track 2 - 1st Place",
      "handtracking",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/939/356/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration 3D modeling is hard to learn and the software are not intuitive. In real life, building blocks solution are plenty and fun for everyone: Lego, KAPLA. We all loved them as kids and for some the love never ended. We want to provide an app to let everyone unleash their creativity in 3D. What it does It is a 3D modeling app based on simple colorful cubes. Snap them together, and cube by cube you will be able to build anything! The MR capabilities and the quest 3 allows the user to play / build directly on their table with our virtual blocks. They can take inspiration from their environment thanks to the passthrough.  The app use hand tracking for a more intuitive experience. Colorful cubes with only snapping function - it is a tool for people to create and build, a place to expand imagination and to relax. How we built it The app was made in Unity. 3D assets and texture by Rhino, Blender, and Photoshop.\nIt was made using the Meta quest 3 for testing. Challenges we ran into The app concept might be easy to grasp, but the implementation is way more complex.\nWe had a hard time at first with the placement / snaping algorithm between the blocks. \nWe needed more than we thought, face detection, orientation, grouping, collision checks, ... Accomplishments that we're proud of We are proud of the fluency of the experience interaction, and the simplicity of the visual effect, so as the easy movements that allows everyone to build up 3D objects without difficult technical learning. What we learned We learned to collaborate, communicate constantly and to learn from each other. What's next for Quarters We hope this app can be used by more and more people, and there will be a lot more functions that can be added on in the future. Built With blender c# handtracking meta mr photoshop unity xr Try it out GitHub Repo drive.google.com Submitted to XR Creator Con – by immersive insiders Winner Meta Track 2 - 1st Place Created by killian BAILLIF Jiachen Zeng www.jiax2.com Ji"
      }
    ]
  },
  {
    "file_path": "./devposts/puzzles-ahoy.html",
    "project_id": "puzzles-ahoy",
    "title": "Puzzles Ahoy!",
    "tagline": "Secretly a Promposal",
    "hackathon": "",
    "built_with": [
      "css",
      "javascript",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best solo win! Created by Sean Wang",
      "MetHacks 2023WinnerBest solo win!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/472/859/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Instagram reel: \"When you're wife is an IT professional\" Prom is coming up within a month and a simple text won't do the job What it does Serves as an innocent little application disguised as a prom-posal The purpose is to get the developer who made this a date for his senior high school prom How we built it Puzzles Ahoy! was built with React Native, allowing the app to fully take advantage of the mobility of the cell phone. This prom-posal can be conducted anywhere where there's internet connection Challenges we ran into Coming to the hackathon halfway late from a part-time job I couldn't miss Working solo without a team forcing me to time manage all the tasks on my own Getting distracted by all the peers and hanging out outside Working on a technology I haven't learned before Accomplishments that we're proud of Despite having no team members to relieve the work, arriving with half the time, and starting off with a new technology, I eventually a working functional application that could be used in action this Monday 💪, as well, coming out of this hackathon with 10 hours less sleep, I mean 10 hours of experience on a technology I've never used before. What we learned Despite wasting lots of time socializing with people and hanging out outside, it's easy to forget in a competition to enjoy the process and it's ok to cut a bit of slack sometimes. What's next for Puzzles Ahoy! The \"lines\" could definitely be improved, add more animations, and perhaps have a title screen as well. This can be very well transformed into a real proposal some day who knows ¯_(ツ)_/¯ Built With css javascript react-native Try it out expo.dev Submitted to MetHacks 2023 Winner Best solo win! Created by Sean Wang"
      }
    ]
  },
  {
    "file_path": "./devposts/quadreal-regression-project-cxc.html",
    "project_id": "quadreal-regression-project-cxc",
    "title": "QuadReal Regression Project CxC",
    "tagline": "Using machine learning with PyTorch to predict sensor readings during outages.",
    "hackathon": "",
    "built_with": [
      "collab",
      "cuda",
      "numpy",
      "pandas",
      "pytorch",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "QuadReal Challenge Winners Created by Ben Meaker Jerry Zhu CS @UWaterloo | Retired | Fanatic Organi",
      "CxC Powered by EYWinnerQuadReal Challenge Winners",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration 📡 Our interest was piqued by the QuadReal challenge, as we wanted to explore air quality sensor data and were interested in the IOT sector. What it does 🖥️ Our team Ben and Jerry's built a linear regression model, to predict missing values in the IAQ fields of the dataset, as well as detecting anomalies using anomaly detection methods (ANNs) that can adapt to changes in the data fields. How we built it 🚧 We used Pytorch to train a customized Regression model. We decided on using dropout layers and three hidden layers. For the dataset preprocessing, we decided to use one-hot encoding to treat the features as categorical rather than numerical. We also performed an EDA and tracked results using libraries like pandas, sklearn, numpy, and matplotlib, for visualization and analysis. We used feature engineering to extract relevant features, as well as the regression model to plot and predict any missing values in the dataset before training. We then saved the model for inference, for our validation and test sets (for submission). Challenges we ran into 🚩 We initially had trouble figuring out the best regression model to use (XGBoost and Random Forest regression were ideas that we ended up scrapping), but we ultimately decided on Artifical Neural Network Regression, as it had the most wiggle room for dynamic-ness as well as being customizable and had a good baseline accuracy. Accomplishments that we're proud of 💪 We're proud of being able to preprocess the data, build a model, and get a high accuracy result (with a relatively low epoch count) in a short amount of time! What we learned 🧠 We learned a lot about IoT sensor data, data quality principles, and feature engineering/regression, as we gained a much deeper understanding in ANNs and one hot encoding for conversions between categorical and numerical data. We learned about anomaly detection and using regression for interpolating missing values. What's next for QuadReal Regression Project CxC ➡️ In the near fu"
      }
    ]
  },
  {
    "file_path": "./devposts/queue-t-esseract.html",
    "project_id": "queue-t-esseract",
    "title": "Queue T(esseract)",
    "tagline": "Image to text processor that attempts to preserve the order of messages in a conversation.",
    "hackathon": "",
    "built_with": [
      "python",
      "tesseract",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/248/087/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The CBRE challenge seemed like a good way to create a command line project that would be interesting. It was also a good way to learn more about using python to access the file system. What it does Accesses a user-specified directory and converts each image to text using the tesseract library. Separates each “bubble” into a separate message by analyzing line spacing. How we built it We used Visual Studio Code to allow for everyone to work together on the code and created the code using python. Challenges we ran into At the outset, our program printed an unusual string for each comic analyzed. Troubleshooting revealed that tesseract worked properly outside of the main loop. We discovered that our loop was mistakenly printing the last comic by name alphabetically instead of looping through each comic. Accomplishments that we're proud of Fixing the core loop, properly reading images using an unfamiliar library, and working on some side projects related to data. What we learned We learned how to code as a group and use different techniques to make an image appear as text. What's next for Queue T(esseract) We had a very enjoyable time and learned a lot through coding and doing the challenges for image tracking. Now we plan to use this knowledge to work towards new projects revolving around image tracking. We could create a tool using machine learning libraries to classify objects, bodies of text, or solve relevant problems. Built With python tesseract visual-studio Try it out GitHub Repo Submitted to TAMU Datathon 2022 Created by garshaam Garsha Krish Vora Ryan Kerstetter Will Borchers"
      }
    ]
  },
  {
    "file_path": "./devposts/qunect-four.html",
    "project_id": "qunect-four",
    "title": "Qunect Four",
    "tagline": "Qunect Four allows any four iPhones to be conjoined and form a bigger viewing screen, enhancing the viewing experience for movies, videos, etc. Qunect Four centralizes device control and playback.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "realtimedb",
      "swift",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/431/058/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Star Wars on Qunect Four Star Wars on Qunect Four Star Wars on Qunect Four 1 2 Inspiration We came up with the idea for Qunect Four while on our 3 hour drive from College Station to San Antonio. While strolling down Hwy 21, we were discussing unconventional uses for mobile devices and the idea that we could combine multiple mobile devices to form one mega device intrigued us. So, we set out on a journey to create a mobile application that allows users to watch a movie across four devices, with each device playing a specific frame to create a much bigger \"TV-like\" contraption. What it does Qunect Four allows any four iOS devices (so not only iPhones) to connect to a movie \"room\" in order to play that movie in a much bigger frame. Users place their devices next to each other in grid-like fashion and the app syncs playback, allowing for a pleasant viewing experience. How we built it Qunect Four was built in Xcode using Swift for OS development. It also relies on Firebase's Realtime Database to synchronize playback. Challenges we ran into Figuring out how to synchronize playback was a big challenge as we did not want users to have to manually start playback. Instead, we opted to have one master user that controls playback for all devices. We also struggled initially with technological difficulties as some devices were not responding well to the database. Accomplishments that we're proud of We are proud of the fact that we were able to get Qunect Four up and running on four devices and actually synchronize media between these four devices. What we learned We learned that unconventional uses of mobile devices can lead to some pretty cool outcomes. Qunect Four is just one example of how thinking outside of the box can lead to new innovations. What's next for Qunect Four Because Qunect Four seemed like such an exciting idea, we plan to continue pursuing Qunect Four after this hackathon and hope to get it published as an app on the App Store in the near future. Built With fi"
      }
    ]
  },
  {
    "file_path": "./devposts/quikserve.html",
    "project_id": "quikserve",
    "title": "QuikServe",
    "tagline": "Eat the Food, not the Time 👨‍🍳🍖",
    "hackathon": "",
    "built_with": [
      "assemblyai-api",
      "docker",
      "express.js",
      "firebase",
      "gcp",
      "ipfs",
      "javascript",
      "jina-ai",
      "mapbox",
      "react",
      "svm",
      "tailwind",
      "talwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack Using Jina AI hackUMBC Fall 2021 Winner Best Financial Hack | Capital One Created by Pratyay B",
      "Jina AI - Best Hack Using Jina AI hackUMBC Fall 2021 Winner Best Financial Hack | Capital One Creat",
      "VolHacks VWinnerJina AI - Best Hack Using Jina AI",
      "First and foremost, it is Crafted with 💙.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/722/045/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 Inspiration 💡 The COVID-19 pandemic imposed severe in-restaurant dining restrictions that deleteriously affected the restaurant industry. According to industry experts, there has been a bloodbath in the industry because of Covid-19 curbs. A Survey estimates that nearly 40% of restaurants have shut shops globally & because of the same many waiters, butlers lost their source of income. But now, things have started changing as people are getting vaccinated, the traffic in restaurants & cafes has started to increase. Although strict hygienic rules have been foisted, citizens are concerned about catching the Covid-19 infection in restaurants and cafes as they are frequented by a variety of people. And as things begin to move back to normal, because of that traffic it becomes very hectic for the workers such as waiters to provide the necessary priority towards their customers & this is a massive reason why Restaurants lose their customers. As they say, Patience is the key, but not everyone owns it. We believe that with the power of AI, this can be solved if we proceed creatively. Thus we made QuikServe ! What it does 🤔 Transcribing process of order Saving the audio files securely Meals Identification from Notes Recognize the prices from the photo of a bill Allows waiter to directly process payment with the option of splitting the bill QuikServe is a PWA which has been specially curated for waiters so that customers can spend more time eating their food, rather than eating their time! We simplify the current approaches that are undertaken in most of the restaurants starting from taking the order till the checkout. Different technologies have been leveraged while building the application. How we built it 🏗 First and foremost, it is Crafted with 💙. Our fully-working web-app is primarily built with React.js using Tailwind CSS . We used Firebase for OAuth. Inside the app, we have different sections each registered for doing specific operations. For the first inst"
      }
    ]
  },
  {
    "file_path": "./devposts/quickdraw-r1x4o3.html",
    "project_id": "quickdraw-r1x4o3",
    "title": "Bad Copy",
    "tagline": "A drawing game where players 1v1 to replicate a picture on a virtual whiteboard, judged by AI",
    "hackathon": "",
    "built_with": [
      "flask",
      "pillow",
      "python",
      "react",
      "scipy",
      "socket.io",
      "tailwind",
      "tensorflow",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/344/986/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Example win Home page Game start Play again Example win Home page Game start Play again Example win 1 2 3 4 5 Inspiration This game was inspired from the scribble.io which is an online version of pictionary. What it does Users can start a game which will allow them to compete against their friend or someone else. They’re able to replay the game as much as they want. They'll have 30 seconds to replicate an image shown on screen by using a virtual white board. How we built it We built Bad Copy using React, Vite, TypeScript, and Tailwind for the frontend and Python, Flask, and Tensorflow for the backend. The backend uses a custom image similarity calculation algorithm using a pre-trained tensorflow model, imagenet, to calculate how similar a user's sketch is to the actual reference drawing. Challenges we ran into Creating the image similarity algorithm was hard as images that had more texture produced a lot of noise. We fixed this by adding noise filters. Accomplishments that we're proud of We were able to create a working similarity comparator between two images and a working full-stack app given the short amount of time (we thought of the idea at 5pm on Saturday). What we learned How to use Tensorflow and how to make an image similarity algorithm. What's next for Bad Copy Better similarity calculation Multiple players Global leaderboard More customization (custom timers, style of reference images, etc.) Built With flask pillow python react scipy socket.io tailwind tensorflow typescript vite Try it out bad-copy.vercel.app GitHub Repo Submitted to BearHacks 2025 Created by Sho Adachi Ryan Xing First Year Computer Science Student Jaden Park uoft eng '28"
      }
    ]
  },
  {
    "file_path": "./devposts/r-u-safe.html",
    "project_id": "r-u-safe",
    "title": "R U Safe?",
    "tagline": "Safe Surfing, Simplified ✔️🛡️",
    "hackathon": "",
    "built_with": [
      "css3",
      "dcp",
      "github",
      "html5",
      "javascript",
      "sublime-text",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Google Cloud Winner Best Application of DCP API 1st Place Created by Tasfiq Jasimuddin 3rd y",
      "Mini Win: Most Engaging Demo Video Winner Best Use of Google Cloud Winner Best Application of DCP A",
      "RU Hacks 2022: DigitalWinnerMini Win: Most Engaging Demo VideoWinnerBest Use of Google CloudWinnerBest Application of DCP API 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/926/394/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Bongo Hacks GIF GIF Bongo Hacks GIF GIF Bongo Hacks GIF 1 2 3 4 Inspiration 💡 The advent of online education due to recent events has made it the new norm. Upsurge in the use of collaboration tools e.g., Google Meet eventually substituting business meetings, educational classrooms, and all sorts of social interactions has been noted. But just like a double-faced coin, with the increase of shared technology usage for good, there has also been a surge of cybercrimes during this pandemic. \nSurveys state that, alone in the US, digital fraud attempts in 2020-21 have increased by 37.24% . Bad for us that we're now getting used to a new digital world to open a link sent by someone else without knowing if its contents are malicious or not. In addition, it is estimated that cybercrime alone costs businesses worldwide $1.8 million per minute , and phishing amounts to the largest portion. However, applications of AI technology from various platforms can detect malicious links to save the business approximately $9 for each detection. We decided to make let you know whether R U Safe by keeping users safe without needing to spend energy checking if a link is safe or not. What it does 🤔 The R U Safe Chrome extension ensures that users can surf the web without needing to worry about links to malicious websites. The extension immediately terminates any tab that leads to a malicious website. By analyzing links using a Machine Learning algorithm trained with Google’s Tensorflow software library, R U Safe is able to reliably detect malicious websites. How we built it ⚙️ For the Chrome extension, it uses front-end HTML, CSS, and JS, which also connects to the list of untrusted sites (hosted on a Heroku app). This list of untrusted sites is regularly updated using the ML model using Tensorflow in Python. This implies the extension will automatically evaluate all links before navigating to them. The DCP API is used to optimize the response speed of the chrome extension. It lets us per"
      }
    ]
  },
  {
    "file_path": "./devposts/quiknotez.html",
    "project_id": "quiknotez",
    "title": "QuikNotez",
    "tagline": "Note editor incorporated with AI not to REPLACE you but to ASSIST you. Try it out at https://quiknotez.netlify.app. Or View the code at https://github.com/edufaus/BayAreaHackathon-Solo-Project-",
    "hackathon": "",
    "built_with": [
      "bulma",
      "firebase",
      "gpt3",
      "openai",
      "quilljs",
      "svelte",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "in Popular Choice Winner Created by I did everything Eduard Faus Passionate developer who also love",
      "Best in Popular Choice Winner Created by I did everything Eduard Faus Passionate developer who also",
      "Bay Area HacksWinnerBest in Popular Choice Winner",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/393/778/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "QuikNotez QuikNotez QuikNotez 1 2 Welcome to QuikNotez! 🎉🎉🎉 Hey there! Thanks for checking out my project! What we have here is a QuikNotez 🔥🔥🔥 Functions ⚒️ You can write notes with a modern google docs like text editor You can click ALT to auto complete your notes 🔥 NoteGPT will answer questions about your notes and manipulate your notes ! You can also turn your notes into Flashcardss You can also listen to Lofi Music What I used ⚙️ I used the following functionalities to develop our project- Svelte Open AI JavaScript HTML Tailwind CSS, Bulma CSS, and Daisy UI Google Firebase Quill JS How it works ⚙️ I used firebase auth to make accounts and log in The users info and notes are stored in firestore I use GPT3 to autocomplete the notes when you click ALT Using a cool prompt to generate json I made NoteGPT Work The Lofi Music is just Stolen cough. cough. I mean Borrowed from Freecodecamp Things I would change in the future 🧐 Make my Firebase and Open AI credentials be private and as enviorment values ( I was too lazy ) Improve Flashcards option Add collaboration Built With bulma firebase gpt3 openai quilljs svelte tailwind Try it out quiknotez.netlify.app GitHub Repo Submitted to Bay Area Hacks Winner Best in Popular Choice Winner Created by I did everything Eduard Faus Passionate developer who also loves business"
      }
    ]
  },
  {
    "file_path": "./devposts/ragebot-k4l6p7.html",
    "project_id": "ragebot-k4l6p7",
    "title": "RageBot",
    "tagline": "A real-time desktop application that uses live audio transcription and Gemini AI API to generate provocative and manipulative responses using classic ragebaiting tactics and logical fallacies.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "pyaudio",
      "pyside6",
      "pyttsx3",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration After watching a tiktok about speedrunning 10 logical fallacies in an argument against my girlfriend, we were enchanted. We wanted to make a hackathon project that allows everybody to ragebait with maximal effectiveness and minimal effort. What it does RageBot's core functionality is an AI-powered conversation assistant that creates emotionally engaging interactions using psychological manipulation techniques and logical fallacies. How we built it Detailed technical architecture breakdown covering: Frontend with PySide6 and custom styling Real-time audio processing with PyAudio Speech recognition with OpenAI Whisper AI generation with Google Gemini API Text-to-speech with pyttsx3 Multi-threaded architecture Challenges we ran into Real technical challenges encountered: PyQt6 DLL compatibility issues --> switched to PySide6 Real-time audio processing optimization TTS voice quality across platforms UI responsiveness during heavy processing API integration and rate limiting Cross-platform compatibility Psychological prompt engineering for the most rage enducing responses Accomplishments that we're proud of Key achievements: Seamless real-time experience Advanced psychological manipulation implementation Smart audio management system Cross-platform TTS with natural speech What we learned Real-time audio processing techniques Prompt design for LLM rage response Python multithreading What's next for RageBot Voice recognition for continuous conversation Rage hints for user with logical fallacy suggestions Better TTS library for more realistic conversation Built With gemini pyaudio pyside6 pyttsx3 whisper Try it out GitHub Repo Submitted to SpurHacks Created by Allen Lian Julian BK Oliad-R Rundassa"
      }
    ]
  },
  {
    "file_path": "./devposts/questioncraft.html",
    "project_id": "questioncraft",
    "title": "QuestionCraft",
    "tagline": "Generate questions, to help with your quizzes!",
    "hackathon": "",
    "built_with": [
      "flask",
      "hugging-face",
      "kaggle",
      "langchain",
      "ngrok",
      "redis",
      "scss",
      "tavily"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/801/695/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Loading Screen Homepage Generated Question Question Template Answer Output Loading Screen Homepage Generated Question Question Template Answer Output Loading Screen 1 2 3 4 5 6 Inspiration Whenever we always wanted to do more questions to prepare for a test, outside of what the teacher assigned, there weren’t good online resources. A lot of our friends and other students experienced this problem, so we set out to solve it using AI. What it does Our App, QuestionCraft allows users to generate multiple choice questions with 4 answers, along with the topic. The model will take all of this data, and give a question similar in style, difficulty and topic to the question provided. How we built it We used an HTML/JS/CSS frontend along with SCSS to make the website look nicer and more AI-based. We used Redis to store user information, and the ngrok link where the ML model backend was. We used Vercel to deploy both of these services. On the ML side, we used the LLAMA-213B model from HuggingFace to do our ML processing. We decided to go with kaggle to host our model, and used Tavily to give our model up to date accurate information on the questions it generated. Challenges we ran into The first challenge we ran into was the model. We wanted to use the GPT API, but none of us had the free credit, so we decided to use open source models. The next problem we had was the inference time, as the model was very slow, so we decided to use Langchain to speed up inference time using LLM chains. Finally, we encountered the problem that Kaggle didn’t allow SSH access, so hosting our model would be a challenge. We tried a multitude of cloud services, but in the end had to use Kaggle. Accomplishments that we're proud of We are proud of being able to create a decent fullstack AI app, complete with a good frontend, backend and ML infrastructure for our app. It took a lot of work to get there, and in the end we’re really happy with being able to experiment with stylings and open source models"
      }
    ]
  },
  {
    "file_path": "./devposts/rabbit.html",
    "project_id": "rabbit",
    "title": "Rabbit Browser",
    "tagline": "A new recursive AI browser that helps generate users' deep body of knowledge while minimizing AI hallucination: completely changing how you normally search the web and ask questions.",
    "hackathon": "",
    "built_with": [
      "electron",
      "express.js",
      "gemini",
      "reactflow",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/763/026/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our Main Menu An example of a web of knowledge Our Main Menu An example of a web of knowledge Our Main Menu 1 2 3 Inspiration The inspiration for Rabbit stems from persistent frustrations with existing search experiences, particularly when using platforms such as GPT or Google Search. These widely used tools frequently generate unsubstantiated information, often lack reliable citations, and tend to present results in a way that feels rigid and disconnected. This makes it especially difficult for users who want to connect ideas quickly or thoroughly explore complex subjects. Wanting a better solution, the team set out to create a system that would make it much easier to build a flexible web of knowledge. By enabling users to rapidly jump between sources and visually map out relationships, Rabbit is designed to foster curiosity and make search and knowledge discovery both interactive and engaging. What it does Rabbit is an AI-powered browser built to address key weaknesses in current web and AI search tools. Its core purpose is to minimize hallucinations, streamline web search workflows, and develop persistent user context to clarify or expand upon the sometimes confusing answers generated by AI. Users can rapidly move (\"hop\") through sources and selectively choose which Gemini results to incorporate into their answer. As users research, a knowledge node graph grows and changes to reflect their evolving understanding. At any point, a user can dig more deeply (\"burrow\") into a particular part of their original question, expanding the knowledge node graph and uncovering new connections. This approach allows Rabbit to replicate and enhance the process of going down an information rabbit hole, ultimately helping users build a much broader and more interconnected body of knowledge. How we built it The Rabbit project uses a modular architecture designed for speed, flexibility, and experimentation. The backend server was built with TypeScript and implemented all essential sy"
      }
    ]
  },
  {
    "file_path": "./devposts/quiz-craft.html",
    "project_id": "quiz-craft",
    "title": "Quiz-Craft",
    "tagline": "Learn and Practice with Quiz-Craft.",
    "hackathon": "",
    "built_with": [
      "css3",
      "github",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/876/905/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "reasons for answers log-in sign-up start page quiz result reasons for answers log-in sign-up start page quiz result reasons for answers 1 2 3 4 5 6 💡 Inspiration while preparing for interviews quiz is a fun way for learning and practicing ⚙ What it does a fun interview quiz that will help you to get better with your answers and will help you explain those answers with ease 🔧 How we built it By using HTML, CSS and java script 💪 Challenges we ran into As a new comer and a student in high school lack of experience was the major challenge I faced 📌 Accomplishments that we're proud of I got better at javascript 📚 What we learned many new things about coding and environment ⏭ What's next for Quiz-Craft expanding it knowledge and making it more ease to use and provide more important questions with reasons Built With css3 github html5 javascript Try it out GitHub Repo Submitted to Power Up Hacks Created by Gourav Sharma I like to code"
      }
    ]
  },
  {
    "file_path": "./devposts/race-in-space.html",
    "project_id": "race-in-space",
    "title": "Race in Space",
    "tagline": "A Flying Game",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our group's mutual interest in learning Unity. We also found a great tutorial which helped us a lot. We treated this as more of a learning experience due to our lack of experience and our inability to complete our previous ideas. What it does It is a flying game in which you move the ship around the screen to avoid hitting into the mountains. How we built it We followed a tutorial and used our basic knowledge of Unity to create our game. Also we used assets that were provided online. Challenges we ran into We only decided on doing this project once we had already tried to get our previous ideas to work which left us with very little time left and very little options when it came to what we can do. Accomplishments that we're proud of We are happy that we actually did learn some new features in unity like terrains. This was one of our groups goals at this hackathon. Unfortunately that about covers our accomplishments because we were unable to do a lot of what we had originally thought of doing. What we learned We have learnt the difficulties of using VR or AR or any hardware in Unity. It was impossible to figure them out and get them to work in a short time period of 24 hours. We learnt the importance of using what you know and that if we want to use any special hardware like VR or AR then we will need some experience outside of the hackathon to be able to at least get it working. We also learnt how to use terrain in Unity which seems useful and something we plan on learning more about. What's next for Race in Space Built With c# unity Try it out GitHub Repo Submitted to McHacks 7 Created by Raiyan Sayeed Amman Waheed Krzysztof Oleksiak"
      }
    ]
  },
  {
    "file_path": "./devposts/re-food.html",
    "project_id": "re-food",
    "title": "re-food",
    "tagline": "An innovative, easy, and low-cost solution to a pressing global problem--food waste.",
    "hackathon": "",
    "built_with": [
      "chatgpt",
      "javascript",
      "node.js",
      "react",
      "stablediffusion"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/461/738/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration A few days before we went to LA Hacks, we needed to throw out a bunch of rotten foods, and on the car ride down from Santa Barbara, we were inspired to make an app to limit such food waste as much as possible. What it does Our app takes different foods as an input and outputs a recipe! This is meant to help with people who have leftovers in the fridge from making another dish or are faced with ingredients they don't normally cook with! How we built it We built this app using mainly React, ChatGPT, and stable diffusion. Challenges we ran into None of us had much front-end experience prior to this hackathon. Accomplishments that we're proud of We were proud of our excellent teamwork and ability to finish a high quality prototype in a short time period. We were also proud of deciding to take a gamble with React since none of us had much experience with it before, and we're glad it turned out well! What we learned We all definitely developed out React expertise as well as familiarity with the ChatGPT API and stable diffusion concepts. What's next for re-food Mobile expansion! We're definitely looking to make our app more accessible and easier to use in the future through adapting our web app to a mobile application. Built With chatgpt javascript node.js react stablediffusion Submitted to LA Hacks 2023 Created by I worked on the backend, working both on the connection between the front end and the backend and setting up and querying ML models. Ryan He Anthony Jin Guy Wilks David Wang"
      }
    ]
  },
  {
    "file_path": "./devposts/rainbow-s-beginning.html",
    "project_id": "rainbow-s-beginning",
    "title": "Rainbow | Seamless Mixed Reality Begins Here",
    "tagline": "Rainbow organizes virtual information for real space through shareable mixed reality layers.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c#",
      "mapbox",
      "meta",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/546/715/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Mixed Reality Network Diagram Circuit diagram for IOT with Arduino Logo Mixed Reality Network Diagram Circuit diagram for IOT with Arduino Logo 1 2 3 4 Inspiration We already live in augmented reality. But the user experience is sorely lacking. In order to access information or connect with others virtually, we rely on smartphones, hiding behind our screens and disconnecting from the real world. We believe that accessing virtual information should be effortless, allowing us to interact naturally with the world around us. As A/R technology improves, this reality is moving closer and closer. But how might we ensure that today's information overload doesn't pollute our physical reality? How do we maintain what is true and what is real in a landscape of ubiquitous digital augmentation? To begin to answer these questions we created Rainbow, a design pattern for shareable mixed reality. What it does Rainbow is an A/R solution for organizing virtual information in real spaces. By collecting digital content into layers, Rainbow helps users navigate between several different augmented experiences for one location. User Scenario If Ben needed to get to the T Station today, he’d have to take out his phone, find the right app, get directions, and keeps his nose pressed to the screen while mentally navigating between the image on his phone and world around him. He’d have to switch apps to check the train schedule or see if there might be a better transit option.\nBut with Rainbow, Ben could simply turn on the City Layer published by the municipal government, containing all the transit and tourist information he would need to navigate the space. This information would sync up with actual landmarks and transit hubs, providing a contextual navigation experience that makes sense. If he needed to interact with other information around him, he could easily switch the layer in his A/R headset. What is layerable reality? Layers of mixed and augmented reality that can be programmed s"
      }
    ]
  },
  {
    "file_path": "./devposts/raveon.html",
    "project_id": "raveon",
    "title": "RaveOn",
    "tagline": "It's like Tinder, but instead of people, you swipe for music!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/023/454/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration 💜 For my spontaneous music lovers out there, have you ever wanted to create the ultimate list of rave songs? Like most ideas, this one was born from the desire to make discovering music a more adventurous process, and allow friends to make the most hype playlist for a party- only, its randomly generated. What it does 🌍 The platform will automatically generate a random song off the internet, allow the user to listen to it, skip to another song (swipe left), or favourite the song (swipe right)! All of the songs would then be added to a “Liked” section on the website. How we built it ⚙️ The website was primarily built using React (react-router-dom), Javascript, HTML, CSS and several React wrapper components such as React-audio-player. Challenges we ran into 😖 The biggest challenge we ran into was figuring out how to get the songs and files to be displayed on the website. After a plethora of errors and quite a few hours spent on Stack, I realized several issues relating to my original plan. Additionally, the idea kept evolving throughout the process of the project, making it heavily research-based overall. For instance, I was originally planning on using the Spotify API, but it ended up not being compatible with my idea, and many of the terminologies were far too advanced. Accomplishments that we're proud of 😁 I am most definitely proud of being able to make a fully functional and interactive platform! Given that there were several external factors that prevented me from working on it during the majority of the weekend, I am proud that I was able to pull through with my idea! As usual, I am also proud of the new learnings that I gained from doing this project, especially being solo. What we learned 📚 Throughout this project, I really intended on solidifying my knowledge relating to the languages and components that I used- on top of the extra practice, I also learnt about incorporating audio and videos into my platform, something that I hadn’t explor"
      }
    ]
  },
  {
    "file_path": "./devposts/raja-ai.html",
    "project_id": "raja-ai",
    "title": "Raja AI",
    "tagline": "Raja understands tickets, crafts code, and submits pull requests in minutes.",
    "hackathon": "",
    "built_with": [
      "clerk",
      "convex",
      "github",
      "langchain",
      "netlify",
      "openai",
      "pinecone"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/521/772/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Raja generated Code Raja Architecture Raja Dashboard Clerk Auth Raja generated PR Raja generated Code Raja Architecture Raja Dashboard Clerk Auth Raja generated PR Raja generated Code 1 2 3 4 5 6 Raja AI Your newest team member for your software engineering project - fast, reliable and cost-efficient. Inspiration With the advancement of LLMs in recent years, developers have been reaping benefits through their use in code generation. Tools like GitHub Copilot and StarCoder have already demonstrated efficiency and productivity boosts in day-to-day coding tasks. In this light, we identified an unmet need to extend these AI capabilities beyond mere code predictions. We were driven to explore how these code-generating LLMs could be transformed into individual contributors within development teams, especially when they are now more powerful and nuanced in understanding context, ensuring that the time is ripe for such an innovation. What it does Raja AI serves as a sophisticated code assistant that utilizes deep understanding of your entire codebase. It interprets engineering tickets, encompassing detailed elements such as reproduction steps, acceptance criteria, error descriptions, or feature outlines. Leveraging this information, Raja AI generates relevant code and proactively submits a pull request, ready for human review and approval. How we built it Our tech stack uses Tailwind CSS and Next.JS on the front-end, with Flask, Langchain, Pinecone, OpenAI, Convex, and Clerk on the back-end, all deployed through Netlify. We store vector embeddings of the codebase in Pinecone, which lets us accurately identify code changes needed based on ticket details using a self-query retriever. For meaningful code changes, we use Langchain and chain of thought prompting techniques, leveraging the OpenAI GPT-3.5 Turbo Model with a 16k Context Window to preserve the context of file contents. We've built a custom API with Flask to call the Raja agent. Clerk manages user authentication and "
      }
    ]
  },
  {
    "file_path": "./devposts/raja.html",
    "project_id": "raja",
    "title": "Raja AI",
    "tagline": "Automate tickets to pull requests in minutes.",
    "hackathon": "",
    "built_with": [
      "ghapi",
      "javascript",
      "langchain",
      "pinecone",
      "python",
      "react",
      "trello-api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/510/840/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "User can merge in the PR or ask Raja to make further modifications Create a bug ticket on Trello Assign Raja to fix the bug Raja fixes error and creates a PR Raja reviews the PR User can merge in the PR or ask Raja to make further modifications Create a bug ticket on Trello Assign Raja to fix the bug Raja fixes error and creates a PR Raja reviews the PR User can merge in the PR or ask Raja to make further modifications 1 2 3 4 5 6 Inspiration “If you're busy at work, odds are you will eventually be replaced by a robot” - Nicholas Nassim Taleb. Observing that up to 50% of a software engineer's tasks consist of working through backlogs, fixing pesky bugs and performing chores, we realized there's a vast potential for code generation models to intervene and reshape the labor dynamics within software engineering teams. Raja was conceived as an agent to tackle this backlog, automating a significant share of routine tickets that traditionally consumed much of an engineer's time. By shouldering this burden, Raja allows engineers to devote more of their attention to high-level tasks, where their expertise can make a profound difference. For medium to large software engineering teams, Raja is the engineering manager’s wet dream that reduces turnaround time for tickets, accelerates development sprints and ultimately, reduces developer cost. Rather than displacing human labor, this AI-human collaboration redefines it, enabling software engineering to be more productive, efficient, and cost-effective. Raja represents an exciting step towards a future where AI and human capabilities complement each other in harmony, enhancing the software engineering process. What it does Raja is an AI-powered agent that transforms your Trello tickets into ready-to-review pull requests, functioning like your dedicated Junior Developer. Swiftly deciphering ticket requirements, Raja navigates your entire Git repository to generate and submit a pull request within minutes. This seamless automation "
      }
    ]
  },
  {
    "file_path": "./devposts/recall-ucjf8l.html",
    "project_id": "recall-ucjf8l",
    "title": "ReCall",
    "tagline": "Ever tried to look for a website but can't quite remember its name? ReCall allows users to look through their search history using keywords and descriptions. Never lose a webpage again!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "gemini",
      "graphrag",
      "indexeddb",
      "plasmo",
      "rag",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/330/572/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "History search feature ReCall new tab and history graph view Popup settings page History search feature ReCall new tab and history graph view Popup settings page History search feature 1 2 3 4 Inspiration The inspiration behind ReCall came from an incident when one of our group members could not find a website in his browser history. He was able to describe the website, and its content, and could come up with relevant keywords, but could not remember the exact website link. With the normal search function, he was unable to find the website in his browser history. This inspired us to come up with ReCall, which lets you search for websites in your history by conversing with an agent, alongside a graph view showing related websites in your history. What it does ReCall uses a Retrieval-Augmented Generation (RAG) system integrated with a Large Language Model (LLM) to help users quickly locate previously visited websites. Unlike the standard browsing history feature in Google Chrome, ReCall enables users to search their history by inputting specific keywords or descriptions about past sites. Webpage data and metadata are stored as vector embeddings using the IndexedDB. When users perform a query, Cohere's Rerank is utilized to retrieve and rank relevant pages based on semantic similarity. Finally, Google Gemini serves as the conversational LLM, presenting users with ranked results through an intuitive chatbot interface. How we built it We built ReCall as a Chrome extension using Plasmo's framework alongside React and Tailwind CSS, developing a responsive, user-friendly interface. The backend utilizes IndexedDB to store webpage content in the form of vector embeddings, enabling an efficient semantic search through these processes: Dynamic Content Processing\nWe used Typescript to build background workers that analyze and classify webpages in real time so that when a user visits a site, the system extracts keywords, summarizes content, and checks against user-defined prefere"
      }
    ]
  },
  {
    "file_path": "./devposts/raidology.html",
    "project_id": "raidology",
    "title": "RAIdology",
    "tagline": "Simplifying radiology, one conversation at a time",
    "hackathon": "",
    "built_with": [
      "bytescale",
      "gpt",
      "javascript",
      "minigpt-4",
      "python",
      "qlora",
      "t3",
      "tailwind",
      "typescript",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/571/846/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Verbwire Verbwire 1 2 3 4 5 6 7 RAIdology Inspiration 80 million CT scans are performed every year in the US according to Harvard Medical School. With CT scan appointments taking up to 1hr and 30 minutes , that's 120 million Physician Hours spent on scans. Given the average Radiology Physician makes $217 per hour, which means that's 26.04 Billion USD spent every year on CT scan. With healthcare getting more expensive and more backlogged with physicians increasingly experiencing burn out, our team has come together with an exciting vision to streamline the process by developing an AI-driven radiology assistant. As we began our discussions, we explored several innovative ideas, including wildfire prevention, text-to-movie conversions, and AI ultrasound detection. After a few deliberations, we felt most inclined toward the AI ultrasound detection concept. Objective: The project is intended to serve as an AI-powered radiology assistant that analyzes ultrasound images to provide insights. The primary goal is to \"replace\" the need for a doctor to interpret ultrasounds, offering a first-line analysis and guiding users to a doctor if there are any serious issues. However, the emphasis is on recognizing and providing insights about the ultrasound images, particularly focusing on the health of the baby and parent. We want to promote social equity and inclusion by providing accessible care for any users that want a deep understanding of their ultrasound or radiology images broken down. By creating this app, anyone can upload their radiology photos, and \"replace\" the need to spend a high cost asking the doctor to explain a radiology scan, with even that possibly being more cryptic than our app. General Flow Users are introduced via a landing page and directed to a Voiceflow interface.\nUsers then upload ultrasound images.\nAn AI model, which we are actively developing, will then analyze these ultrasound images.\nInsights drawn from the images will be processed and presented throug"
      }
    ]
  },
  {
    "file_path": "./devposts/rainbow-cross.html",
    "project_id": "rainbow-cross",
    "title": "Rainbow Cross",
    "tagline": "BruinWalk for Hospitals&Doctors aimed at QWER community",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "html",
      "javascript",
      "mongodb",
      "node.js",
      "pandas",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Finish soon... What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Rainbow Cross Github https://github.com/SruthiR03/qwer_hacks Built With css express.js html javascript mongodb node.js pandas python react Try it out GitHub Repo Submitted to QWER Hacks 2023 Created by Sreya Muppalla Arathi Nair Anagha Srivatsav Sruthi Rangarajan"
      }
    ]
  },
  {
    "file_path": "./devposts/readright-q5exuz.html",
    "project_id": "readright-q5exuz",
    "title": "ReadRight",
    "tagline": "1 in 10 people in the world have Dyslexia. Similar to Duolingo, ReadRight through AI and ML, reads out prompts to users and processes their voice allowing them to learn a new language with ease.",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "firebase",
      "google-cloud",
      "html",
      "javascript",
      "llm",
      "machine-learning",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the 6ix: Third Place Created by Worked on the frontend with react with chakraui, created the e",
      "Hack the 6ix 2023WinnerHack the 6ix: Third Place",
      "Secondly, we struggled with the generation of prompts for the user to repeat and using AI to implement that.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/565/903/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration We wanted to tackle a problem that impacts a large demographic of people. After research, we learned that 1 in 10 people suffer from dyslexia and 5-20% of people suffer from dysgraphia. These neurological disorders go undiagnosed or misdiagnosed often leading to these individuals constantly struggling to read and write which is an integral part of your education. With such learning disabilities, learning a new language would be quite frustrating and filled with struggles. Thus, we decided to create an application like Duolingo that helps make the learning process easier and more catered toward individuals. What it does ReadRight offers interactive language lessons but with a unique twist. It reads out the prompt to the user as opposed to it being displayed on the screen for the user to read themselves and process. Then once the user repeats the word or phrase, the application processes their pronunciation with the use of AI and gives them a score for their accuracy. This way individuals with reading and writing disabilities can still hone their skills in a new language. How we built it We built the frontend UI using React, Javascript, HTML and CSS. For the Backend, we used Node.js and Express.js. We made use of Google Cloud's speech-to-text API. We also utilized Cohere's API to generate text using their LLM. Finally, for user authentication, we made use of Firebase. Challenges we faced + What we learned When you first open our web app, our homepage consists of a lot of information on our app and our target audience. From there the user needs to log in to their account. User authentication is where we faced our first major challenge. Third-party integration took us significant time to test and debug. Secondly, we struggled with the generation of prompts for the user to repeat and using AI to implement that. Accomplishments that we're proud of This was the first time for many of our members to be integrating AI into an application that we are devel"
      }
    ]
  },
  {
    "file_path": "./devposts/ready-o128ul.html",
    "project_id": "ready-o128ul",
    "title": "Ready",
    "tagline": "A platform aimed to make illiteracy a thing of the past.",
    "hackathon": "",
    "built_with": [
      "alan-ai",
      "css",
      "html",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/017/176/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration 💜 Are you able to read this? Well, count yourself lucky because there are still 781 million illiterate adults globally, who wouldn’t be able to. English is the most-spoken language worldwide, and there’s a significant lack of access to education. This is how the idea of Ready was invented. For those who are just starting to learn English as a second (or third, or fourth!) language, or for children who are looking to improve their communication skills, get ready to see how language combined with the help of a virtual assistant makes things just a little more magical. What it does 🌍 The idea is simple: a platform that aims to make learning English accessible and make illiteracy a thing of the past. Users are able to learn the basic English alphabet with audio, practice reading short stories with the help of Red (our very own voice assistant), and practice real-life speaking scenarios in English! How we built it ⚙️ The user interface was primarily built with a combination of React, HTML and CSS, the navigation bar was built with react-router-dom, and the virtual assistant was built using Alan AI. Challenges we ran into 😖 Well! This was one of my first times working alone, and I went into this project only knowing basic HTML and CSS. So, it came down to watching hours and hours of tutorials (with no attention span), reading documentation and staring into a long red carpet of errors :,D Accomplishments that we're proud of 😁 I am proud of creating a functional and interactive website, despite not having much knowledge, to begin with, and having pretty limited time to do so! For this particular hackathon, I wanted to try relying on myself to learn the concepts, after not being a particularly big contribution in my last one, and I’m glad I was able to come up with something even after a plethora of frustration and mistakes. What we learned 📚 I learnt a lot about the fundamentals of using React, as well as had the opportunity to implement my learnings"
      }
    ]
  },
  {
    "file_path": "./devposts/ready-sing.html",
    "project_id": "ready-sing",
    "title": "Ready? Sing!",
    "tagline": "Help theater performers ready themselves before their performances!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "javascript",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Created by Chantal Pino Joshua Sintos Renz Vital",
      "Thehacktrical 2WinnerThird Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/313/405/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 Inspiration We wanted to create an app that helps theater performers manage their nervousness and stress levels before a play or a show. We know the amount of bad vibes performing gives to performers before they go on stage: they might screw up or they might overthink or they might even fail to show up because of fear paralysis. This application’s goal is to solve those worries and mishaps and help performers shine their best. What it does Our application, Ready? Sing!, has four parts to it: a meditation blob that helps performers catch their breath, manage their anxiety, and ease their tense body through the use of a breathing exercise, a voice warm-up aid to loosen their vocal cords, a wellness exercise to distinguish the good and the bad thoughts to alleviate their nervousness, and a voice-to-text virtual diary that helps record their progress and clear their mind before they go perform. How we built it We developed the application with love using vanilla HTML and TailwindCSS for styling. On the other hand, we used the Flask framework for the backend to develop the API endpoints for our application and Tensorflow for the speech-to-text feature. Challenges we ran into We started late and had to accomplish a lot of features in a considerably short amount of time to make our application well-rounded. Most of our usual hackathon friends and teammates are busy as well so it was up to the three of us to finish it which made us revisit the planning stage to see what we could accomplish on time. Accomplishments that we're proud of We are proud that we were able to deliver a stellar output with only three of us present for this hackathon. Furthermore, this is compounded by the fact that we started late into the hackathon which made it a tad bit difficult for us to submit an output. What we learned Even with very unreliable WiFi and the late starting date, we learned how reliable each of us was and collaborated while having fun! What's next for Ready, Sing! B"
      }
    ]
  },
  {
    "file_path": "./devposts/red-flag-dfhrbq.html",
    "project_id": "red-flag-dfhrbq",
    "title": "Red Flags",
    "tagline": "It’s Time To HIRE Your Invisible Bodyguard! AND YOU WILL NEVER BE AFRAID OF LATE-NIGHT WALKS AGAIN!!!",
    "hackathon": "",
    "built_with": [
      "cloud",
      "database",
      "go",
      "node.js",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of Location Data (Hypertrack) Created by Nathan Chung richard zhou Serena Ge",
      "How to make the best use of Location Data (Hypertrack) Created by Nathan Chung richard zhou Serena",
      "Hack the North 2022WinnerHow to make the best use of Location Data (Hypertrack)",
      "My first priority after the completion of the IOS App is to get an Android version RedFlags out as well.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/226/533/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "A handful of technologies we've used. Our cloud dashboard demonstrating sentiment analysis Global ranking of queried ratings based on a number of information sources such as Reddit and various news sources. A handful of technologies we've used. Our cloud dashboard demonstrating sentiment analysis Global ranking of queried ratings based on a number of information sources such as Reddit and various news sources. A handful of technologies we've used. 1 2 3 4 Inspiration Some members of our team have solo travelled cities like Toronto, Montreal, Paris, Munich, Vienna... Even after fully preparing for unsafe situations, they have still encountered many moments of uncertainty leading to anxiety in their travels. Other members walk home on a daily basis and like many of our peers, have a certain degree of anxiety for their own safety. Whether you're a traveller, commuter, student, or city-person, navigating has become increasingly filled with anxiety due to the world becoming increasingly unsafe. Toronto's crime rate has shown a 19.4% increase, Vancouver's 36.1%, Montreal's 27.1%, and the United States shows similar growth rates (Numbeo). As such, our project is inspired by the increasing demand for ensuring individual safety in cities. However, after hearing about multiple stabbing events that occurred at Waterloo, we have decided to action and bring the project to life through  Hack the North. As RedFlagers, We believe that there are people out there who are suffering the same problem we are going through, and we are committed to protecting everyone through our own effort. Our Mission At RedFlags, our priority is to protect you, your family, and your community from any dangerous events. Whether you’re going to work in the morning, traveling with friends, or simply walking from place to place, RedFlag will alert you of nearby incidents and allow you to take timely action! As RedFlagers, our mission is to be the invisible bodyguard behind everyone, and ultimately, make the"
      }
    ]
  },
  {
    "file_path": "./devposts/reduce-reuse-recycle-ne0vzg.html",
    "project_id": "reduce-reuse-recycle-ne0vzg",
    "title": "Reduce, Reuse, Recycle",
    "tagline": "A quick and easy way to find out how to best reduce the waste that your produce through the three ideas of reducing, reusing, and recycling.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini",
      "google-maps",
      "python",
      "react-native",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/046/100/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Grabbing image through camera (preview shows default Android emulator camera) Upload screen for images Generated output Uploaded image (awaiting response) Markers on Google Maps of nearby recycling centers Grabbing image through camera (preview shows default Android emulator camera) Upload screen for images Generated output Uploaded image (awaiting response) Markers on Google Maps of nearby recycling centers Grabbing image through camera (preview shows default Android emulator camera) 1 2 3 4 5 Inspiration Our inspiration for this project came from our observations that many people are unaware of how to properly dispose of different types of garbage to most effectively reduce environmental waste. Therefore, we created this project as a way to help people get a quick summary of the most effective methods to tackle this problem. What it does The project takes an image of an article of garbage, either by upload or through camera, and uses Google's Gemini AI to determine the best ways to deal with the waste. There is also a separate tab that finds recycling centers in the user's vicinity to give information on where they are located to encourage more recycling. How we built it The project uses React Native with Typescript for the frontend, and a Python and Flask server in the backend to handle requests between the Gemini and Google Maps APIs. Challenges we ran into We ran into some issues with the time window of the hackathon due to our time zone, so we were a bit more restricted on time. In addition, some of the APIs that we originally planned to use were not available for free public use, so we had to find alternatives. Accomplishments that we're proud of We are proud of finding a way to bring together all of these technologies to help work towards one main goal. What we learned We learned about how to use a new component library (React Native Paper) as well as new APIs such as Gemini and Google Maps. What's next for Reduce, Reuse, Recycle We plan on adding some more "
      }
    ]
  },
  {
    "file_path": "./devposts/recruiters-r-us.html",
    "project_id": "recruiters-r-us",
    "title": "MortalReviewer",
    "tagline": "To master the art of the interview you need to think like a recruiter. This game helps a student get better at being interviewed by allowing them to experience the stress of being a recruiter.",
    "hackathon": "",
    "built_with": [
      "figma",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We are very happy to present a fess idea that to our knowledge is the first of its kind."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/346/808/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Planning Planning Planning 1 2 3 4 🧐Inspiration On average, employers look at resumes for six to seven seconds. Although this feels unfair time and resources are limited so the recruiter need to make a few assumptions to narrow the application pool to emulate the pressure of limited resources added a timer. 🎯What it does The user is given a set amount of time to read/grade resumes. They can then only pick X people to interview. The more people you pick the less time each person will naturally get as a player receives the same amount of time regardless. We then let them prepare questions from our list to ask the applicants. As you navigate the conversation tree the timer tics up until the interview reaches its natural conclusion or time expires: you can end it early. You then choose one person to join your quiz bowl team.\nThe user then asks trivia questions which the player gets to answer but depending on the partner chosen some will get answered for you by them and their unique skill set. 👷How we built it Simply build with react, python, figma, and locofy. ⏱Challenges we ran into The scale of the MVP needed much more work than me had hoped which was brutal on our timeline. 🏆Accomplishments that we're proud of We are very happy to present a fess idea that to our knowledge is the first of its kind. 👩‍🏫What we learned You can easily go from your Figma design to fully functioning prototype to developer-friendly React code using Anima. ⏭What's next for MortalReviewer Add more resources for a more diverse field. Built With figma react Try it out www.figma.com GitHub Repo Submitted to Treasure Hacks 3.0 Created by I did the Figma, with the Nicole. Mike Odnis Hi, I am an aspiring software engineer / full-stack developer. Currently in undergrad. Adam Solomon Caleb Hairston"
      }
    ]
  },
  {
    "file_path": "./devposts/reliacheck.html",
    "project_id": "reliacheck",
    "title": "ReliaCheck",
    "tagline": "A groundbreaking website that powers up the research process",
    "hackathon": "",
    "built_with": [
      "ai",
      "beautiful-soup",
      "nextjs",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Created by Veerrohit Veeravadivel Aravindkrishna Arivudainambi Rohan Fernandes A full-stack",
      "Track Winner Created by Veerrohit Veeravadivel Aravindkrishna Arivudainambi Rohan Fernandes A full-",
      "NorCal Hacks 23: Largest High School Hackathon in Northern CaliforniaWinnerTrack Winner",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/670/322/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The final result which the api returns Landing Page where you enter url Answer few questions for us to get better understanding of your requirements Some more information The final result which the api returns Landing Page where you enter url Answer few questions for us to get better understanding of your requirements Some more information The final result which the api returns 1 2 3 4 5 Inspiration We were inspired to do this project while we were doing research projects and had trouble picking reliable sources to support our research papers. What it does ReliaCheck is meant to help people determine how reliable an author of a news article/journal/publishing is by cross-checking it with other websites and sources that have similar content to the original author's work. We then process all the data using state-of-the-art technologies and return a score out of 5 on how reliable the author is and a CRAAP score, which is a score of how reliable the source is. How we built it We used Next.js for the front end and Flask(built with Python) for the back end and all the data processing steps. Challenges we ran into Some of the biggest challenges that we ran into included not knowing how to determine how to give a score to the user, and how to scrape the internet for other similar sources. Accomplishments that we're proud of We are proud of the fact that this project can be used by many more people than just teens, but can be used by university students and adults doing higher-level research. What's next for ReliaCheck We plan on using better analysis algorithms to evaluate the score of the author and the CRAAP score of the source so that this website can become very reliable and mainstream in the future. Built With ai beautiful-soup nextjs python Try it out docs.google.com GitHub Repo GitHub Repo Submitted to NorCal Hacks 23: Largest High School Hackathon in Northern California Winner Track Winner Created by Veerrohit Veeravadivel Aravindkrishna Arivudainambi Rohan Fernande"
      }
    ]
  },
  {
    "file_path": "./devposts/remindio.html",
    "project_id": "remindio",
    "title": "Remindio",
    "tagline": "Providing An Advanced Reminder System For Students",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css",
      "flask",
      "html",
      "javascript",
      "jquery",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Website for Social Good Created by I worked on the front end and developed the UI for the web",
      "HackJA December 2021WinnerBest Website for Social Good",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/768/783/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration as students, we also have busy schedules that require a more convenient system to enter in reminders and tasks. What it does our web app can allow users to enter in tasks and mark them as done. How we built it we used a variety of languages and had a front and backend. we added backgrounds, colors, buttons, etc. Challenges we ran into the buttons sometimes failed to work. Accomplishments that we're proud of we created, in only a couple of hours, a sleek and beautiful reminder system. What we learned we learned to work together and learned new coding languages. What's next for Remindio we hope to make it even more personalized, where people can choose for their reminder system any fonts, colors, images, etc. Built With bootstrap css flask html javascript jquery python sqlite Try it out replit.com docs.google.com Submitted to HackJA December 2021 Winner Best Website for Social Good Created by I worked on the front end and developed the UI for the web app. I'm familiar with Html and Css but Javascript was new to me- however, after more discussion, research, and tutorials, we were able to integrate javascript into our project. julia huang hackathon enthusiast and coder I made the back-end which consists of the web server, apis, and database. In the front-end, I helped integrate the api with the website. I also helped fix some bugs and helped with finishing touches on the website. Samvid Konchada"
      }
    ]
  },
  {
    "file_path": "./devposts/recycle4good.html",
    "project_id": "recycle4good",
    "title": "[the best]Recycle4Good",
    "tagline": "Recycling made easy.",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "google-maps",
      "html",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/492/260/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Login Page with sgID Home Page Categories of Bins Page Rewards Page Profile Page Google Map of the bins Login Page with sgID Home Page Categories of Bins Page Rewards Page Profile Page Google Map of the bins Login Page with sgID 1 2 3 4 5 6 7 Inspiration One of the primary motivations for creating a recycling website is to contribute to environmental conservation. Recycling plays a crucial role in reducing waste, conserving natural resources, and minimizing pollution. By providing information, resources, and tools related to recycling, a website can educate and encourage individuals to participate in recycling efforts, thus promoting a cleaner and greener environment. What it does Recycle4Good allows people to recycle with greater ease. The website provides a map indicating the locations of different recycling bins across singapore. On the Categories page, information on the different types of recycling bins that can be found on the map is shown, ensuring recyclables are disposed of in the right bin. The profile page has a form to fill in information on the recycled items. Every item recycled gains the person a point, and 100 points can be exchanged for a $10 voucher shown in the Rewards page. How we built it We used reactjs to create the frontend of the components of the website eg Home, Categories, Rewards and Profile Page. We linked the googlemaps-api to the website so that users can access the map. Challenges we ran into It was difficult to filter the markers on the google maps interactive interface on the home page based on the different types of recycling bin. \nWe have attempted to use SgID into our login page but faced several technical difficulties. Due to time constraints, we decided to use id/password instead. Accomplishments that we're proud of We have managed to include Google Maps API which allows the users to find the different types of nearest recycling bins according to their current location.\nClean and minimalistic design principles for a great user"
      }
    ]
  },
  {
    "file_path": "./devposts/random-name-uj7my8.html",
    "project_id": "random-name-uj7my8",
    "title": "Academy of Talents",
    "tagline": "Personalized chatting at anytime",
    "hackathon": "",
    "built_with": [
      "ai",
      "authentication",
      "fastapi",
      "next.js",
      "python",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/330/829/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Leo Avatar Rex Avatar Aria Avatar Room Menu Landing Page Leo Avatar Rex Avatar Aria Avatar Room Menu Landing Page 1 2 3 4 5 6 Inspiration Education should be limitless. Imagine a world where anyone can learn anything—without barriers, without high costs, and without waiting for the right teacher. Traditional learning methods are often expensive, rigid, or uninspiring. Online courses lack interactivity, and tutors aren’t always available when you need them.\nThat’s where Academy of Talents comes in. What if learning felt personalized, engaging, and instantly accessible—powered by AI tutors that never sleep and evolve with you? We wanted to push the boundaries of AI and education, creating a revolutionary learning experience where knowledge isn’t just consumed, it’s experienced. What it does Setting: School where AI-powered students specialize in different talents. Academy of Talents is an AI-powered learning platform that acts as a virtual school, combining immersive storytelling with AI-powered classmates that teaches you concepts\nMeet the Academy of Talents classmates:  Artistic Aria (Art), Rhythm Rex (Music), Logic Leo (Code) How we built it Our entire frontend is written using Next.js. We used Three.js to create our landing page using free online models. After selecting an avatar, the user is redirected to a page with an avatar to chat with. Using Chrome's built in speed-to-text, we can take input multimodal inputs. We send these responses to our backend Gemini agent hosted on FastAPI which selects the most appropriate tool (text, image generation, audio generation). The avatars were created using Ready Player Me. What's next for Academy of Talents We’ll use a subscription model—basic features are free, but users can pay to unlock ‘Elite’ agents. These agents are built on the best AI models available, with massive context windows that allow for hyper-personalized interactions. Imagine having a personal tutor who knows exactly how you learn, and adapts"
      }
    ]
  },
  {
    "file_path": "./devposts/reflectai-64j25i.html",
    "project_id": "reflectai-64j25i",
    "title": "BrightPath",
    "tagline": "A journey toward improved mental health.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "express.js",
      "mongodb",
      "node.js",
      "openrouter",
      "python",
      "react-native",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "reflects the overall sentiment from the available choices,"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/224/716/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Techstack BrightPath mobile App Main menu seeing the calendar moodboard Entering/Modifying a journal entry Getting tailored advice Techstack BrightPath mobile App Main menu seeing the calendar moodboard Entering/Modifying a journal entry Getting tailored advice Techstack 1 2 3 4 5 6 Inspiration BrightPath bridges the gap between passive journaling and proactive self-improvement by combining emotional reflection with AI-driven sentiment analysis. While traditional journaling provides a space for personal expression, it often lacks the tools to uncover emotional patterns and turn them into actionable growth. Inspired by the desire to help those around us, particularly those struggling with depression, BrightPath empowers users to take charge of their mental health. By analyzing journal entries, it offers insights and tailored recommendations that foster emotional awareness and support both mental and physical well-being. The app’s AI-powered sentiment analysis also provides a visual representation of mental health trends, helping users track their progress over time in an engaging and meaningful way. What it does BrightPath is a mobile journaling app designed to improve mental and physical health through emotional reflection and AI-driven sentiment analysis. By recording daily journal entries, users can track their emotions over time as the app analyzes the sentiment of each entry. BrightPath provides insights based on emotional patterns and offers personalized suggestions for self-improvement. The app features a calendar view that visualizes emotional trends, making it easy for users to reflect on their progress and take actionable steps toward a balanced lifestyle. In times of crisis, BrightPath’s Crisis Mode ensures users are not alone. This feature identifies distress signals in journal entries and connects users to trusted contacts or professional resources, offering immediate support when it’s most needed. But how? BrightPath was built using a combination of mod"
      }
    ]
  },
  {
    "file_path": "./devposts/rekora.html",
    "project_id": "rekora",
    "title": "Rekora",
    "tagline": "Many musicians struggle with finding out how to record their progress. Rekora is a website that users can use to keep track of their progress by creating a \"music journal.\"",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Since all of our group members are musicians, we found a problem within the community is that it is very hard to keep track of our progress. The solutions available currently have multiple problems including a bad user interface and consistently crashes meaning that users can't find their progress after practicing. This is when we thought of Rekora, a solution to be organized and keep track of music and have \"journals\" for songs. Rekora can also be used for non-music purposes such as public speaking and speeches. What it does Rekora saves a musician's songs into separate journals. These journals have the option to record a song or speaking and will put these recordings in chronological order. Additionally, there is also the option to make certain timestamps to point out specific details such as \"I was flat\" at 2:45. There is also the option for general notes for each recording. How we built it We used React for our frontend in project. The backend and API was created by Flask in Python. Challenges we ran into One of our frontend developer was not very familiar with React.js, and we had to take some time to catch him up to speed with a general idea of how react.js works. We faced difficulty with connecting our backend (which we built with python) with the frontend (which we built with React.js), but we figured it out in the end. It was also quite a hassle for us to figure out a way to allow users to record themselves--as well as save their recording--on Rekora. Accomplishments that we're proud of For all of us on the team, this was our very first hackathon. We're proud of the fact that we each decided to come out of our comfort zone and do something new. We performed the ever awe-inspiring act  of having an idea and working towards making it a reality. What we learned This entire hackathon has been quite an interesting experience. We've all learned a lot about what it's like to work on an hackathon, with people with skills/perspective different from ours,"
      }
    ]
  },
  {
    "file_path": "./devposts/remy-gsj65u.html",
    "project_id": "remy-gsj65u",
    "title": "Remy",
    "tagline": "Remy learns from you and offers the best recipes just for you!",
    "hackathon": "",
    "built_with": [
      "ai",
      "javascript",
      "llm",
      "love",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Remy learns from you and offers the best recipes just for you!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/674/810/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF 1 2 3 4 Inspiration Our group was mainly inspired by the versatility offered from machine learning models, as well as the colourful variety that the culinary world offers. We wanted to do something different than just bringing the customer to a pre-defined recipe that is likely to be fitting. Therefore, we decided to bring the recipe to the user - not limiting us to a finite dataset of foods, but rather generating a set of recipes created just for the user. What it does Essentially, REMY collects data from the user and creates a unique taste profile just for them. This data is collected directly from what the consumer tells us during registration (general preferences like vegetarianism or applicable allergens), as well as from the user's interactions with the platform - REMY remembers what foods the user has chosen in the past and queries the user after each week about how much they enjoyed their meals, in order to continuously update and improve the taste profile. After collecting information about the user, this information is analyzed by an LLM in order to create an accurate user taste profile. This taste profile is then again fed into an LLM that then analyzes it and gives back a set of recipes that it deems the most fitting for the user. How we built it For the backend, we employ FastAPI as well as Python in order to communicate with the OpenAI API. Through this API, we interface with ChatGPT in order to process all of our queries, beginning with the taste profile and ending with the specific steps of the cooking recipe. For the frontend, we have chosen to use React and we program everything relating to the user interface in JavaScript. Challenges we ran into Beginning with issues with the frontend not cooperating with us and ending with ChatGPT's often inexplicably weird and unexpected behaviour, the developmental proces made us face many difficulties. However, we were able to overcome almost all of our issues and came out the other more knowledgab"
      }
    ]
  },
  {
    "file_path": "./devposts/readspeak.html",
    "project_id": "readspeak",
    "title": "ReadSpeak",
    "tagline": "An app that empowers kids' language skills through reading and pronunciation assistance.",
    "hackathon": "",
    "built_with": [
      "node.js",
      "npm",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "LaunchHacks IIWinnerFirst Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/447/674/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Stats Page Home Page Reading Page (1/2) Reading Page (2/2) Flashcards Page (1/2) Flashcards Page (1/2) Stats Page Home Page Reading Page (1/2) Reading Page (2/2) Flashcards Page (1/2) Flashcards Page (1/2) Stats Page 1 2 3 4 5 6 7 Inspiration I was primarily inspired by my younger brother who has autism and struggles with reading and writing. As he is unable to carefully pay attention to words when he is reading, he often feels discouraged and frustrated when he loses track of where he is in the story or book. In order to help facilitate his reading and help other kids read as well, I developed Read Speak. What it does ReadSpeak is a comprehensive app designed to help users improve their reading and pronunciation skills. With its user-friendly interface and advanced features, ReadSpeak is the perfect tool for anyone looking to enhance their language abilities. One of the most impressive features of ReadSpeak is its ability to extract text from images, allowing users to practice their reading skills on the go. Users can also enter their own sentences or choose from a wide selection of pre-made examples to practice with. Users can also read a generated sentence from the app. Once the text has been selected, ReadSpeak's speech recognition module comes into play. This module helps users read the text word by word, ensuring that each word is pronounced correctly. Additionally, ReadSpeak has a text-to-speech module that will read out the word to help the user with pronunciation. ReadSpeak also comes with advanced tools that track how long it takes users to pronounce a word correctly, allowing them to measure their progress over time. If a user struggles with a particular word, ReadSpeak will detect this and add it to a list of hard words. This list can then be uploaded to a flashcard system within the app, allowing users to practice their pronunciation with the help of speech-to-text and phonetic breakdowns. Finally, ReadSpeak's stats page provides users with a detailed o"
      }
    ]
  },
  {
    "file_path": "./devposts/recoil.html",
    "project_id": "recoil",
    "title": "Recoil",
    "tagline": "Recoil is an arcade-based multiplayer snake game designed for two players and a Reinforcement Learning AI-controlled snake that offers a unique spin to a typical opponent-based game.",
    "hackathon": "",
    "built_with": [
      "flask",
      "next.js",
      "p5",
      "python",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Arcade-Themed Created by Claire Wang adorawu Wu Naveen Iyer I am a human and I live on Earth Anish",
      "Best Arcade-Themed Created by Claire Wang adorawu Wu Naveen Iyer I am a human and I live on Earth A",
      "HackTX 2024WinnerBest Arcade-Themed",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/116/840/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Arcade Game Page Landing Page Character Selection GIF Arcade Game Page Landing Page Character Selection GIF Arcade Game Page 1 2 3 4 Inspiration Ever since RL conquered Atari and old 16-bit games, it has been inextricably linked to video games. Moreover, projects like AlphaGo and AlphaStar continued to push the boundaries of what we thought AI was truly capable of. In a world where multiplayer games often follow predictable patterns, we sought to create a truly dynamic experience that adapts to player strategies. We were inspired by the concept of AI that learns and evolves, much like players do. The idea of a snake game where the AI grows stronger with each encounter sparked our imagination, leading us to envision a game that not only challenges players but also provides an opportunity for continuous growth and adaptation. Our goal was to create a competitive yet cooperative environment where players could engage in strategic gameplay. To do this we leverage Proximal Policy Optimization or PPO. This algorithm improves upon traditional policy gradient methods by balancing simplicity, efficiency, and performance. It alternates between sampling data through interaction with the environment and optimizing a \"surrogate\" objective function using stochastic gradient ascent. PPO introduces a novel objective function that allows multiple epochs of updates while avoiding large, destabilizing policy updates. What it does Recoil is an arcade-style snake game designed for two players. One player controls a snake competing against a Reinforcement Learning AI snake, while the second player only observes the first player and competes against them directly. The AI adapts and retrains itself each time the first player loses a life, creating an evolving challenge. This setup allows for unique gameplay dynamics, as the second player must strategize to outmaneuver the first player, while the first player focuses on overcoming the AI. The blend of competition and observation makes f"
      }
    ]
  },
  {
    "file_path": "./devposts/remy.html",
    "project_id": "remy",
    "title": "Remy",
    "tagline": "REMY is your AR buddy. They help you build support systems and take care of yourself.",
    "hackathon": "",
    "built_with": [
      "aftereffect",
      "arkit",
      "ios",
      "maximo",
      "photoshop",
      "proto.io",
      "swift",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "UI/UX Winner Best Overall Hack (2nd Place) Created by I worked on 3D design, animation, UIUX design",
      "Best UI/UX Winner Best Overall Hack (2nd Place) Created by I worked on 3D design, animation, UIUX d",
      "HackHarvard 2019WinnerBest UI/UXWinnerBest Overall Hack (2nd Place)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/864/887/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "UIUX Guide UIUX Guide UIUX Guide 1 2 3 Inspiration We got together a team passionate about social impact, and all the ideas we had kept going back to loneliness and isolation. We have all been in high pressure environments where mental health was not prioritized and we wanted to find a supportive and unobtrusive solution. After sharing some personal stories and observing our skillsets, the idea for Remy was born. How can we create an AR buddy to be there for you? What it does Remy is an app that contains an AR buddy who serves as a mental health companion. Through information accessed from \"Apple Health\" and  \"Google Calendar,\" Remy is able to help you stay on top of your schedule. He gives you suggestions on when to eat, when to sleep, and personally recommends articles on mental health hygiene. All this data is aggregated into a report that can then be sent to medical professionals. Personally, our favorite feature is his suggestions on when to go on walks and your ability to meet other Remy owners. How we built it We built an iOS application in Swift with ARKit and SceneKit with Apple Health data integration. Our 3D models were created from Mixima. Challenges we ran into We did not want Remy to promote codependency in its users, so we specifically set time aside to think about how we could specifically create a feature that focused on socialization. We've never worked with AR before, so this was an entirely new set of skills to learn. His biggest challenge was learning how to position AR models in a given scene. Accomplishments that we're proud of We have a functioning app of an AR buddy that we have grown heavily attached to. We feel that we have created a virtual avatar that many people really can fall for. What we learned Aside from this being many of the team's first times work on AR, the main learning point was about all the data that we gathered on the suicide epidemic for adolescents. Suicide rates have increased by 56% in the last 10 years, and this will "
      }
    ]
  },
  {
    "file_path": "./devposts/refriender.html",
    "project_id": "refriender",
    "title": "ReFriender",
    "tagline": "Connect with people you might know or have forgotten about over the years!",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html5",
      "javascript",
      "node.js",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/823/273/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "ReFriender Inspiration The theme of restoration is usually connotated with tangible things such as the environment. In this project, though, we wanted to take a creative approach by restoring one of the most meaningful things in our life: our social connections. Everyone has old friends that they lost their touch with, or people they could not really get to know. ReFriender has born as a solution to this. With its advanced algorithm to find the user's old connections using their current ones, ReFriender is an app for everyone that wants to get back in touch with their old friends to see what they are up to. Especially during the pandemic where people may feel lonely, ReFriender is THE app to spark some new (or reborn the old) connections. What it does Our algorithm to find the old friend's of the user was an essential component of this project that we are proud of. The algorithm works by first getting the user's friend (in other words, first degree of separation) either through Facebook API (had it allowed developer's to get user's friend list without Facebook reviewing our app for 5 days) or through getting the user's location and making them confirm their friend(s) on the app. Then, the algorithm checks the friends of the user's friends (second degree of separation), and we consider these people to be \"potential old friends (or never got to meet in detail)\" of the user. The more shared friends the user has with those that are separated by two degrees (friends' friends), the higher weight those people have. Hence, our algorithm displays the people with most mutual friends the user has, but those that are not actually a friend of the user. The user then decides whether the person actually is an old friend of them, and the algorithm updates accordingly.\nWhen the user chooses a person as their old friend, they get to start a conversation with that person to see what they have been up to using the app's chat function. The user is also able to edit their profile to upda"
      }
    ]
  },
  {
    "file_path": "./devposts/recovr.html",
    "project_id": "recovr",
    "title": "RecoVR",
    "tagline": "Immersive data visualization project for localized climate action efforts",
    "hackathon": "",
    "built_with": [
      "c#",
      "esri",
      "magicleap",
      "meta",
      "oculus",
      "sdk",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MIT Reality Hack 2023WinnerProtecting and Restoring the Environment",
      "Tracks",
      "Type 2: Technology | Best use of an ArcGIS Maps SDK",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/347/449/datas/medium.",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Tracks Type 1: Purpose | Protecting and Restoring the Environment Type 2: Technology | Best use of an ArcGIS Maps SDK Inspiration The ongoing energy crisis and rising global temperature levels require climate action. Some of us acknowledge the issue at hand, and some do something about it, resulting in a growing number of engaged players and greater funding to support climate action. Still, finding initiatives that match your interests remains challenging. A lack of centralized spaces for climate initiatives, unclear and at times, disorganized communications from climate organizations, and limited visual representation of progress are just some of the barriers people face when looking for climate initiatives they could support. About (what it is) recoVR is an immersive data visualization project for localized climate action efforts that present data in an informative and engaging way. We are on a mission to help individuals and organizations discover climate efforts they could support, collect and highlight data discrepancies between affected areas and support efforts, and increase climate change awareness through VR. Watch as the data come to life and find organizations and communities you can engage with in an immersive and gamified way. Let’s recoVR the earth together! Who is it for For VR users, recoVR is a tool that helps understand localized climate issues, as well as learn and support organizations working to resolve them For climate action communities and startups, recoVR will be a Marketing Vehicle as well as a market research tool to quickly find other organizations interested in solving the same climate problems. For climate action funds, advocates and policymakers, recoVR is a reference resource that helps identify areas with excess or minimal support and investment. It also helps them understand and evaluate progress initiatives they invest in, make or fail to make. How it works No login is required, any user can move around the map, see dis"
      }
    ]
  },
  {
    "file_path": "./devposts/recall-zvdgec.html",
    "project_id": "recall-zvdgec",
    "title": "recall",
    "tagline": "Scan, Notify, Protect: Your Receipts, Your Safety – Stay Informed with Every Bite!",
    "hackathon": "",
    "built_with": [
      "azure",
      "cloudflare",
      "css",
      "fastapi",
      "react",
      "redis"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked on the back-end. It was my first time using Azure Blob Storage & AI Document Intelligence and SendGrid."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/751/628/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "/cron Azure Blob Dashboard Redis Database SendGrid Dashboard FastAPI Documentation React App recall logo Receipt Dashboard Receipt Details Recalled Products /sample_recall /upload /cron Azure Blob Dashboard Redis Database SendGrid Dashboard FastAPI Documentation React App recall logo Receipt Dashboard Receipt Details Recalled Products /sample_recall /upload /cron 1 2 3 4 5 6 7 8 9 10 11 12 Inspiration Food recalls occur too often and end up being a boy who cried wolf. The recent Salmonella cantaloupe outbreak and Salmonella Quaker outbreak show it affects every company. You can sign-up for notifications via the Government of Canada , but they come too frequently. We wanted to make a product that tailored recalls to what you really bought. What it does Grocery receipts are uploaded to Azure Blob Storage and then passed to Azure AI Document Intelligence. Document Intelligence uses optical character recognition to extract merchant info, transaction date, and items. These items are vectorized and the metadata about the transaction is stored in our Redis database. Our background cron job will check the government's RSS feed for new recalls. We embed the recalled items and perform a cosine similarity search. If the match reaches our threshold, we send a notification to the user using SendGrid. The cron job runs at regular intervals to ensure users are updated. How we built it We used Azure's Blob Storage and AI Document Intelligence to process the receipts. Cloudflare's Workers AI was used to convert text into embeddings. We stored everything in our vector database. The front-end was made using Tailwind and React, and the back-end was made using FastAPI. Challenges we ran into Integrating React and FastAPI Parsing some receipts Accomplishments that we're proud of Can extract text from any grocery receipt Azure Blob allows for access anywhere What we learned OCR to extract text Azure Blobs for file storage What's next for recall Parse even more receipts Improve front-end B"
      }
    ]
  },
  {
    "file_path": "./devposts/red-handed.html",
    "project_id": "red-handed",
    "title": "Red-Handed",
    "tagline": "Decentralizing productivity by leveraging Qualcomm's HDK8450s, a Flow blockchain and 3 computer vision models to articulate a robot arm, using a quadrature rotary encoder.",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "arduino",
      "flow",
      "jupyter",
      "mediapipe",
      "next.js",
      "ngrok",
      "opencv",
      "pybluez",
      "python",
      "qualcomm-hdk",
      "react",
      "socket.io",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Flow Created by Xin Lei Lin Nikhil Gante Krish Modi Purav Gupta Bioinformatics and Comp",
      "MakeUofT 2024WinnerBest Use of Flow",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/774/113/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Slapped! Slapped! Slapped! 1 2 Inspiration Decentralizing productivity with flow is the key to your success!\nHave you ever found yourself in the paradoxical situation where you're too tired to continue working but also too stressed about deadlines to sleep? We've discovered the solution you never knew you needed (and probably still don't): Red Handed. Inspired by the countless souls who've fallen victim to their own procrastination and the relentless pursuit of productivity, we decided to tackle the problem head-on, with a slap. After all, why rely on caffeine or traditional means of staying awake when you can have a machine physically prompt you to stay alert? In the grand tradition of inventing solutions to problems you didn't know existed, Red Handed stands proud, ready to slap the sleepiness right out of you. It's the wake-up call you never asked for but might just appreciate in your most desperate, caffeine-deprived moments. What it does Red Handed uses a standard webcam to monitor your facial expressions in real-time. With the power of MediaPipe, an open-source machine learning framework for building multimodal (audio, video, etc.) applied machine learning pipelines, it detects signs of sleepiness or inattentiveness, such as yawning or eye closure. Here's the step-by-step process: Facial Detection : The webcam captures live video input, focusing on the user's face.\nYawn and Eye Shape Analysis: Using MediaPipe, Red Handed analyzes the shape of the eyes and the mouth. We also process the position of the face for the optimal slap. A significant change in these shapes, such as a yawn or the eyes closing, triggers the next step. Processing : The analysis is sent to a Qualcomm HDK via a Socket.io socket (Hardware Development Kit), where the decision logic resides. This powerful Android kit processes the input in milliseconds and sends the appropriate Bluetooth signal to the robotic slapper. Action - The Slap : The real-time feedback loop ensures that the robotic sla"
      }
    ]
  },
  {
    "file_path": "./devposts/renterloo-s9xvmr.html",
    "project_id": "renterloo-s9xvmr",
    "title": "RenterLoo",
    "tagline": "Renting in Waterloo has never been easier!",
    "hackathon": "",
    "built_with": [
      "amazon-dynamodb",
      "amazon-web-services",
      "api-gateway",
      "aws-lambda",
      "css",
      "javascript",
      "python",
      "react",
      "rest-apis",
      "syro",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/591/265/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Webpage for property owners to post a property RenterLoo homepage User log into account Find a property based on users' search (google maps layout) Find a property based on users' search Webpage for property owners to post a property RenterLoo homepage User log into account Find a property based on users' search (google maps layout) Find a property based on users' search 1 2 3 4 5 6 Inspiration Every year, more than 50,000 students at the University of Waterloo scramble to find housing and are rarely completely satisfied with their purchase. With no concrete platform to search for rentals, students, just like us, are often left unsatisfied paying thousands of dollars for a rental without being sure that they're receiving the best available deal and location for their needs. What it does RenterLoo is a platform that connects students with available housing in the region. With RenterLoo, students can purchase quick, smart and easy. This platform allows students to filter by location, dates and number of roommates, thus producing tailor-made search results that are recommended based on past residents and proximity to your campus. To top this off, our product offers enhanced web-scraping features which search the internet for accommodations posted to other sites. With RenterLoo, students can \"favourite\" accommodations that interest them and even \"add to cart\", thus allowing an easy way for students to keep track of their most promising options. How we built it As with any ideation session, our journey began with a brainstorming session. Here is how we took our idea from the E7 couches, to the whiteboard and beyond.\n1) Mapped out the UI by, considering all the features we needed, and inspiring ourselves with some design ideas on online templates.\n2) Decided on the perfect product name and logo.\n3) Divided the tasks amongst the team.\n4) Tackled the front end used React, Typescript, CSS and JavaScript.\n5) Tackled the back end using python and AWS Lamda. Challenges we ran i"
      }
    ]
  },
  {
    "file_path": "./devposts/rentinder.html",
    "project_id": "rentinder",
    "title": "Rentinder",
    "tagline": "Tinder... but for finding good rentals!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "express.js",
      "mongodb",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The concept for Rentinder was driven by the need to streamline the rental process, making it easier for landlords to find reliable tenants and for tenants to find their ideal homes. Recognizing the efficiency of the swipe-based selection process in other applications, we saw an opportunity to apply this approach to the rental market, enhanced with AI to improve matches based on detailed preferences. What it does Rentinder utilizes a swipe-based interface to allow users to quickly browse and select potential rental properties or tenants. It incorporates an LLM to offer intelligent interactions, such as answering queries about listings and providing personalized recommendations, aiming to make the search process more intuitive and efficient. How we built it We developed Rentinder using the MERN stack for a robust, scalable web application. MongoDB is used for data storage, Express.js and Node.js for backend services, and React for a responsive frontend. An LLM integration through enables advanced natural language processing for user interactions and content generation. Challenges we ran into Integrating LMMs while maintaining performance was challenging, requiring optimizations to handle real-time data processing. Developing an effective matching algorithm that accounts for diverse user preferences and improves with user feedback also presented a significant challenge. Accomplishments that we're proud of Successfully integrating the LLM to enhance user interaction and creating a functional, AI-enhanced matching system are our key accomplishments. These elements combined have significantly improved the efficiency and user experience of the rental matching process. What we learned We gained insights into the complexities of AI integration within web applications, particularly in natural language processing and developing algorithms that adapt to user behavior and preferences. We also refined our skills in the MERN stack and AI application in real-world scena"
      }
    ]
  },
  {
    "file_path": "./devposts/renteasy.html",
    "project_id": "renteasy",
    "title": "RentEasy",
    "tagline": "Easy Peasy Rent Easy 🏠🔑",
    "hackathon": "",
    "built_with": [
      "atsign-sdk",
      "dart",
      "figma",
      "filecoin",
      "firebase",
      "flutter",
      "gcp",
      "infura",
      "ipfs",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Google Cloud Winner The @ Company - Best Use of @ Platform Created by Worked on both front/b",
      "BlackRock Challenge - Financial Wellbeing Winner The @ Company - Mobile Apps Post “The Social Dilem",
      "MLH - Best Use of Google Cloud Winner The @ Company - Best Use of @ Platform Created by Worked on b",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/712/513/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 Inspiration 💡 Due to rising real estate prices, many students are failing to find proper housing, and many landlords are failing to find good tenants . Students looking for houses often have to hire some agent to get a nice place with a decent landlord. The same goes for house owners who need to hire agents to get good tenants. The irony is that the agent is totally motivated by sheer commission and not by the wellbeing of any of the above two. Lack of communication is another issue as most of the things are conveyed by a middle person. It often leads to miscommunication between the house owner and the tenant, as they interpret the same rent agreement differently. Expensive and time-consuming background checks of potential tenants are also prevalent, as landowners try to use every tool at their disposal to know if the person is really capable of paying rent on time, etc. Considering that current rent laws give tenants considerable power, it's very reasonable for landlords to perform background checks! Existing online platforms can help us know which apartments are vacant in a locality, but they don't help either party know if the other person is really good! Their ranking algorithms aren't trustable with tenants. The landlords are also reluctant to use these services as they need to manually review applications from thousands of unverified individuals or even bots! We observed that we are still using these old-age non-scalable methods to match the home seeker and homeowners willing to rent their place in this digital world! And we wish to change it with RentEasy! What it does 🤔 In this hackathon, we built a cross-platform mobile app that is trustable by both potential tenants and house owners. The app implements a rating system where the students/tenants can give ratings for a house/landlord (ex: did not pay security deposit back for no reason), & the landlords can provide ratings for tenants (the house was not clean). In this way, clean tenants and "
      }
    ]
  },
  {
    "file_path": "./devposts/replate-xzg1jn.html",
    "project_id": "replate-xzg1jn",
    "title": "Replate",
    "tagline": "AI-powered platform connecting restaurants and groceries with food banks, shelters, and community kitchens through real-time matching and volunteer coordination.",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "python",
      "tensorflow",
      "torch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/466/376/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home Upload Produce Marketplace Home Upload Produce Marketplace Home 1 2 3 Inspiration We were inspired by how frequent food in our homes go to waste. We noticed a lack of tools to help people keep track of what they buy. We also saw the impact of food waste on the environment. That's when we decided to create RePlate. What It Does RePlate is a smart tool that helps people keep track of what's in their fridge by letting them scan and see their food, so they can use it before it spoils. You can scan barcodes or receipts, and the app will automatically add your groceries for you. The app lets you scan barcodes or receipts, and it adds your groceries to your list by itself. The purpose of RePlate is to help you waste less food, save time, and spend less money. How We Built It We used NextJS and Tailwind CSS for the UI, as well as v0.dev for inspiration. We used the useHooks library for additional UI animations and used Google Maps data for real-world restaurant data. For the backend, we used Python and PyTorch for a neural network image recognition model. This directly allowed users to effortlessly upload images and be listed on the marketplace. In turn, other users could save food and buy from others. What We Learned We learned how to connect APIs into one seamless app. We also learned how to use OCR in real-world situations. Working under pressure taught us to focus and stay organized. Team communication was key to our success. What's Next for RePlate We want to improve the accuracy of our receipt scanner. We also want to add features like a shared pantry for families or roommates. Smart fridge integration is something we're excited about. Our goal is to make RePlate a tool people use every day. Built With nextjs python tensorflow torch Try it out GitHub Repo Submitted to HackaKhan 2025 Created by Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Tejas Tammana"
      }
    ]
  },
  {
    "file_path": "./devposts/restoration-of-the-night.html",
    "project_id": "restoration-of-the-night",
    "title": "Restoration of The Night",
    "tagline": "Our project locates the areas with high light pollution through a user input of location and time. Afterwards, a national light pollution map will update real-time with the user's data.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Often times, at least one of our members had trouble sleeping because of artificial light. After discussing, we realized that all of us had frequent problems because of artificial light. We decided to further research on the topic, and to our surprise found out that light pollution is a major problem that affects many many people. What it does The user takes a photo, and uploads it to our database in which scientists can use the geographical data, the inputted time, and the light particles in the photo to analyze the light pollution. This helps us to further understand light pollution and its affects. How we built it We used python, html, .css, and javascript to code the software. Challenges we ran into Getting the servers to equally communicate with each other and also finding a way to determine the light in the image properly. Accomplishments that we're proud of We were able to make a completely functioning website that took an input and analyzed for the first time. The website gives an accurate output to our input, and does the desired function. What we learned How to properly communicate with each other, how to work as a team, and how to divide and conquer.  We also learned everyone's strengths and weaknesses, allowing us to assign everyone with what they did best. What's next for Restoration of The Night We look to support more than one country, rather than stay only in the US. Built With css html javascript python Try it out loss-of-the-night.vercel.app Submitted to BellHacks 24 Created by I came up with the idea and worked on the website. Tejas Patel I designed the majority of the Website along with the entirety of the front and back end. Nilesh Mudupalli Aspiring Developer I helped research the problem and worked on the presentation slides. Bruhath B I worked on a large amount of the presentation slides and did research on the topic. Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/replate-8oev32.html",
    "project_id": "replate-8oev32",
    "title": "Replate",
    "tagline": "The world is your fridge. Discover surplus meals tailored just for you—sustainably, affordably, and intelligently.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "express.js",
      "flask",
      "gemini",
      "javascript",
      "leaflet.js",
      "next.js",
      "node.js",
      "postman",
      "python",
      "react",
      "socket.io",
      "tailwind",
      "twilio",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AI Eco-Mobility Hack Sponsored by Dartmouth Climate Alliance (DCA) - Arduino Starter Kit Created by",
      "Best AI Eco-Mobility Hack Sponsored by Dartmouth Climate Alliance (DCA) - Arduino Starter Kit Creat",
      "GenAI Genesis 2025WinnerBest AI Eco-Mobility Hack Sponsored by Dartmouth Climate Alliance (DCA) - Arduino Starter Kit",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/330/166/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "beautiful architecturing beautiful architecturing beautiful architecturing 1 2 3 4 5 6 🧠 Project Inspiration Food waste is one of the most pressing sustainability challenges of our time. As university students juggling busy schedules and tight budgets, we saw an opportunity to create something meaningful—an app that not only reduces waste but also empowers users to eat sustainably, healthily, and affordably. We realized that many restaurants throw away perfectly good food at the end of the day, while students like us are searching for inexpensive, convenient meals. At the same time, dietary restrictions—whether due to allergies, religion, or lifestyle—are often overlooked in existing food waste solutions. This sparked Replate —a generative AI-powered platform that connects users with surplus food from restaurants while personalizing recommendations to their preferences and restrictions. Our goal was to create a system that understands each user's unique needs and recommends safe, sustainable meals in real time. ⚙️ Technology Stack 🧑‍💻 Languages TypeScript JavaScript Python 🧰 Frameworks and Libraries Node.js – Backend infrastructure React & Next.js – Interactive frontend Leaflet.js – Dynamic mapping of radius of preference Express.js – Node.js backend API Flask – Python backend for AI coordination Twilio – Communication and SMS notifications Socket.io – Real-time streaming and delivery tracking Gemini API – Natural language interpretation Cohere API – Contextual RAG and preference processing Too Good To Go API – Restaurant and surplus food data sourcing ☁️ Platforms / Cloud Services Google Cloud Platform (GCP) – Hosting backend services and deploying AI agents Gemini API – Understanding user intent and requests Cohere API – Semantic analysis and preference interpretation Twilio – SMS messaging and notification system 🛠️ Tools and Software Postman – API testing and endpoint verification Liveshare – Real-time collaborative coding Git & GitHub – Version control and team"
      }
    ]
  },
  {
    "file_path": "./devposts/retro-act.html",
    "project_id": "retro-act",
    "title": "re.live",
    "tagline": "Where memories come to life.",
    "hackathon": "",
    "built_with": [
      "3js",
      "cohere",
      "flask",
      "mediapipe",
      "opencv",
      "python",
      "pytorch",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "UofTHacks 11WinnerCo:Here",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/736/962/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "re.live re.live re.live 1 2 Inspiration We all deal with nostalgia. Sometimes we miss our loved ones or places we visited and look back at our pictures. But what if we could revolutionize the way memories are shown? What if we said you can relive your memories and mean it literally? What it does retro.act takes in a user prompt such as \"I want uplifting 80s music\" and will then use sentiment analysis and Cohere's chat feature to find potential songs out of which the user picks one. Then the user chooses from famous dance videos (such as by Michael Jackson). Finally, we will either let the user choose an image from their past or let our model match images based on the mood of the music and implant the dance moves and music into the image/s. How we built it We used Cohere classify for sentiment analysis and to filter out songs whose mood doesn't match the user's current state. Then we use Cohere's chat and RAG based on the database of filtered songs to identify songs based on the user prompt. We match images to music by first generating a caption of the images using the Azure computer vision API doing a semantic search using KNN and Cohere embeddings and then use Cohere rerank to smooth out the final choices. Finally we make the image come to life by generating a skeleton of the dance moves using OpenCV and Mediapipe and then using a pretrained model to transfer the skeleton to the image. Challenges we ran into This was the most technical project any of us have ever done and we had to overcome huge learning curves. A lot of us were not familiar with some of Cohere's features such as re rank, RAG and embeddings. In addition, generating the skeleton turned out to be very difficult. Apart from simply generating a skeleton using the standard Mediapipe landmarks, we realized we had to customize which landmarks we are connecting to make it a suitable input for the pertained model. Lastly, understanding and being able to use the model was a huge challenge. We had to deal wit"
      }
    ]
  },
  {
    "file_path": "./devposts/reveille-recs.html",
    "project_id": "reveille-recs",
    "title": "Reveille Recs",
    "tagline": "Welcome to Texas A&M! A sign catches your attention as you drive into College Station, and you can't wait to start exploring. Problem is, what do you do there? That's what Reveille Recs is for!",
    "hackathon": "",
    "built_with": [
      "java",
      "swing"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/241/778/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landmarks on Campus Our Project Logo Home page Food on Campus Shopping in CSTAT Food in CSTAT Food in CSTAT 2 Entertainment in Cstat Landmarks on Campus Our Project Logo Home page Food on Campus Shopping in CSTAT Food in CSTAT Food in CSTAT 2 Entertainment in Cstat Landmarks on Campus 1 2 3 4 5 6 7 8 Inspiration Reveille Recs is a College Station travel guide platform with a special subsection for the TAMU campus. This was inspired by the lack of information new TAMU students have on what resources and \"cool things\" there are to see near and around campus. What it does Reveille Recs has two separate sections on an interactable website. One section is a Texas A&M specific section that lists off different A&M locations that have been categorized by type: food, landmark, or facility. On the College Station side, there are recommendations for similar categories, but each category features a most popular interactable element. When one of the categories or elements are clicked on, it will lead to a splash page where users can scroll through and click on different UI elements and receive pop up information and images on the location that they have selected. Ways to exit the UI in the form of back buttons as well as highlight indicators to show which UI element is currently selected were also implemented. How we built it This app was built on Eclipse IDE, shared via GitHub, and built entirely in Java swing. We built this website by first creating the base UI elements and lists and then programming in the interactable elements such as buttons, selection indicators, image pop ups, and aesthetic tweaks. Challenges we ran into We ran into logistical challenges when first setting the project up in the sense that we had a lot of additional features we wanted to implement in the form of tags, etc. But did not realize that the time constraints would prevent any more in-depth implementations of those additional features. Accomplishments that we're proud of We are particularly proud "
      }
    ]
  },
  {
    "file_path": "./devposts/reviewstar.html",
    "project_id": "reviewstar",
    "title": "ReviewStar",
    "tagline": "Find your problem areas and find out why.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/362/913/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Landing Page Landing Page Landing Page 1 2 How we built it We built it using help from Youtube videos and online coding. We also implemented OpenAI's Davinci model into our code to read from the websites. Challenges we ran into We ran into challenges with the AI outputting wrong data even when instructed otherwise. We also ran into problems with getting the map to display on our webpage and correctly zoom in and out depending on which airport was selected. Accomplishments that we're proud of We are very proud of getting the AI to produce good feedback based on the scraped reviews What we learned We learned more about machine learning and AI. We also learned how to use HTML and CSS better on a front end and back end environment. What's next for ReviewStar Revolutionize how companies take in feedback Built With css html javascript python Try it out TAMUHACK-TEST-1.jar448.repl.co GitHub Repo replit.com Submitted to TAMUhack 2023 Created by Jacob Quintero MAJ-23 Jimenez jar 448 Brandon Hawkins"
      }
    ]
  },
  {
    "file_path": "./devposts/reval.html",
    "project_id": "reval",
    "title": "ReVal",
    "tagline": "Customer Analytics Beautified",
    "hackathon": "",
    "built_with": [
      "flask",
      "next.js",
      "nltk",
      "pandas",
      "postgresql",
      "python",
      "react",
      "sqlalchemy",
      "summa",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We are proud of creating our first data visualization web app."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/295/153/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Key word/phrase search Landing Page Analytics Dashboard Key word/phrase search Landing Page Analytics Dashboard Key word/phrase search 1 2 3 4 Inspiration As a business owner, director of a club, or anyone who provides a good or service, it can be difficult to gauge customer response without sifting through hundreds of reviews manually. ReVal is designed to streamline the customer analytics experience and provide powerful insights into your product or service, made beautiful. What it does Drag your exported reviews/feedback data into ReVal and gain access to advanced customer response tools in a sleek, interactive user interface. We do natural language processing in Python to determine review sentiments and provide a way for users to know where their product is succeeding or lacking. How we built it The frontend is made with React, TailwindCSS, and Next.js, hosted on Vercel. The backend utilizes the natural language toolkit, the summa library, and pandas. It also has an API made with Flask and SQLalchemy. Challenges we ran into It was our first time doing natural language processing so it was a struggle to figure out how to parse though the reviews and gain insights based on the language used. Creating the API and utilizing a database was also challenging.\nA challenge on the front end was visualizing the data, since none of us had any experience making charts in React. Another challenge was designing the front-end to be sleek and intuitive. Accomplishments that we're proud of We are proud of creating our first data visualization web app. What we learned We learned a lot about NLP and connecting front-end to back-end via APIs. It was also interesting to learn how different product owners think when it comes to reviews/feedback on their product. We learned how important it is to draw insights from feedback using technology. We've all seen google feedback forms with 15-20 responses, but working with datasets containing thousands of reviews showed us the scale of this g"
      }
    ]
  },
  {
    "file_path": "./devposts/resume-turns-pure-brainrot.html",
    "project_id": "resume-turns-pure-brainrot",
    "title": "Resume turns into pure brainrot",
    "tagline": "Imagine you just passed the final round for some second tier summer internship and you want to get your inflated ego down into the basement, resume-turns-pure-brainrot got you!",
    "hackathon": "",
    "built_with": [
      "openai",
      "pydparser",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "brainrot jia.seed hackathon ($5,772) in prizes",
      "Tracks"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/163/942/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Tracks i laughed. (new hackers prize) (10 winning teams) (10) ouck tuah spit on that faang ($50) memeing this one (WPPOIL) would piss people off on linkedin ($25) (LAKOG) lowkey actually kind of good ($50 + a snack) reaching for this one Inspiration Wanted to turn my own resume into a brain rot meme and I thought this is a great tool for the general public. What it does Pretty straight forward. We parse your resume, do some prompt engineering and display your brain rot meme. How we built it My one-man team had to take some shortcuts, which is why we used streamlit for the frontend (frontend is not my thing), we parse the resume, create a prompt and finally call open ai dalle-3 to generate the meme. There is about 4.20$ left on my open-ai api key, so once this is used up, users will be prompted for their own api key. Challenges we ran into Streamlit has some issues with post installation downloading of models. Aside from that had some of the usual dependency issues with old, unmaintained packages. Accomplishments that we're proud of This is in fact my first hackathon ever, yaay. After a rocky start trying to make something work with a few teammates on discord which lacked coordination, I only started working solo on Saturday night on this, so proud that this works now (kinda). What we learned Friend told me about streamlit, I always thought I needed a front end dev to make this work, but lowkey streamlit is great. What's next for Resume turns pure brainrot TO THE MOON. Nah jk probably not a lot, will send to some friends to meme their accomplishments Built With openai pydparser python streamlit Try it out resumeturnsbrainrotmeme.streamlit.app GitHub Repo Submitted to brainrot jia.seed hackathon ($5,772) in prizes Created by Nicolas Dickenmann"
      }
    ]
  },
  {
    "file_path": "./devposts/review-reviewer.html",
    "project_id": "review-reviewer",
    "title": "Review Reviewer",
    "tagline": "Flagging irrelevant Google reviews using open-source AI models — free, efficient, and ready for real-world deployment.",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/706/488/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "TikTok TechJam 2025 Review Reviewer Product of Team Null for TikTok TechJam 2025 Project Overview Problem Low-quality comments such as advertisements and irrelevant feedback often clutter platforms like Google Maps, reducing user experience and making it harder for businesses to receive genuine reviews. Solution Our product is an AI-based comment classifier that analyzes comments based on text, images, ranking, and information about the place. It automatically flags low-quality and irrelevant comments (text and images) for moderation to improve the overall quality of reviews. Impact Users: Enhance trust in location-based reviews by flagging low-quality and irrelevant comments. Business Owners: Ensure fair representation by highlighting irrelevant or malicious reviews. Platforms: Automate moderation by flagging suspicious comments, reducing manual workload. Setup Instructions Clone the repository: bash  \ngit clone https://github.com/Noob-No-1/TikTok-TechJam-2025.git  \ncd TikTok-TechJam-2025 Install dependencies: Ensure you have Python installed, then run: bash  \npip install -r requirements.txt Create a .env file: Add your API keys and environment variables securely in a .env file in the project root. To get your Groq API key, visit the GROQ website . For example: env  \nGROQ_API_KEY=your_api_key_here Run the comment classifier: Use the provided scripts or notebooks to start classifying comments. Tools and APIs Python: Primary programming language for backend logic and AI integration. VSCode: Main IDE used for development. Jupyter Notebook: Used for prototyping and interactive testing. Groq API: Provides access to free hosted large language models (Llama 3.1 8B) for AI-based text classification. JSON: Used for structured data exchange between the AI model and application. Libraries dotenv: Securely loads environment variables from .env files. groq: Official Python client for interacting with the Groq API. json: Standard Python library for parsing and generating JSON da"
      }
    ]
  },
  {
    "file_path": "./devposts/reveille-s-diner.html",
    "project_id": "reveille-s-diner",
    "title": "Reveille's Diner",
    "tagline": "Come enjoy an amazing evening at Rev's Diner! Here, we have space, food, and merchandise for people and pets alike! Don't forget, if you spot Rev, add her live location to our site so others can see!",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/582/994/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Rev Spotted Page Home Page Merch Page Menu Page Menu Page Part 2 Rev Spotted Page Home Page Merch Page Menu Page Menu Page Part 2 Rev Spotted Page 1 2 3 4 5 Inspiration Our team wanted to make sure that everyone has easy and intuitive access to one of the greatest places on earth, Reveille's Diner. We know that we can make you feel right at home here at Rev's Diner, and we wanted to make sure you could get here. We built the website to show our amazing menu, merch, and more! Also, because we know everyone spends the majority of the day thinking about what Rev is up to, we added a \"Where's Rev\" feature where you can upload her live location and keep everyone in the loop! What it does Our website allows users to see what food and merch we offer at our diner. It also allows users to see where Rev is based on the uploads the site receives. How we built it We used a combination of html, CSS, and JavaScript to create the website. We collaborated on GitHub and coded in VS Code. Challenges we ran into There were a lot of issues with formatting. The divs were either not centered, images were too small, some images wouldn't show up at all. Accomplishments that we're proud of We were able to unify the headers for each embedded page, create logos for our company and add them to the website, make the website look clean, add nice borders and padding to each div, and make the divs pop up when the mouse hovers over them. What we learned We learned the ins and outs of cleaning up a website in CSS and the overall format of coding in HTML. We also learned how to collaborate in GtiHub, learned how to pull, push, and deal with merging issues. We also learned how to embed pages in our website, linking everything together. Most importantly, we learned how to work as a team that worked on their individual things with the mindset that we would all connect our pages at the end. This made us keep the common goal in mind while still adding our own personal touch. What's next for Reveille's Din"
      }
    ]
  },
  {
    "file_path": "./devposts/rfid-reader.html",
    "project_id": "rfid-reader",
    "title": "RFID Reader",
    "tagline": "Howdy,\n I'm sure many of us carry something with RFID. You may even be carrying a work/student ID with you. Well what if I told you all of that could be replicated, leaving a security vulnerability?",
    "hackathon": "",
    "built_with": [
      "arduino",
      "github",
      "sveltekit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/740/927/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "RFID Reader RFID Reader RFID Reader 1 2 Preface My inspiration for the project came about due to my interest in the L3 hardware cybersecurity challenge. I think this would be a cool project to demonstrate to people of all ages how security vulnerabilities genuinely exist and that they can hack life. Inspiration My main inspiration came from playing Watch Dogs and the protagonist, vigilante Agent Pearce, was able to bring down ctOS, basically ChatGPT on steroids being controlled by a really bad interests, basically a tamer version of OpenAI. He does this with various hacks, one of those being getting into anywhere he wants. He does this with a device basically known as a Flipper Zero. What it does The cards and the flipper zero work to demonstrate that my RFID scanner works as a cheap RFID reader, but that companies may be depending on insecure technology. How we built it -I used an NodeMCU which goes about $10 on Amazon.\n-Wifi module.\n-Arduino IDE.\n-Some github libraries.\n-For the Flipper Zero I covered it with electrical tape. This is so I could get sponsor credentials discretely, in order to get in their company buildings and pretend I work there (intern). Challenges we ran into We were able to connect both the scanner and the computer to my phone's hotspot. However, trying to interface and make computations based on select cards proved difficult due to routing issues from using Svelte. We switched to Sveltekit for easier routing. Accomplishments that we're proud of We were able to make an RFID scanner in just a short time period and confirm it works, and that we're working toward doing something special with the ability to read cards, such as respond to unique cards with a specific website on a user terminal/POS system. What we learned We learned Arduino code, RFID technology, and security vulnerabilities. What's next for RFID Reader Make card and RFID scanner interact with cards uniquely with a website frontend. Built With arduino github sveltekit Try it out Git"
      }
    ]
  },
  {
    "file_path": "./devposts/ride4food.html",
    "project_id": "ride4food",
    "title": "Ride4Food",
    "tagline": "Empowering your daily commute to make a difference, connecting restaurants' surplus food with those in need, fighting waste and hunger together. Join the movement now and be a part of the change!",
    "hackathon": "",
    "built_with": [
      "cohere-api",
      "css",
      "google-maps",
      "html5",
      "javascript",
      "json",
      "mongodb",
      "node.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/471/996/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "\"Mobilizing Compassion, Fighting Hunger, and Transforming Lives and Communities\" 🎯Inspiration In downtown Toronto, there are 7,500 restaurants spread across 140+ neighborhoods. Shockingly, the total value of wasted or lost food in Canada amounts to a staggering $49 billion . A report by Second Harvest reveals that if this food was saved, it could provide nourishment for every Canadian for a period of five months. The annual cost of wasted food in Canada stands at $1,766 per household.\nSadly, hunger and malnutrition are not limited to Canada alone but are pervasive worldwide. In fact, global hunger, which had been decreasing steadily for ten years, has experienced a resurgence, affecting nearly 10% of the global population. Between 2019 and 2022, the number of undernourished individuals grew by approximately 150 million due to conflicts, climate change, and the COVID-19 pandemic.\nEven in Canada, a University of Toronto study reports that nearly 6 million people faced food insecurity in 2021 . Homelessness and hunger are growing concerns among Canadians, particularly in Toronto.\nWhat if we could divert all the food that restaurants discard as waste and leftovers from landfills and garbage dumps and instead use it to feed people in need?\nTherefore, this lead us to come up with the idea of Ride4Food. 👨🏻‍💻 What it does This innovative platform aims to connect restaurants with surplus or leftover food to individuals who are commuting and willing to help deliver this food to those in need, particularly homeless individuals.  \"ride4food\" provides a platform that enables restaurants to redirect their excess or leftover food for donation. Through our platform, individual commuters who are already traveling within the city can opt to pick up these food donations from the participating restaurants and ensure their safe delivery to homeless individuals or community centers that cater to those in need. By harnessing the power of community and utilizing existing transportation rou"
      }
    ]
  },
  {
    "file_path": "./devposts/rescue-ready-vr.html",
    "project_id": "rescue-ready-vr",
    "title": "Rescue Ready VR",
    "tagline": "Rescue Ready VR empowers civilian first responders through a VR training experience, designed to enhance their ability to assist disabled neighbors during fire emergencies with empathy & efficiency.",
    "hackathon": "",
    "built_with": [
      "adobe-audition",
      "adobe-premiere",
      "elevenlabs",
      "mixamo",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Design for Emergency Response Track, Presented by Quasar Lab Created by - Creative Direction - Prod",
      "Best Design for Emergency Response Track, Presented by Quasar Lab Created by - Creative Direction -",
      "MIT Reality Hack 2025WinnerBest Design for Emergency Response Track, Presented by Quasar Lab",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/239/675/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Rescue Ready VR is a response to the devastating LA wildfires, where more than 30 people lost their lives.\nAt least 3 people of the victims had a physical disability, and 8 of them were elderly citizens with limited mobility issues. The stories of the amputee father and son with cerebral palsy, who couldn't be evacuated in time, and the mother who had to leave behind her son with cerebral palsy, hit home for our team - as one of our team members has a child with CP as well. 1 in 4 Americans have a disability, yet disabled people are up to 4 times more likely to die in natural disasters. This is because our society doesn't value disabled folks enough to include them in planning for emergencies. There are over 2 million disabled residents of Los Angeles. In rebuilding our community and looking towards the future, we need to include disabled people in our emergency response planning, and develop a culture of readiness among our neighbors. YOU are the first \"first responder\" - so if you are Rescue Ready, you can save a life. What it does Our project, Rescue Ready VR, aims to raise awareness and share basic practices for communicating with and evacuating disabled individuals in an emergency. This prototype walks you through a simulation of a fire emergency while introducing general protocols for evacuating a wheelchair user - including asking if assistance is needed, assessing imminent danger, identifying nearest exits, accessing their mobility aids and medical devices, ensuring a clear path to travel, and notifying emergency personnel. Like with school fire drills, repetition, and practice is key to staying calm and being prepared for the worst. We want to raise a call to action for all users to learn how to pack an emergency kit, reach local accessible transportation, build plans with on-the-ground organizations, and more. How we built it Rescue Ready VR was built in Unity by our two developers, one on the ground here at ASU Local LA, and the other on t"
      }
    ]
  },
  {
    "file_path": "./devposts/research-base.html",
    "project_id": "research-base",
    "title": "Survey Savvy Scientists",
    "tagline": "Users get points from researchers for answering surveys. The points can then be used to claim charitable donations that can be written off on the user's taxes.",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "CivicHacksWinnerBest Domain Name from Domain.com",
      "The collected revenue is then saved until a user claims the donation prize.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/351/324/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "🔬Inspiration Conducting research is important for advancing the arts and sciences but it can be expensive to recruit diverse applicants and receive high-quality data. This is unfortunate as in most cases the demographic of people being studied serves to gain the most but with limited funding that research is less impactful than it could have been otherwise. Researchers and Participants deserve a centralized community to maintain participant safety and data cost acquisition low. 🪙What it does We created a platform for participants to help Researchers collect data at discounted prices, donate to charities, and receive tax write-offs all at the convenience of their own homes. Researchers: Research Groups use our survey creator to put the participant requirements, survey questions, timeframe, and the number of responses needed and post it to our sight. After the period closes we off the data to the researchers for a set price. The collected revenue is then saved until a user claims the donation prize. Participant: In your spare time you can search our site for surveys you qualify for and then you can receive points for filling them out. These points can then be used to claim charitable donations in your name. We then forward you the information needed to fill out Form 8283 for your taxes. 🏗How we built it Front end react and back end firebase. 🚧Challenges we ran into Unfortunately, we felt wix limited in our ability to customize it for our needs therefore we switch to react. 🏅Accomplishments that we're proud of Creating a unique idea that to our knowledge hasn’t been explored in other hackathons. 🧠What we learned We now have a better understanding of US tax laws and how to leverage them for tax incentives. ⏭What's next for Research Savvy Scientist We would like to leverage ad space to keep the platform running indefinitely. In addition, we would like to increase the number of safety features to prevent unethical or false research campaigns from soliciting information on"
      }
    ]
  },
  {
    "file_path": "./devposts/ringhox.html",
    "project_id": "ringhox",
    "title": "RINGHOX",
    "tagline": "Propose with a digital ring using hand tracking as a surprise proposal",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Propose with a digital ring using hand tracking as a surprise proposal",
      "hand tracking"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Find the love also in the virtual world What it does Place the rings on fingers and create real-time wedding experiences How we built it hand tracking Challenges we ran into Accomplishments that we're proud of What we learned What's next for RINGHOX Created by Alberto Tono I work as Researcher for Stanford ( HAI Graduate Fellow and CIFE Researcher) Hannah Luxenberg"
      }
    ]
  },
  {
    "file_path": "./devposts/reservd.html",
    "project_id": "reservd",
    "title": "Reservd",
    "tagline": "Offering Contactless Pickup. Faster for them, Smarter for you.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "python",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/255/507/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration In today’s digital world, students arriving at college carry fewer belongings, knowing they can buy whatever they need, but buying new items all the time can be wasteful and expensive. They could borrow items or buy or get it free from someone local, but they don’t always have the time to meet in person to make the exchange. Having lockers to facilitate this exchange is not a new concept, but how we use them is. What it does Similar to Amazon Hub, we offer an IoT Smart Locker System that allows people to exchange items in a clean, secure, safe, and contactless way. Unlike what currently exists, we implemented 3 factor authentication to ensure that the right items go to their intended recipient. Reservd allows people to find, rent, and unlock lockers at their convenience, without the hassle of a burdensome administrative process or without having to pre-determine the need or use and commit to a specific locker for a long period of time, we increase efficiencies and provide safe, clean, contactless pick-up options for recipients around the clock. And all you need is your phone to do all this. How we built it We use React Native for the mobile interaction, Google Cloud Platform to facilitate triggered actions and object detection, and a lot of hardware to make the actual locker. Challenges we ran into Time is the biggest challenge, and with spotty wifi, it slowed our progress further. Accomplishments that we're proud of We made a working IoT smart locker!!! What we learned With a background in React, we just picked React Native. For some of us, we had never worked with hardware, so we learned a lot about soldering and different tools needed to facilitate interactions. We also learned about designing endpoints. What's next for Reservd Implementing blockchain for further security and on a campus or in a small community! Built With expo.io python react-native Try it out GitHub Repo Submitted to HackHarvard 2022: Control, Alt, Create Created by Munt"
      }
    ]
  },
  {
    "file_path": "./devposts/riotbot.html",
    "project_id": "riotbot",
    "title": "RiotBot (Team Fried Eggs)",
    "tagline": "RiotBot",
    "hackathon": "",
    "built_with": [
      "discord",
      "javascript",
      "node.js",
      "tensorflow.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "SF Hacks 2022WinnerMost Creative Use of GitHub",
      "Tracks: Mental health, AI",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/870/268/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration We took the inspiration of this project from game stats viewer websites and Discord bots where people get to view their gaming information from inputting commands for Discord bots. We took both ideas and combined the two which allows this bot to be very useful in league of legends communities on discord (as the community is pretty toxic). Tracks: Mental health, AI What it does The discord recognizes a list of commands where users can view champion and game statistics. This covers a wide range of topics which users may be discussing about in a typical gaming server. In addition to displaying data, RiotBot helps maintain a healthy environment by using AI (tensorflow) to identify and delete toxic posts from users. How we built it The bot is written in Javascript using DiscordJs for registering the commands and performing its actions. The toxicity detection feature used a third party api called TensorflowJs which is an AI library that helps detect whether a set of text is toxic. Challenges we ran into As this was our first time making a discord bot, we ran into many challenges. Since the running code is directly associated with the bot that is online, two people running the code simultaneously on different devices resulted in weird outputs from the input. Accomplishments that we're proud of Generally, we are proud of making a bot which can help out with a variety of tasks as a complete beginner. The feature to showcase data while helping moderate the channel all packed into one bot seems like a decent accomplishment. What we learned We learned how to create a discord bot using DiscordJs and TensorflowJs. Built With discord javascript node.js tensorflow.js Try it out GitHub Repo Submitted to SF Hacks 2022 Winner Most Creative Use of GitHub Created by Ryan Lam UWaterloo Physics Jax Wang uwo 24' intermediate FE"
      }
    ]
  },
  {
    "file_path": "./devposts/revrewards.html",
    "project_id": "revrewards",
    "title": "RevRewards",
    "tagline": "As a fun project to bring a creative hack to local businesses, we introduce Reveille Rewards: a  loyalty app that unleashes the power of small businesses, the people who truly drive our communities!",
    "hackathon": "",
    "built_with": [
      "axios",
      "chakraui",
      "django",
      "google-maps",
      "html/css",
      "postgresql",
      "python",
      "react",
      "tesseract",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for Small/Local Businesses Created by I worked mostly on the frontend with React",
      "Best Hack for Small/Local Businesses Created by I worked mostly on the frontend with React",
      "HowdyHack 2023WinnerBest Hack for Small/Local Businesses",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/582/280/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Small Business Spotlight - Used ChakraUI grid to showcase small businesses, click takes customer to each respective business's site Registration Page Login Page Small Business Map - used google maps api to mark small businesses on custom map, popup with business name shows when marker is clicked Receipt Recognition Software - used duplicate rejection and text parsing with Tesseract OCR Aggie Merch Incentive Shop - Use TamuTokens gained from shopping at small businesses to purchase A&M merch; progress bar implemented Purchase Confirmation Page - collected email and address to ship merch; deducted tokens from current balance Small Business Spotlight - Used ChakraUI grid to showcase small businesses, click takes customer to each respective business's site Registration Page Login Page Small Business Map - used google maps api to mark small businesses on custom map, popup with business name shows when marker is clicked Receipt Recognition Software - used duplicate rejection and text parsing with Tesseract OCR Aggie Merch Incentive Shop - Use TamuTokens gained from shopping at small businesses to purchase A&M merch; progress bar implemented Purchase Confirmation Page - collected email and address to ship merch; deducted tokens from current balance Small Business Spotlight - Used ChakraUI grid to showcase small businesses, click takes customer to each respective business's site 1 2 3 4 5 6 7 8 Inspiration In general, small businesses have a hard time gaining recognition. While we have been doing a better job promoting and supporting them in the past few years, there is still more work to be done, as they are just as valuable as our larger franchises. This inspired our team to create a project that helps these businesses thrive and rewards customers for shopping at said businesses. We are proud to introduce Reveille Rewards! What it does Reveille Rewards is a platform that encourages users to shop at local small businesses by offering a rewards system. Users can discover ne"
      }
    ]
  },
  {
    "file_path": "./devposts/rock-hand-s6yatq.html",
    "project_id": "rock-hand-s6yatq",
    "title": "Rock Hand",
    "tagline": "Like Rock Band, For and With the Deaf and Hard of Hearing Community",
    "hackathon": "",
    "built_with": [
      "c#",
      "mediapipe",
      "opencv",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility to Technology Created by Anita Yip Product owner, project manager, retired hackathon-",
      "Hack with Us - TechNova 2022WinnerAccessibility to Technology",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/205/862/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration There's a huge misconception that the deaf and hard of hearing can't enjoy music. They feel music through vibrations and derive the same joy from it as a hearing person would listening to music. Video games are notoriously not accessible to everyone, including for the deaf and hard of hearing, as games rely on sound cues without the addition of visual cues or even closed captions. There are a lot of social games that bring people together and create memories, and there are educational games that are fun but have little replay value after mastering knowledge. But can there be a social and educational video games that can bring the hearing and deaf/hard-of-hearing communities together in ways they haven't before? That's why I came up with Rock Hand. What it does It takes all the fun and social elements of Rock Band, no longer requires hardware additions, and adds an educational twist. Instead of learning how to play various instruments, you learn how to sign various words curated from song lyrics while jamming to music we all love. How we built it I used Unity and C# to build the game. The sign language translation was done using opencv, mediapipe, and python (libraries). Challenges we ran into I started out with a team of 4 but ended up going solo (!) because the team disbanded.  Consequently, there were time constraints for implementing everything desired, so I had to stick to the essentials. One of the biggest challenges was figuring out how to unify two desired features into one cohesive product. Accomplishments that we're proud of I did it all - the design, the game, the pitch in a sleepless day's worth. I didn't give up! What we learned Don't quit - you never know what will happen. The experience is the experience - just live and learn and you'll be fine. What's next for Rock Hand Simply finesse - taking time to implement the entire interface in a less time constrained scenario. Built With c# mediapipe opencv python unity Submitted to Hack with Us - "
      }
    ]
  },
  {
    "file_path": "./devposts/risk-assessment-tool.html",
    "project_id": "risk-assessment-tool",
    "title": "Live Secure",
    "tagline": "LiveSecure redefines AI in real estate, insurance, and travel. With risk assessments, real-time alerts, safety scores, and LeBron James chatbot, we deliver smarter decisions, safety, and convenience.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "css3",
      "html5",
      "javascript",
      "nextjs",
      "python",
      "sql",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/237/323/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The idea for LiveSecure stemmed from recognizing the untapped potential of live CCTV footage. Existing systems rely heavily on manual monitoring or static object detection models, which limits their ability to adapt to dynamic situations. We were inspired to create a system that uses AI to transform CCTV feeds into real-time actionable insights for individuals, businesses, and travelers, solving real-world problems in security, real estate, insurance, and travel safety. What It Does LiveSecure is a versatile platform that: For Users: Acts as a real-time security tool, detecting custom and predefined events (e.g., “masked man near a fence”) and sending instant alerts through Telegram or mobile notifications. For Businesses: Provides risk assessments for specific areas, using live CCTV feeds within a defined radius to generate safety scores for insurance and real estate decision-making. For Travelers: Offers personalized itineraries, real-time safety scores, and updates for cities, ensuring secure and hassle-free travel experiences. Entertainment: Features a LeBron James chatbot to blend technology with engaging, user-friendly experiences. 5. We utilize two of the APIs for verifying the user details like the address and the phone number. How We Built It Backend: Built using an RTMP server to process live CCTV streams, chunking them into 30-second intervals. We utilized the Marengo 2.7 model to analyze these chunks and generate vector embeddings for event detection. Frontend: Designed intuitive dashboards for users and businesses, equipped with interactive maps and search functionalities. AI Model: Enabled natural language queries, making event detection fully customizable without the need for retraining. Alert System: Integrated a Telegram bot to provide real-time notifications for detected events. Travel Assistant: Developed a chatbot with safety scores and personalized travel itineraries using data insights from CCTV feeds. Challenges We Ran Into Rea"
      }
    ]
  },
  {
    "file_path": "./devposts/robber-ducky-ai.html",
    "project_id": "robber-ducky-ai",
    "title": "Robber Ducky AI",
    "tagline": "\"The best way to learn, is to teach it yourself\"",
    "hackathon": "",
    "built_with": [
      "github",
      "node.js",
      "openai-api",
      "react",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "\"The best way to learn, is to teach it yourself\""
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/345/081/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Demo2 Demo1 Demo2 Demo1 Demo2 1 2 Inspiration \"The best way to learn is to teach it yourself.\" We were inspired by the recent influx of interest in conversational AI models, notably due to ChatGPT. Rather than learning through asking questions, however, we wanted to introduce a platform where you learn through answering questions. What it does Our project helps people from all different backgrounds, from students to educators to professionals, to have a in-depth learning experience where we the goal is to not just know, but to understand. Through our chatbot model, users can learn by first inputting an explanation of the topic. The chatbot then responds with a question in order to prompt the reader into explaining more. How we built it Utilizing the resources and workshops provided by TreasureHacks, we were able to gain valuable insights on how to get started with building our project. We used a variety of technologies such as the JavaScript React library for the front-end development and OpenAI API for our conversational model. Challenges we ran into When working with our team members, we were all in different time zones, which means we all had different working hours and sometimes response times could be slow, making coordination difficult. We also had different skills, which initially posed a challenge since we had to figure out how to delegate tasks across our team. Due to time constraints, we are not able to provide a video. Accomplishments that we're proud of We overcame multiple hurdles, such as learning how to organize our workflow based on the different skills we all had in order to work together efficiently. We looked into topics we weren't familiar with and learned as much as we could in the given time period. What we learned We learned that when dealing with a conversational model, we need to use large amounts of training data to continuously evaluate and improve a chatbot's performance. We can also monitor user interactions to help identify any issues w"
      }
    ]
  },
  {
    "file_path": "./devposts/ridebuddy.html",
    "project_id": "ridebuddy",
    "title": "RideBuddy",
    "tagline": "Carpool easily with RideBuddy!",
    "hackathon": "",
    "built_with": [
      "blockchain",
      "css",
      "figma",
      "html",
      "javascript",
      "polygon",
      "react",
      "solidity",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Created by I worked on the UI/UX design and frontend of the app",
      "First Place Overall Created by I worked on the UI/UX design and frontend of the app",
      "MagicHacks 2WinnerFirst Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/543/131/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Anupam worked on the backend while Michelle and Jamie worked on the UI/UX design/frontend. Inspiration The inspiration behind creating RideBuddy was to address the inefficiencies and challenges faced in the traditional ridesharing industry. We recognized that many existing ridesharing platforms suffer from centralized control, high commission fees, lack of transparency, and limited user data protection. To overcome these issues, We decided to leverage blockchain technology to build a decentralized and transparent ridesharing app called RideBuddy. What it does RideBuddy is a ridesharing blockchain app that allows users to connect directly with drivers in a peer-to-peer manner. It facilitates the sharing of rides and transportation services without the need for intermediaries. Here are some of the main features of RideBuddy: Decentralized Platform: RideBuddy operates on a blockchain network, which means there is no central authority governing the platform. All transactions and interactions are recorded on the blockchain, ensuring transparency and security. Peer-to-Peer Ridesharing: RideBuddy enables riders and drivers to connect directly, eliminating the need for a middleman and reducing commission fees. Users can negotiate terms and payment within the app. Secure Payments: The app uses cryptocurrency or a digital token for payments. This ensures fast, secure, and borderless transactions, while protecting sensitive financial information. Smart Contracts: RideBuddy implements smart contracts to automate and enforce the terms of each ride agreement. These contracts execute when predefined conditions are met, providing a trustless environment for users. Reputation System: To establish trust among users, RideBuddy features a reputation system that allows both riders and drivers to rate and review each other after each completed ride. How we built it The development of RideBuddy involved multiple stages: Conceptualization and Planning: We brainstormed the idea of a dec"
      }
    ]
  },
  {
    "file_path": "./devposts/riski.html",
    "project_id": "riski",
    "title": "Riski",
    "tagline": "Riski is a risk management tool that allows you to assess the risk in a portfolio. The risk algorithm is a system of weights. API calls to gain live data from the US Bureau of labor and statistics.",
    "hackathon": "",
    "built_with": [
      "json",
      "python",
      "requests",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "TAMUhack 2023WinnerGoldman Sachs Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/361/498/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Challange Riski is a product of the Goldman Sachs Challenge which was to \"build a risk analysis tool that someone would use when considering how to manage and invest their money.\" What it does Riski takes in your portfolio data and analyses it. It used real-world statistics, that are fetched from API's , to calculate a risk score. The risk algorithm is a system of weights combined with your portfolio's values and percentages. For stocks, the risk is based on their beta and their percent in your portfolio. Unemployment, interest rates, stocks and bonds, and diversification . The challenge asked us to incorporate one other way to calculate risk and for that what better than diversification?  We decided to do this due to how diversification is one of the largest factors that play into risk. Diversification can be seen in risk by messages telling you whether you are over-invested in certain assets and can also be seen in the pie charts Riski creates for you. How we built it We built it using python, tkinter, PIL, requests, finance, and many more. Challenges we ran into One challenge we ran into was later development with the UI. Unfortunately after creating a large UI in our selected software the program took a long to open and made the debugging process challenging. Accomplishments that we're proud of We are really proud of the fact that we created a complete and working risk management tool within 24 hours.   The use of API's and real-world data factored into our risk calculations is also something to be proud of. What's next for Riski We plan on re-making Riski in a multi-platform system such as React.js so we can adapt it to a website and an app. We also plan on improving the risk algorithm and adding more factors that play into it. Built With json python requests tkinter Try it out GitHub Repo Submitted to TAMUhack 2023 Winner Goldman Sachs Challenge Created by Lucian Chauvin Soham Nagawanshi"
      }
    ]
  },
  {
    "file_path": "./devposts/rollyai.html",
    "project_id": "rollyai",
    "title": "RollyAI",
    "tagline": "RollyAI allows communities to convert Telegram chats into responsive websites instantly without needing specialised knowledge, empowering them in disseminating information to a large population.",
    "hackathon": "",
    "built_with": [
      "daisyui",
      "firebase",
      "next.js",
      "ngrok",
      "react",
      "tailwind.css",
      "telegrambotapi",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "learning new languages for the first time",
      "we learnt for to link to firebase for the first time"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/343/945/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Feedback Confirmation Page Website Overview Subscribe Feature Comment Feature Feedback Option Log In Page Feedback Confirmation Page Website Overview Subscribe Feature Comment Feature Feedback Option Log In Page Feedback Confirmation Page 1 2 3 4 5 6 7 Inspiration On one fine day, at the Deck canteen, I was casually queuing for a spaghetti with spinach and an egg hoping to fill my already starved stomach after a long CS2100 tutorial, I realised to my dismay that I had lost my wallet. Hence, I went to the NUS Lost and Found Telegram group chat and saw that there were many messages flowing into the group chat. Hence, I had to repeatedly scroll to find the item I lost as it was drowned in hundreds of messages. Thus, I wanted to create a telegram bot which effortlessly converts into a responsive website with good UI design for easy access and use. What it does The telegram bot, RollyAI which with a touch of a button, seamlessly creates a website with a compiled lists of items that were lost and found. The website also has a great UI design which allows one to search for items that were found that are tagged and the post would also include a button which opens a direct message to the person who found the item. This creates a lot of convenience for those who lost their items and allows seamless transactions of items. How we built it For frontend development, we used react and tailwind css to create the cards which are the compiled data from the telegram chat. We also created a subscribe button at the top right corner so that one can be immediately notified when the item they are looking for is posted in the chat. A feedback button is also made at the bottom of the website so that we can update and make any changes in the future. To compile the data, we linked the data from the chat to Google Firebase where the website retrieves the data. Challenges we ran into time constraints sleep constraints trying to navigate the Telegram bot API without prior experience was painful c"
      }
    ]
  },
  {
    "file_path": "./devposts/roam-8qw7xk.html",
    "project_id": "roam-8qw7xk",
    "title": "Roam",
    "tagline": "Roam free with accessibility",
    "hackathon": "",
    "built_with": [
      "ai",
      "api",
      "ejs",
      "express.js",
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "WaffleHacks 2023WinnerHonorable Mention for Use of Data",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/515/833/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "API Result API Frontend Image Options API Result API Frontend Image Options API Result 1 2 3 4 5 API Video Link Inspiration Roam is a mobile app that targets those with disabilities. Although there are many apps that aid those was disabilities, they typically focus on only one type of disability or have very limited features. In Roam, we combined multiple apps into one that provides those the opportunity to navigate through their everyday lives while being able to filter for places that offer accessibility services. This is not only targets those with visual or hearing impairments, but also those with communicative disorders. Users can plan out their day with our daily itinerary or read reviews from other users. What it does Roam caters to a variety of disabilities, such as visual impairments. For this disability, we implemented a Dark mode, a Larger text option, and added an AI tool that can describe anything the user points its camera to. For those with communicative disorders, we added a tool to speak with a microphone, translate text, or plan out their day. Some things we also paid attention to were color, font legibility, and the use of icons to convey information for varying types of disabilities. Our API built on Express.js offers users the flexibility to upload images from various sources, including their personal computer, a URL, or even directly from their camera. Regardless of the image's origin, our system ensures a seamless experience for the user. Once the image is obtained, our AI model kicks into action,  to examine the visual content thoroughly. By analyzing the image's attributes, objects, scenes, and colors, the model generates a comprehensive and accurate description of what the image represents. How we built it We first built our project in Figma and worked collaboratively in Figjam to ideate possible solutions, competition, and develop user personas. From there, we designed sketches and eliminated certain features through low fidelity, mid fide"
      }
    ]
  },
  {
    "file_path": "./devposts/rock-paper-scissors-sz4oc5.html",
    "project_id": "rock-paper-scissors-sz4oc5",
    "title": "Rock Paper Scissors",
    "tagline": "Bored? Play rock paper scissors with me!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I was able to build my very first working site."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/790/020/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "This is how my website looks ;))) What it does A spinning wheel that will randomly select an option on click. How we built it This was built using HTML, CSS, Javascript Challenges we ran into Being a beginner to web development I had to refer a lot of sites online and watch a handful of videos. Accomplishments that we're proud of I was able to build my very first working site. What we learned I learnt to make and actual working page using Js. Built With css3 html5 javascript Try it out GitHub Repo aakanksha-rangdal.github.io Submitted to Local Hack Day: Build Day 2 Created by Aakanksha Rangdal"
      }
    ]
  },
  {
    "file_path": "./devposts/rogers-continuous.html",
    "project_id": "rogers-continuous",
    "title": "Rogers Continuous - Team Barns",
    "tagline": "Providing quick and accessible self-serve customer support through the use of cutting-edge augmented reality technologies",
    "hackathon": "",
    "built_with": [
      "arcore",
      "c#",
      "flask",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/849/996/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration With technology becoming ever more present in our day to day lives, it’s inevitable that people will run into technical difficulties. The current solutions of calling customer support and having someone visit you is both time consuming for customers and costly for companies. What if we could provide in-home support some other way? What it does By using augmented reality, we have created an app that guides users through a step by step process of how to fix their technical problems. By scanning a QR code, our app will both diagnose and solve their problems. Users can see a virtual version of their hardware and find directions of how to solve the issue at hand. How we built it Rogers Continuous is built with Unity and used Vuforia Engine to power the Augmented Reality. The server we used to run router diagnosis is hosted on a Raspberry pi 3B and used Python, Flask, and C#. Challenges we ran into With little to no experience in developing AR apps, it was initially challenging in understanding the feasibility of building our app. Half of the team spent the entirety of Saturday morning looking into learning ARCore, ARkit, and Vuforia with little progress. Additionally, we faced issues with connecting Unity to our Server. Accomplishments that we're proud of Totally getting the recommended amount of sleep while working on the hack.\nGrabbing as much food as we could for dinner.\nCreating a working AR application in a weekend using Unity.\nTotally NOT leaving everything to the last minute. What we learned This project gave our whole team and incredible opportunity to learn tons about creating AR/VR applications using Unity and ARCore. For many of us, this was our first time creating a mobile application, and for all of us, this was our first time creating an AR application, resulting in a huge amount of learning for everyone in our team. What's next for Rogers Continuous The next steps include adding onto the AR functionality by improving the visual cues to diagnose"
      }
    ]
  },
  {
    "file_path": "./devposts/roni-lytics.html",
    "project_id": "roni-lytics",
    "title": "Roni-lytics",
    "tagline": "We created an analytics platform that provides dynamic interaction with data and provides predictive insights and analysis.",
    "hackathon": "",
    "built_with": [
      "pandas",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/126/472/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We were inspired by the legendary mac and cheese of Roni's and the sample dashboard provided before the hackathon. We wanted to see what we could create and how we could expand upon the preliminary analysis in the sample. What it does Our dashboard provided basic and advanced data analysis on the sample data set of Roni's. The dashboard is interactive and allows for several different views that display different metrics. How we built it We built the dashboard with python and streamlit. We hosted locally and build in an iterative process using github for version control. Challenges we ran into We ran into several problems with the way we were reading the data, which necessitated the need to transform it. No revenue data was provided so we had to compute that ourselves. Moreover, some entries were ambiguous and we had no idea how to process them. Accomplishments that we're proud of We were able to create several displays that show different statistics. What we learned We learned quite a bit about dashboard development, and honed our skills in data exploration. What's next for Roni-lytics Building more predictive models for more business insights. Built With pandas python streamlit Try it out GitHub Repo Created by praketdesai Karan Bhalla Allen Sun"
      }
    ]
  },
  {
    "file_path": "./devposts/roni-s-mac-bar.html",
    "project_id": "roni-s-mac-bar",
    "title": "Roni's Mac Bar",
    "tagline": "Analyzing and drawing insights from Roni's Mac Bar data",
    "hackathon": "",
    "built_with": [
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/129/224/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Roni-s-Mac-Bar Data Setup: For the data setup, we used google colab( https://colab.research.google.com/drive/1NTlExhqaiB9hASCAbkQ-BCL3ITSOCbJf?authuser=1#scrollTo=9xYnDbwZiJ95 ) to sort and parse the data. We only really had to concatenate the data for the nona_data.csv file but for the shirts we had to cleverly utilize pandas to parse and seperate it from the rest of the data. The colab is a little messy but we simply just used it just to get the data combined together, drop the corrupted or empty data slots, and export the final csv's we used for this project. Setup: In order to setup this project, all you need to do is go to streamlit cloud( https://streamlit.io/cloud ) and select your github and choose the repository and what file(app.py) that you want the cloud to run, and that is simply all that needs to be done to setup the dashboard. Dashboard Functionality: Using the code in app.py we created a very clean dashboard to view insights from the monthly Roni's Mac Bar data presented to us. With the use of streamlit cloud, the user will be presented with 4 graphs per section. There are 4 sections, Main insights, Additional insights, and shirt insights. Each section has a detailed Statistics tab that will summarize the key insights from all the data collected and presented by the graphs. You can hover over each graph to see the exact value presented by the x and y axis, for precise analysis. Key Insights: We conclude from the data and the graphs that from the 7 months given(October-July, 2024) Roni's Mac Bar: Total Orders: 9064 Average Orders per Day: 46.5 Busiest Hours of the Day: 12:00(11:00pm) and 19:00(7:00pm) Busiest Day: Saturday Average Items per Order: 30.1 Most Popular Item: Mac and Cheese Most commmon Modifier: Regular Month of Least Orders: July, 2024(Can be explained by college students going home for the summer) Shirt Insights We additionally included data for the merch at Roni' Mac Bar, which we find as a very important aspect of business. With this "
      }
    ]
  },
  {
    "file_path": "./devposts/room-design-mental-health.html",
    "project_id": "room-design-mental-health",
    "title": "ZenDen",
    "tagline": "Better your mental health, starting at your room. With just the a photo, ZenDen uses AI to determine how your room affects you mentally, and offers suggestions to improve it!",
    "hackathon": "",
    "built_with": [
      "dart",
      "flask",
      "flutter",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/363/217/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "✨ Inspiration People spend days, months, or even years at a time in their rooms. However, one overlooked detail about these rooms is that they might be the cause of the commonplace anxiety and stress we experience daily. Unfortunately, due to us being super accustomed to these rooms, we often don't notice. According to the Ohio State University , the interior design and layout of our rooms can affect our mental health. 🚀 What it does ZenDen uses Google’s Cloud Vision AI to analyze factors like dominant colors, light levels, objects, etc. This is then fed into an algorithm to output a score ranging from 0 to 100. Accompanied with recommendations, the user is given an analysis for aiding mental health. 🔧 How we built it For the frontend, we used Flutter to create a cross-platform(IOS + Android) app. We wrote a middleware in Python (Flask) to interface with the Google Cloud Vision API, and handle scoring calculations and lighting analysis. 💥 Challenges we ran into It was our first time using the Google Cloud Vision API. As we beginners in using AI in our apps, it was difficult to successfully incorporate it. We had issues getting the correct room colors from the API, and had to adjust some of the score weights to account for detection issues. Another major challenge was using a local database as opposed to a cloud database like Firebase. Using json to store room data locally was a minor challenge for us. However, storing images proved a major challenge. Due to Flutter caching images to a temporary file, images we stored weren’t available. We had to circumvent this by moving the image to a more permanent location and retrieving the image from there. In the last few hours of the hackathon, we noticed that the score calculations were very off. Images that we judged to be perfect were getting detected as low as 35%. We were able to fix this by utilizing the image labels as well as object detection from the Google API. 🌌 Accomplishments that we're proud of We are proud of u"
      }
    ]
  },
  {
    "file_path": "./devposts/rootstoretail.html",
    "project_id": "rootstoretail",
    "title": "rootsToRetail",
    "tagline": "Sustainable & Local",
    "hackathon": "",
    "built_with": [
      "api",
      "chatgpt",
      "firebase",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/821/267/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Cover Page Cover Page Cover Page 1 2 Inspiration We found that sometimes it may be difficult for restaurants to pinpoint the most efficient and cost-effective way to find ingredients for their business, so we came up with this app idea that helps them analyze the factors associated with finding the proper suppliers within their budget. What it does Roots to Retail aids restaurants in finding the most suitable food supplier while accounting for factors like distance, food quality, stock level, food storage and handling practices, and nutrition when deciding what supplier/ingredients they need the most. How we built it Our team used React for the front end, Firebase for the backend, as well as ChatGPT & API calls for the produce information. Challenges we ran into One of our biggest challeges was finding a good API to track local produce and groceries, some APIs have more features but were not functional. We also had to figure out a way to effective deliver the info to the user Accomplishments that we're proud of We are proud of our front-end, as we tried putting thought into how the user would interact with the website comfortably when browsing different suppliers. What we learned Time management and learning to put everything together are things we had to delve into and learn in order to complete this project. We also learned how to grow more accustomed to version control with Github. What's next for rootsToRetail It would be preferred if we put more work into incorporating the backend with the rest of the project and getting ChatGPT to be more functional within the web application. Built With api chatgpt firebase react Try it out GitHub Repo Submitted to Build4Good Created by Summer Wong Salina Teng Claire Wang Private user"
      }
    ]
  },
  {
    "file_path": "./devposts/roni-challenge.html",
    "project_id": "roni-challenge",
    "title": "Roni Challenge",
    "tagline": "We created an interactive UI that allows the manager to input a csv file and get a visual representation of the month's data. Additionally, we use ML to make predictions from the given data",
    "hackathon": "",
    "built_with": [
      "html",
      "javascript",
      "mendix",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/129/709/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Title Screen Title Screen Title Screen 1 2 Inspiration## Inspiration We were mainly inspired by the manager of Roni's who introduced Mendix to us for our front end. We also were inspired by our engr 102 classes where we learned how to display numerical charts. What it does There are two parts to our web app.\npart 1:\nOur website allows the user to input a csv file with their orders for the month and displays them in a much more readable way.  It provides key information on the most popular menu items by displaying bar graphs demonstrating how many people ordered each meat, topping, and cheese for their macaroni. This provides key insight into what the most popular menu item is allowing the owner to prepare inventory. Additionally, it has graphs regarding overall trends while also making predictions based on machine learning that is computed in part 2 Part 2: \nThis part of the website was built mostly in Python with a frontend of HTML. This part of the project goes more indepth for the overall trends. It shows the most used modifiers, busiest months, busiest days. etc. Additionally, the ML model is coded in this part and it provides a prediction over the next few months, as well as giving predicted order counts for the next 10 months. How we built it Part 1: \nThe entire thing was built using Mendix , which is a platform that allows you to do front end much quicker. Part 2:\nwe used python libraries pandas, matplotlib, numpy, sklearn, and streamlit. We used these files for our main backend and to display the information in an easy to understand format by using graphs created from matplotlib. We created our predictions using sklearn, which gives us the capability to use ML. Challenges we ran into The main challenge that we ran into was that none of us had ever done front end before. Therefore, we were at a bit of a loss on how to start. Additionally, the platform Mendix seems to heavily favor windows users over mac leading to a lesser user experience for my team (most of"
      }
    ]
  },
  {
    "file_path": "./devposts/safe-path-qfzom4.html",
    "project_id": "safe-path-qfzom4",
    "title": "Safe Path",
    "tagline": "Reroute the path around high-density crime areas to avoid hate crimes and create safer trips. (Available in NYC)",
    "hackathon": "",
    "built_with": [
      "openrouteservice",
      "openstreetmap",
      "pandas",
      "porfolim",
      "python",
      "streamlit",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Created by David Seijas Jimmy (James) Kha Caleb Hairston",
      "TransportHacksWinnerThird Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/387/583/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Example Scenario 2 Route Example Scenario 1 Example Scenario 1 Route Example Scenario 2 Example Scenario 2 Route Example Scenario 1 Example Scenario 1 Route Example Scenario 2 Example Scenario 2 Route 1 2 3 4 5 Inspiration Since the pandemic, hate crimes against Asian Americans have increased. This is unacceptable and needs to be assessed in technology, politics, and law enforcement to make an impact. What it does Instead of simply routing the most time-efficient path, our calculation also chooses the directions by avoiding heavier crime areas with an emphasis on preventing travel in regions with higher hate crimes. Our hope is this will reduce the user's likelihood of being attacked. How we built it We used police reports and crime maps to find high-density crime areas in NYC and placed them in the OpenRouteServices polygon, the stream level, to track the route. We used Twilio to text directions to the phone. Challenges we ran into We couldn't get the Auth0 to work. Accomplishments that we're proud of The intuitive design. What we learned How to use streamline. What's next for Safe Path Expand the service outside NYC and to other hate crime-heavy areas. Built With openrouteservice openstreetmap pandas porfolim python streamlit twilio Try it out jameskha-transporthacks-app-hhlzpb.streamlit.app GitHub Repo Submitted to TransportHacks Winner Third Overall Created by David Seijas Jimmy (James) Kha Caleb Hairston"
      }
    ]
  },
  {
    "file_path": "./devposts/rolodex-site.html",
    "project_id": "rolodex-site",
    "title": "rolodex.site",
    "tagline": "Beautiful business cards and mini linktree relevant projects, shared with a QR code",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/586/487/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Digital Rolodex - Premium Business Cards 🚀 Inspiration In our increasingly digital world, traditional business cards are becoming obsolete, while platforms like Linktree offer basic functionality but lack the professional polish and comprehensive features professionals need. We envisioned a solution that combines the elegance of premium business cards with the convenience of digital sharing and the security of client-side encryption. 🎯 What it does Digital Rolodex transforms how professionals share their contact information and showcase their work. It creates beautiful, interactive digital business cards that can be easily shared via QR codes. Users can: Create Multiple Cards : Build a complete rolodex of professional contacts Showcase Portfolios : Include project highlights with images, descriptions, and links Share Instantly : Generate QR codes for immediate sharing at networking events Maintain Privacy : All data is encrypted client-side - no servers, no data collection Professional Design : Apple-level aesthetics with smooth animations and responsive design ⚡ How we built it Frontend : React + TypeScript + Tailwind CSS Modular component architecture for maintainability Responsive design that works flawlessly on all devices Lucide React icons for consistent, professional iconography Security : Client-side AES encryption All user data encrypted before URL encoding Zero server dependencies - completely client-side Self-replicating QR codes that preserve data integrity User Experience : Smooth card transitions and micro-interactions Intuitive rolodex navigation Real-time preview while editing One-click QR code generation and sharing 🔧 Challenges we ran into Data Persistence : Creating a robust system for storing multiple business cards entirely client-side while maintaining security URL Length Limits : Optimizing encryption to keep shareable URLs within browser limits Mobile Optimization : Ensuring QR codes are easily scannable and cards display perfectly on"
      }
    ]
  },
  {
    "file_path": "./devposts/routez.html",
    "project_id": "routez",
    "title": "RoutEZ",
    "tagline": "Providing EZ and efficient Routez",
    "hackathon": "",
    "built_with": [
      "ajax",
      "drone",
      "flask",
      "google-places",
      "gpt",
      "javascript",
      "leaflet.js",
      "openstreetmap",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We represented a stop by counting out loud for 3 seconds before / after every bump depending on the # of stops",
      "The 3 seconds counted out loud may not be exactly 3 seconds"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/484/623/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Visualized Data of the traffic in Davis Picture of web application broken wheel fixed wheel drone car Visualized Data of the simulation Visualized Data of the traffic in Davis Picture of web application broken wheel fixed wheel drone car Visualized Data of the simulation Visualized Data of the traffic in Davis 1 2 3 4 5 6 7 RoutEZ What is it? RoutEZ is an application which uses LLMs (in the future Neural Networks) to analayze real time data of traffic to determine which of the traffic lights should be red and which should be green. In our research we discovered an average commuter to work spends around 4.7 months of their life sitting in front of a traffic light (Assuming you started driving at age 15 and end at the age of 75) so we decided to do something about it as this time is being wasted, this could potentially be someone's luxury time or even time that can be put into the economy. Turns out the city of Sydney in Australia had already done something about it by implementing the system SCATS (Sydney Coordinated Adaptive Traffic System) According to the government SCATS had resulted in 28% Reduction in travel times 25% Reduction in stops 12% Reduction in commuter costs Now the real question is if SCATS is so efficient why is not a similar protocol implemented in the US especially at hot spots such as University of California Davis. To answer this question we made our own simulation using a toy remote-controlled car and collected data on how fast the car could complete a track with the perimeter of 74' Experiment Hypothesis: Having more # of stops results in having a higher commute time We represented a stop by counting out loud for 3 seconds before / after every bump depending on the # of stops Lap Time   # of stops    \n--------------------------------\n17.80         0\n16.56         0\n17.50         0\n20.46         1\n22:05         1\n19:86         1\n23:33         2\n22:46         2\n24:02         2\n26:00         3\n25:89         3\n26:03         3 Potential flaws in da"
      }
    ]
  },
  {
    "file_path": "./devposts/rufi.html",
    "project_id": "rufi",
    "title": "RuFi",
    "tagline": "RoundUp for Impact turns spare change into investments or donations, enabling accessible wealth growth and impact for all users, with multilingual voice-enabled support for global accessibility.",
    "hackathon": "",
    "built_with": [
      "accessible",
      "and-cron-jobs-to-build-a-secure",
      "anyone-protocol",
      "application",
      "butterfly",
      "css",
      "dain",
      "data",
      "fastapi",
      "git",
      "github",
      "html",
      "javascript",
      "polygon-api",
      "python",
      "real-time",
      "singlestore-sql",
      "tailwind-css",
      "voice-integrated",
      "we-used-next.js",
      "with"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "SoCal Tech Week 2024WinnerAnyone Protocol Sponsor Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/130/369/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration RoundUp for Impact (RuFi) was born from a simple idea: that anyone, regardless of background, should have the opportunity to make a difference and grow their wealth, even through small, everyday actions. By rounding up daily purchases to the nearest dollar, RuFi empowers users to turn spare change into impactful contributions—whether toward causes they care about or investments for their future. Prioritizing privacy and accessibility, RuFi makes responsible investing and charitable giving effortless and secure, showing that financial empowerment and positive change are possible for everyone, one purchase at a time. What it does Automated Onboarding : Once users register, RuFi’s onboarding process is fully automated, with progress visible through log entries to simplify setup. Voice-Enabled Onboarding : Available on both web and mobile, RuFi’s voice-activated onboarding process ensures users can set up their accounts easily, without needing to navigate complex menus. Real-Time Financial Insights : Users can access up-to-date financial trends, news, and stock insights via chat or voice commands, helping them make informed decisions effortlessly. Flexible Algorithmic Trading: Integrated in DAIN , RuFi’s algorithmic trading options democratize complex financial strategies, enabling anyone to invest confidently. Users can also easily integrate custom trading algorithms, adding flexibility and personalization to their investment experience. Multilingual Voice Support : RuFi removes language barriers with voice support in multiple languages, making it accessible to a global audience. Privacy-First Design : Built on the Anyone Protocol , RuFi ensures privacy and security in every interaction, encrypting communication and protecting user data to provide a safe, anonymous experience. Comprehensive Website : RuFi has a dedicated website where users can access information, register, and explore all available features.\nThrough these features, RoundUp "
      }
    ]
  },
  {
    "file_path": "./devposts/rtqlit.html",
    "project_id": "rtqlit",
    "title": "RTQlate",
    "tagline": "Elevate your speech and AR-TI-CU-late your words!",
    "hackathon": "",
    "built_with": [
      "arduino",
      "assemblyai",
      "cplusplus",
      "firebase",
      "flask",
      "openai",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Real-time eye-tracking to measure eye contact",
      "This was our first time working with speech analysis, we learned how to use AssemblyAI!",
      "First time working with account authentication with Firebase",
      "Also some of our first times working with a Python server (Flask)",
      "Our first hardware hack!",
      "Combining the data from the eye tracking and the speech analysis to give an overall score"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/771/691/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Video demo: https://drive.google.com/file/d/1MmmLX3Pf4cuSbbscgkJjEWgz4qH2dfGu/view?usp=sharing Inspiration Fall is the time to get your shit together. It brings the academic pressures with the onset of the school year, as well as a new recruiting season! But since you were slacking off and relaxing in the summer, you now realize it's been a long long time since you last practiced your speaking skills. Suddenly the fall season is throwing all these school presentations, job interviews, and other super-important speaking situations right at you and you've totally forgotten how to articulate your words! Introducing... RTQlate! (AR-TI-CU-late) What it does RTQlate is a 5-feature speaking assistant and feedback provider: Auto-summarized flashcards in the convenient form of a physical wearable Real-time eye-tracking to measure eye contact Playback and audio transcription Sentiment analysis Enunciation and clarity level indicator How we built it The flash card bullet points are displayed on an LCD display, built using Arduino and C++. A push button is used to flip through the cards. These points are automatically summarized by our OpenAI API. We track the motion of your eyes using the GazeTracking library to monitor whether your eyes are looking away from the screen or not. We used AssemblyAI to accomplish audio transcription, clarity detection, and sentiment analysis. Firebase is used for email authentication for account logins and signups. The backend server is written in Python Flask The frontend is written in React and styled with Tailwind CSS Challenges we ran into Choosing a topic relating to the four seasons (😰) Connecting all the components (i.e. a functional frontend, backend, and Arduino piece) together Accomplishments that we're proud of Completing a working app with a functional hardware component! Figuring out how to use AssemblyAI for sentiment analysis Learning how to track eye movement with the limited resources that were available online Having a n"
      }
    ]
  },
  {
    "file_path": "./devposts/rubiking.html",
    "project_id": "rubiking",
    "title": "RUBiking",
    "tagline": "Making lending bikes convenient for RU students",
    "hackathon": "",
    "built_with": [
      "android",
      "java"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/615/076/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "My Bookings Homepage Booking List Map My Bookings Homepage Booking List Map My Bookings 1 2 3 4 5 Inspiration Many students want to commute around the Rutgers campus; however there are a couple of reasons why this is difficult: Very expensive to buy vehicle and equipment, hard for commuter students to bring their vehicles to campus Difficult to find places to store the bike safe The bus system is not effective for students due to high traffic Health benefits by having students move around more outside and having a more active day What it does This is a vehicle lending service that focuses on bikes that allows users to share their vehicles for specified periods of time and check out other vehicles. How we built it Android Studio and Java Challenges we ran into Merging each others work into one application Relearning parts of Java syntax Debugging UI components in Android Accomplishments that we're proud of Learning Android Studio in 24 hours Working as a team on this large projeect Having fun and learning while failing in some ways What we learned Making a large scale Android project using Java and how to create components How to use Git collaboratively How to use GitHub properly Parsing and organizing XML files for the UI components What's next for RUBiking Finishing the core functionality Adding more vehicles Providing more methods of contact between users Potentially expanding to other schools Presentation: https://www.youtube.com/watch?v=TZ_ai3ZIuXg&feature=youtu.be Demo: https://www.youtube.com/watch?v=kxS87HjXU9o Built With android java Try it out download.rubiking.tech GitHub Repo Submitted to HackRU Fall 2023 Created by Worked on the artboards of the design, and the backend of the project. Coded the classes used to store the data for the vehicles and current bookins. Darsh Patel Aneesh Maganti sunnyapatel267 Patel"
      }
    ]
  },
  {
    "file_path": "./devposts/safeschool-za9ivs.html",
    "project_id": "safeschool-za9ivs",
    "title": "Safe School",
    "tagline": "Automating the attendance system to save student and staff lives",
    "hackathon": "",
    "built_with": [
      "css3",
      "flask",
      "html",
      "javascript",
      "machine-learning",
      "mongodb",
      "postgresql",
      "python",
      "react-js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/167/175/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration SafeSchool solves two major issues: A security issues which is that school faculty doesn't know who is entering the school and an attendance issue. The school attendance system has stayed relatively the same for generations. It is the classic, student comes to class, teacher calls name, student raises hand, teacher registers attendance and BOOM! Their attendance has been taken. This ancient technique has become obsolete in the modern times due to its lack of productivity. It is a HORRIBLE way of doing things because of its lack of efficiency and now because of COVID, human contact health risk. We decided to solve this problem by creating Safe School, a revolutionary way of taking the attendance that lets students take their own attendance using machine learning. What it does Safe School is a web application that utilizes machine learning to create social change by saving student and staff lives in our local and global schools. It does this by letting students safely admit themselves into classes in the morning or if they arrive late to school. The current norm for students to be admitted to class if they come late is to go to the attendance office and scan their id. This requires constant contact with the person in charge of attendance and a delay for students to arrive at class. This lack of productivity puts lives at danger and creates unnecessary risk. With our application, students can just sign in by taking a selfie of themselves, and a one time pass will be provided for students to show to their teachers. As you can see from trying out our website, first the student will need to login or create an account, then they will be greeted to a dashboard showing their statistics, then they will be at they will go to the capture page where they will take a picture of themselves and our ml model will capture them and finally add their status to the database. On the website, the student can also edit their profiles and look at the project's links. From the te"
      }
    ]
  },
  {
    "file_path": "./devposts/safe-bite.html",
    "project_id": "safe-bite",
    "title": "Safe Bite",
    "tagline": "An application that promotes accessibility equality for individuals with diverse dietary needs",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/623/188/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Restaurant Search Home page Restaurant Choice Filtered Menu Items List of Restaurant Restaurant Search Home page Restaurant Choice Filtered Menu Items List of Restaurant Restaurant Search 1 2 3 4 5 Inspiration Dietary restrictions and allergies make our community more diverse. However, equality is not shared between people with allergies and people without. It is unfair that people with allergies need to spend an extensive amount of time, effort, and worry to safely explore the universe of flavors. We are inspired and motivated to promote equality within our community. What it does Safe Bite is a platform that bridges info gaps between producers and consumers. Users can input their dietary restrictions at a specific restaurant to receive an output of every dish they can or cannot eat. Restaurants can input their dishes and ingredients without revealing their recipes;  this process will keep the restaurant's information private and also notify if the user is eligible to eat. How we built it Our backend was built in Python with the Flask framework, along with our frontend built with HTML, Javascript and CSS. The restaurant’s data was stored within json files that are accessible through the backend. Through the development stage, we ensured that the website was user friendly so that it is accessible for everyone. Challenges we ran into Retrieving data through the backend, and being able to integrate it though our frontend Finding data for restaurants database (json files) Some of us are relatively new to Git, and so it was challenging wrap our head around it Finding a unique project idea took us a lot of time Accomplishments that we're proud of As a high school team that is new to many new languages and frameworks we used, we managed to learn and assist each other as a team during our process of project making and successfully built a project that we are proud of. Debugging error and researching solutions in the given time frame What we learned Use of git and flask in "
      }
    ]
  },
  {
    "file_path": "./devposts/sal-swims-against-the-tide.html",
    "project_id": "sal-swims-against-the-tide",
    "title": "Sal Swims Against the Tide",
    "tagline": "An easy-to-digest and interactive introduction to climate change issues",
    "hackathon": "",
    "built_with": [
      "bluewillow",
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Digital Storytelling Art Category Created by Collaborated on the story and coded the interactive we",
      "MEGA Hackathon 2023WinnerDigital Storytelling Art Category",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/455/489/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "For Digital Storytelling for Good w/AI Inspiration Our idea started out with fairytales as a means of introducing a heavy topic, such as climate change, in a way that is easy to understand and digest. Fairy tales and cartoons are impactful to all people, especially the younger generation, and so we decided to create a fairy tale of our own about Sal the Salmon who experiences the effects of climate change on his swim upstream through his river home. What it does Sal Swims Against the Tide is an interactive \"fairy-tale\" story that follows the adventure of a Salmon named Sal on his way back upstream through his river home. It introduces the effects dams have on river habitats and includes two interactive activities. The first interactive activity is a scavenger hunt-themed slide that shows multiple effects climate change can cause, all of which are covered in the last scene in depth.  Our goal for Sal Swims Against the Tide is to reach out to people and raise awareness for the effects of climate change in an effort to inspire and help people band together to make a change against this pressing issue. How we built it We built the interactive story with HTML, CSS, and JavaScript. The images were generated using BlueWillow. Challenges we ran into We originally started with the idea of fairytales and merging fictional worlds to fight against a more widespread and devastating challenge called climate change. However, it was hard to explain succinctly and implement the original vision while learning and relearning how to code. Additionally, we faced the challenge of building a story that could reach all ages, show the impacts of climate change in a long-term view, and broach the heavy topic of climat change without boring or turning people off. We also started working on a scrapbook at the end, but it required some additional work and time, so we had to pivot and show a slider with real-world examples that were learning extensions of the original story. Accomplishments that"
      }
    ]
  },
  {
    "file_path": "./devposts/sanguine.html",
    "project_id": "sanguine",
    "title": "Sanguine",
    "tagline": "Revitalizing sad, angry or fearful people with inspiring quotes (some made in-house from our friend Turjo!)",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "jquery"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Sanguine Revitalizing sad, angry or fearful people with inspiring quotes (some made in-house from our friend Turjo!) Built (with a lot of pain) with HTML, CSS, Javascript, jQuery and a lot of pizza. Built With css html javascript jquery Try it out GitHub Repo Submitted to Local Hack Day IV Created by Raiyan Sayeed Amman Waheed Turjo Rafid"
      }
    ]
  },
  {
    "file_path": "./devposts/safepath-ykpu5x.html",
    "project_id": "safepath-ykpu5x",
    "title": "SafePath",
    "tagline": "Using multimodal AI to put independence back in the hands of blind people.",
    "hackathon": "",
    "built_with": [
      "flutter",
      "huggingface",
      "openai",
      "opencv",
      "openml",
      "python",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/858/450/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Social Push There are 43 million blind people worldwide and 1 million in the U.S, alongside 250+ million suffering from severe vision impairments. The World Health Organization estimates that these impairments result in $411bn in annual productivity losses and experts have placed the market for vision-related assistive technologies at $4.2bn with a projected annual growth of 13.1%. Personal impetus From a personal lens, Aksh grew up in rural India, which has the highest density of vision-related illnesses. With this perspective, he connected with Maya, who suffers from visual impairment, along with many others in her family. This project offered them an opportunity to contribute back to a community that had shaped them. Market Opportunity Despite the large market, modern assistive tools are primitive and limited.  Screen readers, braille displays, and speech recognition software, although useful textual inputs, are often bulky/immobile and fail to capture the full spectrum of visual stimuli we are exposed to. SafePath hopes to unlock blind people's lives in these two dimensions. Timing We've seen two parallel movements in the last 2 years: the shift towards powerful generative AI systems and increasing funding towards more powerful edge devices like mobile phones, glasses, etc. The first enables unparalleled generalization of models on images/textual inputs it has never seen before. The second is opening new frontiers for a seamless user-experience, with our ultimate goal being to deploy our technology onto a frame of glasses. Why Us? First, we lower blind people's costs drastically, from a few thousand dollars for current products to around $50/month for our app, and secondly, our app provides a mobile solution that allows them to engage with their environment seamlessly without needing external help. What it does Our backend features our ML suite, ApolloVision, which serves a suite of low-latency vision models and a powerful multi-modal model to se"
      }
    ]
  },
  {
    "file_path": "./devposts/sampleasy-musichat.html",
    "project_id": "sampleasy-musichat",
    "title": "SamplEasy MusiChat",
    "tagline": "SamplEasy finds less obscure songs according to the needs of aspiring music producers for music sampling. It also has a chat feature to bring musical talents together, to create a more musical world.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "mongodb",
      "python",
      "spotifyapi",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/023/729/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What do Kanye’s All Falls Down, Dua Lipa’s Love Again, and Beyonce’s Break My Soul have in common? They’re all critically acclaimed songs– that recycle sounds from less popular songs! This practice, called sampling, is an essential tool for record producers, especially in the dominant genres of pop and hip hop. But, aspiring producers (like Eric on our team) just don’t have the money to buy the rights to sample popular songs and are always looking for more obscure records that’ll set their music apart from the crowd. Unfortunately, most applications only show the most popular songs. We wanted to empower aspiring producers like Eric to have the smoothest sailing journey in finding the right type of records to sample. Furthermore, we wanted to take this idea one step further. Talent is everywhere but opportunity is not. Eric also finds difficulty in meeting other people like him and sharing musical ideas. We want to foster a community for aspiring producers like him, who aren’t lucky enough to have the connections. By doing so, we create a more interconnected world where music production becomes much more accessible, and the world gets to meet more awesome music to rock-n-roll! What it does The user can ask the app to generate songs with important information like its tempo, genre, popularity, and music key. This allows aspiring artists like Eric to easily find the songs he wants to use to make music samples. Users only need to have a Spotify account, and they can play the songs right on the web app, and save songs on spotify. To allow more aspiring music artists to connect and inspire one another, our app provides a simple messaging platform that’s as simple as a click away. Users can choose to connect with others and start chatting with them. Since a web app is generally less accessed compared to phone applications, we chose to remind users by sending a notification message right to their phone when someone contacts them via the web app. Furthermore, use"
      }
    ]
  },
  {
    "file_path": "./devposts/safelynk.html",
    "project_id": "safelynk",
    "title": "SafeLynk",
    "tagline": "Explore Safe Links on the Web with SafeLynk 🛡️🔗",
    "hackathon": "",
    "built_with": [
      "ai",
      "chrome",
      "collab",
      "css",
      "gcp",
      "html",
      "javascript",
      "mutex",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most Fun or Unique Hack Created by Angela Qui angelagaylequi@gmail",
      "DivHacksWinnerMost Fun or Unique Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/683/672/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Inspiration The COVID-19 pandemic has caused an immense amount of change to our daily lives. What it does Extracting the quality index of the links shared (Take that as quality metrics which determines the safety & health of the link) How we built it For building the extension interface, we've used HTML, CSS & JavaScript. We've used IPFS (Inter-Planetary File System) to deploy the media first and then share it into logbox. Challenges we ran into 😤 Sleep is very important! Jokes apart, tbh a lot of things, both summed up in technical & non-technical sides. For the technical part, we did face some serious issues while we're finetuning the hyperparameters. Accomplishments that we're proud of With our team hacking from all around the world, we faced an initial challenge of working with varying time zones which made it difficult to find common meeting times. Despite it, we were able to make compromises and still delegate tasks that we could do during our respective times on the weekend. Working with new technologies and learning the ropes on how to make a Chrome extension was also initially a challenge but with teamwork, we were able to implement and complete our project. What we learned A lot of things, both summed up in technical & non-technical sides. For the technical part, we faced a lot of serious issues in form of errors as we were integrating modules. Not to mention, Stackoverflow was the gem for us while we're troubleshooting some complicated issues late-night. What's next for SafeLynk We just really want this project to create a real positive impact on humanity. Note — API credentials have been revoked. If you want to run the same on your local, use your own credentials. Built With ai chrome collab css gcp html javascript mutex python pytorch Try it out GitHub Repo Submitted to DivHacks Winner Most Fun or Unique Hack Created by Angela Qui angelagaylequi@gmail.com Elaine Su Jun Hong Pratyay Banerjee Trying to learn how to learn ;)"
      }
    ]
  },
  {
    "file_path": "./devposts/savannahdatavisualization2023.html",
    "project_id": "savannahdatavisualization2023",
    "title": "SavannahDataVisualization2023",
    "tagline": "SavannahDataVisualization aims at optimization of social media platform in marketing of services and sales of products.",
    "hackathon": "",
    "built_with": [
      "matlab",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/676/780/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Savannah Analysis Inspiration The quest to find best market practices to the Asian market What it does Savannah Data improves marketing of services and sale of products for organizations to consumers How we built it We built it with 2D subplot. Challenges we ran into Scaling to 3D plots Accomplishments that we're proud of Creative summaries through line chart, pie charts and bar charts What we learned Data Visualization and Big Data analysis What's next for SavannahDataVisualization2023 Piloting of the prototyping of the model Built With matlab python Try it out GitHub Repo Submitted to CANIS Data Visualization and Foreign Interference Created by Albert Thuku Stephen Maina"
      }
    ]
  },
  {
    "file_path": "./devposts/savannah-learning.html",
    "project_id": "savannah-learning",
    "title": "Savannah Learning",
    "tagline": "Savannah learning is a system that aims to enhance the use of AI to make the learning environment attactive",
    "hackathon": "",
    "built_with": [
      "django",
      "nextjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does This project helps learners have daily learning tasks How we built it The project is built with django and nextjs Challenges we ran into Accomplishments that we're proud of What we learned What's next for Savannah Learning Integration with AI Built With django nextjs Try it out GitHub Repo Submitted to IngeniumSTEM Summer Hacks 1.0 Created by Stephen Maina"
      }
    ]
  },
  {
    "file_path": "./devposts/scanjury-qisfxj.html",
    "project_id": "scanjury-qisfxj",
    "title": "Scanjury",
    "tagline": "Scanjury is an AI-powered mobile app that quickly scans and evaluates injuries, providing users with a preliminary diagnosis and guidance on whether professional medical attention is needed.",
    "hackathon": "",
    "built_with": [
      "google",
      "slides"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I've gone to the hospital multiple times for minor things which could be treated at home, but did not have to knowledge to do it. These unnecessary hospital visits cost a lot of money which could be saved. What it does Though I only have done the research portion, Scanjury scans a users injury and gives them a preliminary diagnosis, and guiding them based on the severity of the injury. How we built it I used google slides to create a presentation, and then recorded my presentation. Challenges we ran into I wasn't able to actually create the app that I did research for. Accomplishments that we're proud of I'm proud that I was able to put together an entire presentation about a concept I knew almost nothing about in a matter of a few days. What we learned I learned many surprising things while researching this project, such as that 41% of the US cannot afford frequent hospital visits. What's next for Scanjury I plan to actually create the Scanjury app, and make it available on all platforms, also altering it so it can scan diseases/rashes and other such things which show symptoms so it's not limited to just injuries. Built With google slides Try it out docs.google.com Submitted to KITE Hacks AI for Humanity Hackathon Created by Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/sarah-s-pandemic-adventure.html",
    "project_id": "sarah-s-pandemic-adventure",
    "title": "Sarah's Pandemic Adventure",
    "tagline": "Sarah's Pandemic Adventure is a twist on retro choose-your-own-adventure games such as Oregon Trail. In this game, you help Sarah make decisions during the pandemic that can have serious consequences.",
    "hackathon": "",
    "built_with": [
      "python",
      "random"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/369/778/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Beginning scene of Sarah's Pandemic Adventure Beginning scene of Sarah's Pandemic Adventure Beginning scene of Sarah's Pandemic Adventure 1 2 Inspiration choose your own adventure games like oregon trail and visual novels What it does a story-based game with 3 different endings, the player makes decisions that affect Sarah's health and sanity. How we built it We used python and vscode live share to create Sarah's Pandemic Adventure Challenges we ran into At first, we had trouble making our code efficient, but after researching classes and objects, we were able to make our different scenes much smaller blocks of code and easier to manage. Accomplishments that we're proud of We are proud of creating a fully functioning game that has error handling and changing visuals.  The scrolling text is also cool. What we learned We learned lots about python as 3/4s of our team are in their first semester of coding and all of us are not cs majors. We learned about classes, objects, parameters, libraries,  etc. What's next for Sarah's Pandemic Adventure We want to add features like different characters you can play as with different attributes, more endings, and move it from the terminal to something like a website. :) Built With python random Try it out GitHub Repo Submitted to WiCS Hacks 2023 Created by adorawu Wu Celeste Hoang Linda Lam Kyla L  Lee"
      }
    ]
  },
  {
    "file_path": "./devposts/scanjury.html",
    "project_id": "scanjury",
    "title": "Scanjury",
    "tagline": "Scanjury is an AI-powered mobile app that quickly scans and evaluates injuries, providing users with a preliminary diagnosis and guidance on whether professional medical attention is needed.",
    "hackathon": "",
    "built_with": [
      "google",
      "slides"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I've gone to the hospital multiple times for minor things which could be treated at home, but did not have to knowledge to do it. These unnecessary hospital visits cost a lot of money which could be saved. What it does Though I only have done the research portion, Scanjury scans a users injury and gives them a preliminary diagnosis, and guiding them based on the severity of the injury. How we built it I used google slides to create a presentation, and then recorded my presentation. Challenges we ran into I wasn't able to actually create the app that I did research for. Accomplishments that we're proud of I'm proud that I was able to put together an entire presentation about a concept I knew almost nothing about in a matter of a few days. What we learned I learned many surprising things while researching this project, such as that 41% of the US cannot afford frequent hospital visits. What's next for Scanjury I plan to actually create the Scanjury app, and make it available on all platforms, also altering it so it can scan diseases/rashes and other such things which show symptoms so it's not limited to just injuries. Built With google slides Try it out docs.google.com Submitted to KITE Hacks Research for All-AI Hackathon Created by Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/savor-sim.html",
    "project_id": "savor-sim",
    "title": "Savor Sim",
    "tagline": "Educational Cooking simulation game. A game about cooking food you can make at home.",
    "hackathon": "",
    "built_with": [
      "camera-api",
      "custom-ui",
      "focused-interaction",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/409/398/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration We drew inspiration from the challenges faced by low-income individuals who often opt for fast food due to a lack of cooking skills and confidence. Our goal is to empower players to learn cooking, which is crucial for better nutrition. Improved nutrition is directly linked to better attention, academic performance, and behavior in school. To ensure authenticity, we consulted a real nutritionist and chef who works in a nursing home, helping elderly people get proper nutrition. What it does SavorSim is a mobile cooking simulation game for the Meta Quest where players: • Buy and manage a restaurant\n• Collect ingredients at the grocery store\n• Cook meals based on real-world recipes\n• Serve customers with unique tastes and moods Every decision — from shopping on a budget to selecting the right meal — affects customer satisfaction and business success. The game emphasizes affordable, nutritious meal planning and builds skills players can carry into real life. How we built it We developed an advanced Cookbook system using the CustomUI API, incorporating the Camera API to enhance focused interactions within the kitchen and cookbooks. Due to numerous workarounds required for the pages, our Cookbook grew to over 5,000 lines of code, reflecting the complexity of its implementation. Our vision was to create a dynamic gameplay loop in which players prepare meals for their family and customers while strategically managing their supplies. When ingredients ran low, they could purchase essentials and uncover new recipes across the world map, adding depth to the experience. The game features four distinct levels—the lobby, house, world map, and restaurant—each offering unique characteristics that shape player progression. Every environment presents its own challenges and opportunities, encouraging thoughtful decision-making. Although we had ambitious plans, certain key features remained unimplemented due to engine limitations and time constraints. Nevertheless"
      }
    ]
  },
  {
    "file_path": "./devposts/safespace-7bdesv.html",
    "project_id": "safespace-7bdesv",
    "title": "SafeSpace",
    "tagline": "Safespace is a community where people can get and give advice related to mental health.",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "html",
      "javascript",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/450/004/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 💡Inspiration: We believe mental wellness is just as important as physical health, and yet the presence of tools on the web for those who suffer from mental illness is lacking, despite over 450 million people suffering from mental illnesses. A lack of coping mechanisms and tools can cause the affected person to suffer greatly and function poorly at work, at school, and in the family. Poor mental wellness at its worst, when left to fester, can lead to suicide. Close to 800 000 people die due to suicide every year. With suicide being the second leading cause of death in 15-29-year-olds. The inspiration for the project came from our experience with the global pandemic and the way it has disrupted our own and the mental well-being of others. During the pandemic, 4 in 10 adults in the U.S. have reported symptoms of anxiety or depression, up from one in ten adults who reported these symptoms last year. January to June 2019. Being mentally healthy makes you feel good about yourself. It also allows you to enjoy the pleasures of life, to grow, and to try new things. Maintaining good mental health is also one of the best ways to prepare for life's difficult moments both at a personal and professional level. ❓What it does: Safespaces is a community where people can give and get advice about issues and topics related to mental health. A person signs up and creates a profile and has two options. One option a person has is to create a post about an issue related to mental health and the second option is to respond to other people’s posts and share advice and kind words. Unlike other websites such as Reddit, Safespace uses Machine Learning to filter out toxic and harmful posts, ensuring a safe community for everyone while providing you with the best quality counseling online. 🏗️How we built it Safespace’s frontend was created using HTML, CSS, React, and Material UI components. Firebase was used to handle the backend logic which handles security, user authentication, and"
      }
    ]
  },
  {
    "file_path": "./devposts/save-a-friend.html",
    "project_id": "save-a-friend",
    "title": "Save A Friend",
    "tagline": "With social media becoming widely used by over billions of users, it is often used to express feelings. Our AI provides the assistance needed to those who are overwhelmed with their lives.",
    "hackathon": "",
    "built_with": [
      "android",
      "css3",
      "flask",
      "html5",
      "ios",
      "javascript",
      "matplotlib",
      "numpy",
      "python",
      "scikit-learn",
      "web"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Hack: Nintendo Switches Created by I worked with others on the fundamentals of the back-end",
      "Best Overall Hack: Nintendo Switches Created by I worked with others on the fundamentals of the bac",
      "MacHacks 3WinnerBest Overall Hack: Nintendo Switches",
      "Submitted for: Best Health Hack, Best Overall Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/369/004/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "iPhone screenshot! Yay to iOS users! (Don't worry, it's available on Android as well) SaveAFriend! Don't wait for tragedies to happen. Front Page of the application with a pleasant, soothing UI for the worried friend. Why use it? This explains to users ML in an approachable, comforting way. Admin Panel for the RCMP AUC model plotting using Mathplotlib for a useful metric on how accurate the machine's prediction was for the user's prediction of SI. iPhone screenshot! Yay to iOS users! (Don't worry, it's available on Android as well) SaveAFriend! Don't wait for tragedies to happen. Front Page of the application with a pleasant, soothing UI for the worried friend. Why use it? This explains to users ML in an approachable, comforting way. Admin Panel for the RCMP AUC model plotting using Mathplotlib for a useful metric on how accurate the machine's prediction was for the user's prediction of SI. iPhone screenshot! Yay to iOS users! (Don't worry, it's available on Android as well) 1 2 3 4 5 6 7 SaveAFriend Suicide is one of the leading causes of deaths in the world with over\nhundreds of thousands people affected every single year. Depression is\none of the main factors that causes people to have thoughts of ending their\nlives. People resort to many ways to cope against the painful thoughts, whether\nit is seeking therapy, talking with loved ones, or writing in a journal. \nUnfortunately, many experience it worse enough to avoid any resources that \ncould give them a reason they have all the reasons to live. With the world evolving\ninto a digital-centric society. People's digital footprint, all the social media\nposts, photos, words, we've posted on the internet--paints a bigger picture\nof our lives than we realize; particularly their mental health. With\nbillions of users using the platform everyday, there is no telling how many\npeople reach the climax of their mental breakdown, and leave their final message\nto the world before they leave. AI, an revolutionary investment in tec"
      }
    ]
  },
  {
    "file_path": "./devposts/sceneit-lrhfqo.html",
    "project_id": "sceneit-lrhfqo",
    "title": "SceneIt",
    "tagline": "SceneIt takes a product photo, constructs a 3D mesh and Buyers can observe the model, ask a voice sales agent anything and the agent responds and modify the 3D view or execute corresponding tasks.",
    "hackathon": "",
    "built_with": [
      "css",
      "javascript",
      "python",
      "typescript",
      "vapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/739/752/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Product Catalogue SceneIt Landing Page Checkout Cart Product Page Product Upload & Scanning Vendor Dashboard Product Catalogue SceneIt Landing Page Checkout Cart Product Page Product Upload & Scanning Vendor Dashboard Product Catalogue 1 2 3 4 5 6 Inspiration Shopping online still makes buyers do a ton of work: hunting for the right listing, asking basic questions, and trying to guess what an item really looks like from a couple of photos. We wanted to flip that around—let the seller upload one photo, and give buyers a hands-on 3D model plus a conversational sales agent that can answer questions and tour the product for them. What it does SceneIt takes a single product photo (e.g., a car), reconstructs a 3D mesh, and auto-uploads a the model to our site. Buyers can observe the model and ask a voice sales agent anything—“show me the tires,” “what’s the interior like?”—and the agent responds and drives the 3D view to the right angle. How we built it We built the web app in Next.js + TypeScript with a product page that loads the generated 3D model. A Python service runs TripoSR to turn a single uploaded image into a mesh we export as object file and auto-post back to the site. On top, a Vapi conversational agent—built with Vapi’s TypeScript SDK—handles real-time Q&A and can programmatically rotate, pan, and zoom the 3D view based on user requests. Challenges we ran into Making the 3d renderings look good (colour, texture, etc) Learning how to use the VAPI sdk Integrating different aspects of the project together Accomplishments that we're proud of Getting VAPI to navigate and describe 3d models in detail Modyfing the 3d modelling code to display textures and colours more precisely What we learned Computing the textures in a 3d model is the post computationally expensive part! What's next for SceneIt Add capabilities for the voice agent to use the web and find other relevant product in the catalogue for more comprehensive suggestions and feedbacks Enhance 3d scanning ph"
      }
    ]
  },
  {
    "file_path": "./devposts/schedula.html",
    "project_id": "schedula",
    "title": "Schedula",
    "tagline": "Your scheduler for all things.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/984/789/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Schedula Schedula 1 2 3 4 5 6 7 8 Inspiration Students are tired of back and forth emails to schedule video calls everyone in their group can attend. Teachers are fed up with unproductive students. We have decided to create this app to mitigate the scheduling problem for high school and university students. Schedula is an application that focuses to help high school and university students with scheduling using their existing Google Calendar information. This increases student productivity by finding common times for students when most of their peers are available. Teachers will be able to assign groups based on the matching availability of students, thereby allowing for greater productivity. What it does Schedula finds common times when the most number of students in a specified group are available in real-time. Schedula's algorithm extracts the Google Calendar of each user in the same group. The software then selects the appropriate times when the majority of all users are available. If, for instance, there were four members in Group A, Schedula would first optimize when all four users are available. Then all three, then two, then one. The darker shades of red indicate the most ideal times, when all four members are available. As the shade of red gradually decreases to lighter shades, less members become available for the specified time. How we built it We used Javascript and HTML & CSS for the application, and we implemented technologies from our sponsors like Github for storing code and Domain.com for our domain name. We initially decided to use React but due to technical difficulties, we transitioned to Javascript and HTML & CSS. Challenges we ran into React, our team had some experience with coding frontend and backend but we had never used a framework like react which was a challenge. At first we absolutely hated it as we made no progress but as we were using the tool we started getting accustomed to it. This was definitely a major challenge in the beginning "
      }
    ]
  },
  {
    "file_path": "./devposts/schedumate-7elsd6.html",
    "project_id": "schedumate-7elsd6",
    "title": "ScheduMate",
    "tagline": "Struggle with schedules? Let ScheduMate do it for you!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "github",
      "html",
      "llm",
      "natural-language-processing",
      "opeanai",
      "python",
      "taipy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Taipy Created by Shlok Bhakta Kevin Zhang I am a sophomore studying CS and statistics a",
      "TAMU Datathon 2023WinnerBest Use of Taipy",
      "The power of OpenAI's GPT to plan your day for you to make sure you enjoy every second of it",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/644/273/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Schedule generation and task breakdown Schedule generation and task breakdown Schedule generation and task breakdown 1 2 Schedumate Time is limited, You can't buy more no matter how healthy or wealthy you are, so why waste this precious resource? Check out ScheduMate! Your one stop shop for creating the best schedule tailor-made for you! Give it feedback to iteratively create a schedule that works just right for you. Features The power of OpenAI's GPT to plan your day for you to make sure you enjoy every second of it Give it feedback depending on wether the schedule conflicts with some plans See a breakdown of your daily tasks via a pie chart Benefits Great for students wanting to get more done without wasting any time Great for parents who already have enough on their plate Great for teachers who need to plan out tasks for the day Great for children too! Challenges We were unable to deploy this app to Taipy Cloud. Impact This will make schedule building as easy as possible for students looking to organize their life. We are hoping to help students around the world take control of their personal and academic life. Built With css flask github html llm natural-language-processing opeanai python taipy Try it out GitHub Repo Submitted to TAMU Datathon 2023 Winner Best Use of Taipy Created by Shlok Bhakta Kevin Zhang I am a sophomore studying CS and statistics at Texas A&M with an interest in web development. Karan Bhalla"
      }
    ]
  },
  {
    "file_path": "./devposts/schedumate.html",
    "project_id": "schedumate",
    "title": "ScheduMate",
    "tagline": "Do you struggle with making schedules? let ScheduMate do it for you",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "github",
      "html",
      "llm",
      "natural-language-processing",
      "openai",
      "python",
      "taipy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The power of OpenAI's GPT to plan your day for you to make sure you enjoy every second of it"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/644/180/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Schedumate Time is limited, You cant buy more no matter how healthy or wealthy you are. So why waste this precocious resource? check out ScheduMate, your one stop shop for creating the best schedule tailor made for you! Give it feedback if there are conflicts and take control of your life. Check out ScheduMate! some things you can do with ScheduMate: The power of OpenAI's GPT to plan your day for you to make sure you enjoy every second of it give it feedback depending on wether the schedule conflicts with some plans Great fur students wanting to get more done without wasting any time Great for parents who already have enough on their plate Great for teachers who need to plan out tasks for the day Great for children too! Built With css flask github html llm natural-language-processing openai python taipy Created by Kevin Zhang I am a sophomore studying CS and statistics at Texas A&M with an interest in web development. Shlok Bhakta Karan Bhalla"
      }
    ]
  },
  {
    "file_path": "./devposts/scantry.html",
    "project_id": "scantry",
    "title": "Scantry",
    "tagline": "Scantry helps users scan, keep track of, and access their groceries in real-time.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "clarifai",
      "css3",
      "expo.io",
      "firebase",
      "html5",
      "javascript",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Scantry helps users scan, keep track of, and access their groceries in real-time."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/718/040/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Website with grocery list App interface Website with grocery list App interface Website with grocery list 1 2 3 Inspiration We wanted to build this app for two main reasons. First, at this hackathon we were able to listen to a presentation about Machine Vision, which we found incredibly interesting. We decided to focus to create a project that could integrate and apply Clarifai's Machine Vision API in order to demonstrate the power of this concept. Second, we love food. But in all seriousness, the issues of the tons (literally) of food waste created every day due to expired goods, as well as the lack of a simple and accessible way to cataloguing a personal inventory of such groceries, provided us with an opportunity to solve them and create something new. We also wanted to extend our project so that users could find cooking recipes using ingredients they already have. The combination of these two factors thereby led to our idea, a simple management system taking advantage of a new technology. The choice was as easy as eating another slice of cold cheese pizza. What it does Scantry is comprised of a few elements interacting with one another-to illustrate how they work, let's imagine how Scantry would work in a situation where its user just bought some groceries. The first element is a mobile app, built with Expo.io. The user uses their camera to scan the grocery items in front of them. Clarifai's Machine Vision API then identifies the different items (like an apple, orange, or soup can) and records them down. Data is then pushed real-time to Firebase. Finally, a website draws data from Firebase to display this information online, which the user can access. In this way, the user can create a catalog of what they've bought simply by scanning items with their phone, and can similarly very easily view the list of food they already have. An added feature is that Scantry will also provide the user with possible recipes they could create with ingredients they already have. "
      }
    ]
  },
  {
    "file_path": "./devposts/school-gpt.html",
    "project_id": "school-gpt",
    "title": "School GPT",
    "tagline": "School GPT is a revolutionary tool for classroom communication, tracking student progress, and academic success.",
    "hackathon": "",
    "built_with": [
      "chatgpt",
      "css",
      "google-calendar",
      "html",
      "javascript",
      "python",
      "tsx"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "School GPT is a revolutionary tool for classroom communication, tracking student progress, and academic success."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/749/966/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired to make an education system that fit our needs and that implemented AI into it. We felt that many students used ChatGPT and wanted them to learn to use it more responsibly. What it does This system is for students to check their grades and for interacting with other students. How we built it We used tsx, python, and javascript. Challenges we ran into Implementing ChatGPT into the system. Accomplishments that we're proud of Implementing ChatGPT What we learned We learned how to implement an API and implement ChatGPT onto a website. What's next for School GPT We plan to expand communication channels for teachers and students and introduce direct messaging. We hope to improve the \"look\" of the website Built With chatgpt css google-calendar html javascript python tsx Submitted to BellHacks 24 Created by Nathan Thomas Sanjay Darshan Ramkumar Ponkarthikeyan Saravanan"
      }
    ]
  },
  {
    "file_path": "./devposts/save-our-snooze.html",
    "project_id": "save-our-snooze",
    "title": "SnoozeSafe",
    "tagline": "Saving Lives By Waking Eyes 👀",
    "hackathon": "",
    "built_with": [
      "android",
      "figma",
      "firebase",
      "gcp",
      "glide",
      "heartbeat.js",
      "java",
      "javascript",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best use of Google Cloud Created by Pratyay Banerjee I share memes more than I code :p // Smurfing",
      "Hacky Winterland 2WinnerBest use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/332/806/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Drowsy driving is the dangerous combination of driving when sleepy. This usually happens when a driver has not slept enough, but it can also happen because of untreated sleep disorders or shift work. Prescription and over-the-counter medications can also cause drowsiness, and alcohol can interact with sleepiness to increase both impairment and drowsiness. It is a leading cause for traffic-accidents resulting in property loss, economic damage and deaths across the world. A survey of 19 countries across Europe revealed, that a median of 17% of all drivers have fallen asleep across all the countries that had taken the questionnaire.\nCDC revealed that 1 in every 25 adult drivers have fallen asleep at the steering wheel at least once in a month. These starting figures how prevalent drowsy driving is. An estimated 6,400 people died annually in crashes involving drowsy driving, according to the National Sleep Foundation. Background Drowsy driving affects everyone, including adolescents and teens, who are not getting enough sleep (according to the CDC, it is recommended that teens get 8-10 hours of sleep each night). That means interventions focusing on this age group can help reduce drowsy driving. One such intervention is for parents to incorporate discussions and rules on drowsy driving while completing their parent-teen driving agreements. The prime reasons which lead to Drowsy Driving include: People who don't get enough sleep . Commercial drivers operating vehicles such as tractor trailers, tow trucks, and buses ( long distance drive ). Drivers with untreated sleep illnesses such as one where breathing stop and begins constantly (sleep apnea). Drivers who use medicines that make them sleepy . Learn the warning signs of drowsy driving: Yawning or blinking frequently. Trouble remembering the past few miles driven. Missing your exit. Drifting from your lane. Hitting a rumble strip on the side of the road. Taking into account all the above mentioned sources wh"
      }
    ]
  },
  {
    "file_path": "./devposts/savy.html",
    "project_id": "savy",
    "title": "Savy",
    "tagline": "Your AI finance advisor and expense tracker",
    "hackathon": "",
    "built_with": [
      "azure",
      "cohere",
      "github",
      "google-maps",
      "mongdb-atlas",
      "mongodb",
      "node.js",
      "python",
      "react",
      "s3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/354/247/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sample Insight card Navbar Distribution of expenses by categories Top expenses in the interval Sample Insight card Navbar Distribution of expenses by categories Top expenses in the interval 1 2 3 4 5 Inspiration Expense management is very crucial, and even more so for young adults nowadays given the rising daily-essentials' prices and too many non-leisure expenses done by people which can be easily cut down, but no one even glances on it. What it does This app allows users to record their expenses, track them, visualize them in various ways, get AI-powered insights on how and where to cut costs as well as see deals and offers of stores nearby How we built it This app has 3 parts: A React.js frontend, Node.js backend, and a Python Recommendation Engine. Challenges we ran into We mostly ran into challenges on the time management part and that we planned on integrating a lot of solutions that we are capable of. \nThe ML text classification model took a lot of time to train but it resulted in an astonishing score of 0.92. Accomplishments that we're proud of We were able to brainstorm the solutions pretty quickly, and were able to use a lot of different technologies given every member's strength. What we learned Although we weren't able to achieve everything we planning(ofc due to time constraints), we have got a very solid project to keep working on and learning. \nWe solved a lot of design as well as technical challenges in the past few days since we started discussing about it. What's next for Savy We're going to keep improving it till we reach a level of satisfaction and the existing plan is completed first, which in itself has many USPs. Built With azure cohere github google-maps mongdb-atlas mongodb node.js python react s3 Try it out GitHub Repo Created by I was involved in this project as a Full Stack developer. I worked on the Desig, Frontend and Backend. Gurjeet Singh Babbar I was responsible for developing the whole backend involving the Recommendations and AI! I"
      }
    ]
  },
  {
    "file_path": "./devposts/schwab-bot.html",
    "project_id": "schwab-bot",
    "title": "SchwabBot",
    "tagline": "Get the key indicators for the stock you know, from balance sheet to cash flow.",
    "hackathon": "",
    "built_with": [
      "node.js",
      "react",
      "rest",
      "spline"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/089/251/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration After seeing the mountain of influencers who give terrible financial advice, we felt there was a strong need to educate the general public about what actually matters. What it does The SchwabBot seeks to educate ordinary people on how to value a stock. It does this by providing key indicators (like BVPS, current assets, current liabilities, etc.) to develop an independent opinion on their investment strategy. In combination, we feature a report generation function for our product. Using generative AI, we can create fundamental, technical, and sentimental analysis reports. Recommending you key trends to look at and why they might affect your investment decisions.\nThis information is then fed into our chatbot we call SchwabBot (unrelated to Charles Schwab). Rather than telling us to buy or sell the stock, SchwabBot recommends key trends to look for when analyzing the stock. It also gives explanations on why these trends are important to look for. The SchwabBot will answer any financial questions that one may have. How we built it We used React for our frontend. In addition, 3D elements of our UI used the Spline package. For our backend, we used Node.js. We heavily used the Financial Modeling Prep API for our key metrics and OpenAI API for report generation and chatbot. Challenges we ran into We initially envisioned a financial product using AI. However, we weren’t able to find a way to extract the practicality and creativity from our ideas. This made brainstorming our biggest challenge. We hadn’t agreed on an idea until 5 PM yesterday. Accomplishments that we're proud of We’re really proud of our frontend. What we were able to extract from the 16 hours we had was mind-boggling. Thanks, Chris for being the GOAT. What we learned We faced challenges in time management as we were unable to pre-plan this project. This project has shown us the importance of brainstorming and high-level designing before we enter the project.\nAs not all members of the te"
      }
    ]
  },
  {
    "file_path": "./devposts/scheduled-venture.html",
    "project_id": "scheduled-venture",
    "title": "Scheduled Venture",
    "tagline": "This is our jumping point into a future in UX design!",
    "hackathon": "",
    "built_with": [
      "figjam",
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/740/935/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chart of our categorizing functionalities Chart of our categorizing functionalities 1 2 3 4 5 6 7 8 9 10 Prototype link (Please submit a link to a playable prototype, not a link to your design file) Link Describe your project (max 150 words) As undergraduate students, we are well aware of how busy our semesters can get.  Not only must we time manage our courses, we want to attend fun events, helpful career development panels, make time for ourselves, etc.  Through this app, we aim to help ease undergraduate students’ lives through time management assistance and create a more seamless experience for students as they coordinate their lives academically, professionally, and socially.  With the Scheduled Venture, students will be able to connect with other students seamlessly through overlaid calendars, register for various types of events, promote their own events, and have AI assistance in managing their valuable time. Describe your research process and findings. If you conducted any surveys or interviews, please include the survey form and/or interview questions here. If you conducted secondary research by pulling from online sources, please include a link to your sources. (Max 500 words) While discussing our initial thoughts for the app, we discussed common issues on our own college campuses.  This was beneficial since each team member is from a different college.  We expressed our frustrations with current apps available and found common themes that would function as a starting point. To conduct further research, we decided to conduct interviews using the master-apprentice model where we allowed people who have had their own personal experiences using the apps from their university to describe their experiences of finding opportunities, connecting with other students, and managing their time. The users were regarded as the experts in using the product whereas we were the apprentices who would learn about their experiences. We avoided asking any leading questions wh"
      }
    ]
  },
  {
    "file_path": "./devposts/sceneeditxr.html",
    "project_id": "sceneeditxr",
    "title": "Unity Enzo",
    "tagline": "Unity Enzo: Uniting Realms of Creativity – Where Spatial Computing Meets Collaborative Innovation across Platforms.",
    "hackathon": "",
    "built_with": [
      "c#",
      "gpt",
      "photon",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/740/101/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 Inspiration The main inspiration for 'Unity Enzo' stemmed from the growing demand for augmented productivity in diverse enterprise scenarios. As spatial computing becomes increasingly prevalent, the need for a unified, cross-platform workflow is more apparent than ever. The project was inspired by the vision of a seamlessly connected world, where the boundaries between physical and digital realms blur, enabling unprecedented collaboration and creativity. What it does 'Unity Enzo' reimagines the workflow across various devices, from computers to headsets and mobile applications. It integrates the immediate rendering capabilities of Unity with the dynamic procedural generation of Houdini, creating a world where real-time interaction and procedural creation intersect. This integration allows for the construction of dynamic environments and landscapes that respond to user interactions, creating a rich, immersive experience. How we built it The project began with a focus on VFX creation in Houdini, establishing a close loop with Magic Leap 2 and Meta Quest 3 through Photon for asset sharing and interactive modification. The MIT Building site served as the real-world canvas for testing and refining our collaborative and interactive features. The project leveraged a robust technology stack, including Unity 2022.3.f1, Chat GPT Vision API, and Meshy.ai, along with the extensive use of Codeberg/GitHub for version control and collaboration. Challenges we ran into Multiplayer Setup: Photon Pun presented intermittent issues, mainly related to connection stability, impacting the continuous operation of multiplayer features. Cross-Platforming Project: Creating a unified project proved challenging, leading to the creation of separate projects for MRTK Magic Leap 2 and Meta Quest 3 XR Interaction Blocks. Multiplayer Syncs: Implementing a synchronized experience for materials, textures, and details across participants was particularly challenging, as this w"
      }
    ]
  },
  {
    "file_path": "./devposts/scribe-5r2nds.html",
    "project_id": "scribe-5r2nds",
    "title": "Scribe.ai",
    "tagline": "Scribe: Revolutionizing healthcare with AI-driven patient management, not only do we organize/write paperwork, we also help catch misdiagnosis, wrong dosage, contraindictions, and more!",
    "hackathon": "",
    "built_with": [
      "api",
      "css",
      "gemini",
      "hallucination",
      "intel",
      "javascript",
      "python",
      "reflex",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "LA Hacks 2024WinnerIntel Company Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/858/628/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Our journey to create Scribe was deeply rooted in the poignant narratives of lives marred by misdiagnoses, leading to unimaginable hardships. The revelations from the People Safety Technology Challenge were stark—statistically, 44% of errors stemmed from incorrect prescriptions, a haunting reality that underscores the intricacies of human biology. We realized that this wasn’t about pointing fingers at doctors; rather, it was a call to arms to harness the power of data for precision healthcare. The human body's complexity often requires insights beyond intuition, and Scribe emerged as our heartfelt response—a tool designed to empower doctors with accurate, data-driven diagnoses, freeing them to nurture patient connections while effortlessly managing vital information and progress. Our journey embodies a shared commitment—to transform heart-wrenching stories into tales of triumph, where every patient's journey is guided by knowledge, compassion, and the promise of a healthier tomorrow. Join us in rewriting the narrative of healthcare with empathy and cutting-edge innovation at its core. Scribe is not just a tool; it's a robust and indispensable asset in the healthcare landscape. Its multifaceted capabilities are designed to address crucial aspects of patient care with precision and reliability. First and foremost, Scribe excels at identifying incorrect medication doses, a critical function that directly impacts patient safety. By analyzing dosage data and patient profiles, it helps prevent potentially harmful medication errors and ensures that patients receive the correct treatment. Additionally, Scribe is adept at preventing contraindications, another vital aspect of healthcare management. By cross-referencing patient data and medication histories, it alerts healthcare providers to potential conflicts, minimizing risks and enhancing treatment efficacy. Moreover, Scribe plays a pivotal role in flagging errors in tests and prescriptions. Its intelligent algor"
      }
    ]
  },
  {
    "file_path": "./devposts/scriptum.html",
    "project_id": "scriptum",
    "title": "Scriptum",
    "tagline": "AI-Powered Document Analysis and Quiz Creation. This website allows you to upload your document/resume and uses AI to analyze and answer any questions you have about it.",
    "hackathon": "",
    "built_with": [
      "cloud-convert",
      "daisy",
      "flask",
      "python",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Second Place Created by Pranav Yerramaneni Gaurav Bansal Sarvesh Madullapalli Full Stack Dev | Pyth",
      "PioneerHacks IVWinnerSecond Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/423/030/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "image image image 1 2 This website allows you to upload your document/resume and uses AI to analyze and answer any questions you have about it. If you do not have access to the file, you can take a picture of your paper and use that instead.\nOur program also has a feature of creating a short quiz based on the text that you just uploaded. Built With cloud-convert daisy flask python tailwind Submitted to PioneerHacks IV Winner Second Place Created by Pranav Yerramaneni Gaurav Bansal Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly"
      }
    ]
  },
  {
    "file_path": "./devposts/script-generator.html",
    "project_id": "script-generator",
    "title": "Script Generator",
    "tagline": "Youtube Essay Script Generator",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "openai",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "What Inspired Us -As Young College Students with a passion for coding and innovation we wanted to use our knowledge of these topics and combine them with a popular form of media entertainment in today's digital age \"YouTube\", The popular video platform is largely based upon generating clicks with enticing thumbnails and edits, however a great video must always have a great script to go along with it. Our idea was to use our skills in Python, HTML5, CSS, Flask and combine them with Open AI's Turbo API in order to create a Video Essay Script Generator. What it does We utilized clever prompt engineering to generate an excellent YouTube video script using Open AI's Turbo API in order to provide desirable, entertaining and well formatted Video Essay Scripts which can be generated through the click of a button on our frontend web application. How we built it -We used Python as our main language along with HTML5, CSS, and Flask and combined them with Open AI's GPT-3.5 Turbo API. We formatted our HTML5 and CSS to be interconnected with the backend Python Script using Flask to achieve a desirable result. Challenges we ran into -Our Main Challenge was fine tuning prompts through what is commonly referred to as Prompt Engineering. While we could get Open AI's API to understand our desirable result, fine tuning details such as grammar, outline structure, and prompts formats to achieve the most realistic, captivating Video Essay Script proved to be a challenge which required a significant amount of time, which thankfully we were able to overcome and perfect. Accomplishments that we're proud of -As Undergraduates from SUNY Binghamton in New York, traveling 3 hours on a road trip with friends, spending the weekend in a new city the historic Philadelphia, Pennsylvania and doing what we enjoy most coding and learning new ways to utilize technology this entire experience has been nothing short of surreal. We are proud to have traveled from a long distance safely and arrived to have f"
      }
    ]
  },
  {
    "file_path": "./devposts/script2slides.html",
    "project_id": "script2slides",
    "title": "Script2Slides",
    "tagline": "Never make a slideshow again!!! This tool generates slide decks for you in seconds using AI.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "google-image-search",
      "html",
      "openai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Never make a slideshow again!!! This tool generates slide decks for you in seconds using AI."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/592/078/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Slideshow generated by AI Enter the script here! Slideshow generated by AI Enter the script here! Slideshow generated by AI 1 2 Inspiration Having to prepare presentations is already dreadful enough. But also having to prepare slides to accompany it? So much worse. As students, we could not be any more familiar with this situation. While our speeches for English class may be a valid indicator of our English skills, the slides we make are not. The time we spend making these slides is better allocated elsewhere, and this is where Script2Slides comes in. What it does This productivity tool we created automatically generates a visually appealing slideshow containing key information and relevant images. All you need to do is copy and paste your script into the textbox on our website, and your brand-new slideshow will be downloaded for you to use! How we built it Script2Slides was created with HTML and styled with CSS. The script is summarized into bullet points in GPT-3.5 using the OpenAI API, and an image description is generated. We then use this description to find relevant images for the slides using Google Image Search API. With both bullet points and images, we create a PowerPoint file downloaded for the user. Challenges we ran into We decided on the idea quite late — around 11:30 a.m. on Saturday! This meant we only had a day to work on the project. A few more challenges we ran into included crafting a prompt that worked well with GPT and downloading the slideshow as a PowerPoint since the formatting would have problems. Accomplishments that we're proud of We’re proud of creating our first hack that successfully implements AI. But beyond that, we’re simply happy to solve an issue the whole team can relate to. What we learned Since this is our first time implementing AI, we learned how to use OpenAI API, and more specifically, Victor learned how to use Flask. What's next for Script2Slides In the future, we wish to run Script2Slides in a way that is more personalize"
      }
    ]
  },
  {
    "file_path": "./devposts/search-project-nb92418cim0x.html",
    "project_id": "search-project-nb92418cim0x",
    "title": "Quasar - eCommerce for the future",
    "tagline": "Your shopping should be as smart as you are. Experience an intelligent shopping platform that utilizes AR and ML to find the product you need. Crypto friendly and NCR-services compatible.",
    "hackathon": "",
    "built_with": [
      "cryptojs",
      "echo3d",
      "firebase",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "! * See it here - best on Desktop Inspiration As brick-and-mortar stores close across the country, b",
      "See it here - best on Desktop"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/712/360/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The incentive portal for users to contribute to the project. The homepage with rotating 3D models and clean, modern UI. A product from our webapp visualized in AR. Purchasing a product using NCR coins through the Metamask browser wallet extension. This was done through Web3. Reactive, beautiful product page with 3D models, AR, crypto, and blockchain integration. The incentive portal for users to contribute to the project. The homepage with rotating 3D models and clean, modern UI. A product from our webapp visualized in AR. Purchasing a product using NCR coins through the Metamask browser wallet extension. This was done through Web3. Reactive, beautiful product page with 3D models, AR, crypto, and blockchain integration. The incentive portal for users to contribute to the project. 1 2 3 4 5 6 * NCR's 'Machine Learning in Retail' Challenge Winner! * See it here - best on Desktop Inspiration As brick-and-mortar stores close across the country, beaten by online retail giants like Amazon and Walmart, shoppers are forced to purchase online. While digital shopping can be more convenient and accessible to millions, consumers miss out on the interaction with products in their own physical environment and finding products can be tough when you do not know what to search for. This is why we have created Quasar , a web app available on desktop, iOS, and Android that uses augmented reality, machine learning, blockchain, and crypto to modernize shopping - making a new interplay between the physical world and digital shopping platforms. What it does Modernizes the digital shopping experience, leveraging augmented reality (AR) and machine learning (ML) techniques to bring digital shopping to your physical world Visualizes products in their own physical environment through 3D product models and augmented reality ML-powered smarter search - users can search for products by scanning images of related products, eliminating the need for keyword searches Have peace of mind knowing the us"
      }
    ]
  },
  {
    "file_path": "./devposts/sensai-nvh940.html",
    "project_id": "sensai-nvh940",
    "title": "Sensai",
    "tagline": "Sensai transforms how you workout by providing you with real-time suggestions and analytics, powered by advanced computer vision algorithms.",
    "hackathon": "",
    "built_with": [
      "figma",
      "flask",
      "git",
      "github",
      "jwt",
      "mediapipe",
      "mongodb",
      "nuxtjs",
      "python",
      "socket.io",
      "vsc",
      "websockets",
      "windicss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/985/030/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration During the COVID-19 pandemic, we noticed that many people were leading unhealthy lifestyles and not exercising since many facilities such as gyms were closed. This inspired us to create a cost-free fitness platform which encourages people of all ages to pursue healthy active living from their own homes, without the need to hire an expensive personal trainer. What it does Sensai allows you to choose one of our custom-made recommended workouts, each of which has a routine of exercises and reps. Using an integrated webcam combined with MediaPipe’s AI pose estimation, Sensai tracks your progress by automatically counting the number of reps you do, while alerting you if your form can be improved and giving you hints to improve your technique through both text-to-speech and visible dialogs. How we built it The backend API consists of a Flask webserver that handles authentication, image processing, and workouts. We used JWT (Json Web Tokens) for authentication, and MongoDB as our database. It also uses SocketIO for real-time data exchange with the client. The AI was created in Python using MediaPipe's Pose Model, which finds (x, y) coordinates of body landmarks. The frontend was built with NuxtJS and WindiCSS, and designed on Figma. Challenges we ran into One challenge we faced was getting the AI to count the number of reps by detecting the change in angle between certain joints during the exercise. We needed to identify optimal angle ranges for each exercise, which caused a process of trial-and-error. Another challenge we faced was integrating the AI with the frontend. The logic was complex, so we had to draw diagrams and organize all our thoughts in notes to map out how the code would work. Accomplishments that we're proud of We are proud of that we were able to create the AI using Python and MediaPipe, despite using both for the first time. It was also our first time using OpenCV, which was used to locally test the AI without integrating it with "
      }
    ]
  },
  {
    "file_path": "./devposts/scholar-cat.html",
    "project_id": "scholar-cat",
    "title": "Scholar Cat",
    "tagline": "Scholar Cat aims to provide high school students with opportunities and extra curricular activities to improve their overall portfolios.",
    "hackathon": "",
    "built_with": [
      "css3",
      "echoar",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of echoAR Created by First solo project! edit 6 months later: omg embarrassing Lily Meng UofT C",
      "Best Use of echoAR Created by First solo project! edit 6 months later: omg embarrassing Lily Meng U",
      "GTA HacksWinnerBest Use of echoAR",
      "Winner",
      "First solo project!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/392/454/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Map Page Index Page Register Page Login Page Logged In Home Page Profile -> My Profile Page Profile -> My Account Page Opportunties Page Opportunities -> Job In Person 1 Page Map Page Index Page Register Page Login Page Logged In Home Page Profile -> My Profile Page Profile -> My Account Page Opportunties Page Opportunities -> Job In Person 1 Page Map Page 1 2 3 4 5 6 7 8 9 10 Inspiration 💡 I've recently been looking for internships and volunteer opportunities. Especially since I'm a high school student with not a lot of knowledge of programming languages and softwares used in computer science, finding an internship in STEM, specifically technology, with requirements that fit my skill set has been a challenge. The idea of creating a website to help other students facing the same problem has crossed my mind many times and although there is not actual content on this website that students can use, the cute cats and images are placeholders for when I find actual opportunities and partnerships in the future. What it does 💻 The goal of Scholar Cat is to provide opportunities for high school students specifically for jobs, internships, and volunteering. The big picture was to implement a login function for students to create and access their account, fill in their information and apply to real opportunities. There's also a map for students interested in applying to opportunities based on their location because sometimes, people more comfortable with doing work in person or are open to any locations for remote work. How I built it 🔨 I built this site using HTML, CSS, JavaScript, and echoAR. I planned to finish certain parts of the website given a certain time frame so I finished the foundation, basic placement of the elements, functions such as hover affect, and more by the end of the first day. On the second day, I cleaned up my code by making it more readable as well as fixed up spacing and colours. I spent a lot of time trying to get the filter function to work with Jav"
      }
    ]
  },
  {
    "file_path": "./devposts/searchly-9pn6go.html",
    "project_id": "searchly-9pn6go",
    "title": "Readabl",
    "tagline": "Your assistant for giving you a better and more understandable search results catered to your age",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "custom-search-json-api",
      "fast-api",
      "figma",
      "gcp",
      "py-readability-metrics",
      "python",
      "svelte",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "3rd Place Overall Created by Anita Yip Product owner, project manager, retired hackathon-er Benedic",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/890/870/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Elementary school kids are very savvy with searching via Google, and while sometimes the content returned are relevant, they may not be at a suitable reading level when the first search results talks about something like phytochemicals or pharmacology. Is there a way to assess whether links in a search result are at the level users desire to read? That's why we created Readabl. Readability is about the reader, and different personas will have their own perspective on how readability metrics can help them. Our vision is to enable users to find content suitable for their needs and help make content accessible to everyone. What it does Readabl offers search results along with readability metrics so that users can at a glance see what search results are suitable for them to read. How we built it The entire application is hosted in a monorepo consisting of a Javascript frontend framework - Svelte with a FastAPI backend endpoint. The frontend is hosted on Netlify while the backend is hosted using GCP's Cloud Run. The search and processing that takes place in the backend is built using both Google Cloud Custom Search JSON API and the py-readability-metrics library. Backend Hosted on GCP's Cloud Run using Docker, we are using FastAPI to communicate with our frontend to get user's search term and rank the information according back to the users. The FastAPI talks to Google Search API, retrieving information and passing it along. Before passing to the frontend, we parsed the information using a Python Library - BeautifulSoup - to get the text on the particular page to be ranked for readability. We also explored concurrent programming via Python in the backend so that we can parse multiple webpages in parallel to speed up the processing. backend -> https://api.readabl.tech/ Frontend The frontend uses the Svelte framework as the main driver due to it's fast run time and minimalistic structure with little boilerplates code. We explored using a UI framework to speed u"
      }
    ]
  },
  {
    "file_path": "./devposts/semantic-search-of-3d-graph-of-high-signal-social-network.html",
    "project_id": "semantic-search-of-3d-graph-of-high-signal-social-network",
    "title": "Nebula",
    "tagline": "3d search for network graphs",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/500/357/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Description related to search query Home page after a search query Description related to search query Home page after a search query Description related to search query 1 2 Inspiration We believe that great work is accomplished when great talent unites. This was our attempt at mapping the academic landscape to hopefully encourage more collaboration within academia. Heavily inspired by Bell Labs. What you learned Learned how to work with the unpkg open source 3d graph visualizer and edit features such as a lighting up specific nodes or connections. Also learned how to build a great dataset from scratch scrapping directly from Google Scholar. Challenges A large challenge was pulling the whole project together, getting our vectordb results to light up related nodes. Another challenge was the slow speed of scrapping Google Scholar IDs, we spent at least 4 hours running scripts just to collect data. Built With flask gemini Try it out GitHub Repo Submitted to UC Berkeley AI Hackathon 2025 Created by Nicolas Dickenmann Daniel Kiss"
      }
    ]
  },
  {
    "file_path": "./devposts/scripthub.html",
    "project_id": "scripthub",
    "title": "ScriptHub",
    "tagline": "The golden brick path to your screen-writing Oz",
    "hackathon": "",
    "built_with": [
      "ckeditor",
      "css",
      "dotenv",
      "express.js",
      "html5",
      "javascript",
      "jquery",
      "node.js",
      "tailwind",
      "twilio",
      "twiliosync"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ThehacktricalWinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/804/219/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The real-time collaboration in plain-text format Our landing page Rich Text Formatting feature The real-time collaboration in plain-text format Our landing page Rich Text Formatting feature The real-time collaboration in plain-text format 1 2 3 4 💡Inspiration💡 Screenplay writers have a tough job and their script makes or breaks a play. We understood this, and created a simple yet comprehensive editing suite for scriptwriters that works in the browser, has the capability to edit scripts in rich text format, and most importantly, facilitates real-time collaboration between multiple scriptwriters and artists. 💪What it does💪 ScriptHub is a collaborative script writing web application. It allows users to collaborate over a script in real time, perfect for projects involving multiple screenwriters and artists. Users can self-host the application, add the required libraries and environment variables and instantly start collaborating and editing their scripts. Users may choose to work in plain text format, or rich text format which unlocks access to dozens of cool text editing features that make ScriptHub as efficient as a Google Doc, for instance. There is also a button to export the finished script, which when clicked, renders the screenplay in a printable PDF format. You could print it out or print to PDF and share it with your fellow editors or artists. We hope to facilitate better coordination among various artists to allow their ideas and inspirations to come to fruition. 🏗How we built it🏗 We built ScriptHub using Express, Node, HTML, CSS, JS for the User Interface, which was further bolstered with Tailwind CSS. We used Ckeditor and Jquery for the rich text formatting feature of our script-writing software. Furthermore, we did full justice to various sponsor tools from the MLH Software Lab this weekend and used them in the following ways: 🔴 Twilio 🔴 This weekend, we learnt that there is a whole lot more to Twilio than just text messages and phone calls. We created a T"
      }
    ]
  },
  {
    "file_path": "./devposts/settlemize-byg3pn.html",
    "project_id": "settlemize-byg3pn",
    "title": "Settlemize",
    "tagline": "Settlemize remains steadfast to optimizing the settlement process for immigrants coming to Canada through the abundance of user-friendly tools that our application has to offer!",
    "hackathon": "",
    "built_with": [
      "css",
      "figma",
      "gui",
      "python",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "and most accurate results! How we built it Since our entire group consists of first-time hackers, t"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/194/314/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "An isometric decomposition of our application's web pages! An isometric decomposition of our application's web pages! An isometric decomposition of our application's web pages! 1 2 Inspiration When finalizing an idea to pivot on, our group found it rather difficult, considering that there was no specific theme for this year's hackathon. However, we decided to go with mitigating an issue that hundreds of thousands of Canadians struggle with; life after immigration. We were inspired by one of our group member's experiences with a family friend's recent move to Canada. Said group member began to witness, first-hand, the sheer number of difficulties that they soon encountered. This included struggle to find housing, inaccessibility to transportation, English professional incompetence and unemployment. With that said, our group was motivated to create something to improve the well-being of all immigrants coming to Canada. What it does Settlemize, derived from the words settlement and optimize, is a website that targets two of the most common struggles that immigrants face, the language barrier and unemployment. In order to combat a newcomer’s ineptitude with English and/or French, we created a section where the user has the ability to watch tv shows/movies and listen to songs in either of Canada’s official languages (English or French). Depending on the country that the user emigrated from, subtitles in their language will be displayed along with the English or French entertainment. In addition to this leisure, we offer access to courses and modules that teach the user the foundations of English. As for helping with unemployed immigrants, we have a built-in job search section that the user is able to navigate in order to find positions they may be interested in. Several filters are included to ensure the best and most accurate results! How we built it Since our entire group consists of first-time hackers, the majority of our project was built using the Figma API in order"
      }
    ]
  },
  {
    "file_path": "./devposts/sentimap-534oxp.html",
    "project_id": "sentimap-534oxp",
    "title": "SentiMap",
    "tagline": "SentiMap is a machine learning, data visualization software capable of analyzing public sentiments regarding climate change, and displaying it in a manner that is easy to understand.",
    "hackathon": "",
    "built_with": [
      "natural-language-processing",
      "python",
      "sentiment-analysis",
      "textblob",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/424/456/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration From the scrapping of Canada’s Carbon tax due to protests in 2019, to the withdrawal of the USA from the Paris Agreement. Even more recently, the Green New Deal proposed in the US which targets climate change and economic inequality is lagging behind due to public opposition and critics that question scientific consensus around climate change. Public sentiment about climate change is a double-edged sword since it can be both an impediment and a driving force for climate change-focused policy. Cue SentiMap, our team’s NLP-based, data visualisation tool to help inform policy decisions with a higher potential success rate. It uses text classification of regional tweets to analyse public sentiment around climate change. What it does Our data visualization tool makes it easy to explore emissions data by sector and region. Policymakers can see which regions contribute the most to overall emissions and hence identify where changes are most needed. This would help design policy interventions tailored to the region’s overall carbon emissions contributions Also, we have developed a sentiment analysis tool that analyzes social media conversations, more specifically tweets sent from a particular location, about climate change. By understanding people's emotions and attitudes towards this issue, policymakers can get valuable insights into public opinion. How we built it We used a python library called TextBlob that helped us implement an NLP model onto our tweet data. We used the model to assign a sentiment score to each data point and used the score to produce a heat map using the Folium library in python. For the front end, we used Python's Tkinter module to create a simple and accessible user interface. Challenges we ran into We had originally planned on using the Tweepy python library to interact with the Twitter API, but ran into an issue when we realized we would actually have to have a developer Twitter account in order to interact with the Twitter API. We the"
      }
    ]
  },
  {
    "file_path": "./devposts/seedlytics.html",
    "project_id": "seedlytics",
    "title": "Seedlytics",
    "tagline": "An innovative web app that redefines entrepreneurship by connecting pre-seed and seed-stage startups to investors early on.",
    "hackathon": "",
    "built_with": [
      "chakra-ui",
      "css",
      "flask",
      "html",
      "kaggle-datasets",
      "mongodb-atlas",
      "python",
      "streamlit",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/630/288/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Search Engine Result Page, Business Info 2 Search Engine Home Page Search Autofill Streamlit Data Input Streamlit Grapher Search Engine Result Page, Business List Search Engine Result Page, Business Info Search Engine Result Page, Business Info 2 Search Engine Home Page Search Autofill Streamlit Data Input Streamlit Grapher Search Engine Result Page, Business List Search Engine Result Page, Business Info Search Engine Result Page, Business Info 2 1 2 3 4 5 6 7 Inspiration As undergraduate students experienced with the engineering design process, we were very interested in the next steps after prototype development—commercialization and bringing products to market. When developing our projects in high school, we ran into multiple issues regarding procuring prototyping materials as well as the software and technology to implement our ideas. For a new venture into any industry, developing a viable product and refining it will take money—lots of it. As such, early “angel” investors are an integral part of the “seeding” of startups which may eventually grow into the next Amazon or Airbnb. However, this critical stage is where most startups begin AND end their life cycles as many potential investors are rarely made aware of their presence or potential. What it does To make a marked change in this field, we have created Seedlytics, which offers potential investors a search-engine form of indexing and interacting with startup companies. Seedlytics will bridge the gap between avid investors and the crucial financial seeding stage by allowing users to search key sectors, geographical locations, prior funding, and names of companies (among other criteria) to encourage “matching” of interests. How we built it We used TypeScript, Flask, MongoDB (Atlas), Streamlit, and Python. We used a typescript home page that had a search bar. After searching, the backend would query the databases and return the companies with matching values. We used Flask to send requests to the backend, and"
      }
    ]
  },
  {
    "file_path": "./devposts/sentimental-ai.html",
    "project_id": "sentimental-ai",
    "title": "Sentimental Sentance AI",
    "tagline": "predict sentiment of a sentance",
    "hackathon": "",
    "built_with": [
      "natural-language-processing",
      "nltk",
      "numpy",
      "pandas",
      "python",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "The code tells you if a given review is positive or negative. We coded this in python with the natural language toolkit and sci-kit learn machine learning library. The biggest challenge is that our team is new to python and AI and we encountered many new commands, hence much time was for learning and debugging. Built With natural-language-processing nltk numpy pandas python scikit-learn Try it out GitHub Repo Submitted to Ignition Hacks 2020 Created by Private user Qwertu Meng Sean Wang"
      }
    ]
  },
  {
    "file_path": "./devposts/sf-civil-pro.html",
    "project_id": "sf-civil-pro",
    "title": "SF Civil Pro",
    "tagline": "SF Civil Pro is a platform designed to assist civil service professionals in preparing for civil service exam. With study materials and practice tests, SF Civil Pro aims to empower individuals.",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH: Best Use of AI in Education Created by Neha Hussain Hanson Vuong Anh Vo Rian Corcino i code st",
      "SFHacks 2024WinnerMLH: Best Use of AI in Education",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/839/689/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Exam Page Our Home Page Profile Page Exam Page Our Home Page Profile Page Exam Page 1 2 3 Inspiration Essential civil worker positions are understaffed due to a lack of preparedness for the civil service exam. By providing resources for the exam, we can help increase the amount of people hired as civil workers. What it does An online platform providing study materials, practice tests, and interactive resources for people studying for the civil service exam. How we built it We used React.js, FireBase, Chat GPT API, and Figma. Challenges we ran into We hard pivoted on day 2 and struggled with implementing MVP. Accomplishments that we're proud of We are proud of implementing the Chat GPT API and our idea. What we learned We learned that passion for an idea is what drives the team. What's next for SF Civil Pro We would like to standardize the flashcards and the mock exams. Built With figma firebase react Try it out GitHub Repo Submitted to SFHacks 2024 Winner MLH: Best Use of AI in Education Created by Neha Hussain Hanson Vuong Anh Vo Rian Corcino i code stuff for fun"
      }
    ]
  },
  {
    "file_path": "./devposts/semantic-drive.html",
    "project_id": "semantic-drive",
    "title": "Semantic Drive",
    "tagline": "Imagine if your file directory could give more than be a mess of month-old files. With the power of AI and ML using MindsDB, we provide invaluable semantic contexts for your personal files.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "mindsdb",
      "python",
      "pytorch",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "AI Track"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/645/784/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "💡 Inspiration💡 Navigating through a digital jungle of files and documents is a common struggle for students and professionals alike. The frustration of sifting through folders filled with cryptic file names like \"syllabus_fall23 (5).pdf\" or \"README.txt\" is something we all can relate to. The existing file management tools, like Google Drive, although efficient, often fall short in providing us with insightful, semantic information about our files' contents. This sparked our inspiration for a solution that could transform the way we organize and access our digital resources. ⚙️ What it does ⚙️ We present Semantic Drive, a cloud-based file management platform, akin to Google Drive, but with a revolutionary twist. We've harnessed the power of machine learning technologies, seamlessly integrated with MindsDB, to provide summary data for a wide range of file types. Whether you're dealing with text documents or images, Semantic Drive doesn't just store your files; it comprehends them. AI Track In the AI Track, we've taken file management to a whole new level by infusing it with the intelligence of machine learning. This involves using MindDB's integration with ML models as well as Hugging Face to allow for more accurate semantic searching. 🏗️ How we built it 🏗️ Our frontend was built with React and our backend was made using Flask. 🟣 CockroachDB Serverless 🟣 Our foundation is built upon CockroachDB Serverless, paired with Python, where we securely store your files and their associated metadata. This secure database forms the backbone of our system, ensuring your data is organized and accessible. We've created a user-friendly Flask backend to streamline the process of entering file data and metadata. This allows for efficient data management and retrieval. 🔴 MindsDB 🔴 MindsDB plays a pivotal role in the Semantic Drive ecosystem. As files are uploaded, MindsDB springs into action, automatically summarizing each file's content. What sets us apart is that this isn't limited t"
      }
    ]
  },
  {
    "file_path": "./devposts/scrolla.html",
    "project_id": "scrolla",
    "title": "Scrolla",
    "tagline": "Scroll endlessly, learn boundlessly — The Scrolla way ✨",
    "hackathon": "",
    "built_with": [
      "docker",
      "firebase",
      "flask",
      "python",
      "radix-ui",
      "react",
      "redux",
      "tailwind",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Hack + Best Code + Best Startup Idea + Best Design Team Name: Scrolla Why Scrolla? 💡 In an",
      "Design with code Winner Best Technical Implementation Created by Built the magic ✨ → that converts",
      "Best Design with code Winner Best Technical Implementation Created by Built the magic ✨ → that con",
      "SacHacks VIWinnerBest Design with codeWinnerBest Technical Implementation",
      "Targeted Tracks → Best Overall Hack + Best Code + Best Startup Idea + Best Design",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/305/254/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Your Feed GIF Profile and Liked Videos Your Feed GIF Profile and Liked Videos Your Feed 1 2 3 4 Targeted Tracks → Best Overall Hack + Best Code + Best Startup Idea + Best Design Team Name: Scrolla Why Scrolla? 💡 In an era characterized by short attention spans and the pervasive influence of social media , Scrolla emerges as a revolutionary platform that transforms the way educational content is delivered. By leveraging the addictive nature of infinite scrolling and the popularity of short-form videos , Scrolla bridges the gap between passive content consumption and active learning . Declining Attention Spans : Studies have observed a significant reduction in the average human attention span, decreasing from approximately 2.5 minutes in 2004 to around 45 seconds in recent years. Increased Stress Levels : Engaging in multitasking, especially with digital devices, can lead to cognitive overload, resulting in elevated stress levels and reduced comprehension. Impact on Learning : Media multitasking has been associated with poorer academic performance, diminished executive function, and reduced memory retention. Content Consumption Patterns : The rise of short-form content and infinite scrolling has conditioned audiences to prefer brief, easily digestible information, potentially reducing the capacity for sustained focus. What it does 🤔 Scrolla is a smart learning platform designed to transform educational content into engaging, short-form videos that mimic the social media experience . The app's goal is to support students in learning complex material while keeping them engaged through familiar scrolling mechanics. Studies estimate that the average attention span has dropped to just 8 seconds , making traditional learning methods increasingly ineffective. Unfortunately, less than 30% of students fully engage with assigned reading materials, leading to knowledge gaps and academic underperformance. Although educational platforms already exist, they often fail to capture st"
      }
    ]
  },
  {
    "file_path": "./devposts/securevision-gl09kb.html",
    "project_id": "securevision-gl09kb",
    "title": "SecureVision",
    "tagline": "Distributed Enrichment of Breached Data - uOttaHack 6 Winner on DoraHacks",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "nextjs",
      "shadcn",
      "solace"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Distributed Enrichment of Breached Data - uOttaHack 6 Winner on DoraHacks"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/226/860/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Backend Logic Dashboard Risk Analysis Backend Logic Dashboard Risk Analysis Backend Logic 1 2 3 Inspiration The quality of threat analysis is directly tied to the quality of the input data. To enhance our analysis, we enrich raw data with details about open ports, web applications, CAPTCHA, and more. How It Was Built Our architecture was designed with scalability in mind, ensuring fast processing across multiple nodes. Solace's event broker efficiently distributes accounts to worker nodes, each performing specialized tasks. Once a task is complete, the node writes the results to the database and updates Solace. The entire system is containerized with Docker and deployable via Terraform for seamless scalability and flexibility. Optimizing for Speed We leveraged specialized APIs for their strengths while handling everything else in-house using FastAPI. This approach allowed us to distribute functions effectively via Solace, ensuring optimal performance. Data Enrichment Data enrichment combined our in-house tools with external APIs to deliver comprehensive results. Shodan provided fast insights on domains, ports, and IPs, while Ransomwatch and Ransomware.live helped identify potential breaches. Our FastAPI backend also analyzed web pages for login forms, routability, CAPTCHA, and other features, ensuring detailed data coverage. Use of Terraform Terraform made it easy to deploy and manage worker nodes alongside the Solace message broker. Its flexibility allowed us to quickly scale the system by modifying a single file, making it adaptable to changing workloads. Use of Solace Solace was integral to task distribution, ensuring efficient work division among worker nodes. Its queuing system enabled nodes to pick up new tasks as they became available, eliminating bottlenecks and maximizing throughput. Use of groq With groq, we leveraged LLama 3.3 and Whisper to provide an overall security score based on the analysis of the accounts. This includes warnings about compromised p"
      }
    ]
  },
  {
    "file_path": "./devposts/share-web.html",
    "project_id": "share-web",
    "title": "Share Web",
    "tagline": "Imagine a world where beginners can learn by sharing projects. This is what share web attempts to accomplish. It is a platform where web developers can play around inside a sandbox and get feedback.",
    "hackathon": "",
    "built_with": [
      "jamstack",
      "javascript",
      "mysql",
      "next",
      "planetscale",
      "react",
      "serverless",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "high school hack (all team members must be in HS) Created by Lino Le Van",
      "Best high school hack (all team members must be in HS) Created by Lino Le Van",
      "HackBytesWinnerBest high school hack (all team members must be in HS)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/005/425/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration When I was just starting out as a web developer, I spent a lot of time playing around with the khanacademy programming section. It became a hobby and I thought it would be amazing if I could revive some of the community from that in a more up-to-date format. What it does It is a small sandbox where users can write HTML and see the result immediately. This can then be published and receive community feedback (upvotes). How we built it I used next.js to build the actual site. I added google authentication to handle the account creation. I used sequelize to communicate with the database. Accomplishments that we're proud of This project is truly a jamstack site. It can scale from zero users to a billion without breaking a sweat. Everything is serverless! What we learned Non-standard SQL databases are painful. For a hackathon, speed is really important and I should have just found another host instead of sticking with planetscale (even if it is technically more complex and superior). What's next for Share Web Adding more in-depth community features (like a comment section).\nAdding more account options (ability to change pfp, username, etc).\nInternal security review + Pentest Built With jamstack javascript mysql next planetscale react serverless typescript Try it out GitHub Repo Submitted to HackBytes Winner Best high school hack (all team members must be in HS) Created by Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/shesaves-lmrs71.html",
    "project_id": "shesaves-lmrs71",
    "title": "SheSaves",
    "tagline": "SheSaves is an app that works to assist young women by helping them save smart both short term and long term.  The best part, it comes with Mona, a money coach that can provide user-tailored guidance.",
    "hackathon": "",
    "built_with": [
      "figma",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/907/855/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "UI Highlights Inspiration When thinking of what app we should create we thought to ourselves, what’s a problem that we as young woman encounter? We noticed that a lot of us always hear the phrases \"you're still young start saving early\" and \"invest in your future!\" but never really knew how to start. With this app, we have revolutionized the way in which young women manage their finances. What it does SheSaves is an app that works to assist young women by helping them save smart both short term and long term. Say you wanted to save up for a new car. This car costs $8000. You create a savings ring in the app and start saving! For every dollar you put in towards your goal, $0.90 goes towards the car, and $0.10 gets invested into stocks for long term investment... but not just any stocks. The money is invested into stocks of companies that are led by women, such as Oracle and Ulta Beauty. This was an idea that sparked when we learned that women only represent 6.6% of CEOs in the fortune 500 and we felt that we should empower these women. Not only can you save for yourself, but you can save together. We have group savings options that allow you to find friends, and set goals together, for concerts, get together's and more. \nYou can set these savings rings to take a pre-authorized amount, or you can put in custom amounts. And best of all, our app includes Mona the money coach. We did some research to determine what the most common missteps were that young woman take regarding financial decisions and had Mona address these. Mona provides daily tips according to these identified problem areas. For example, young women often sign tax credit papers without knowing what they truly mean. Our virtual money coach Mona would help to teach them these tools through videos or articles it would recommend. With this app, we want to assist young women with saving their money as well as empower female entrepreneurs. How we built it We built the app using figma UI/UX as well as writing a"
      }
    ]
  },
  {
    "file_path": "./devposts/shifter.html",
    "project_id": "shifter",
    "title": "shifter",
    "tagline": "This project encourages local restaurants to donate leftover food to soup kitchens in need.",
    "hackathon": "",
    "built_with": [
      "css",
      "firebase",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/595/426/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sign Up Front Page Posts Sign Up Front Page Posts Sign Up 1 2 3 4 Inspiration Our inspiration for Shifter derived from when one of our members mentioned that he worked at a restaurant. He saw firsthand how much food was being thrown out simply because it was not feasible to store or donate. It seemed so wasteful and harmful to the environment when there are people who are hungry right here in our city. We sought after a solution to all these issues. What it does Shifter provides a practical way for restaurants to donate their leftover food to local soup kitchens. How we built it Our team built the website using HTML, CSS, and JavaScript. We also used a Firebase database to store account information and posts. Challenges we ran into As inexperienced programmers, our team encountered plenty of technical issues and bugs when building the website. Accomplishments that we're proud of We are proud that our website has expected functionalities we implemented. What we learned We've learned much about how HTML, CSS and JavaScript work together to form a website. What's next for shifter Our team plans to take shifter to the next step by starting on various social media platforms, and adding more secure functionality to our current code. Built With css firebase html javascript Try it out GitHub Repo Submitted to byteKode - Beginner - Summer 2021 Created by Steven Vuong David Zhou Armaan Nanji Kelvin Wu"
      }
    ]
  },
  {
    "file_path": "./devposts/seatr-solution-to-air-boarding.html",
    "project_id": "seatr-solution-to-air-boarding",
    "title": "Seatr: Solution to Air Boarding",
    "tagline": "Tired of waiting in line for a seat you don't even like? (hello, middle seat!) Seatr is the solution to inefficient and messy boarding queues and allows passengers to pick the seats they want.",
    "hackathon": "",
    "built_with": [
      "american-airlines-api",
      "next.js",
      "node.js",
      "react.js",
      "tailwind",
      "tailwind-css",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/362/863/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Result Page Our Landing Page! Ticket Input Page, where users can choose to either pick their seat preference or choose a specific seat. Auth: given an invalid ticket number (using American Airline's Ticket Numbering of a 12-digit number), the user cannot proceed. Preferences Page Seat Selection Page Result Page Our Landing Page! Ticket Input Page, where users can choose to either pick their seat preference or choose a specific seat. Auth: given an invalid ticket number (using American Airline's Ticket Numbering of a 12-digit number), the user cannot proceed. Preferences Page Seat Selection Page Result Page 1 2 3 4 5 6 7 Inspiration We love traveling - but we hate boarding time. We decided to create Seatr to improve queue times during boarding and allow those who are veterans, elderly, or disabled to board first. What it does Seatr reduces boarding time exponentially. Through our algo to sort user seat preference and create a queue for boarding, passengers wait a lot less in line! How we built it We bootstrapped Seatr with T3, a bootstrapping agent that delivers TypeScript, Tailwind CSS, Next, and React all together. From there, we implemented an algorithm to sort user seat preferences and assign seating, and an algorithm that develops a queue based on passenger traits and passenger seat location for most efficiency. Challenges we ran into We all had to learn TypeScript, Next, and React to develop the UI of our site. While many of us had exposure to HTML & CSS prior to this hack, we had little exposure to React. During this project, we had to do a LOT of Googling, and we mean A LOT to fully understand React and Next.js. We also implemented page routing, which was new to us to do in Next. Some of us also did not have a lot of prior experience with Git and version control, so the initial stages of Googling and asking each other questions to be sure of the correct way to push our changes. Accomplishments that we're proud of We're especially proud of our UI - we spent qu"
      }
    ]
  },
  {
    "file_path": "./devposts/seefit.html",
    "project_id": "seefit",
    "title": "SeeFit",
    "tagline": "Exercise your body with feedback and entertainment",
    "hackathon": "",
    "built_with": [
      "figma",
      "javascript",
      "opencv",
      "p5js",
      "processing",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Real World Application Created by Ideation, 3d design, uiux web design, video, front end codin",
      "Hack@Brown 2020WinnerBest Real World Application",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/921/647/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration One of our teammates saw people with disabilities going to a service center to move and exercise their bodies. They became more energized and engaged with the exercise  as they danced with one another while listening to pop music. We thought we could create a website that teaches users how to exercise, detects their body movements, gives feedback about their movement, and generates sounds corresponding to their movements. What it does SeeFit teaches a user how to exercise in the right way. Sometimes, we may be unsure whether we’re exercising our bodies correctly. To solve this problem, our virtual coach will give feedback based its detection of a user’s body movement. If a user moves correctly, the coach will give positive feedback, so that the user gradually learns the correct movements. SeeFit also makes exercise more entertaining by providing auditory and visual inputs based on the user’s body movement. Ultimately, we want to add a multiplayer section that allows interaction among different users, with the movements of each user generating sound, and the sounds combining to create music. How we built it We built our platform using an open-source library called Openpose; specifically, we used MLI instead of COCO. We also edited some of the functionalities such that it would better fit our purpose. For example, we took out the hand and finger calculations and only focused on the major joints such that the computational speed would be faster since we were mainly focusing on how our general body moves during a workout. Challenges I ran into It was our first time using OpenCV. Thus we ran into many issues with different programs such as Caffe. We ultimately had to switch to a combination of OpenCV and tensorflow. This was an arduous process because we had to learn everything from scratch. Accomplishments that I'm proud of We were proud that we were able to simulate a squatting motion and also a bicep curl motion using code. We feel that having "
      }
    ]
  },
  {
    "file_path": "./devposts/serfana.html",
    "project_id": "serfana",
    "title": "RackRanger",
    "tagline": "Server Rack Monitoring with microcontrollers.",
    "hackathon": "",
    "built_with": [
      "ansible",
      "caddy",
      "docker",
      "embassy-rs",
      "esp32",
      "espflash",
      "grafana",
      "hedgedoc",
      "loki",
      "prometheus",
      "rust",
      "svelte",
      "sveltekit",
      "zerotier"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Domain Name from GoDaddy Registry Created by Miika Tuominen Pol Fernàndez Justus Beck Va",
      "HackUPC 2024Winner[MLH] Best Domain Name from GoDaddy Registry",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/880/100/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our monitoring solution (outside of the rack) Dashboard Our monitoring solution (outside of the rack) Dashboard Our monitoring solution (outside of the rack) 1 2 3 Inspiration After deciding to take on the Grafana challenge, our team closely examined the range of sensors provided. We began by considering one of Grafana's primary use cases—server observability—and realized that while monitoring server usage data like CPU and RAM is common, measuring the environmental conditions inside and around server racks is not. We believed that tracking such data could be very useful, providing an independent source to detect unusual conditions and potential tampering. Motivated by this insight, we started to build RackRanger. What it does Our project connects multiple server racks across various locations to a single Grafana dashboard. This dashboard shows real-time temperature and humidity data for all the racks. It also detects and displays any tampering events, like someone trying to mess with a server rack. When tampering is detected, the dashboard not only shows an alert but also sends an instant notification to the server administrator through Discord. This setup ensures that our server environments are constantly monitored and secure. How we built it Architecturally the monitoring system consists of three different components: microcontrollers, Prometheus instances and a Grafana server. The microcontrollers are small ESP32 development kits that are connected to sensors for things like temperature, humidity, motion etc. They're programmed with the PlatformIO Arduino framework and expose the real-time sensor data at an HTTP endpoint. Because the microcontrollers are usually behind a firewall, each deployment site has a Prometheus instance connected to the same network, which can then poll and store the sensor data in the time-series database. The in-site servers can be Raspberry PIs or other lightweight Linux devices. To make the metrics viewable from anywhere on the inter"
      }
    ]
  },
  {
    "file_path": "./devposts/shakespare.html",
    "project_id": "shakespare",
    "title": "Shakespare",
    "tagline": "Make a change with your Spare Change 😉💰",
    "hackathon": "",
    "built_with": [
      "firebase",
      "javascript",
      "node.js",
      "ocr",
      "react",
      "stripe",
      "tailwind",
      "tesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/803/400/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF GIF 1 2 3 4 Inspiration 💡 When was the last time you donated to charity ? How much did you donate? Was it £25 ? £4 ? Or a few pence? With an increasing amount of local stores and chain conglomerates adapting a round-up policy, at checkout, sometimes an option to round up to the nearest dollar is offered so that the extra change can be forwarded to charitable campaigns. With the pandemic, we can no longer contribute to live fundraisers and local stores that usually ask customers to round up, a proven way to garner more contributions, can no longer promote this practice. So, in this digital era with emerging challenges, we seek to keep one thing constant: the flow of donations. We believe with creative thinking and a proper approach we can innovate novel methods that’ll help us tackle the same in an intuitive manner. Thus, we build, Shakespare ✨ What it does 🤔 Shakespare makes it easier for us to donate spare change from our bills . With the snap of the camera, those spare receipts can be automatically rounded up in the comfort of home without ten impatient shoppers glaring at you from behind. The few cents that awkwardly follow your grocery bill or food delivery can transform into a catalyst that sustains global ecosystems. Squeezing out the potential in the smallest of change, we provide you with the ability to maximize your gift to those most in need, in true-Shakespearean fashion. We are targetting (ESG) - Environmental/Social/Governments - Environmental/Social events through our project! How we built it ⚙️ First and foremost, it is Crafted with 💙. \nFor the front-end, we’ve used React.js & Tailwind as a CSS framework. The Authentication (OAuth) is done through Firebase. The ML model that analysis the receipts image is made in javascript. For the backend we have used Stripe for payment gateways :- Tech Stack :- Design 🎨 We were heavily inspired by the revised version of Iterative design process, which not only includes visual design, but a full-fledged "
      }
    ]
  },
  {
    "file_path": "./devposts/seniar.html",
    "project_id": "seniar",
    "title": "SeniAR",
    "tagline": "Build shareable affective memories for elders",
    "hackathon": "",
    "built_with": [
      "aftereffect",
      "antoinejeanjeanpiano",
      "c#",
      "maya",
      "microsoft-hololens",
      "miscrosoftmixedreality",
      "mixedrealitytoolkit",
      "mrtk",
      "photogrammetrysdk",
      "photoshop",
      "proto.io",
      "sketch",
      "sketchfab",
      "soundjay",
      "unity",
      "youtube(audio)"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/917/061/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Design Mobile 3d environment builder Yinggui's AR message to his grandmother Social impact for elders Logo Design Mobile 3d environment builder Yinggui's AR message to his grandmother Social impact for elders 1 2 3 4 5 6 7 Inspiration Last Christmas, one of our team members saw her grandmother who now lives in a nursing home. She is now bedridden with a very limited mobility, but she is still so alive inside. Our teammate could see the liveliness in her eyes. She talked about her hopes to move, travel and share memories with us . Her vision is the inspiration of this project. Moreover, everyone has grandparents, and this application will let you build shareable memories with elders in augmented spaces, and eventually create a new virtual heritage between you and them . Problems Elders suffer from social isolation by staying in a limited space for a long time, which eventually causes many complications such as loss of muscle strength and mental illness . We decided to build AR Intimate messenger that connects younger generations with elders through technology. How can we create an affective environment to reconnect generations, and fulfill their hopes to share memories with us? What it does SeniAR is an AR application for family members to create an AR space using photogrammetry technique and 3D templates, and send the new space to elders using AR Cloud . Elders receive the augmented reality messages along with text messages from their family. They can immerse into the environment, be relaxed, exercise, listen to music and sound and share memories with their family, creating intimate feelings. We believed that interaction in AR allows elders to be more engaged to situations, and exercise their bodies in a more entertaining way. For restricted and disabled people, eye-tracking on Hololens2 seems the resolution of this isolation. You will craft a shareable memorial environment with landscape and registered audio message to send to your grandmother laying on her be"
      }
    ]
  },
  {
    "file_path": "./devposts/sharktainer.html",
    "project_id": "sharktainer",
    "title": "Sharktainer",
    "tagline": "A discord bot for your sharky needs",
    "hackathon": "",
    "built_with": [
      "discord.py",
      "photoshop",
      "pillow",
      "python",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Most SharkHacks Shark Hack Created by Aashi Shah Creatively curious and love building things",
      "SharkHacks3WinnerMost SharkHacks Shark Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/640/089/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Play music The s!help command for commands directory Buying a blahaj in Pet-A-Shark : The game Pet-A-Shark Appling the frame filter using the bot Play music The s!help command for commands directory Buying a blahaj in Pet-A-Shark : The game Pet-A-Shark Appling the frame filter using the bot Play music 1 2 3 4 5 6 🦈Inspiration Sharks are cool, we enjoy memes and who doesn't love a good discord bot? 🦈 What it does The Sharktainer is capable of doing a multitude of things such as: play music to help you chill put a cool shark filter on any photo has a mini game where you can buy a pet shark and feed it at regular intervals (if you forget to feed it, it will run away!) tell you cool shark themed riddles and puns :) play shark themed music and videos It's shark time y'all! 🦈 How we built it We used discord.py to make the bot and hosted it on repl.it. We used Photoshop to make the cool filters and game assets. 🦈 Challenges we ran into Getting the bot to play audio was complex and we had to rack our brains and dive deep into docs to figure it out. 🦈 Accomplishments that we're proud of We're proud of making a bot that has so many fun features and shows off our love for BLAHAJ sharks! 🦈 What we learned We learned that sharks are really cool creatures, but also how to make use of different python libraries to implement the features of the bot. Blahaj Never Gonna You Up, Never Gonna Let You Down :) What's next for Sharktainer Add ability to purchase different sharks in the Pet-A-Shark game Add a db to add customization to the game Add more filters Incorporate AR Built With discord.py photoshop pillow python replit Try it out replit.com GitHub Repo blahaj-never-gonna-give-you-up-never-gonna-let-you-down.tech discord.com Submitted to SharkHacks3 Winner Most SharkHacks Shark Hack Created by Aashi Shah Creatively curious and love building things. Neel Adwani yeet Tiffany Trinh Recent graduate from MIT, studied EECS Bailey Luu Hi everyone! My name is Bailey. I’m a third-year studen"
      }
    ]
  },
  {
    "file_path": "./devposts/sgcm.html",
    "project_id": "sgcm",
    "title": "SGCM",
    "tagline": "This Project does not have a description yeat, but it will be for the City of Munich",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "java"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration None What it does Not sure yet How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for SGCM Built With android-studio java Submitted to hackaTUM 2021 Created by David Kratz Adrian Lieven Francisco Kusch"
      }
    ]
  },
  {
    "file_path": "./devposts/shopifind-fo8sxr.html",
    "project_id": "shopifind-fo8sxr",
    "title": "Shopifind",
    "tagline": "The safety glasses that track and direct you to your tools.",
    "hackathon": "",
    "built_with": [
      "3dprinting",
      "arduino",
      "opencv",
      "python",
      "solidworks"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The safety glasses that track and direct you to your tools."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/904/294/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "You won't lose these while you're wearing them McMaster views Behind every great product is a large backend What a view! Are the glasses even on?! You won't lose these while you're wearing them McMaster views Behind every great product is a large backend What a view! Are the glasses even on?! You won't lose these while you're wearing them 1 2 3 4 5 Inspiration We always manage to lose things that were in our hands a minute ago, so we made glasses to remember for us. What it does Shopifind tracks and identifies tools that are being held by the user with computer vision. It also remembers where the user let go of the tool. At the touch of a button, the user is then guided to the spot where they left the tool with the use of LED's mounted on the glasses. How we built it We first assembled the general circuit layout for the glasses on a breadboard, then began 3D-modeling (in Solidworks) the pieces to mount the electrical components. While those pieces were printing, we used Arduino IDE to read orientation from a gyroscopic sensor to control a non-obstructive LED display on the glasses, then tracked objects in the environment by streaming a live camera feed for processing and object identification using OpenCV in Python. Challenges we ran into Lack of wireless connectivity in the Arduino Uno caused us to have to use a serial connection from a laptop to communicate with the glasses. Extremely high latency with the live camera feed meant we sometimes had to use a laptop webcam for computer vision. Accomplishments that we're proud of We successfully completed everything we wanted in an MVP for Shopifind! What we learned What's next for Shopifind Fully wireless and more compact electronics. Voice commands to request tools to be found. Incorporation of TensorFlow for more robust object identification. Built With 3dprinting arduino opencv python solidworks Try it out GitHub Repo Submitted to Hack The Hammer II Created by I designed, printed, assembled and wired the glasses. I "
      }
    ]
  },
  {
    "file_path": "./devposts/siggi.html",
    "project_id": "siggi",
    "title": "Siggi",
    "tagline": "Bridging Generations, Revolutionizing Housing",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "heroku",
      "python",
      "retellai",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hackaTUM 2024WinnerInterhyp",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/151/846/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Calling Siggi Chatting with Siggi Calling Siggi Chatting with Siggi 1 2 3 4 Inspired by a French government initiative encouraging elderly people to rent a room to a young tenant and live together, Siggi matches a host with a renter. To make this process painless, Siggi writes the contract based on the pair's requirements which they can just sign. Importantly, Siggi doesn't just make existing housing even more competitive - it creates new opportunities, fostering intergenerational symbioses in the process. What it does For this year's hackaTUM, we decided to tackle the challenges of loneliness and finding a place to live: So, we created Siggi.\nSiggi is an AI agent that interacts with each generation through their preferred means of communication and quickly drafts a contract to sign.\nThis means that Siggi talks to hosts by phone and to the younger generation via WhatsApp, matches a renter to a host, creates a contract, sending a Docusign link to the renter and a paper copy to the host. How we built it Siggi is comprised of 3 main parts: We used Twilio to provide a phone number and interface with the WhatsApp Business API. We used Retell AI for low-latency voice agents, providing a smooth phone call experience. And we used Python with FastAPI to piece them together and implement the matching algorithm. Accomplishments that we're proud of While creating each component was a challenge, integrating them proved the hardest. Twilio doesn't work well with AI agents directly so we had to come up with a way to use Retell AI. Additionally, we had to start drafting the contract during the ongoing phone call to eliminate disruptive wait times. Ultimately, the integration was a great success: Siggi provides a streamlined flow to offer and rent housing. What we learned We learned how to use Twilio, that Twilio+Gemini is too slow, and that Retell AI is way faster. The only uncertainty we're still left with is what \"elastic SIP trunking\" means... What's next for Siggi By offering a"
      }
    ]
  },
  {
    "file_path": "./devposts/shoot-em-logs.html",
    "project_id": "shoot-em-logs",
    "title": "Shoot 'Em Logs",
    "tagline": "Help our cowboy shoot his way out of exile!",
    "hackathon": "",
    "built_with": [
      "c#",
      "deso",
      "javascript",
      "react",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of DeSo Created by Chantal Pino Christian Mina Renz Vital Joshua Sintos Lib Joshua Martini",
      "YeeHaw Hacks 2WinnerBest Use of DeSo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/254/531/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 Inspiration Howdy neigh-bor! When we were brainstorming for the hackathon theme, we got the idea to emulate the comfy vibes we’d get from retro video games such as Jackal and Contra 🤠🎮 What It Does It’s a retro-inspired video game where our character, a cowboy, is in the ~wild west~ helping to protect the peace of the land from enemies with a classic point-and-shoot game. How we built it We built it using Unity’s game engine and C#. We deployed the Unity program using WebGL and used the build files in ReactJS that helped us bring it to the web. Challeneges we ran into It was our team's first time using Unity and C# so we had a bit of trouble with the installation and setup of our dev environments. We were basically running blind when we were using Unity, but we’re glad that we’re more familiar with it now than we were before using the help of guides and Youtube tutorials. Accomplishments that we’re proud of We’re happy that we were able to get the Unity game engine up and running since none of us was familiar with it and we’re happy that we got to create a few sprites ourselves while revising our physics knowledge when we had to emulate the movement of some of the entities in our game. What we learned We learned how to use Unity's interface to create our 2D game and how to use C# to create custom scripts and physics to mimic real movement. We also explored concepts like enemy behavior, how to bind keys to a character’s movements, and how to create assets for a game. A notable learning experience is how we had to learn how to import our Unity game into the web by using React and WebGL when generating our build files. What’s next for Shoot ‘em Logs For the future milestones of Shoot ‘em Logs, we envision it evolving into a full-fledged game. We visualize it having a boss, multiple levels and stages, and a more defined and robust game flow. Built With c# deso javascript react unity Try it out GitHub Repo Submitted to YeeHaw Hacks 2 Winner Best Use of "
      }
    ]
  },
  {
    "file_path": "./devposts/shadow-rp79tk.html",
    "project_id": "shadow-rp79tk",
    "title": "Shadow",
    "tagline": "Shadow is your PM and dev in one—turning tasks into tickets, completing them in the background, and opening PRs so your team stays in control with full visibility and oversight.",
    "hackathon": "",
    "built_with": [
      "aws-lambda",
      "docker",
      "groq",
      "html",
      "martian-api",
      "next.js",
      "opencode",
      "react",
      "shadcnui",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/739/190/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Shadow's Pull Request Login with GitHub Chat with Shadow Kanban Board Shadow's Pull Request Login with GitHub Chat with Shadow Kanban Board Shadow's Pull Request 1 2 3 4 5 Problem Software teams waste countless hours on repetitive coding tasks and boilerplate updates. Developers get pulled away from solving core problems to handle routine fixes, refactors, and setup work. Project managers, meanwhile, must constantly track progress and update boards, leading to context switching and overhead. The result: slower iteration cycles, more bugs slipping through, and less focus on impactful work. Solution We built Shadow — a background PM and developer in one. Developers log into our Next.js web app and connect their GitHub repos via our custom GitHub integration . Using a chat interface, they describe what they want done. Our Martian routing LLM analyzes the entire codebase for context and breaks requests into small, well-scoped tickets (to reduce LLM hallucinations). Tickets are created in a lightweight Kanban-style view, where you can move items from Todo → In Progress. Once a task moves to In Progress, an AWS Lambda (running in a Docker container) is triggered. This Lambda: Clones the repo and checks out a new branch. Uses Groq’s fast inference API to execute an agentic flow that makes the code changes. Commits the changes with descriptive, LLM-generated messages. Opens a PR with a detailed, auto-generated title and description. The dev team reviews, suggests changes, and Shadow updates the PR accordingly. Once merged, you can pick the next ticket or run multiple tasks in parallel. Shadow keeps your team in control, while removing the grunt work. How We Built It Next.js Web App → handles authentication, repo selection, and the chat interface. Martian Routing LLM → creates context-aware, small unit tickets from natural language input. GitHub Integration → OAuth + repo linking for seamless collaboration. AWS Lambda Functions (Dockerized) → perform background code changes "
      }
    ]
  },
  {
    "file_path": "./devposts/sign-sensor.html",
    "project_id": "sign-sensor",
    "title": "Sign Sense",
    "tagline": "Sign Sense revolutionizes sign language education by gamifying and revolutionizing the industry with DIY features that allow users to practice sign language with real-time feedback.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "css",
      "fastapi",
      "html",
      "javascript",
      "python",
      "pytorch",
      "svelte",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Implementing a Health Bar for tracking progress through the lessons.",
      "What techniques are best for optimizing machine learning models"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/087/555/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sign Sense: Revolutionizing Sign Language Education Inspiration Sign Sense was inspired by the challenges deaf children face when learning sign language through traditional methods, especially during the early stages of development. Recognizing the need for a more engaging and effective approach, we set out to create an interactive learning experience that makes the process both enjoyable and impactful. Inspired by popular language learning tools like Duolingo, Sign Sense does what these big corporations are scared to do: actually focus on teaching and using all resources available to do so without looking for profit. We spare no expense for our users, and are not focused on gathering a profit, but rather simply in educating the future youth. What it does Sign Sense goes above and beyond by integrating a one-of-a-kind, state-of-the-art real-time feedback mechanism. Using machine learning, AI, and various elements of data science, Sign Sense delivers personalized guidance and feedback, catering specifically to the needs of the deaf community. It's a gamified app designed to revolutionize sign language education for deaf children. It offers: Engaging learning experiences through GIF's and Interactive Videos. Implementing a Health Bar for tracking progress through the lessons. Using statistics it promotes healthy learning through Goals and Progress by minutes. A never-seen-before DIY feature allows real-time practice with feedback through a highly trained AI Model How we built it Our development process was thorough and challenging: Frontend We started with React for web development Transitioned to Swift for backend integration possibilities Explored Flutter, when Swift was not working for cross-platforms Finally settled on Svelte for its performance and ease of use with both Mobile and Web development Backend We gathered different datasets that we deemed appropriate. We then had to classify and label these different classes based on multi-class classification decision"
      }
    ]
  },
  {
    "file_path": "./devposts/sightsense.html",
    "project_id": "sightsense",
    "title": "Sight Sense",
    "tagline": "Your Third Eye - Empowering the visually impaired",
    "hackathon": "",
    "built_with": [
      "jetson",
      "jetson-nano",
      "openai",
      "python",
      "react",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Generative AI Hack Winner Best Pitch WaffleHacks 2023 Created by I created a speech recognition sys",
      "Best Generative AI Hack Winner Best Pitch WaffleHacks 2023 Created by I created a speech recognitio",
      "Treasure Hacks 3.5WinnerBest Generative AI HackWinnerBest Pitch",
      "Your Third Eye - Empowering the visually impaired",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/466/108/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Object detection Hardware Used Object detection Hardware Used Object detection 1 2 3 Inspiration We were inspired to create a product that could help individuals with visual impairments navigate the world around them with greater independence and autonomy. What it does SightSense is a wearable device that utilizes object detection, voice commands, and text-to-speech functionality to aid individuals with visual impairments in navigating their surroundings in real-time. How we built it We built SightSense using a Jetson Nano 4GB module running on a Linux operating system, a Microsoft webcam, a speaker, and normal sunglasses. We also utilized advanced artificial intelligence algorithms for real-time object detection, captioning, and speech recognition. Challenges we ran into We faced several challenges in building SightSense, including integrating all of the components seamlessly into a pair of sunglasses, optimizing the algorithms for real-time object detection, and ensuring the device was both affordable and accessible. Accomplishments that we're proud of We are proud to have created a product that has the potential to enhance the independence and quality of life of individuals with visual impairments. We are also proud of the seamless integration of all the components into a practical wearable device. What we learned During the development of SightSense, we gained experience in working with various cutting-edge technologies, including the Jetson Nano 4GB module, Microsoft webcam, and text-to-speech functionality. We learned how to integrate these technologies and optimize their performance to create a seamless user experience. Additionally, we developed expertise in programming languages such as Python and in using development tools like Tensorflow and OpenCV for real-time object detection and image processing. Through this project, we acquired new skills and knowledge that will enable us to tackle even more complex challenges in the future. What's next for SightSen"
      }
    ]
  },
  {
    "file_path": "./devposts/shoot-for-the-riches.html",
    "project_id": "shoot-for-the-riches",
    "title": "Shoot for the riches",
    "tagline": "A game for FPS (first person shooter) fans who want to win money from doing what they love",
    "hackathon": "",
    "built_with": [
      "blender",
      "c#",
      "unity",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Design Created by I came up with the idea for the game, worked on the game design in unity, an",
      "LaunchHacks IWinnerBest Design",
      "A game for FPS (first person shooter) fans who want to win money from doing what they love",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/806/508/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We have always been interested in game design and 3d modeling, so we decided to make a profitable, innovative product by integrating the two. What it does \"Shoot for the Riches\" is an fps game we developed that rewards players with real (not actually real as this is simply a prototype) money for killing AI's that are programmed to chase and attack them. Players can acquire new weapons, drive cars, and attack their enemies while trying to move on to the next waves (each with stronger AI's, more rounds, and new weapons). The game can be infinite but will end when a player runs out of health. If the player reaches a certain number of waves or more, he or she will be rewarded money based on how well they performed. If this were to be taken up to be an actual product, our funding would come from sponsors and ad revenue. How we built it We built this project using Unity 3d which provided a vast library for game design. We used Blender to create 3d models to build our scene. We used Visual Studio to write the C# code for the game. We split up the workload by having two of us focus on 3d modeling while the other focused on coding and structuring the game (although we helped each other greatly in between) Challenges we ran into As we had never used Blender before coming to the hackathon, we needed to rely on googling and watching youtube tutorials (to get to know Blender's complicated controls) for creating the 3d models. Additionally, we ran into trouble when trying to make the player enter a vehicle and drive as well as creating animations for gun muzzle effects in Blender. Accomplishments that we're proud of We were proud of having been able to go from knowing absolutely nothing about how to use blender to creating complicated 3d objects such as trees, rigged robots, and guns. We were also proud of having been able to create an FPS game (although not as intricate as modern FPS games) in 24 hours while being able to take breaks in between. What we learned We le"
      }
    ]
  },
  {
    "file_path": "./devposts/shipsmart.html",
    "project_id": "shipsmart",
    "title": "SHIPSmart",
    "tagline": "SHIPSmart helps UC SHIP students estimate medical costs upfront, ensuring the lowest price. If our estimate is lower than your bill, we handle the claims and fight for rebates. No surprises!",
    "hackathon": "",
    "built_with": [
      "cerebras",
      "figjam",
      "figma",
      "openai",
      "python",
      "swiftui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/382/742/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Logo Logo 1 2 Inspiration Have you ever walked out of a doctor’s appointment, already exhausted, only to be hit with a surprise bill? The expectation is endless phone calls, paperwork, and fighting with insurance companies just to understand what you owe. But what if it didn’t have to be that way? SHIPSmart is here to help UC students enrolled in SHIP take control of their healthcare costs. Our app estimates medical, dental, and vision costs upfront, ensuring the lowest possible price, and if our estimate is lower than what you were charged, we’ll fight for rebates and handle the follow-up claims. No more surprise bills, no more endless phone calls—just peace of mind knowing your insurance is working for you. What it does SHIPSmart is a smart assistant for UC SHIP students, offering real-time cost estimates for medical, dental, and vision services.\nUsing a secure login system and a locally hosted database, SHIPSmart tracks user details, past visits, and insurance data, updating this info with each chat. When a user interacts with SHIPSmart, the AI gathers information about their symptoms, priorities, and insurance status. Based on this data, it searches our SQL database for the best available providers and streamlines the booking process, including extracting details from insurance cards to auto-fill forms.\nSHIPSmart uses UC SHIP data to provide accurate medical cost estimates. By training an AI model on policy documents and using regression analysis on historical data, we guarantee precise estimates. Any discrepancies in pricing are flagged and managed — the AI will work with insurers and providers using Cerebras AI to track down the reason for the difference, ensuring users are either refunded or the issue is explained.\nAdditionally, SHIPSmart updates policy changes and healthcare charges in real-time, automatically analyzing data to identify trends and price fluctuations for specific procedures. How we built it We designed the app's interface using Figma to "
      }
    ]
  },
  {
    "file_path": "./devposts/signspeak-kgufm1.html",
    "project_id": "signspeak-kgufm1",
    "title": "SignSpeak",
    "tagline": "This program provides an accessible service for many people to learn and perfect sign language whilst being evaluated using computer vision.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "mediapipe",
      "next.js",
      "node.js",
      "react",
      "tenserflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "uOttaHack 5WinnerTop 3 Finalist!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/380/754/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sign Speak Logo Sign Speak Logo 1 2 3 4 1st Place! Inspiration Sign language is a universal language which allows many individuals to exercise their intellect through common communication. Many people around the world suffer from hearing loss and from mutism that needs sign language to communicate. Even those who do not experience these conditions may still require the use of sign language for certain circumstances. We plan to expand our company to be known worldwide to fill the lack of a virtual sign language learning tool that is accessible to everyone, everywhere, for free. What it does Here at SignSpeak, we create an encouraging learning environment that provides computer vision sign language tests to track progression and to perfect sign language skills. The UI is built around simplicity and useability. We have provided a teaching system that works by engaging the user in lessons, then partaking in a progression test. The lessons will include the material that will be tested during the lesson quiz. Once the user has completed the lesson, they will be redirected to the quiz which can result in either a failure or success. Consequently, successfully completing the quiz will congratulate the user and direct them to the proceeding lesson, however, failure will result in the user having to retake the lesson. The user will retake the lesson until they are successful during the quiz to proceed to the following lesson. How we built it We built SignSpeak on react with next.js. For our sign recognition, we used TensorFlow with a media pipe model to detect points on the hand which were then compared with preassigned gestures. Challenges we ran into We ran into multiple roadblocks mainly regarding our misunderstandings of Next.js. Accomplishments that we're proud of We are proud that we managed to come up with so many ideas in such little time. What we learned Throughout the event, we participated in many workshops and created many connections. We engaged in many conversat"
      }
    ]
  },
  {
    "file_path": "./devposts/signforgood.html",
    "project_id": "signforgood",
    "title": "SignForGood",
    "tagline": "AI Compliance Engine Helping Non-profits Build Trust & Transparency ✨",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "cloudflare",
      "docker",
      "docusign",
      "docusign-click",
      "docusign-connect",
      "docusign-esignature",
      "docusign-oauth",
      "docusign-webform",
      "next.js",
      "openai",
      "shadcn-ui",
      "typescript",
      "uploadthing",
      "vercel",
      "vercel-ai-sdk"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/240/299/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Architecture diagram of Sign4Good Sign4Good Leaderboard Dashboard showing all Non-profits managed by the admin Adding a contract to be tracked by Sign4Good Showing all contracts that are being tracked Logical flow diagram of Sign4Good Sign4Good is a multi-tenet web application, and we use role based access control. An admin can manage multiple non-profits Architecture diagram of Sign4Good Sign4Good Leaderboard Dashboard showing all Non-profits managed by the admin Adding a contract to be tracked by Sign4Good Showing all contracts that are being tracked Logical flow diagram of Sign4Good Sign4Good is a multi-tenet web application, and we use role based access control. An admin can manage multiple non-profits Architecture diagram of Sign4Good 1 2 3 4 5 6 7 8 9 About HawkEye: AI-Powered AWS Cost Optimization Platform Inspiration Public cloud has become the stepping stone that enables all of us to build, deploy, and scale applications within minutes. You no longer need a basement with air conditioning, cooling systems, and multiple backup generators to launch your next idea on the web—all because with a few clicks, we can rent a server in a remote datacenter. The public cloud market is currently valued at around $723.4 billion USD and is growing by 21.5% year over year . From decentralized blockchain Ethereum nodes to centralized movie streaming websites like Netflix, to governments—everyone is on public cloud. However, despite this massive adoption, cloud is tricky . People with years of experience make mistakes and even costly blunders. The UI isn't very intuitive, nobody truly understands public cloud pricing, and it's really difficult to use the cloud the right way. This is where HawkEye comes in—an AI agent designed to monitor your public cloud accounts, identify security recommendations, and provide actionable insights on how you can reduce costs. What it does HawkEye is a comprehensive AWS cost optimization platform that provides: 🔍 Intelligent Cost Analysis S3 St"
      }
    ]
  },
  {
    "file_path": "./devposts/silent-voice-o1tue0.html",
    "project_id": "silent-voice-o1tue0",
    "title": "Silent Voice",
    "tagline": "Speech to American Sign Language (ASL) translator",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Created by MariHacks Team MariHacks is the first and largest hackathon for high school and CEGEP st",
      "First Place Created by MariHacks Team MariHacks is the first and largest hackathon for high school",
      "MariHacks 2018WinnerFirst Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Silent Voice Silent Voice is developed after realizing that people with hearing disabilities often get the short end of the stick when it comes to translation and linguistic software developments. To overcome this issue, we developed a speech to American Sign Language (ASL) translator. During our pitch, we will present the challenges we overcame to get here. The GitHub link has our software we created at MariHacks. Try it out GitHub Repo Submitted to MariHacks 2018 Winner First Place Created by MariHacks Team MariHacks is the first and largest hackathon for high school and CEGEP students in Québec! Laurence Liang Wassim Mouhajer Omar Abdel Baky RolandRiachi"
      }
    ]
  },
  {
    "file_path": "./devposts/shylock.html",
    "project_id": "shylock",
    "title": "Shylock",
    "tagline": "PayDay Loan Comparisons",
    "hackathon": "",
    "built_with": [
      "css",
      "django",
      "html",
      "javascript",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Shylock is a moneylender in Shakespeare's play, The Merchant of Venice. He is accused of practicing usury, i.e lending money with extremely high fees. Payday loans are the modern version of Shylock, with interest rates ranging from 36% or lower to over 600% (Center for Responsible Lending, 2021). Payday Loans. While they might be convenient, payday loans are generally expensive and should only be seen as a last resort. Many lenders charge late fees if you cannot pay out the loan in time. This starts a vicious circle of borrowing and debt. People have no choice but to pay this once they have taken out the loan, with many not knowing what exactly they are getting themselves into. As well as these extortionate interest rates, payday loans can have numerous other, and equally damaging, consequences such repeat borrowing and increases in the chances of overdrafts, losing a bank account, bankruptcy and difficulty paying bills. The Consumer Financial Protection Bureau found that nearly 1 in 4 payday loans are reborrowed nine times or more, with most borrowers taking five months to pay off the loans, resulting in an average of $520 in finance charges in ADDITION to the original loan amount (The Pew Charitable Trust, 2012). We wanted to create an application which would allow people to rate their payday loan providers. Not only will this mean that people can anonymously review the hidden charges and interest rates given by that lender, but this application will also act as an incentive for these companies to be more transparent and adopt fairer practices in order to increase their ranking and attract new customers. Fun Fact:\nThere are 23,000 payday lenders in the US, that's almost twice the number of McDonald's restaurants!! Payday loans being taken out have tripled with the pandemic, and consumers continue to do so with triple-digit interest rates! What it does This web application allows users to input data about their loan provider into several different field"
      }
    ]
  },
  {
    "file_path": "./devposts/shopwise-cf75sd.html",
    "project_id": "shopwise-cf75sd",
    "title": "ShopWise",
    "tagline": "Forget the days when you had to spend hours agonizing over the best product to buy.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gpt-4",
      "python",
      "react",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Forget the days when you had to spend hours agonizing over the best product to buy."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/662/017/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Chatbot Search Page Chatbot Search Page Chatbot 1 2 3 4 Inspiration All of us have struggled with online shopping. There are so many similar products, which one should we buy? We often spend hours checking reviews and researching the best product and often still aren't sure if we made the right decision. ShopWise can easily solve this issue by analyzing customer reviews to identify trends and allow you to ask questions. What it does Users can enter a product they want to buy, for example, 'frying pan'. Then we get the top 5 products on Amazon, analyze their respective reviews, and summarize the key info for each product. The user can also choose to engage in a conversation with these products. For example, 'Which pan is the most durable?'.  If the user has narrowed down their own products and doesn't simply want the top 5, they can also enter the URLs for the chatbot and ask questions comparing them. How we built it We used React for the front end to allow for dynamic and responsive rendering. We used Python-Flask for the backend. Once the user enters a product name, we scrape Amazon for the top 5 URLs. Then we scrape each URL using multithreading for all of the reviews and associated info. We then use gpt-4 to analyze the reviews and summarize the pros and cons. For the chatbot, we load the scraped reviews and reference them when answering the user questions, again using gpt-4. Then React calls the corresponding Flask APIs and renders the info. Challenges we ran into Back-end wise, we struggled with making React work with Flask as there were many cross-platform (namely CORS) issues that made the API calls difficult. We also struggled with making so many requests for the URLs and accessing the reviews, as it took a long time. We learned how to use Multithreading to speed up requests.\nFront-end wise, we struggled with rendering the 3D model since there were so many aspects to set up such as camera angle/rotation/lighting. Accomplishments that we're proud of We are pr"
      }
    ]
  },
  {
    "file_path": "./devposts/signar-hw6rxf.html",
    "project_id": "signar-hw6rxf",
    "title": "SignAR",
    "tagline": "Our goal is to break down barriers for non-verbal communicators. to have the experience of voice to voice conversation.  We believe everyone has an opinion and opportunities should be for all.",
    "hackathon": "",
    "built_with": [
      "adobe",
      "adobe-illustrator",
      "augmented-reality",
      "c#",
      "interviews",
      "leap-motion",
      "oculus",
      "photoshop",
      "unity",
      "ux",
      "zed"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/917/479/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "LOGOTYPE 1 UI MOCK UP 2 UI MOCK UP UI MOCKUP 3 LOGO LOCK UP LOGOTYPE 1 UI MOCK UP 2 UI MOCK UP UI MOCKUP 3 LOGO LOCK UP LOGOTYPE 1 1 2 3 4 5 6 Inspiration We are inspired to augmented reality to create an experience for those who are hearing and speech impaired to be able to communicate via sound and text. What it does SignAR is the next generation of sign language application, providing non-verbal communicators new tools to communicate.  Core features include a gesture/sign language to voice/text translation, the ability to customize vocabulary and phrases [hot keys] to be able to verbally communicate with friends, family, coworkers and loved ones. How we built it We built this experience in Unity, utilizing leap motion for hand-tracking, oculus rift which was hacked with a camera to empower an AR function, several laptops, a Bluetooth speaker - as no directional audio speaker was available. Usability and readability were our main concerns of UX and UI. For UX, we worked on a user persona and sketched low fidelity prototyping with a functional flow. We focused on visual indicators/feedbacks for hearing impaired users and more comfortable face to face communication. To differentiate a user and a conversation partner, the complementary colour was used. We used a user's eye level as a reference for the position of UI so that, augmented reality UI harmonized well with reality and do not disturb a user's conversation. We leveraged Adobe Photoshop and Illustrator for the UI and branding elements. Challenges we ran into We ran into challenges around teaching the experience to detect human hands and the associated meaning behind the gestures made by human hands. None of the team previously knew American sign language and it was a fairly steep learning curve, but we learned enough to start the creation of a gestural vocabulary.  Machine learning would be a fantastic addition to the experience in order to build the vocabulary efficiently and create a meaningful tool. This ex"
      }
    ]
  },
  {
    "file_path": "./devposts/skip-the-walk.html",
    "project_id": "skip-the-walk",
    "title": "Skip the Walk",
    "tagline": "Skip the Walk - When you're at Hack the North... but still want pizza.",
    "hackathon": "",
    "built_with": [],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/023/458/datas/medium.png",
    "description": []
  },
  {
    "file_path": "./devposts/sketch-architect.html",
    "project_id": "sketch-architect",
    "title": "SketchGAN",
    "tagline": "This project make your sketches jumping in 3D, today's modelling software require a lot of experience even in initial Conceptual design phases. Using fast.ai and pytorch3D we simplify this process.",
    "hackathon": "",
    "built_with": [
      "fast.ai",
      "pytorch",
      "pytorch3d"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/192/201/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Complitely distrupt the modeling industry, specifically the Architecture Industry. We envisioned to usign simple sketch interfaces to provide real time feedback for initial conceptual design phases. What it does This application is able to recognize and classify sketch to 3D solid and geometry How I built it with pytorch and fast.ai Challenges I ran into Using large multiple GPU to train model with a new custom dataset that we developed Accomplishments that I'm proud of Experimenting with Pytorch3D in order to achieve this goal Built With fast.ai pytorch pytorch3d Try it out GitHub Repo Submitted to PyTorch Summer Hackathon 2020 Created by Alberto Tono I work as Researcher for Stanford ( HAI Graduate Fellow and CIFE Researcher)"
      }
    ]
  },
  {
    "file_path": "./devposts/signtrans.html",
    "project_id": "signtrans",
    "title": "SignTrans",
    "tagline": "This app can convert speech to Hand Sign Language proving helpful for those with hearing impairment.",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "java",
      "kotlin"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/860/564/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Click on mic button and speak and to convert click on hand sign button. It will show the hand signs according to the letters. Click on mic button and speak and to convert click on hand sign button. It will show the hand signs according to the letters. 1 2 3 4 Inspiration The main inspiration behind this application is to remove the communication barrier for Deaf-mutes. Hearing loss or deafness has a direct impact on communication, educational achievements, or social interactions. Lack of knowledge about Deaf culture is documented in society as well as in the healthcare environment. So we tried to close that barrier with this app which helps us to easily interact with Deaf people using sign language. What it does People can use this app on their phone to convert their voice/text into Hand Sign Language to communicate by showing Hand Signs generated with people having a hearing impairment. People with hearing loss can use this app to act as a listener which can then convert voice into readable text sentences or generate its translated Sign Language. How we built it We build this app using android studio, its code is written in kotlin, and to design the user interface we used XML code after that for voice recognition we used a class to work with Android speech recognition Authored by Aleksandar Gotev, for displaying hand signs we simply used and font in which all characters are stored in hand sign form. Challenges we ran into We specifically remember when we tried to iterate each letter in the string sentence, We couldn't use the Thread.sleep() function as it was causing the whole app to freeze. So we used numerous methods of using Handlers, Thread functions and finally figured it out with some help from StackOverflow posts. Accomplishments that we're proud of We are proud of the Kotlin app that we created as this is our first working kotlin project for most of us. We learned a lot about creating UI elements in Kotlin. Finally, we are happy that we can create an app th"
      }
    ]
  },
  {
    "file_path": "./devposts/skribblio-demon.html",
    "project_id": "skribblio-demon",
    "title": "Skribblio Demon",
    "tagline": "Model built to detect image matching using Quick, Draw",
    "hackathon": "",
    "built_with": [
      "cnn",
      "keras",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/644/188/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We are inspired CS students who were looking for a challenging project to grow as developers. What it does We created a ML project to be able to correctly match images based on input strokes How we built it We built it using tensorflow, keras, and a convolusional neural network for doing the ML Challenges we ran into amount of files and runtime Accomplishments that we're proud of We are proud to give a working output What we learned We learned about what it is like doing a datathon and troubleshooting at the last minute What's next for skribblio demon Hopefully greater growth as students. Built With cnn keras tensorflow Try it out GitHub Repo Submitted to TAMU Datathon 2023 Created by Co-developed models and ran the data training. John Mo :D Akshath Venkataraman Joanne Liu Andrew Zheng"
      }
    ]
  },
  {
    "file_path": "./devposts/simplehr.html",
    "project_id": "simplehr",
    "title": "SimpleHR",
    "tagline": "HR software to help small businesses manage scheduling, payrolls, recruiting, and employment records",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "firebase",
      "html5",
      "javascript",
      "node.js",
      "scss",
      "twilio",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Make an employee-side for the website (to track hours, etc.)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/822/988/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Scheduling Page Scheduling Page Scheduling Page 1 2 Inspiration We wanted to help small businesses bounce back from covid (and navigate \"the great resignation\") by helping them manage, maintain, and recruit employees. We also wanted to help restore economic activity by increasing employment as well as increasing economic productivity. We felt that an HR management software would be the best type of software to tackle these challenges. What it does SimpleHR is an HR manager that allows small business owners to manage their HR using a simple and easy-to-use website. Businesses can manage the schedules of employees, calculate and streamline payrolls, schedule interviews with potential employees, and access business/employment records (like tax forms). SimpleHR also uses the Twilio API to send notifications (and scheduling requests) to employees if there's a change in their schedule or if the business needs them for an on-call shift. How we built it Backend: Express, Node Frontend: Vue Database: Firebase APIs: Twilio Languages: Javascript, HTML, CSS/SCSS Challenges we ran into Figuring out how to design the database (especially since it's a NoSQL database) Figuring out how to use the Twilio API Figuring out how middleware and JSON parsing works Figuring out how to work with JSON dynamically Accomplishments that we're proud of Passing data props to child components Resolving issues with CORS/JSON-parser Working with APIs, especially figuring out how the headers work Designing modern SPA What we learned Learning how to work with dynamic JSON Vue routing Designing a NoSQL database to work with our project Making API routes that utilize 3rd-party APIs Learning Twilio and how you shouldn't git push your API key (LOL) What's next for SimpleHR Make a mobile app Make an employee-side for the website (to track hours, etc.) Built With css3 express.js firebase html5 javascript node.js scss twilio vue Submitted to UofTHacks IX Created by Worked on backend, database design, and Twil"
      }
    ]
  },
  {
    "file_path": "./devposts/skillscore.html",
    "project_id": "skillscore",
    "title": "SkillScore",
    "tagline": "SkillShare: Train like a pro, Score like a pro.",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Tejas Patel wanted to be on the school's basketball team, but couldn't afford a basketball coach and thus failed the tryouts. He was very discouraged by this, but this gave our group the idea of our project: SkillScore. What it does SkillScore allows users to submit their video of them doing an exercise/sport and compares their movement with a coach's movement. Our algorithm carefully analyzes both videos to find any similarities. Afterwards, it outputs a percentile score based on the user's performance and feedback on what to improve on for the user. How we built it We built it using HTML, JavaScript, CSS, Python, and Flask. Challenges we ran into One difficult challenge we ran into was that the response wasn't going to the server (aka the front end connection was \"hideous\"). The program crashed and it took a lot of time to fix. Another issue was how would the user get the video of the coach doing the workout/sport. Accomplishments that we're proud of We're proud of the algorithm we developed and how accurate it is when finding similarities between the learner's video and the coach's video. Another thing we are proud of is the potential of this website and how many people it can help educate. What we learned We learned how to communicate with each other, and how flask works. What's next for SkillScore Build a bigger community of sports enthusiasts and scale our website globally. Built With css flask html javascript python react Try it out drive.google.com Submitted to Phoenix Hacks Created by Tejas Patel Aravindkrishna Arivudainambi Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python"
      }
    ]
  },
  {
    "file_path": "./devposts/sir-model-with-migration-and-stochastics-for-ncov-19.html",
    "project_id": "sir-model-with-migration-and-stochastics-for-ncov-19",
    "title": "SIR Viral - nCoV-19 SIR Model with Migration",
    "tagline": "We created a simple SIR model with migration term and stochastics based on the immigration data in the US.",
    "hackathon": "",
    "built_with": [
      "google-notebook",
      "python",
      "r"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Brown Datathon 2020WinnerCorona Impacts 1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/952/070/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Multicity without Ban Vanilla SIR Model Multicity with Ban Multicity without Ban Vanilla SIR Model Multicity with Ban Multicity without Ban 1 2 3 https://github.com/jackshen1998/Brown-Datathon-2020-Group-Sir-Viral https://docs.google.com/presentation/d/10-amg9KMbpBd5I5sutp_ajdAdReDMQQqgY1hUq59I-c/edit?usp=sharing Project Summary The project is divided into two parts. For the first part, we did some exploratory analysis and visualization of the data sets given at first and found out that if the outbreak continues. The second part included an exploratory model using SIR system of ODEs with the parameters determined by the given data. Introduction The rapid development of novel corona virus (nCoV-19) is the most pressing issue the humanity is facing today. Globally, there have been ~78k confirmed cases with ~2500 deaths, and the figures are expected to grow more in the coming months. We aim to provide some insights to the ongoing situation via visualization and model the outbreak on a popular SIR model with some tweaks. We used all six data sets that are provided by Fidelity and we scraped the most updated corona virus outbreak infection number from a Chinese website.  model was to provide some insights into the situation, not to accurately model the outbreak. Many research institutions are striving to predict the situation more accurately. Even though the provided dataset only provided the inbound US travellers, we determined that China should no longer be the focus of the issue with the recent major super-infection events having taken place in Japan, Korea, and Italy; it has already become a global phenomenon and needs to take other affected countries into account. Moreover, the politically charged fear against the outbreak on imposing strict ban on international travellers and growing distrust against people of the Asian origin, we thought it would be interesting to see if limited migration would affect the spread of the spread in the US cities. Of course the model "
      }
    ]
  },
  {
    "file_path": "./devposts/slackattack.html",
    "project_id": "slackattack",
    "title": "SlackAttack",
    "tagline": "Expose your shit talk via Slack",
    "hackathon": "",
    "built_with": [
      "fishaudioapi",
      "slackapi",
      "typescript",
      "webspeechapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Toronto Stupid Ideas HackathonWinner$tupid",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/783/263/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Have you ever had a passive aggressive coworker and wanted to know what they really thought? YEA, us too, so we created SlackAttack. What it does SlackAttack records your audio while your on mute and sends them to your teams Slack channel in SpongeBob’s voice. How we built it We developed a TypeScript-based Chrome extension that integrates hotkey detection with the WebSpeech API for real-time speech-to-text transcription. The transcribed text is then processed through the Fish Audio API to generate audio in SpongeBob's distinctive voice. Finally, the generated audio file is automatically posted to Slack via the Slack API, completing the entire workflow within seconds Challenges we ran into Initially, we wanted to use Veo3 to generate a video of Spongebob with the transcribed audio. But, we realized this would take too long (~30 seconds) which wouldn't make sense within the context of what was said in that moment. Accomplishments that we're proud of Using the WebSpeech and Fish Audio API. What we learned You're your own worst disaster. What's next for SlackAttack Integrate multiple voices like Barack Obama and Donald Trump. Built With fishaudioapi slackapi typescript webspeechapi Try it out GitHub Repo Submitted to Toronto Stupid Ideas Hackathon Winner $tupid Created by Fred He Michelle Zhang Mike Nguyen"
      }
    ]
  },
  {
    "file_path": "./devposts/slouchn-t.html",
    "project_id": "slouchn-t",
    "title": "Slouchn’t",
    "tagline": "Are you sick of having back and neck pain? We spend our time working 24/7 with our back pain attacking us every second in the present and future. So, how do we save our backs? USE SLOUCHN'T!",
    "hackathon": "",
    "built_with": [
      "discord",
      "git",
      "github",
      "google-docs",
      "mediapipe",
      "opencv",
      "playsound",
      "python",
      "threading",
      "tkinter",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/986/841/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "WARNING (When the user slouches, a pop up window will appear and warn the user to fix their posture) Slouchn't Logo Tip of the Day (Intro Screen) Sit Straight ( Asks user to sit in a good posture so that the program can record the data) Sean Sitting Straight Now Slouch (Asks user to sit in a bad posture so that the program can record the data) Sean Slouching Calibration Complete ( finalizes the posture ) WARNING (When the user slouches, a pop up window will appear and warn the user to fix their posture) Slouchn't Logo Tip of the Day (Intro Screen) Sit Straight ( Asks user to sit in a good posture so that the program can record the data) Sean Sitting Straight Now Slouch (Asks user to sit in a bad posture so that the program can record the data) Sean Slouching Calibration Complete ( finalizes the posture ) WARNING (When the user slouches, a pop up window will appear and warn the user to fix their posture) 1 2 3 4 5 6 7 8 9 Inspiration Slouchn’t was inspired by the high rates of back pain induced by bad posture, which is a severe issue that affects people of all ages, especially students and adults. This issue continues to impact people today, and the habit of bad posture has only worsened ever since COVID-19 started. Thus, we’re introducing Slouchn’t, a very accessible and effective way to improve your posture while working on your laptop or computer. What it does Slouchn’t first calibrates with the user to determine their correct and incorrect posture. With this collected data, the program will determine the range the user would have to meet in order to maintain a good posture. If the user does not have the right posture - straight back and neck - for a certain amount of time, the program will urge the user to adjust their posture through audio and video effects. The program also includes tips the user can keep in mind for maintaining the perfect posture. How we built it We used the opencv-python package, along with mediapipe to build our computer vision program. It "
      }
    ]
  },
  {
    "file_path": "./devposts/skyscraper.html",
    "project_id": "skyscraper",
    "title": "SkyScraper",
    "tagline": "SkyScraper is an AI-powered aviation operations and safety platform that provides real-time flight risk assessments, weather impact analysis, ATC coordination insights, and smart rescheduling.",
    "hackathon": "",
    "built_with": [
      "claudesonnet4",
      "google-cloud",
      "groq",
      "nextjs",
      "vapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/495/700/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "🌟 Inspiration The aviation industry operates under immense pressure to balance safety, efficiency, and customer service in real time. From unpredictable weather patterns to high ATC load, risk management can feel reactive rather than proactive. We were inspired to build SkyScraper as a modern AI-driven solution that gives operators, airlines, and even customers real-time insights, proactive alerts, and automated assistance — helping them make safer, faster, and smarter decisions. 🚀 What it does SkyScraper is a real-time aviation safety and operations dashboard combined with AI assistants.\n✅ It provides live flight tracking with detailed risk scores based on weather, ATC load, aircraft type, and more.\n✅ It features an AI chat agent that answers safety-related queries, recommends rescheduling, and evaluates flight risks.\n✅ It integrates a Vapi-powered voice agent for lead qualification, smart calling, and customer follow-ups, enabling human-like conversations over the phone.\n✅ The platform issues automated alerts when flights surpass critical risk thresholds, helping operators act fast. 🛠 How we built it Frontend: Next.js + TailwindCSS for a clean, responsive UI with interactive components (scroll areas, dialogs, badges).\nFlight data: Mock + live API integrations (e.g., AviationStack) for simulating flight risk metrics.\nAI agents:\nCustom AI chat assistant using Next.js API routes + OpenAI API for responses.\nVapi integration to handle outbound calls and lead qualification, with webhooks to capture results.\nState management: React hooks and context for managing flight data, messages, and agent states.\nDeployment-ready: Designed with scalability in mind, easily hosted on platforms like Vercel.\n⚡ Challenges we ran into Real-time simulation: Since we didn’t always have access to live flight data during development, we had to design realistic mock data structures that could seamlessly integrate with actual APIs later.\nVapi integration: Handling phone interactions and lead q"
      }
    ]
  },
  {
    "file_path": "./devposts/slacker-tracker-6qjpw1.html",
    "project_id": "slacker-tracker-6qjpw1",
    "title": "slacker tracker",
    "tagline": "It will never leave you lacking... if you be slacking, it be tracking... so get hacking!",
    "hackathon": "",
    "built_with": [
      "chart.js",
      "css",
      "flask",
      "html",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "It will never leave you lacking... if you be slacking, it be tracking... so get hacking!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/702/913/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Many of us (especially computer science students) suffer from spending too much time on the computer which is very bad for our health. Moreover, we often find ourselves wasting too much time on the computer gaming or doing something recreational like social media rather than the work we should be doing, and for some they work too much and don't take the breaks they should. What it is supposed to do slacker tracker is a Full-stack Web Application that helps you track the amount of time you spend, working , gaming , and offline . Using the optimal ranges (with respect to healthy living) of times we should be spending doing these things every week, slacker tracker helps you see if you have a healthy balanced life or not. When you are working on the computer, run the work timer. When you are gaming (recreating on the computer), run the game timer. When you are off the computer (the app is closed), it keeps track of your offline time. Lastly, to make sure you don't cheat, you have an hour leeway of unallocated time when you are on your computer (app is open) but haven't started the game or work timer. How we built it Full-stack Web Application using Flask and SQLite. Challenges we ran into Both of us had midterms Saturday morning and so we didn't have much time and didn't have the contribution that we needed, so unfortunately the back-end is minimal and adds users from the registry page and records start and stop times into the database (the screenshots showcase samples of the front-end and the intended layout). Accomplishments that we're proud of Pulling together what we did in the short time we had. What's next for slacker tracker Hopefully to get actually complete implementing it, add usergroups so time data is only visible to your selected friends for privacy, and messaging your friends when they need it most (are having a bad week). Built With chart.js css flask html python sqlite Try it out GitHub Repo Submitted to Hack the Valley V Created by My "
      }
    ]
  },
  {
    "file_path": "./devposts/smart-search-wx75zi.html",
    "project_id": "smart-search-wx75zi",
    "title": "Smart Search",
    "tagline": "This project is a submission for the Schonfeld Street ID Challenge. It is a search engine that gives users matches to the security IDs that they input in the search bar.",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "html5",
      "javascript",
      "node.js",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/215/334/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Brand logo Brand logo Brand logo 1 2 Inspiration We wanted to learn something new to expand our skillset as future software engineers, so after scrolling through the list of challenges provided by ShellHacks, we decided to enter the Schonfeld Challenge. What it does Our web app is a search engine that helps users find financial security IDs parsed from the given Schonfeld Securities .csv file. How we built it React for the front end and Node.js and Typescript for the backend. Challenges we ran into Our main challenge was finding a way to build the search engine itself. The algorithm was to be written in the backend folder, while the frontend only had to call on the function from the backend and input the necessary details from the search bar input that the user types in on the actual app. Another challenge was creating a function that successfully parsed through the .csv file for filtering out the necessary security_id's that would appear as suggestions/matches when the user types in the ids on the search bar. With the help of online documentation, we successfully implemented our own function and parsing. Accomplishments that we're proud of It took us a long day to figure out the parsing and searching algorithm, but we persisted and were successful. What we learned It was possible to write code parsed through a big .csv file in only a few lines of code using functions from the csv-parse library. Also, the search engine algorithm function traverses the parsed data in an array, and from whatever the user inputs in the search bar, we sort the matches based on similarity. We also learned how to use Docker to run the frontend and backend simultaneously without any issues. What's next for Smart Search Make searching algorithm more efficient and better UI. Built With css3 express.js html5 javascript node.js react typescript Try it out GitHub Repo Submitted to ShellHacks 2022 Created by Private user Julian Tanja Satyam Singh Ayush Garg"
      }
    ]
  },
  {
    "file_path": "./devposts/skript.html",
    "project_id": "skript",
    "title": "Skript",
    "tagline": "Skripting the Unscripted ✨",
    "hackathon": "",
    "built_with": [
      "bert",
      "circleci",
      "cockroachdb",
      "firebase",
      "gcp",
      "materialui",
      "react",
      "tensorflow",
      "typescript",
      "webpack"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "CI/CD Application Using CircleCI Winner Best use of CockroachDB Created by Sacrificed my sleep to b",
      "Overall Winner Best CI/CD Application Using CircleCI Winner Best use of CockroachDB Created by Sacr",
      "Second Place Overall Winner Best CI/CD Application Using CircleCI Winner Best use of CockroachDB Cr",
      "GryphHacks 2022WinnerSecond Place OverallWinnerBest CI/CD Application Using CircleCIWinnerBest use of CockroachDB",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/996/023/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 Inspiration 💡 Going Virtual has become the new norm with the advent of Covid-19 . Applications like Zoom are booming a lot & have become part & parcel of every student as well as teacher's life! We noticed that Zoom meetings/lectures can be tiring and we often miss out on a small snippet of the meeting while we are distracted by sudden events. Improper tackling of so many students online has made new loopholes in the current education system. Whether a student is interested or not in a class, if he’s/she’s looking towards what the teacher is teaching — these informations are extremely valuable to the teachers as well as the school/college they are enrolled in. Moreover, from student’s perspective, it becomes so hectic to go through the entire recording to see if what we missed was important or not. We believe that with the power of AI, this can be solved if proceeded creatively. Thus we made Skript ✨ What it does 🤔 Skript is a smart web-app designed for those out there who get distracted during Zoom calls. It, Analyses user's face to determine when the user is looking away in an active session Features sentiment analysis to study the mood of the user throughout the session Allows users to record audio/video from a session automatically and or manually Extracts the distracted timestamps w/ contents from the session using parent transcript Let's user ask question directly from the same thing, returning hightly accurate answers. How we built it ⚙️ We depended on the Material-UI docs, React documentation and TypeScript documentation The Sentiment Analysis model is actually crafted with Pytorch , & is powered by Affdex-API The QnA model is fueled by Tensorflow 's BERT. Referred to React hooks like useContext, useState, useEffect Frontend development referred to Figma for designs and constantly reiterated based on changes Used VSC's inbuilt features in its fullest potential Frontend and backend paired together to deploy on Netlify, CircleCi and Heroku Ci"
      }
    ]
  },
  {
    "file_path": "./devposts/smart-kicks.html",
    "project_id": "smart-kicks",
    "title": "Smart-Kicks",
    "tagline": "ML-powered IoT smart shoes to enhance your movement",
    "hackathon": "",
    "built_with": [
      "arduino",
      "cockroachdb",
      "esp32",
      "express.js",
      "google-cloud",
      "iot",
      "mediapipe",
      "react",
      "uart"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/223/908/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Filtered velocity by \"kick\" pose Smart-Kicks: Clip-on attachment Mediapipe pose classification User dashboard showing overall velocity Filtered velocity by \"kick\" pose Smart-Kicks: Clip-on attachment Mediapipe pose classification User dashboard showing overall velocity Filtered velocity by \"kick\" pose 1 2 3 4 Inspiration With all of us playing different sports, we know that the most important part of movement starts at the base: the feet. For athletes and those with movement impairments alike, having more data on how the feet move (namely how fast they move) can give valuable insights into enhancing movement. We developed Smart-kicks to combine the power of embedded smart shoes and of computer-vision tracking systems. Athletes can use it to improve their training, those who get injured can use it for rehab, or people with disabilities can use it for QOL improvements. What it does Smart-kicks is a smart shoe system to gather data about foot movement. Our prototype currently tracks foot speed, and clips onto a user's laces to instantly make a shoe \"smart\". The shoe connects to the internet via the WiFi ESP32 chip, and posts the foot speed data to our web app, which inserts it into CockroachDB Serverless in real time. Separately, a MediaPipe pose-tracking application observes user movement and classifies it into different actions. For example, for a soccer player who is practicing dribbling drills and also shooting into the net, our app can classify what they are doing at each time (\"dribble\" or \"kick\") and send that data to CockroachDB. Finally, an Express app serves a React user dashboard with graphs to summarize all of the data. Since we know both foot speed and the classified poses at each time, we can associate the two together. Our soccer player can know the foot speed for dribbling separately from for kicking, allowing them to focus on just one to improve. How we built it The smart shoe used an Arduino Uno to calculate foot velocity in real-time, then transmitte"
      }
    ]
  },
  {
    "file_path": "./devposts/smarchitect.html",
    "project_id": "smarchitect",
    "title": "Smarchitect",
    "tagline": "Search and generate architecture moments with a sketch🏢🎨",
    "hackathon": "",
    "built_with": [
      "annoy",
      "flask",
      "python",
      "pytorch",
      "stable-diffusion",
      "tailwind",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Climate Hack🍀 We significantly cut down on the amount of paper used to print physical atlases of ar",
      "Accessibility Hack👨🏻‍🦯 Many architects, due to geographical location or income, don't have access t",
      "Design Hack✍️ We prototyped a version of our app on Figma according to the Hackathon's theme colors",
      "Design Hack Created by Haven't sketched this much in 24 hours since middle school __〆(￣ー￣ ) Gaurang",
      "Best Design Hack Created by Haven't sketched this much in 24 hours since middle school __〆(￣ー￣ ) Ga",
      "Hack@Brown 2023WinnerBest Design Hack",
      "Best Climate Hack🍀",
      "Best Accessibility Hack👨🏻‍🦯",
      "Best Domain Name⭐",
      "Best Design Hack✍️",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/360/102/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Thank you for viewing our project! GIF Smarchitect lets architects search for any building in the world from just a sketch. When architects look for existing buildings to base their projects on, they have to search through archives of books totally manually. Other than being a tedious process, this also excludes some architects from good-quality archives based on location, and wastes paper. We improve on existing search methods by converting images to line drawings that preserve their geometries and depth. Here's how we parse users' sketches and return images & metadata resembling the sketch. Finally, we added an additional feature where users can generate completely new designs from their sketches. Thank you for viewing our project! GIF Smarchitect lets architects search for any building in the world from just a sketch. When architects look for existing buildings to base their projects on, they have to search through archives of books totally manually. Other than being a tedious process, this also excludes some architects from good-quality archives based on location, and wastes paper. We improve on existing search methods by converting images to line drawings that preserve their geometries and depth. Here's how we parse users' sketches and return images & metadata resembling the sketch. Finally, we added an additional feature where users can generate completely new designs from their sketches. Thank you for viewing our project! 1 2 3 4 5 6 7 Inspiration 💡 Architects are constantly inspired by existing buildings, but searching for these buildings is a tedious, time-consuming, and expensive process. Humans are naturally wired to remember visual memories rather than names of certain buildings or architectural designs. Architects can draw what they have in memory to remember but this does not directly help them in the research process because they can't use it to look up the original image and the drawing is not as good as the real sight they saw. The average architect"
      }
    ]
  },
  {
    "file_path": "./devposts/smurfitkappa-wx059d.html",
    "project_id": "smurfitkappa-wx059d",
    "title": "SmurfitKappa",
    "tagline": "SmurfitKappa! The app to let you take greater pride in choosing environmentally friendly retailers!",
    "hackathon": "",
    "built_with": [
      "capacitor",
      "css",
      "firebase",
      "firestorm",
      "html",
      "ionic",
      "ionic-react",
      "javascript",
      "node.js",
      "react",
      "react-native",
      "sass"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "EarthxHack 2020WinnerSmurfit Kappa Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/070/111/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Sample modal of a store, prototype designed in Adobe XD App login page, prototype designed in Adobe XD App home page, prototype designed in Adobe XD App registration page, prototype designed in Adobe XD Sample modal of a store, prototype designed in Adobe XD App login page, prototype designed in Adobe XD App home page, prototype designed in Adobe XD App registration page, prototype designed in Adobe XD Sample modal of a store, prototype designed in Adobe XD 1 2 3 4 5 Inspiration I really loved SmurfitKappa’s mission statement in making the world a better place by going green and building a company around producing paper based products that replace non recyclable items. I noticed that a big part of their company was corrugated sheets that is efficiently designed to reuse as recyclable paper. Although SmurfitKappa has tons of famous corporations, being Europe's leading corrugated packaging company and one of the world's leading paper-based packaging, I have never heard of SmurfitKappa before my research.  This was the core of my inspiration, I wanted to build an app that would help promote the mission of SmurfitKappa and further incentivize shoppers to purchase not only purchase items packaged in a renewable source. What it does Our app, SmurfitKappa, would allow users to scan a QR code placed on a SmurfitKappa package. The users will then be able to see where the recycled materials for the box came from and the users will feel connected to another community of recyclers. In addition, this would be another method SmurfitKappa could give thanks to their recyclable material suppliers. These suppliers will be able to modify their about page via our Enterprise App. Users will also be given the option of creating an account to enter in a raffle thanking them for their choice in buying from an eco-friendly vendor. On the app, users will also be able to see overall how many trees SmurfitKappa has saved as well as an estimated plastic reduction amount. By displaying these sta"
      }
    ]
  },
  {
    "file_path": "./devposts/smartqueryblockchain.html",
    "project_id": "smartqueryblockchain",
    "title": "SmartQueryBlockchain",
    "tagline": "Transforming Blockchain Queries: Welcome to the SmartQueryBlockchain Revolution!",
    "hackathon": "",
    "built_with": [
      "css",
      "javascript",
      "pythone",
      "react",
      "solidity",
      "typescript",
      "web3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "SmartQueryBlockchain Inspiration The inspiration behind SmartQueryBlockchain stemmed from the growing need for real-time, on-chain query execution within the blockchain ecosystem. Witnessing the limitations of traditional off-chain querying, we were inspired to pioneer a solution that could unleash the true potential of blockchain technology across various sectors. What it Does SmartQueryBlockchain is a revolutionary project that empowers on-chain query execution, providing a platform for real-time, data-driven decision-making on the blockchain. The project comprises smart contracts and a robust infrastructure that handles complex queries, offering unprecedented capabilities for sectors such as DeFi, GameFi, DeSci, DAOs, and more. How We Built It The foundation of SmartQueryBlockchain lies in the integration of smart contracts and a seamless infrastructure. Leveraging technologies like Ethereum, Truffle, and Metamask, we meticulously crafted the QueryExecutor and DataStorage smart contracts. The project also embraces off-chain data handling using technologies such as MongoDB, AWS, and IPFS for a resilient and transparent approach. Challenges We Ran Into The journey was not without its challenges. Optimizing performance, integrating Metamask seamlessly, and balancing on-chain and off-chain data were hurdles we faced. Each challenge became an opportunity for growth, pushing us to refine our solution and enhance its capabilities. Accomplishments That We're Proud Of SmartQueryBlockchain stands as a testament to our dedication and innovation. We take pride in creating a platform where real-time data meets on-chain precision, offering solutions that can revolutionize decision-making across diverse sectors. The curated feature set, robust smart contracts, and resilient data handling mechanisms are accomplishments we celebrate. What We Learned The learning curve was steep, from mastering smart contract development with Solidity to exploring off-chain storage solutions. We g"
      }
    ]
  },
  {
    "file_path": "./devposts/smartbin-qkcliw.html",
    "project_id": "smartbin-qkcliw",
    "title": "SmartBin",
    "tagline": "An intelligent bin that identifies garbage and recyclable material and collects them in separate compartments.",
    "hackathon": "",
    "built_with": [
      "api",
      "arduino",
      "c++",
      "cloudvision",
      "google-cloud",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by Neel Adwani yeet",
      "Hack At Home IIWinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/501/024/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration In third-world countries like India, recyclable and non-recyclable waste is usually misclassified and even a lot of people don't remember where their trash should go. Trash Misclassifications can even have a major impact on increasing greenhouse emissions, which further contribute to climate change. What it does It is a smart bin that is currently using my laptop's webcam to take an image of the material, and then it sends that image to Google Cloud. With the help of Google's CloudVision API, it identifies what is there in the image and returns it to my client. Depending upon the name of that object, my program classifies it as either trash or recyclable material and then opens up one compartment accordingly. How we built it In the hardware part, I've used C++ to establish control of the servo motors. In the software part, Python is used to connect to Google CloudVision and vice versa. More information is given in my readme file (Github). Challenges we ran into Establishing a connection between Arduino and Python was a challenge, and getting started with google cloud was a bit difficult because of transaction issues. Accomplishments that we're proud of Finally getting to work with Google Cloud. What we learned I learned about new ways to read into the serial with python and got to know more about how I can use Google Cloud in my projects. What's next for SmartBin Once the lockdown is over, I'll purchase and integrate it with a standalone camera and change its interface to Raspberry Pi so that it doesn't require anything external. Built With api arduino c++ cloudvision google-cloud python Try it out GitHub Repo Submitted to Hack At Home II Winner First Overall Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/snicklit.html",
    "project_id": "snicklit",
    "title": "76-Snacklit",
    "tagline": "Solving all your dietary problems",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "google-cloud",
      "gpt",
      "html",
      "nextjs",
      "pocketbase",
      "postman",
      "react",
      "replicate",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "4th-7th Prize Created by Worked on frontend using NextJS, Next-Auth JS, and Pocketbase",
      "Los Altos Hacks VIIWinner4th-7th Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/445/028/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Dashboard Using artificial intelligence to get valuable insight From doing analysis of the situations humans are in we learned that... The solution our website provides All the technologies we used for the hackathon Home Page Dashboard Using artificial intelligence to get valuable insight From doing analysis of the situations humans are in we learned that... The solution our website provides All the technologies we used for the hackathon Home Page Dashboard 1 2 3 4 5 6 Inspiration America is known to have one the fattest populations globally. When you think of American foods, you think of fries, hamburgers, chips, and more extremely unhealthy food items. Every day humans eat the same meals which lack diversity and can cause health problems in the future. Bananas, bread, and other foods get rotten or moldy extremely quickly. Eating rotten or expired food can lead to dietary problems. With the advent of new technologies like GPT and BLIP-2 increasing in popularity, we created a unique solution that would not only help America, but the entire world. What it does A website that allows humans to upload a food or food group and get important information like the physical characteristics of the food. Users have the freedom to post foods like chocolate and oranges to create multiple unique recipes like chocolate truffles. Access all your recipes and items you have created as they are saved in a database. In case you ever forget when your food expires, Snicklet saves expiration dates and the specific time the food will expire.  The most amazing feature of the website is the access to amazing technology which does advanced image analysis on food. The artificial intelligence will recommend if the food is healthy to eat and the visuals of the food item. How we built it When we joined the hackathon we decided to use Flask, Replicate, BLIP-2, and GPT for the backend. We saw a research paper that provided a solution for two-way communication between the two amazing models. Since B"
      }
    ]
  },
  {
    "file_path": "./devposts/slice-m6zqpf.html",
    "project_id": "slice-m6zqpf",
    "title": "Slice",
    "tagline": "Gamified Learning for American Sign Language through popular game Fruit Ninja!",
    "hackathon": "",
    "built_with": [
      "html/css",
      "next.js",
      "react",
      "tailwind",
      "tensorflow.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner Best Design Winner Most Innovative Idea Created by Abhishek More Retired Hackathon Enjoyer O",
      "Design Winner Most Innovative Idea Created by Abhishek More Retired Hackathon Enjoyer Official TAMU",
      "General Track Winner Best Design Winner Most Innovative Idea Created by Abhishek More Retired Hacka",
      "CodeRED: GenesisWinnerGeneral TrackWinnerBest DesignWinnerMost Innovative Idea",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/762/879/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Successfully signing a letter! Main page of our Project ASL alphabet! Statistics for running Tensorflow.js (Used in our project) Successfully signing a letter! Main page of our Project ASL alphabet! Statistics for running Tensorflow.js (Used in our project) Successfully signing a letter! 1 2 3 4 5 Inspiration Over a million people use American Sign Language (ASL) to communicate as their native language in the US. In fact, ASL is the third most frequent language in the States behind English and Spanish! Not only is it important for people to be aware of the method of communication, but it is very helpful and even fun to learn. In addition, we came up with the idea during the actual hackathon when we witnessed hackers playing a type-racing game. Not only do we find the idea of gamification extremely interesting, but we also believe it serve as a potent delivery method to help people of all ages to learn about the language. Moreover, statistics illustrate an alarming trend in deafness: 'Hearing loss is the third most common chronic physical condition in the United States and is twice as prevalent as diabetes or cancer.' (Centers for Disease Control and Prevention). As such, we believe it is crucial to raise awareness about this issue through a fun and engaging way. What it does Machine Learning is an incredible technology that allows us to analyze data and find trends to an equal or even higher degree than humans. We leverage this advancement, specifically deep learning, neural networks , and classification algorithms to allow computers the ability to analyze hand patterns and recognize them as ASL letters. This machine learning allows us to figure out what letters someone might be holding up and even determine a score for how well the person is performing the letter. Then, we  create a real-time multiplayer web browser game that allows users to compete on their ASL signing skills! Through the practice and excitement of the activity, not only do the participants get to"
      }
    ]
  },
  {
    "file_path": "./devposts/snacksage.html",
    "project_id": "snacksage",
    "title": "nomnom!",
    "tagline": "find your next favorite snack :)",
    "hackathon": "",
    "built_with": [
      "firebase",
      "flutterflow",
      "gemini"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/269/491/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ex 2: snack descriptions landing page ex 1: similar snacks generated after uploading snack image (treehacks chips from our live demo!) ex 2: similar snacks generated after uploading snack image ex 2: snack descriptions landing page ex 1: similar snacks generated after uploading snack image (treehacks chips from our live demo!) ex 2: similar snacks generated after uploading snack image ex 2: snack descriptions 1 2 3 4 5 Inspiration ✈️🍫 While traveling, we often discover amazing snacks that we wish we could find back home. However, finding similar snacks in different countries can be challenging. nomnom! was born to bridge this gap—helping snack lovers find their next favorite treat, no matter where they are in the world. What it does 🍪🔍 📸 Take a picture of a snack they enjoy.\n🤖 Use AI to identify and suggest similar snacks available in other regions.\n🌍 Filter results by country to find local equivalents.\n📚 Explore a global snack database with images, flavors, and recommendations. How we built it 🛠️ Frontend: Built with FlutterFlow for a seamless cross-platform experience. Backend: Uses the Gemini API to analyze snack images and recommend similar products. Database: We use Firebase to store snack information, including images, categories, and region availability. Challenges we ran into ⚠️ Training the AI to accurately match snacks based on appearance and flavor profiles. Ensuring a diverse snack database that covers multiple countries. Implementing an intuitive UI that makes filtering and searching easy. Accomplishments that we're proud of 🎉 Successfully integrating image recognition with snack recommendations . Creating a user-friendly and visually appealing UI in FlutterFlow. Building a functional prototype within the hackathon timeframe. What we learned 📖 How to leverage AI for food recognition and similarity mapping . Best practices for FlutterFlow development and API integration. The complexity of cross-cultural food preferences and availability . What's next for"
      }
    ]
  },
  {
    "file_path": "./devposts/smooth-claiminal.html",
    "project_id": "smooth-claiminal",
    "title": "Smooth Claiminal",
    "tagline": "A faster way to process insurance claims, using AI and blockchain.",
    "hackathon": "",
    "built_with": [
      "azure",
      "blockchain",
      "css",
      "flask",
      "gensim",
      "google-cloud",
      "html",
      "ipfs",
      "javascript",
      "orbitdb",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Intact: Insurance Hacker Challenge Created by I worked on the back end Python algorithms, including",
      "Hack the 6ix 2020WinnerIntact: Insurance Hacker Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/195/320/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Blockchain Database Claims Viewing Page Dashboard Page Claims List Page Upload Page with Insights Blockchain Database Claims Viewing Page Dashboard Page Claims List Page Upload Page with Insights Blockchain Database Claims Viewing Page 1 2 3 4 5 Inspiration One of the biggest problems during this COVID-19 pandemic and these awful times in general is that thousands of people are filing for property and casualty insurance. As a result, insurance companies are receiving an influx of insurance claims, causing longer processing times. These delays not only hurt the company, but also negatively impact the people who filed the claims, as the payout could be essential.\nWe wanted to tackle these problems with our website, Smooth Claiminal. Our platform uses natural language algorithms to speed up the insurance claiming process. With the help and support from governments and businesses, our platform can save many lives during the current pandemic crisis, while easing the burdens on the employees working at insurance companies or banks. What it does Smooth Claiminal serves three main purposes: Provides an analytics dashboard for insurance companies Uses AI to extract insights from long insurance claims Secures data from the claim using blockchain The analytics dashboard provides insurance companies with information about the previously processed claims, as well as the overall company performance. The upload tab allows for a simplified claim submittal process, as they can be submitted digitally as a PDF or DOCX file. Once the claim is submitted, our algorithm first scans the text for typos using the Bing Spell Check API by Microsoft Azure. Then, it intelligently summarizes the claim by creating a subset that only contains the most important and relevant information. The text is also passed through a natural language processing algorithm powered by Google Cloud. Our algorithm then parses and refines the information to extract insights such as names, dates, addresses, quotes, etc"
      }
    ]
  },
  {
    "file_path": "./devposts/snapcloud.html",
    "project_id": "snapcloud",
    "title": "SnapCloud",
    "tagline": "SnapCloud instantly turns plain‑English system descriptions into interactive cloud architecture diagrams with built‑in security checks, delivering clear, secure blueprints in seconds, effortlessly.",
    "hackathon": "",
    "built_with": [
      "aws-bedrock",
      "minimax",
      "mongodb",
      "react",
      "wiz"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our AI‑powered architecture diagrammer transforms plain‑language system descriptions into polished, production‑ready topology diagrams in seconds. By leveraging Minimax for intelligent task decomposition and Temporal for reliable, stateful orchestration, the tool automates every step—from service extraction to layout—while persisting intermediate results and handling retries. We integrate Wiz’s agentless Cloud Security Posture Management and IaC scanning to automatically detect misconfigurations, map end‑to‑end attack paths on the Wiz Security Graph, and deliver prioritized, AI‑driven remediation guidance—ensuring your designs are both accurate and secure from the very first draft. How we built it The SnapCloud pipeline consists of three pillars: (1) a task planner built on MiniMax M1 and a JSON‑rules engine to decompose user prompts into ordered subtasks; (2) diagram synthesis via AWS Bedrock’s multimodal foundation models, which translate those subtasks into a structured JSON diagram spec; and (3) security annotation using Wiz’s IaC scanner and CSPM APIs to surface normalized misconfigurations and attack‑path findings for overlay on the final diagram. DEMO video: https://drive.google.com/file/d/1lBA0bX9sEkHRQ6li9Qo1OVxS2Yxl5lgE/view?usp=sharing Built With aws-bedrock minimax mongodb react wiz Submitted to MCP - AWS - Enterprise Agents Challenge Created by Joe Quenum Gérald has been in the blockchain ecosystem for ten years, starting with mining before shifting to development five years ago. Harry ."
      }
    ]
  },
  {
    "file_path": "./devposts/social-media-enhancer.html",
    "project_id": "social-media-enhancer",
    "title": "Social Media Enhancer",
    "tagline": "Enhance your 1st appearance on social media!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "gin",
      "go",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/335/300/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡 Inspiration💡 We wanted to increase our status on social media hence we made this chrome extension that allows us to do just that on linkedin! ⚙️ What it does ⚙️ We have a chrome extension that allows you to use AI-generated responses to LinkedIn posts, and it is built right into LinkedIn! After adding the extension, whenever the user visits LinkedIn, there is a button embedded in the end of every post. All the user has to do is click the button and the post’s text will be sent to the Golang server, and the AI-generated response will be put in the comment textbox of the post. The user can then check the response, tweak it if wanted, and have a sensible response to send quickly and right on LinkedIn. 🏗️ How we built it 🏗️ We used Go lang and Cohere for backend along with a chrome extension that made HTTP requests to the Go lang server and got the appropriate response for the comment, then this response is injected onto linkedin and can be posted! 🟣Cohere Gin server in Golang 🟣 The server was made using Go lang and we used Cohere to generate responses for our social media posts. We made the chrome extension use POST requests to send the comment and in return it got the response that was generated by the Cohere model we used. 🔴Chrome Extension in Javascript 🔴 The chrome extension injects customized HTML buttons to each post, and after fetching AI-generated responses from the server, the extension injects the response in the LinkedIn comment box. We used Javascript query selectors and had to look through the extensive HTML tree of LinkedIn to figure out where to identify the texts of the posts and where to inject responses into the comment boxes. 🚩 Challenges we ran into There are no tutorials that tell us about the LinkedIn HTML tree, so we had to figure a lot parts on that end by ourselves when creating the code that the extension injects.\nA lot of errors when trying to make HTTP requests because of \"cors\" and lack of use of headers\nWe were also learning how to u"
      }
    ]
  },
  {
    "file_path": "./devposts/snory.html",
    "project_id": "snory",
    "title": "Snory",
    "tagline": "Defrost; Focus Thoughts",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "godaddy",
      "html5",
      "javascript",
      "machine-learning",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from GoDaddy Registry [APAC Only] Created by Learnt sacrificing sleep & implemente",
      "Hacky WinterlandWinnerBest Domain Name from GoDaddy Registry [APAC Only]",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/778/409/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 💡 Inspiration 💡 Chilly winter days give us an excuse to curl up in our blankets with a hot mug of coffee. According to studies, productivity drops dramatically during the winter months. Students frequently experience difficulties with concentration. Could there be a tool that can assist us to focus when we're distracted and wake us up when we're tired? This prompted us to create Snory, an AI-powered application that tracks facial expressions and gives statistics to help focus better . ❓ What it does ❓ Snory can be your study-mate or your productivity partner. Sign in to your account. Set the time for which you want to focus on a task. Open a PDF, play a video or simply run a link to your work. Let Snory run in the background. After your specified focus period, Snory will provide you with a detailed analysis of your emotions with the help of charts and graphs. It helps you figure out the time duration when you were unfocused. If you get drowsy or quit working during your chosen time, Snory sends you an alert. A session can be started/stopped, restarted, and a CSV file of the results can be downloaded. Essentially, Snory helps one work better and more efficiently. ⚙️ How we built it ⚙️ We built the frontend using HTML, CSS and React . Firstly, we used Figma to design the outlook of the project. Then we took a part of it each and collaborated on Github to create our website.\nThe backend is a machine learning model built using React, JS and TensorFlow .\nOnce the backend and frontend were created, we integrated them.\nWe got our domain \"dont-snore-with.us\" from GoDaddy and hosted it using GitHub pages. 🚧 Challenges we ran into 🚧 On the frontend side of things, it was a challenge to coordinate work on the website because we wanted our website to look cohesive and concise. To keep our style consistent, we made mocks up of our website using Figma so that all of us were on the same page. We faced conflicts while merging the login page branch and had to resolve them toge"
      }
    ]
  },
  {
    "file_path": "./devposts/social-media-post-approval-analytics-for-marky.html",
    "project_id": "social-media-post-approval-analytics-for-marky",
    "title": "Social Media Post Approval Analytics For Marky",
    "tagline": "Answering the future.",
    "hackathon": "",
    "built_with": [
      "colab",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The business case for deriving insights regarding user approval was an interesting problem to solve. Hence our team decided to tackle it head on and gained a lot of insights regarding features that impact the overall approval. What it does Built classifiers to successfully predict the likelihood a user will approve a post. Additionally, we determined what features are most important for Marky to improve the approval percentage of their future posts. How we built it We used google colab, writing code using python. We first loaded in the data. Then cleans the dataset by getting rid of all null values, getting rid of stop words, emojis, and more in order to be able to evaluate it cleanly and easily. We also created various other statistics like the similarity using cosine similarity and tested it using different models and libraries in order to predict the social media approval rating to the best we can, these were built using python library sk learn. Challenges we ran into Our initial plan was to integrate both text and image features into our models through stacking both the features sets with each other for model consideration. However, we ran into an incompatibility between the vectorized text and images as they were not the same dimensionality and caused TensorFlow errors. We had to cut short the scope of our feature base to account for the time limit. Accomplishments that we're proud of We are proud of the various features we implemented in the time we had and even though some couldn't work it worked. What we learned We learned how to built a machine learning model. Starting with cleaning the data by removing stopwords and making the data binary, and for the strings we turned them into TF_IDF vectoriser and the models using svm, randomforest, linear regression. We gained valuable insights into constructing a machine learning model, beginning with the crucial step of data preprocessing. This involved the removal of stopwords and the binarization of our"
      }
    ]
  },
  {
    "file_path": "./devposts/software-engineer-internship-dataset.html",
    "project_id": "software-engineer-internship-dataset",
    "title": "Lost Fishies gets Ghosted by Recruiters",
    "tagline": "Dataset of relevant software engineer internships on popular job sites such as Glassdoor, level.fyi, and indeed.",
    "hackathon": "",
    "built_with": [
      "pandas",
      "python",
      "seaborn",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/703/733/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "Level.fyi data Levels.fyi data Glassdoor data Position vs Number of Jobs - Jobs Per Year Monthly Salary vs. Job Index Level.fyi data Levels.fyi data Glassdoor data Position vs Number of Jobs - Jobs Per Year Monthly Salary vs. Job Index 1 2 3 4 5 6 7 8 9 Inspiration We wanted to create a dataset that is relevant to not only us but millions of people around the world. As a team of freshmen, we have begun to experience the frustration of job/internship hunting. To help both ourselves and other students in their internship application process, we decided to create a dataset for open internship positions on some popular job sites. Our project Our dataset is a collection of open software engineer internship positions on popular job sites. Some data we've pulled includes but is not limited to the company name, job title, pay, and location. Not only can we create a web scraping application from scratch in python to scrape for multiple other job opportunities, the programs are also usable of a variety of sites. For example, we began with Levels.fyi, Indeed.com, and GlassDoor How we built it We used Selenium to address the Dynamic nature of our target websites and BeautifulSoup to read their HTML codes. Our team members actually used two separate approaches, one utilizing the HTML Xpaths present in each element and the other utilizing class names to search through all of the code. Then we used pandas data frames to both enter and clean our data. We used Selenium to scrape job data off of Glassdoor and pandas to format and built-in functions to export to CSV. For levels.fyi, pandas was used to parse through a json file of all the job data. Challenges we ran into For the first ~8 hours, we made minimal progress with our web scraper approach in regards to working properly with dynamic webpages. As we weren't able to properly load the data as a BeautifulSoup object, due to the dynamic nature of the program, we needed to find a workaround through Selenium.\nFurthermore, null values"
      }
    ]
  },
  {
    "file_path": "./devposts/snow-angels.html",
    "project_id": "snow-angels",
    "title": "Snow Angels",
    "tagline": "Connecting seniors with safe winter transportation. ❄️",
    "hackathon": "",
    "built_with": [
      "css",
      "django",
      "html",
      "javascript",
      "mongodb",
      "openstreetmap",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/768/928/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Booked Transport Sign in or make an account Choose User Make an account as a senior citizen Senior home page Request transport Make an account as a volunteer Volunteer home page Booked Transport Sign in or make an account Choose User Make an account as a senior citizen Senior home page Request transport Make an account as a volunteer Volunteer home page Booked Transport 1 2 3 4 5 6 7 8 Inspiration While winter is often associated with festivity and love, it also brings about challenges, particularly for senior citizens who are disproportionately affected. Physical obstacles such as slippery ice, cold-related health issues, and limited access to healthcare pose significant threats. Additionally, mental health hurdles, including seasonal depression, isolation, and loneliness, further compound the difficulties faced by seniors. Introducing Snow Angels, our innovative solution designed to make everyday tasks that are difficult for seniors in winter easier. This app serves as a bridge connecting young adults with senior citizens through these everyday tasks. By allowing seniors to upload events they need assistance with, Snow Angels not only facilitates the safe completion of tasks but also reduces their isolation levels. Simultaneously, it provides an opportunity for the younger generation to make a positive impact in their community. Inspired by the numerous seniors who fear for their health and safety when leaving their homes, we aim to put an end to their struggles. Snow Angels strives to create a supportive network that transcends generational boundaries, fostering a sense of community and mutual care during the challenging winter months. What it does Snow Angels uses the powerful MongoDB database to manage the extensive user base, comprising both senior citizens and young adults seeking connections through the app. Tailoring the interface to cater specifically to each demographic, Snow Angels ensures a user-friendly experience. For senior citizens, we've prioritize"
      }
    ]
  },
  {
    "file_path": "./devposts/so-you-want-to-be-an-auditor.html",
    "project_id": "so-you-want-to-be-an-auditor",
    "title": "So, You Want To Be An Auditor?",
    "tagline": "An interactive and entertaining gamified education system to help you learn about taxes!",
    "hackathon": "",
    "built_with": [
      "ai",
      "cloudflare",
      "docker",
      "fastapi",
      "javascript",
      "natural-language-processing",
      "python",
      "react",
      "redis"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked on the frontend game UI. It was my first time building a gamified app"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/717/184/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Chatbot Logo Landing Page Chatbot w/Translation Level One Level Two Game Over Screen Tech Stack Chatbot Logo Landing Page Chatbot w/Translation Level One Level Two Game Over Screen Tech Stack Chatbot 1 2 3 4 5 6 7 8 9 Inspiration The inspiration behind our app rises from the awareness of the difficulties individuals, particularly immigrants, young adults, and teenagers, encounter when trying to comprehend the intricacies of the Canadian tax system. We realized that many people find the conventional approach to learning about taxes tedious, difficult, and uninspiring. Therefore, our aim was to create an engaging and educational platform that transforms the typically exhaustive task of understanding taxes, tax forms, and regulations into an enjoyable and interactive journey. Our goal is to provide a comprehensive and accessible resource for learning the fundamentals of how Canadian taxes work. Ultimately, our app strives to make tax education not only informative but also enjoyable for everyone. What it does We developed an app that introduces a gamified approach to tax education. Users progress through levels where they are tasked with answering specific questions based on the given definitions and data. We also incorporated a gaming element with theme music and sound effects in which users have a limited number of lives that automatically reset at each level, allowing for multiple attempts at the mini-game in each level. In the event of a challenge, users can restart the game, reinforcing their foundational knowledge of taxes. To further help a user's learning journey, we implemented an A.I. chatbot that can answer any questions a user may have at any of the game levels. This way, users have a reliable way of searching for information without needing to leave the game. How we built it Our application utilizes ReactJS for front-end development, combined with Tailwind CSS, Lottie and MUI, creating a beautiful and interactive user interface that provides an entertainin"
      }
    ]
  },
  {
    "file_path": "./devposts/socialify-aygczn.html",
    "project_id": "socialify-aygczn",
    "title": "Socialify",
    "tagline": "Socialify your project. Share with the world!",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "jest",
      "netlify",
      "react",
      "relay",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH Fellowship - Open Source Orientation Hackathon - Batch 1Winner2nd Place Team",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/233/572/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration Hackers love building projects! However, it requires way too much time and design knowledge to create a social preview image for every project. That's where Socialify comes into rescue! What it does Socialify let’s you easily create social preview images for GItHub projects with minimal effort to make sharing your projects easier. It comes with a ton of beautiful presets and options including custom logo, description, badges, and many handpicked fonts and backgrounds to choose from. How We Built It The frontend of the application is built on React with TS. The application uses Relay and GraphQL to communicate with GitHub API which is proxied through Lambda functions. Finally, the image service is also built on a Lambda function to dynamically serve images. Technologies Open Source Tie-In React Relay Enzyme Jest Other Tooling Coding Style: ESLint, Prettier, Standard, Gitmoji Design Framework: ant-design Icons: devicon Project Management: GitHub Projects Code Review: GitHub Pull Request, VSCode Live Share CI: GitHub Actions CD/Hosting: Netlify Cloud Functions: Netlify CDN: CloudFlare Challenges We Ran Into One challenge we faced was setting up the image service, which can be quite resource intensive requiring a chromium instance to run. Instead of dealing with poor performance running chromium inside lambda, we opt to use Screenshotter - Screenshot as a service to handle image generation. Another challenge we faced was performance degradation while maintaining certain application state inside url parameters which we resolved using a debouncer solution. Accomplishments that We're Proud of The simplicity of the application in its concept and design is definitely something to be proud off, it does one particular task and does it well. What We've Learned This project heavily leveraged open-source best principles in terms of Project Management, CI/CD, Code Review, Style Guidelines, etc. This was definitely a good learning experience in terms of open-sourc"
      }
    ]
  },
  {
    "file_path": "./devposts/solar-sync.html",
    "project_id": "solar-sync",
    "title": "Solar Sync",
    "tagline": "Eco-conscious mobility: Empowering you to drive greener.",
    "hackathon": "",
    "built_with": [
      "chargetrip-api",
      "firebase",
      "google-maps",
      "nextjs",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Girls in Tech : Hack for the EnvironmentWinner1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/567/329/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "App IA - the vision Onboarding - Registration Onboarding - Loan your home charger Map view of chargers List view of chargers Charger view Account Solar credits Leaderboard App IA - the vision Onboarding - Registration Onboarding - Loan your home charger Map view of chargers List view of chargers Charger view Account Solar credits Leaderboard App IA - the vision 1 2 3 4 5 6 7 8 9 10 Inspiration While researching pain points of EV driving and factors that sway people away from purchasing an EV car, we came across the statistic that U.S. consumption of electricity, driven in part by battery-powered vehicles, will triple by 2045 (Elon Musk from a Wall Street Journal article in July 2023). We learned that traditional EV charging uses non-renewable grid energy, meaning an EV boom in the near future could put a major strain on the U.S. power grid. What it does The SolarSync app allows users to find convenient, reliable, and available EV charging stations, connect with a trusted network of verified EV chargers, and embrace solar-powered electricity use. We emphasized creating a user-friendly and intuitive platform that serves as a one-stop shop for EV drivers who are conscious of their carbon footprint. How we built it We built our app with NextJs, Typescript, Firebase, Google Map API, and Chargetrip API. Our frontend developer, Alisa, goes into further detail in our demo video. Challenges we ran into A main aspect of our app is the route planning and locator feature, which requires the integration of a Google Map. However, due to the time constraint, we were unable to do that in the back-end. Accomplishments that we're proud of Creating an app is no easy feat! Each of us have very different skillsets, from Figma to digital marketing to UI/UX development, and we each delivered our sections with excitement to each meeting, despite being in different time zones and working on the app development at different hours. What we learned We learned that time management skills are cr"
      }
    ]
  },
  {
    "file_path": "./devposts/socialchatbotapp.html",
    "project_id": "socialchatbotapp",
    "title": "Bot Dilemma",
    "tagline": "An interactive, creative, and original way to hangout and chat online.",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "dart",
      "firebase",
      "flutter",
      "parlai",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/109/478/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Bot Dilemma Inspiration With the lack of social interaction that we're going through as a result of COVID-19, not only are we getting more and more depressed, but deprived of interesting relationships and interactions with new people. Given the current situation around the world, our group was looking to create a hack that can make living in isolation, not only less... \"iso\", but entertaining and challenging too. We wanted to take something technically advanced, and spin it in a super creative way such that it can improve living for those by themselves, help with mental health issues, make some connections, and most of all, have some fun! What it does Bot Dilemma is both a social network, a Turing test, and an intriguing game. Once you create an account you can start playing. The game is you will be put into a chat room with either a robot (powered by a powerful NLP model we tweaked) or another player, you won't know. You can start having conversations with the other \"person\", and once you are ready, you choose whether you think your opponent was human or not. The app is designed to incentivize meaningful conversations conducive of connections, with higher points awarded to those who can keep up conversations for longer without giving away whether or not they're a bot. The game is a fun aspect, but it's important to keep an eye on the prize (precious social interaction). Our robot's artificial intelligence algorithm 90 million different parameters that enable it to reciprocate slang, mood, context, and more, so it won't be tough to hold those lengthy conversations. We've set up our service so that there are over a 1000 different personas with unique careers, families, and hobbies, so literally every time you speak with it it's like meeting a whole new person. How we built it The conversational chatbot, perhaps the most technically challenging and intriguing part of our project, was an offshoot of the famous Blender model released by Facebook in their recent pa"
      }
    ]
  },
  {
    "file_path": "./devposts/sober-rewards.html",
    "project_id": "sober-rewards",
    "title": "Sober Rewards",
    "tagline": "A new year resolution app for people who are joining Alcoholics Anonymous. It rewards the users who maintain good attendance, and we built an automated texting service to keep them on track.",
    "hackathon": "",
    "built_with": [
      "domain.com",
      "firebase",
      "google-workspace",
      "javascript",
      "react",
      "solidity",
      "twilio",
      "velo-by-wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/334/819/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 🍾 Inspiration Quitting alcohol comprised a significant 34% of resolutions for Americans this year, with people possibly having evaluated their drinking habits and realized there was room for change. 🤝 What it does Uses Web3 smart contracts to incentivize people in recovery to attend all their scheduled AA meetings. users can lock up however much they want; it can be a pledge AND also a way to invest and make money. Donators can donate/ lock up their funds; if they hit x amount of money locked or y amount of time locked, they get a corresponding NFT to show proof, and possibly we track data, so maybe in the future, governments will give tax breaks. We combine user funds + donator funds to return 5% a year on the entire pool. At the end of the year/term, users who get good attendance get rewards. They get: their initial deposit + 5% apy an equal cut (amongst other people who have good attendance) of all the profits of the entire pool from whatever is leftover. For example: Users + donators deposit into the pool. There are 20,000 users. Let's assume users pledge random amounts each. The collection has $70,000,000 in it. $2,000,000 of it is pledges. 1 year goes by. $70M turns into $73,500,000, and 15,000 students have good attendance. So, about $  21,000,000  is given back to all users. Approximately $1,000,000 in profit is given to users who have good attendance. Users who do not have good attendance get their original pledge back only. Donators are also given back their original deposits. Donators are minted NFTs corresponding to how much or long they have donated Users who have good attendance get part of the pool's leftover profit. \n($3,500,00 profit - $1,000,000 pledge winners = $2,500,000 leftover profit)\n$2,500,000 is distributed evenly to 15,000 users who have good attendance.\n$2,500,000 / 15,000 = $166 per winner\nif User Amir pledged $10,000, they would receive $666.00 profit at the end of the year.\nIf User Bob promised $1000, they would receive $21"
      }
    ]
  },
  {
    "file_path": "./devposts/sonicsurf.html",
    "project_id": "sonicsurf",
    "title": "SonicSurf",
    "tagline": "More Screentime ≡ Better Health 👨‍💻",
    "hackathon": "",
    "built_with": [
      "blahaj",
      "computer-vision",
      "love",
      "next.js",
      "tailwind",
      "tf",
      "vercel",
      "webgazer",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from GoDaddy Registry [APAC Only] Created by Pratyay Banerjee I share memes more t",
      "Impractical Hackers 2WinnerBest Domain Name from GoDaddy Registry [APAC Only]",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/225/088/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF 1 2 3 Inspiration 💡 Ocean water covers more than 70% — 75% of the Earth. Over the last decade we have become increasingly alarmed at the amount of plastic in our oceans. Sources say more than 8 million tons of it ends up in the ocean every year. It's estimated that if pollution grows at this rate, there will be more plastic than fish in the ocean by 2050 . Our friend Blahaj 🦈 is stranded in the middle of a toxic water body, starving for oxygen just to live. Our primary objective to make sure that it survives and in return we'll get our reward ! We aim to make both Blahaj's life and Our's better, so the reward is Health Benefits. Thus we came up with SonicSurf ✨ What it does 🤔 Prolonged screentime can extensively affect our eyes and hence might weaken our vision, or worst can give blindness. Leveraging eye-tracking , players can control Blahaj and guide him to safe areas in the ocean by performing various eye-exercises . Don't worry we aren't forcing you to leave your desk, instead you can vibe through the exercises which will increase bloodflow in your eyes stimulating the production of Aqueous Humor (a clear fluid that fills and helps form the anterior and posterior chambers of the eye) that prevents our eyes to dry up, hence keep the moisturization level optimal. Hence, we prove, More Screentime ≡ Better Health 👨‍💻 How we built it ⚙️ SonicSurf is crafted with ❤️. SonicSurf is primarily a Webapp where for the front-end we're using Next.Js with TypeScript along with Tailwind CSS. For Eye-Segmentation & Tracking were using WebGazer API. We also leveraged various 3rd-party API's for optimization purposes. The application is deployed on a free instance of Vercel. Also, it's to be noted that variable lighting condition and low-spec systems might affect the experience! Challenges we ran into 😤 Had to fix tons of Bugs in the way. Also, it was a bit difficult for us to collaborate in a virtual setting but we somehow managed to ship the project on time. Design 🎨"
      }
    ]
  },
  {
    "file_path": "./devposts/solarup-i36o2a.html",
    "project_id": "solarup-i36o2a",
    "title": "SolarUp",
    "tagline": "Reclaim urban spaces for a brighter tomorrow.",
    "hackathon": "",
    "built_with": [
      "1build",
      "bright-data-api",
      "css3",
      "fastapi",
      "git",
      "github",
      "graphql",
      "html",
      "mapbox-gl-js",
      "next.js",
      "nrel.gov",
      "platform.sh",
      "python",
      "react.js",
      "reveal.js",
      "selenium",
      "tailwind.css"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/630/177/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logic Flow Diagram SolarUp Logo GIF Demo Video Landing Page Loaded Dashboard Logic Flow Diagram SolarUp Logo GIF Demo Video Landing Page Loaded Dashboard Logic Flow Diagram 1 2 3 4 5 6 SolarUp Project Story Inspiration and Learning The inspiration behind SolarUp came from the pressing need for sustainable energy sources and the vast untapped potential of parking lots across the United States. We recognized that parking lots, while ubiquitous, remained underutilized in the context of clean energy generation. Our journey began with a passion for addressing this challenge and contributing to a greener future. Throughout the project, we learned the importance of combining innovation and sustainability. We discovered the power of technology to drive environmental solutions and the potential for businesses and property owners to benefit financially while making eco-friendly choices. Project Development SolarUp is a multi-faceted project that leverages various technologies and platforms. On the frontend, we built our user interface using React and Tailwind CSS, ensuring a responsive and user-friendly experience. The backend of SolarUp relies on a robust tech stack, including Python, FastAPI, and Selenium, to collect data from the NREL (National Renewable Energy Laboratory) API. This data is crucial for estimating potential earnings accurately. Additionally, we integrated Next.js and the Bright Data API to enhance our data collection capabilities and ensure up-to-date information for our users. The project is hosted on Platform.sh, providing a reliable and scalable hosting solution. For the FAQ page, we utilized CSS and reveal.js to create an informative and visually engaging resource. We made the FAQ page accessible through GitHub Pages to ensure easy access for users seeking answers to common questions. Challenges Faced Building SolarUp came with its share of challenges. Collecting and processing data from the NREL API required intricate handling, and ensuring data accura"
      }
    ]
  },
  {
    "file_path": "./devposts/socialcurator.html",
    "project_id": "socialcurator",
    "title": "Social Curator",
    "tagline": "Create 👼 - Curate ‍🔧- Elevate 🔝",
    "hackathon": "",
    "built_with": [
      "ai",
      "css",
      "d3.js",
      "figma",
      "gcp",
      "html",
      "javascript",
      "keras",
      "ml",
      "python",
      "rapid-api",
      "react",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Backyard Hacks 2.0WinnerBest use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/671/051/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 Inspiration 💡 The advent of the 𝐂𝐨𝐯𝐢𝐝-𝟏𝟗 has turned all of our lives upsides down. Changes in social dynamics due to local restrictions impacted human behavior and led to a shift in business dynamics. With that, a boom in the online marketplace is also prominent. Social media presence is helping people such as small businesses and organizations make a smart move, especially after seeing the effect that the COVID-19 Pandemic has left on the same. Many small businesses are struggling to stay open during these difficult times due to the lower count of people. This is indeed a very serious problem that is becoming the root cause of economic downfall in most countries. We believe that with the power of AI, this can be solved if proceeded creatively. Thus we made Social Curator ! What it does 🤔 Social Curator is a smart web-app that is built for helping small business owners gain the social media traction they need to keep their doors open. We hope to make the lives of marketers, business people, and influencers on social media easier, so they don't have to search for #hashtags and decide which ones are the best themselves, instead they can rely on our app to decide the same automatically. Hashtags are a surefire way of boosting impressions, improving content searchability, and encouraging more people to talk about the brand. Moreover, it can easily help people finding social media content, increase social media engagement, and attract new customers etc. Choosing the right hashtags for a post can help it sky-rocket in popularity – gaining your content views, likes, re-tweets, and shares. All of this social activity ultimately helps to amplify content and business exposure. But, not all hashtags are created equal. And different types of hashtags reach different audiences – accomplishing different goals for the business. And the best part is that, nobody owns a hashtag. You can’t trademark hashtags, anybody can use them, and they can be any combination of "
      }
    ]
  },
  {
    "file_path": "./devposts/soy-mate.html",
    "project_id": "soy-mate",
    "title": "Soy Mate",
    "tagline": "Choose your match and find good food!",
    "hackathon": "",
    "built_with": [
      "deso",
      "flask",
      "react",
      "socket.io",
      "tailwindcss",
      "twilio",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of DeSo Created by Chantal Pino Lib Joshua Martinito Joshua Sintos Renz Vital Christian Mi",
      "Hack And SnackWinnerBest Use of DeSo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/247/376/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 💡 Inspiration 💡 Sometimes all people knead is love.  So we set out to create an a-maize-ing platform for foodies to find their soymates. The fig idea behind this was to create something that helps people meet their butter half and to find out if they’re a matcha made in heaven! ⚙️ What it does ⚙️ Soy Mate is a platform that is essentially a dating app for foodies and food-centric individuals.\nWhen matching with other people, instead of the typical information that other dating apps emphasize on (such as their occupation or where they went to school), we wanted to emphasize on information such as their top three favorite dishes or their favorite food genre to further push the concept that Soy Mate is a food-focused dating app. When two people are a match, they can strike a conversation and talk to each other using the chat module of our application. 🏗️ How we built it 🏗️ We developed the application with love using the React library for the frontend and TailwindCSS for styling. On the other hand, we used the Flask framework for the backend to develop the API endpoints for our application. Additionally, we used Socket.io to handle the websockets for the chat module, and DeSo for the authentication. 🟣 Use of Github Our commits history Our pull requests 💙  Use of Deso We used Deso's identity API for authentication in our web app and used its user endpoints to provide a more personalized experience. 🖤 Use of Twilio We used Twilio to send user notifications that you've matched with someone to your phone number by utilizing the SMS API. 🚩Challenges we ran into The main challenge that we encountered while constructing our application was the fact that we haven’t used DeSo and Socket.io before. For DeSo, we had to figure out how to use the identity API to use as the auth  entication for our application. For Socket.io, we had to read the documentation and scour the web for tutorials on how we would efficiently set up the chat module of our application. Learning both t"
      }
    ]
  },
  {
    "file_path": "./devposts/spacecraft-re-entry-model-trajecto.html",
    "project_id": "spacecraft-re-entry-model-trajecto",
    "title": "Spacecraft re-entry model trajectory simulation web app",
    "tagline": "visualize the model of space craft re-entry with a web app",
    "hackathon": "",
    "built_with": [
      "matplotlib",
      "numpy",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/696/868/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration As someone who has high interest in physics I like it when things are more visual and interactive, where I can input my own values and test something and that's how I got the idea of creating a simulation in a web app so that others can use and test it too What it does It shows the simulation model of space craft re-entry trajectory and the default values can be changed with the help of slider in sidebar How we built it I used Python and some of its libraries i.e. matplotlib, numpy and streamlit\nstreamlit was mainly used to make it to a web app instead of just a program that can run locally it allowed me to make it available fore everyone on a website where people can change the inputs as per their need\nUsed Numpy to arrange the data in a perfect manner so that it can be used for plotting. Challenges we ran into Took me a while to understand the main goal of the theme and I had little to no experience with streamlit so had some issues learning that since I am more of a typescript person so was having a lot of syntax issues but at the end I made it work. Accomplishments that we're proud of I am proud that I was able to make this work within the time limit at the same time when my finals are going on What we learned I learned a lot about core physics when it comes to spacecrafts like what's drag coefficient, safe g-load and many more parameters that are suppose to be taken care of in order to make sure the parachute deployment is happening at the correct time What's next for Spacecraft re-entry model trajectory simulation web app Will be adding 3d animations and more parameters that people can alter and get accurate values How to run ? clone the repository mentioned below or do git clone https://github.com/KlausMikhaelson/cap_regina.git go to the repository and do pip install -r requirements.txt enter streamlit run main.py Built With matplotlib numpy python streamlit Try it out capregina-25ezxv5rlbpraumft2akbh.streamlit.app GitHub Repo Submitted to 202"
      }
    ]
  },
  {
    "file_path": "./devposts/spacejordan.html",
    "project_id": "spacejordan",
    "title": "SpaceJordan",
    "tagline": "Stay hungry, and stay foolish. Learn all you can about space and become a space Jordan. With our space learning app.",
    "hackathon": "",
    "built_with": [
      "c",
      "c#",
      "css3",
      "discord",
      "figma",
      "flask",
      "nextjs",
      "react",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Second Overall Created by Team Management and Information Collection Sri Harshitha Anantatmula Lear",
      "SpaceAthonWinnerSecond Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/408/693/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Design And Layout (Figma) SpaceJordan Us Tools & Tech Design And Layout (Figma) SpaceJordan Us Tools & Tech Design And Layout (Figma) 1 2 3 4 5 Inspiration 🚀 Who doesn't love listening to music while working? And everyone loves watching space videos! So Space Jordan works on combining those two things: adding a soundtrack from latest sci-fi lofi music to space live video stream. Who would dare procrastinate (not us!) by making them listen with one hand as they work with the other? Imagine you're in space and you have no one to talk to and no way to get back home, what would you do? We wanted to counter this by creating a web application that allows two people to create an account, learn about space and listen to music with an option to play various games like Wordle. What it does 🥳 Features: We built this application to help people learn about space trave l and navigate their way through space. With sounds and videos to guide your learning experience, you will be able to picture yourself hooping through space with minimal effort. We understand that music helps learning, so we built an application with video and audio functionallity to help in the use of our application. How we built it ☺️ The Web-App is built on React and Next.js \nWe built backends with C# Challenges we ran into 🤯 Challenges:We faced many challenges during the making of this project. We initially struggled with the idea of finding a library that could add audio to the existing video files effectively. after some digging we found out about how using c# could be effective here and we went for it . We also had some trouble Debugging our code but we successfully managed to be successful.\nThe biggest one is building the 3D Model with next js to give the app a space feel. We had to try 2 different methods before eventually succeeding Accomplishments that we're proud of 🥺 Our accomplishment was that we managed to work as a team despite all the obstacles. We built an application with languages we are relati"
      }
    ]
  },
  {
    "file_path": "./devposts/sonoverse.html",
    "project_id": "sonoverse",
    "title": "Sonoverse",
    "tagline": "Protecting small artists' work through a decentralized on-chain ML-driven platform, integrating automatic DMCA claims.",
    "hackathon": "",
    "built_with": [
      "caldera",
      "cohere",
      "crossmint",
      "ethers",
      "flask",
      "next.js",
      "pinata",
      "python",
      "pytorch",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Taisu Ventures: Creative Web3 Platform Award ($500 Cash) Created by Built frontend, application API",
      "TreeHacks 2024WinnerTaisu Ventures: Creative Web3 Platform Award ($500 Cash)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/771/750/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 TL; DR Music piracy costs the U.S. economy $12.5 billion annually . Independent artists are the fastest growing segment in the music industry , yet lack the funds and reach to enforce the Digital Millennium Copyright Act (DMCA). We let artists OWN their work (stored on InterPlanetary File System) by tracking it on our own Sonoverse Ethereum L2 chain (powered by Caldera). Artists receive Authenticity Certificates of their work in the form of Non-Fungible Tokens (NFTs), powered by Crossmint’s Minting API. We protect against parodies and remixes with our custom dual-head LSTM neural network model trained from scratch which helps us differentiate these fraudulent works from originals. We proactively query YouTube through their API to constantly find infringing work. We’ve integrated with DMCA Services , LLC. to automate DMCA claim submissions. Interested? Keep reading! Inspiration Music piracy, including illegal downloads and streaming, costs the U.S. economy $12.5 billion annually. \nIndependent artists are the fastest growing segment in the music industry, yet lack the funds to enforce DMCA. We asked “Why hasn’t this been solved?” and took our hand at it. Enter Sonoverse, a platform to ensure small musicians can own their own work by automating DMCA detection using deep learning and on-chain technologies. The Issue Is it even possible to automate DMCA reports? How can a complex piece of data like an audio file be meaningfully compared? How do we really know someone OWNS an audio file? and more... These are questions we had too, but by making custom DL models and chain algorithms, we have taken our hand at answering them. What we’ve made We let artists upload their original music to our platform where we store it on decentralized storage (IPFS) and our blockchain to track ownership . We also issue Authenticity Certificates to the original artists in the form of Non-Fungible Tokens. We compare uploaded music with all music on our blockchain to detect if it is a parod"
      }
    ]
  },
  {
    "file_path": "./devposts/soupersaurus.html",
    "project_id": "soupersaurus",
    "title": "Soupasaurus",
    "tagline": "A Soup-tastic Dinosaur Game: Maybe the real soup was the friends we made along the way!",
    "hackathon": "",
    "built_with": [
      "c#",
      "figma",
      "gemini",
      "python",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/855/572/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "the final screen, with an option to start a new quest landing screen with hand drawn animation at the beach with a mob boss megalodon stimulating convo w/ sherlock holmes interrogation from an aggressive t-rex personalized soup screen the final screen, with an option to start a new quest landing screen with hand drawn animation at the beach with a mob boss megalodon stimulating convo w/ sherlock holmes interrogation from an aggressive t-rex personalized soup screen the final screen, with an option to start a new quest 1 2 3 4 5 6 7 Inspiration If you were a soup, what soup would you be? This question haunted us until we came up with the idea for this choose-your-own-adventure personality test. And what goes better with soup than dinosaurs? Instead of taking the same boring and lengthy personality test every time you forget your MBTI, Soupasaurus is a brand new type of personality test powered by the Gemini API. In each adventure, you have the chance to converse with a new cast of eccentric characters, each with their own unique personalities and quirks, to find out once and for all what soup you really are… What it does Soupasaurus moonlights as a pixel RPG game in which the user plays as a hungry dinosaur craving some soup. In their adventure to the outside world, they meet other kooky dinosaurs against a variety of pixel backgrounds. NPCs ask questions the user responds to by choosing between AI-generated replies – users can even refresh for new answers if the phrasing isn’t their cup of soup. After this, the NPC gifts the user an ingredient based on their conversation! In the end these ingredients are combined to make a soup. Finally, after a lifetime of waiting, you’ll know The Soup that encapsulates your personality, and maybe find out that the real soup was the friends you made along the way! Unlike other personality tests, Soupasaurus values a unique experience for a replay of the game—there’ll never be two play-throughs that are the same. Using Gemini, we we"
      }
    ]
  },
  {
    "file_path": "./devposts/spark-mhxso9.html",
    "project_id": "spark-mhxso9",
    "title": "Spark",
    "tagline": "Empowering Passion, Sparking Change, Inspiring Impact: Connecting Sustainable Hearts with Purposeful Projects.",
    "hackathon": "",
    "built_with": [
      "ant-design",
      "convex",
      "figma",
      "javascript",
      "next.js",
      "react",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Prototyping Process ($1k Cash) Winner Cotopaxi: Most Innovative Sustainability Hack (4x Allpha 35L",
      "Convex: Best Use of Convex Features ($1",
      "Stanford Ecopreneurship: Best Prototyping Process ($1k Cash) Winner Cotopaxi: Most Innovative Susta",
      "3/4 of our team's first hackathon project!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/769/220/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Iterations Who We Are Technology Used Iterations Who We Are Technology Used Iterations 1 2 3 4 Inspiration As we began to look at the TreeHacks 10 tracks, all team members were immediately drawn to the sustainability track. In a world with increasing temperatures, excessive greenhouse gas emissions, biodiversity loss, and pollution, among numerous other ecological challenges, we know we all have an individual responsibility to help preserve and revitalize our environment. As a result, we began brainstorming how we could individually help contribute to a more sustainable future. Our first thoughts centered around how we could encourage contributions to environmental nonprofits. Still, we struggled to name localized organizations that could impact on an individual scale. With three of us originally from Iowa, we did a quick Google search to find potential organizations whose mission aligned with our goal and found over 20 (including 3 within 20 minutes of our hometown) around the state that could utilize resources from people in various ways. The contributions they were seeking primarily consisted of people volunteering and monetary donations. If this was the case in Iowa, we knew most other states would likely have even more available opportunities. But how could we make people aware of them? Looking at the communities of people we know, it’s clear there is no shortage of people interested in environmental sustainability. But just being passionate about an issue doesn’t lead to improvement. A streamlined way to identify tangible ways to catalyze change, though? That is what’s needed to bridge the gap between someone’s desire to make change and their ability to follow through. We realized our platform’s goal: to allow organizations to make themselves known to those people who already have a planted spark and want to help preserve their environment for future generations. What it does Your spark can create change. Spark is a platform that allows environmental organizat"
      }
    ]
  },
  {
    "file_path": "./devposts/sonr-radar.html",
    "project_id": "sonr-radar",
    "title": "Sonr rADar",
    "tagline": "A decentralized advertising platform—leveraging the power of blockchain to incentivize users and give them full control of their personal data.",
    "hackathon": "",
    "built_with": [
      "blockchain",
      "c++",
      "cmake",
      "dart",
      "flutter",
      "go",
      "ruby",
      "sonr",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2022WinnerRebuilding the Internet: Most Creative Data Composition (Sonr)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/224/874/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Dropdown menu with options Our project's logo! Homescreen/dashboard of our mobile application Dropdown menu with options Our project's logo! Homescreen/dashboard of our mobile application Dropdown menu with options 1 2 3 Inspiration As a team, we've been increasingly concerned about the data privacy of users on the internet in 2022. There’s no doubt that the era of vast media consumption has resulted in a monopoly of large tech firms who hold a strong grasp over each and every single user input. When every action you make results in your data being taken and monetized to personalize ads, it’s clear to see the lack of security and protection this can create for unsuspecting everyday users. That’s why we wanted to create an all-in-one platform to decentralize the world of advertising and truly give back digital data ownership to users. Moreover, we wanted to increase the transparency of what happens with this data, should the user opt-in to provide this info to advertisers. That’s where our project, Sonr rADar , comes in. What it does As the name suggests—Sonr rADar, integrated into the Sonr blockchain ecosystem, is a mobile application which aims to decentralize the advertising industry and offer a robust system for users to feel more empowered about their digital footprint. In addition to the security advantages and more meaningful advertisements, users can also monetarily benefit from their interactions with advertisers. We incentivize users by rewarding them with cryptocurrency tokens (such as SNR ) for their time spent on ads, creating a win/win situation . Not only that, but it can send advertisers anonymous info and analytics about how successful their ads are, helping them to improve further. Upon opening the app, users are met with a clean dashboard UI displaying their current token balance, as well as transfer history. In the top right corner, there exists a dropdown menu where the user can choose from various options. This includes the opportunity to enter "
      }
    ]
  },
  {
    "file_path": "./devposts/solspace-gallery.html",
    "project_id": "solspace-gallery",
    "title": "SolSpace Gallery",
    "tagline": "SolSpace Gallery is a virtual world that offers NFT collectables and showcases the winning hack projects each year via VR and WebVR.",
    "hackathon": "",
    "built_with": [
      "blender",
      "c#",
      "figma",
      "miro",
      "photoshop",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/881/146/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration MIT hackathon - We wanted to create a virtual gallery to showcase of all winning hack projects so that current, past and future participants have access to a virtual archive of all winning hack projects and link these with NFTs. What it does SolSpace Gallery is a virtual world that offers NFT collectables and showcases the winning hack projects each year via VR and WebVR, it also hosts an online meeting space for remote participants to watch the awards ceremony. The gallery has rooms for each category and corresponding tracks and the winning teams will each receive limited edition NFTs linked to their category if they sign up for a Solana wallet to collect. Each team's projects will be showcased via video screens, using the video presentations made for their entries. How we built it We built it by using Unity game engine and integrated SOLANA Blockchain for the wallet Challenges we ran into Integrating Solana wallet into the VR space was a challenge and integrating the multiplayer. We only worked out that the Solana integration wouldn't work in VR at the last hours, we have a 2D version working with wallet connection, but future development is required for VR NFT collecting. Also access to support at the hackathon during overnight hours for our team members who were located all around the world - for example Github access, proved challenging. Accomplishments that we're proud of We are proud we had the opportunity to collaborate & connect with participants from different countries with one goal of hacking the hack. We were able to build a functioning APK for the VR gallery part, and a working 2D wallet integration for the Blockchain part of our project. What we learned We learned about team collaborations and teamwork. We delegated tasks irrespective of our time differences. What's next for SolSpace Gallery One of our goals is to make the gallery accessible. In the future, we will like to integrate the following so it is inclusive and acce"
      }
    ]
  },
  {
    "file_path": "./devposts/spacey-9f3mga.html",
    "project_id": "spacey-9f3mga",
    "title": "spaCey",
    "tagline": "Decentralizing the Race to Mars Through Rovers and Bounties",
    "hackathon": "",
    "built_with": [
      "esp32",
      "flow",
      "hardware",
      "ml/ai",
      "nft",
      "node.js",
      "python",
      "react",
      "starknet"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Flow Winner Best Use of Starknet Created by Frontend + robotics Elijah Kurien blockchain + w",
      "Best Use of Flow Winner Best Use of Starknet Created by Frontend + robotics Elijah Kurien blockchai",
      "UTRA HacksWinnerBest Use of FlowWinnerBest Use of Starknet",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/728/866/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Rover NFT (Starknet) Rover Bounties Etherscan NFT Bounty Form Rover NFT (Starknet) Rover Bounties Etherscan NFT Bounty Form Rover NFT (Starknet) 1 2 3 4 5 6 Inspiration 🌌 The inspiration for spaCey came from a desire to democratize space exploration and problem-solving. Typically, challenges such as satellite refueling 🛰️ and colony construction on Mars 🪐 are managed by large contractors. We saw an opportunity to decentralize this power and enable anyone, anywhere, to contribute meaningfully to these pressing space problems. Our vision is to harness the collective intelligence and skills of a global community to accelerate the advancement of life on Mars and beyond. What It Does 🚀 spaCey is an innovative solution that combines a gesture-controlled Mars rover 🤖 with a digital platform for submitting and claiming bounties. Users can contribute to various space-related tasks and earn FLOW tokens 💰 upon completion of these bounties. The platform is an integral part of a DAO, promoting a decentralized approach to decision-making and contribution. This system not only incentivizes participation in space advancement activities but also makes it accessible to a wider audience, democratizing the process of space exploration. How We Built It ⚙️ The Rover Our rover was constructed to demonstrate how anyone can use the platform. With our gesture-controlled rover, we are able to navigate our vehicle and simulate the completion of tasks, which ultimately allows us to demonstrate the possibilities of the spaCey platform. Here's what we used: Tensorflow: Used to train a gesture-controlled neural network ESP32: This was the driving force behind our rover - using bluetooth, we were able to send commands to the rover which the ESP32 received and then sent the necessary signals to the connected motors. The Platform Our frontend allows for users to submit proposal for colony advancement and to claim the bounty once they have completed the task. We allow for everyone to contribute as par"
      }
    ]
  },
  {
    "file_path": "./devposts/soundbite.html",
    "project_id": "soundbite",
    "title": "SoundBite",
    "tagline": "SoundBite is a web application designed to help teach beginner musicians basic Western music theory with information and short games.",
    "hackathon": "",
    "built_with": [
      "github",
      "heroku",
      "html",
      "javascript",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/650/708/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Temi and I have been involved with music for over 7 years and were excited when we heard this Hackathon's theme was music this year. We've always heard people that have wanted to play music but have never known where to start in regards to learning how to read music. What it does Soundbite is a basic web application that teaches beginner musicians about the basics of Western music theory, which includes how to read a treble/bass clef, how to distinguish notes and their rhythms, as well as a perfect-pitch exercise for fun. How we built it We utilized the IDE Visual Studio Code and coded SoundBite using JavaScript and HTML to format and make our web application interactive to an extent. We used an external tool to create our web graphics, one similar to Adobe Illustrator, and used those .png/.jpg files within our HTML code. Challenges we ran into Everything pertaining to this project was a challenge in itself. I have never worked with GitHub, VS Code, JavaScript, nor HTML, so everything in the last 24 hours was a great learning experience. We often ran into problems with basic HTML syntax, integration of basic \"game\" mechanics, and file/image integration. We had to \"hit the books\" with many YouTube videos, LinkedIn Learning courses, and received help from a mentor in order to get our project rolling. Accomplishments that we're proud of Temi and I have only comfortably worked with Python and C++ before this Hack-a-thon, so learning HTML and JavaScript in the matter of 24 hours to make this neat-looking website is a small victory I am proud of. What we learned We learned a lot of front-end design we were never familiar with and how to integrate it into a working web-application. We also learned the mechanics available to these web-apps, and hope to expand our current project. What's next for SoundBite We hope that somewhere along the line of this semester we can finish this project and make it available to anyone who would like to learn music. We loved w"
      }
    ]
  },
  {
    "file_path": "./devposts/sparespace-mo3qru.html",
    "project_id": "sparespace-mo3qru",
    "title": "SpareSpace",
    "tagline": "Connecting students with local businesses to offer underutilized spaces at affordable prices.",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "appwrite",
      "docker",
      "mui",
      "node.js",
      "sendgrid",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Real Estate Data\" Winner Best Use of Appwrite Created by Shannon little Valli Mahavadi Chali",
      "Pearl Hacks Winner CoStar Group: \"Best Use of Real Estate Data\" Winner Best Use of Appwrite Created",
      "Pearl Hacks 2023WinnerPearl HacksWinnerCoStar Group: \"Best Use of Real Estate Data\"WinnerBest Use of Appwrite",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The inspiration for SpareSpace came from the growing need for affordable, accessible, and safe spaces for students who are facing the challenges of finding a place to live, study, sleep or simply hang out. With the increasing cost of housing and the limited availability of on-campus housing, many students are forced to live in their cars or endure overcrowded dorms. SpareSpace aims to solve this problem by connecting students with local businesses that have underutilized spaces available for rent. The platform offers a simple and convenient solution for both students and businesses, providing a win-win solution for all parties involved. With SpareSpace, students can finally have access to affordable and comfortable spaces, and businesses can benefit from additional revenue streams from their underutilized spaces. What it does SpareSpace acts similarly to AirBnB. Students enter the page with an ability to search for rental spaces based on the timeframe and purpose of renting the space, budget, as well as zipcode. SpareSpace is able to filter those information by analyzing real estate and property data from the Town of Cary GIS group. After the students request a rental space, owners will receive emails prompting them to approve or request these rental requests. If their request is approved, students will receive an email directing them to a secure and encrypted payment developed by Stripe API. Once that is done, the students will receive reminders via email about using and maintaining their rental space. How we built it Our team built the frontend using Google Cloud Map API, AngularJS, Angular Material UI, and Typescript, and the backend using Node.js. We implemented our database and user authentication using Appwrite and Docker, payment functionality using Stripe API, and automatic email delivery system using SendGrid API. Aside from this, we collected our rental space data by scraping real estate data from the Town of Cary GIS Group. This is our first t"
      }
    ]
  },
  {
    "file_path": "./devposts/source-savvy.html",
    "project_id": "source-savvy",
    "title": "CourSavvy",
    "tagline": "Find courses that you enjoy the first time around",
    "hackathon": "",
    "built_with": [
      "angular.js",
      "fastapi",
      "mongodb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Find courses that you enjoy the first time around",
      "I worked on the back-end. It was my first time using MongoDB search indexes."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/728/175/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Figma Prototype Main page on Angular Figma Prototype Main page on Angular Figma Prototype 1 2 3 Inspiration 🌟 Course enrolment is stressful 😥, and picking the right courses is even harder. 😓 Just this semester we have hit waitlists 🚫, financial deadlines 💸, and missed lectures 📚 trying to figure out what course to enrol in. It's also hard to find help when you're taking a course. We wanted to create a website 💻 to crowdsource information about courses to remove a stress from a student's life 😌 and to connect them with those who have completed the course. 🙌 What it does 🚀 We built a website that crowdsources reviews of courses from different post-secondary institutions. 🏫 Students review courses they've taken and provide metrics on different aspects such as reading 📖, writing 📝, and presentations 🎤. Optionally, students can add their emails 📧 if they're willing to be contacted about the course in the future. Additionally, we ask that they submit details on the assessments about the course so we know how grades are weighted. 📈 How we built it 🔧 We used MongoDB search indexes to index the course codes and titles. This allows us to autocomplete and suggest courses based on what the user typed into the search box. 🔎 All functions relating to MongoDB went through our FastAPI backend, which is hosted on Render after being containerized. 🐳 The frontend was built using Angular.js. 🅰️ Challenges we ran into 🤯 MongoDB's autocomplete schema was confusing and combining different criteria proved challenging. Often, requests would respond empty, or with long error traces. 🐛 We also encountered an issue with FastAPI where if we returned the ID of the object, the server would fault. 💥 Accomplishments that we're proud of 🏆 The autocomplete works well and fast. ⚡ What we learned 🧠 We learned how to create search indexes and do autocomplete in search boxes. 🙃\nSome of our team members learned how to push content on Github. 🐙 What's next for CourSavvy 🚗 We'd like to add user authenticati"
      }
    ]
  },
  {
    "file_path": "./devposts/spacetro.html",
    "project_id": "spacetro",
    "title": "SpaceTro",
    "tagline": "Empowering young astronauts of tomorrow",
    "hackathon": "",
    "built_with": [
      "flask",
      "geminiapi",
      "python",
      "react",
      "supabase",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/906/005/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Low Fidelity Prototype SpaceTro High Fidelity Prototype Low Fidelity Prototype SpaceTro High Fidelity Prototype Low Fidelity Prototype 1 2 3 4 🌙 Inspiration Only 11% of world’s astronauts are female. 🚀 What it does Educates young women on the fundamentals of our galaxy. 🛠️ How we built it Front: ReactJS, Tailwind Back: Flask, Supabase, Gemini API 🔥 Challenges we ran into Converting Gemini responses into AI articles and quizzes Resolving merge conflicts between front/back end 🌠 Accomplishments that we're proud of Implementing a point system for scoring in quizzes Creating a full stack web app within <24 hours 🫂 What we learned Test LLM prompts within Gemini before integrating Figure out page routing before implementing back end 🔭 What's next for SpaceTro Display ranks and module completions on LinkedIn Incorporate a wider range of media for learning (e.g. videos, games, simulations) Built With flask geminiapi python react supabase tailwind Try it out www.figma.com GitHub Repo youtu.be Submitted to VenusHacks 2024 Created by I contributed on designing and frontend. Aurelisa Juan Vouloir, c'est pouvoir. I worked on both the frontend and backend. Ethan Santos Aurelia Sindhu 아이스 아메리카노 ☕️ Rian Corcino i code stuff for fun"
      }
    ]
  },
  {
    "file_path": "./devposts/speakingpoker.html",
    "project_id": "speakingpoker",
    "title": "SpeakingPoker",
    "tagline": "An opportunity for blind people and/or physically impaired people to play a card game",
    "hackathon": "",
    "built_with": [
      "python",
      "shell"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Top Team Award Created by Surya Jasper Aditya Mittal Karthik Mittal",
      "LingHacks IIWinnerTop Team Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Wanted to create a program for blind and physically-impaired people What it does This program creates an interface to play poker against a certain number of AI's that the player chooses. The player uses voice controls to play the game, and important information is spoken back to the player. the game continues as a normal game of Texas Hold em poker until the player or one of the AI's wins Challenges We originally coded in C# but realized that Unity was not a good platform for a game involving speech recognition, so we decided to switch to python, needing to translate all of our C# code into python 3.7. We also tried to integrate socket based programming, but it proved to be overly complicated. After switching to an offline AI approach, we saw that it would have been merely impossible to create a socket-based poker game in 24 hours in C# or Python. Built With python shell Submitted to LingHacks II Winner Top Team Award Created by Surya Jasper Aditya Mittal Karthik Mittal"
      }
    ]
  },
  {
    "file_path": "./devposts/spark-h39wfe.html",
    "project_id": "spark-h39wfe",
    "title": "Spark",
    "tagline": "Your Education. Your Way. Innovative Personalized Studying with ML generated quizzes and study guides, progress tracking, automated grading, and learning feedback. Study Smarter!",
    "hackathon": "",
    "built_with": [
      "flask",
      "framermotion",
      "javascript",
      "nextjs",
      "nltk",
      "openai",
      "postgresql",
      "prisma",
      "python",
      "react",
      "sqlalchemy",
      "tailwind",
      "typescript",
      "youtube-transcript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/431/421/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Our Landing Page! Our Landing Page! Our Landing Page! 1 2 Inspiration All of us on the team have experienced situations of having many course videos to watch and content to learn in a short period of time, and we realize that simply watching the video and trying to cram memorize the topics is ineffective. According to research at the University of San Diego, the most effective studying methods are \"Distributed Practice\" and \"Retrieval Practice\". (2) Distributed practice involves studying over a long period of time, such that the memory is exercised multiple times over a longer period of time, such as a week, while retrieval practice involves the method of actively recalling and exercising memory (1). These two types, along with successive learning, or studying until 100% accuracy of memory retention, should in the long run result in the optimal performance in the lowest time studying. We were inspired to create Spark by the struggles students face when trying to effectively work through large amounts of seminar or course content. Procrastination and difficulty in comprehending the presented concepts often hinder the learning process, and we wanted to provide a solution that helps students overcome these challenges. We believe that studying smarter will save time for students across any discipline! What it does Spark is an innovative personalized studying platform that utilizes advanced machine learning techniques to generate quiz questions and answers, summaries, study guides, and personalized advice for each video. It enables students to study smarter and not harder by providing progress tracking, automated grading, and learning feedback. Both multiple-choice and free response questions can be graded, making it possible to assess all forms of knowledge. It can store quizzes and track progress in order to aid in distributed practice. Students are able to space out their sessions and monitor their learning rate to take the best course/plan of action towards their goa"
      }
    ]
  },
  {
    "file_path": "./devposts/sparkstream.html",
    "project_id": "sparkstream",
    "title": "Sparkstream",
    "tagline": "Low-Bandwidth Virtual Collaboration Redefined ⚡",
    "hackathon": "",
    "built_with": [
      "chakra",
      "dapp",
      "filecoin",
      "fleek",
      "ipfs",
      "javascript",
      "libp2p",
      "moralis",
      "peerjs",
      "python",
      "react",
      "tailwind",
      "tensorflow",
      "web3.storage",
      "webtorrent"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "3rd place Winner Across the Line Award Created by Pratyay Banerjee Trying to learn how to learn ;)",
      "Faber Web3 HackathonWinner3rd placeWinnerAcross the Line Award",
      "First and foremost, it is Crafted with 💙. The whole process can be broken into the following points :-",
      "Winner",
      "Secondly, go seek a psychiatrist asap!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/874/551/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Project Name : Sparkstream Team Details : Pratyay Banerjee [ https://neilblaze.live ; https://github.com/Neilblaze ; putubanerjee23@gmail.com ] Aziz Abdullaev [ https://azizabdullaev.site ; https://github.com/azyzz228 ; aziz05072000@outlook.com ] Kai You [ https://www.kai-you-portfolio.com ; https://github.com/hardco2020 ; school021195@gmail.com ] Inspiration 💡 Virtual interaction has become the new normal in this Pandemic era & Online Classes , 1:1 interviews & mainly Hackathons are not any exception. In Virtual Hackathons, you can reach everyone in the world, but keeping a limelight on the same fact, it's also quite evident that participants have their own connectivity constraints which eventually degrades the overall experience. All this after investing millions of dollars into servers running on Web2, & still we use this because WE DON'T HAVE much other options :( We believe with creative thinking and a proper approach we can innovate novel methods that’ll help us tackle the same in an intuitive manner. Thus, we built Sparkstream ✨ What it does 🤔 The primary goal of Sparkstream is to uplift the overall hackathon user engagement by enabling ultra low-bandwidth code collaboration and conferencing abilities built for the better! The name actually originated from the 'Spark of the Zeus' that has been generated from the thunder that represents blazing Fast-Speed & 'Stream' indicates the uninterrupted flow of the same. Leveraging web3 tech stacks and with the power of IPFS, Sparkstream is built to help people joining from across the globe to get a better hold of different meetings, conferences, 1:1 interview sessions, and as priorly mentioned, Hackathons! The use cases are numerous as of now, but for this hackathon, we carried out extensive surveys on different discord servers that actually states that people actually face a lot of problem on these sort of Web2 platforms where they often face critical lags, disconnectivity providing the fact, most of them "
      }
    ]
  },
  {
    "file_path": "./devposts/spleef-ai.html",
    "project_id": "spleef-ai",
    "title": "spleef.ai",
    "tagline": "Harnessing AI for Real-Time Interview Training",
    "hackathon": "",
    "built_with": [
      "api",
      "assemblyai",
      "cors",
      "flask",
      "google-cloud",
      "javascript",
      "llm",
      "openai",
      "python",
      "react",
      "tailwindcss",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First, Second, Third Overall - (Option #2) Created by Ian Korovinsky Stephen Ni Lucy Qi",
      "Ignition Hacks 2023WinnerFirst, Second, Third Overall - (Option #2)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/571/717/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Recording Page Tech Stack Diagram Landing Page Interview Question Selection Recording Page Tech Stack Diagram Landing Page Interview Question Selection Recording Page 1 2 3 4 5 💡 Inspiration Behind spleef.ai 🌍 At spleef.ai, our journey began with a simple question: What kind of challenge could we help aspiring professionals overcome? 🚀💼 We pondered over the obstacles that often stand in the way of interview success – the jitters, the uncertainty, and the lack of timely guidance. It struck us that there was an opportunity to bridge this gap with technology and innovation. 💡🔗 From this spark of inspiration, the concept of spleef.ai emerged – an interview assistant designed to provide real-time feedback on responses. We envisioned a tool that wouldn't just evaluate answers but would also nurture growth through personalized insights. 📝🌱 Our goal became clear: to create a companion that harnesses the power of AI to simulate real interview scenarios, offering an immersive practice ground. This would empower users to refine their interview skills and gain confidence, propelling them toward success. 🚀✨ As we embarked on this mission, the name \"spleef.ai\" naturally fell into place, signifying our fusion of speech (speak) and guidance (feedback). With unwavering determination, we set out to create an innovative solution that would revolutionize the interview preparation experience. 💬🗂️ 🎙️ What spleef.ai does 🚀 A user starts on the landing page, where they have the option to get started on their interview training. At first, they are directed to a screen where they can choose what type of question they want to practice. The difficulties are easy, medium, and hard, and there are four categories of questions: Behavioural:  Ask about past experiences to assess skills and behaviour Motivation and Fit: Ask about enthusiasm and cultural alignment Situational: Ask about hypothetical scenarios to evaluate decision-making Personal: Ask about personal interests and values After they sel"
      }
    ]
  },
  {
    "file_path": "./devposts/speechwiz.html",
    "project_id": "speechwiz",
    "title": "SpeechWiz",
    "tagline": "Improve your speaking skills with a cross-platform AI-based application",
    "hackathon": "",
    "built_with": [
      "dart",
      "flask",
      "flutter",
      "google-cloud-speech",
      "python",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Solo Hack Created by Neel Adwani yeet",
      "Best Solo Hack Created by Neel Adwani yeet",
      "HackRU Fall 2023WinnerBest Solo Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/615/168/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Stage fright is common and at some point affects us all. I had the fear of speaking in my first few days of teaching and walking up to a stage. What it does SpeechWiz will allow you to practice your next big speech or speaking skills in general. You just have to hit record and begin your speech. It will transcribe your speech, mark the grammatical errors, along with a listenability score and how it will sound to your audience. It will provide you with the corrections as well. These pointers will help you correct your speech How I built it Front-end - Flutter Back-end - Python-Flask API - Google Cloud Speech Recognition Challenges we ran into The initial plan was to build it with ChatGPT at the back-end but I also had a plan in mind to launch it on product hunt too. With ChatGPT, I would have to pay for their costs, which was not feasible, so I came up with workarounds for grammar correction, emotion recognition, and getting a listenability score. Accomplishments that we're proud of I'm proud of building it over the span of 24 hours and also making it launch-ready! What we learned I got myself familiar with flutter and learned about so many python libraries, which I used to avoid using ChatGPT. What's next for SpeechWiz Next I will launch it within the hour and see how it goes! Built With dart flask flutter google-cloud-speech python replit Try it out GitHub Repo GitHub Repo speechwiz.tech Submitted to HackRU Fall 2023 Winner Best Solo Hack Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/spookudoku.html",
    "project_id": "spookudoku",
    "title": "SpookuDoku",
    "tagline": "A puzzle that tests your knowledge on movies of the horror genre 👻🎃🦇",
    "hackathon": "",
    "built_with": [
      "api",
      "javascript",
      "react",
      "tmdb"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best App Created by Marky Salinas Chantal Pino Renz Vital",
      "Horror Hacks 2023WinnerBest App",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/643/440/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration 💡 The inspiration behind this project was our love for horror movies. We wanted to create an app to demonstrate our knowledge of the genre. An app that would essentially let us test each other on our horror movie knowledge. A great deal of inspiration also came from PokeDoku ( https://pokedoku.com/ ) and Wordle ( https://www.nytimes.com/games/wordle/index.html ), getting elements mostly from PokeDoku, to create our app. These three things combined led us to create SpookuDoku. What it does ⚙️ SpookuDoku is a puzzle game where people can test out their knowledge on movies of the horror genre. How we built it 🏗️ The application was built with love using React. Challenges we ran into 🚩 We were rusty as this is our first hackathon in such a long while and had to warm up the gears not only in development but also in time commitment and in communication. Finding resources for our app wasn’t pretty either. We had to find a movie database with keywords embedded onto them to use as the categories for our puzzles. Accomplishments that we're proud of 🏅 We are proud that we were able to share our love of the horror genre and created an application that expresses that adoration. What we learned 📚 Coming off from a hackathon hiatus, we learned what works and what doesn’t. We learned what steps we can cut out to smoothen out the development process and what strategies we can integrate to have a more effective workflow. What's next for SpookuDoku ⏩ For SpookuDoku, we hope to scale the project and make it more accessible to people. It’d be also great if we can find a way to have our own movie database so we don’t create this sort of dependency with the API we used. Built With api javascript react tmdb Try it out GitHub Repo Submitted to Horror Hacks 2023 Winner Best App Created by Marky Salinas Chantal Pino Renz Vital"
      }
    ]
  },
  {
    "file_path": "./devposts/sphere-zkbvtp.html",
    "project_id": "sphere-zkbvtp",
    "title": "Sphere",
    "tagline": "Whether you need help with school or just want to connect with other learners, Sphere is the perfect place to start. Join our community today and discover a world of opportunities to learn and grow!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "css",
      "flask",
      "html",
      "javascript",
      "json",
      "mysql",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/410/703/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration As current first-year students ourselves, our first thought was about education, and how that can perpetuate the existing inequalities and barriers to access technology for such users. For the past 24 hours, we have been working on a solution that can address this problem in a manner that is feasible, sustainable and innovative. What it does Users are first greeted by a landing page in which they scroll through or access by clicking the navigation bar to get to their destination. Currently, we have 3 services available -- signing up as a student, signing up as a tutor, and connecting with other students with similar interests.\nOur platform will then automatically match tutors and students if they are available at the same time and list the same subject on their information. However, we recognize that naturally, through a free service like this, the demand of students will far outweigh the supply of tutors. \nThis is where Sphere differs from other platforms, and where Co-Here comes in: Using Co-Here’s natural language processing capabilities, The Cohere API uses semantics search to connect students with similar interests and pair them with students. How we built it Sphere uses a combination of HTML, CSS and JavaScript to build the front end, and MySQL, Python, Flask and the Co-Here API to build the back-end. \nWe use Flask to connect both ends, get user data, and then store it in a MySQL database. Additionally, we use Co-Here’s semantic search API to connect students to other students with similar needs and interests based on their own description. Challenges we ran into It was really hard patching up the whole project in less than 24 hours, especially with just a team of two first-years, but we are really proud of the results of our hard work, and we hope you like it too! Accomplishments that we're proud of We are very proud of successfully using API's like Cohere and Flask, since this is the first time we have come across these technologies. We also inte"
      }
    ]
  },
  {
    "file_path": "./devposts/stack-overflow-chrome-extension-ghw-launch.html",
    "project_id": "stack-overflow-chrome-extension-ghw-launch",
    "title": "Stack Overflow Chrome Extension (GHW Launch)",
    "tagline": "This project helps you to easily copy stack overflow code",
    "hackathon": "",
    "built_with": [
      "chrome",
      "extension"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration GHW Launch What it does Copy Stack Overflow code How we built it Tutorial, chrome extension Challenges we ran into Changing to the 3rd version of the manifest Accomplishments that we're proud of Learning What we learned How to create an chrome extension What's next for  Stack Overflow Chrome Extension (GHW Launch) Built With chrome extension Try it out GitHub Repo Submitted to Global Hack Week: Season Launch Created by Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python"
      }
    ]
  },
  {
    "file_path": "./devposts/spypooch.html",
    "project_id": "spypooch",
    "title": "SpyPooch",
    "tagline": "Save your maniac pet with SpyPooch",
    "hackathon": "",
    "built_with": [
      "express.js",
      "node.js",
      "react",
      "tailwind",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Undercover Hack Winner Most Creative Use of Twilio Created by Satyam Singh Kartik Patel Nothing muc",
      "Agent:Hacker 2WinnerUndercover HackWinnerMost Creative Use of Twilio",
      "TensorFlow JS, React JS, Node JS, Twilio. Most importantly this was our first ML/AL project. Lot of learnings!!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/274/952/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration I have seen a lot of posts on social media on dogs getting lost since they crossed the gate and ran away and most of the time they get into an accident or gets badly injured by other dogs so we made this in order to prevent it. What it does It keeps track of the gate of the users and lets the users know if they crosses it by sending them a sms and they can even see the video when he leaves the door since with the help of tensorflowjs it only records when the dog/cat are their in the frame How we built it We build the ML model using TensorFlow JS and implemented the notification (message) feature using Twilio. Challenges we ran into Initially, we are finding it hard to implement the idea that we were thinking obviously with the time constraint. It was hard to find videos to test the model and build the connection between the flag generated with activity and the notification feature. Accomplishments that we're proud of As soon as we get started gaining the confidence to improve and finish it all up on time. What we learned TensorFlow JS, React JS, Node JS, Twilio. Most importantly this was our first ML/AL project. Lot of learnings!! What's next for SpyPooch We'll try to add some extra features in the future. Built With express.js node.js react tailwind twilio Try it out GitHub Repo Submitted to Agent:Hacker 2 Winner Undercover Hack Winner Most Creative Use of Twilio Created by Satyam Singh Kartik Patel Nothing much..!"
      }
    ]
  },
  {
    "file_path": "./devposts/starshine.html",
    "project_id": "starshine",
    "title": "StarShine",
    "tagline": "Star shine is a self-care app that has a food recipe page and a rant page, it uses Auth0 to sign in.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "css",
      "github",
      "google-web-speech-api",
      "html",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "thing about a hackathon is the having fun What's next for StarShine finishing the app; connecting t",
      "its not always going to be perfect, the best thing about a hackathon is the having fun"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/841/992/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration more now than ever, we need something to decompress, that's what star shine is for. What it does starshine is a web based app that has a recipes page and a ranting page, it uses auth0 for sign in so you can safely secure all of your work! How we built it a react app with python projects that were to be connected. Challenges we ran into unfortunately, the project wasn't able to connect due to a lack of time and the issues caused by the routing pages. Accomplishments that we're proud of We put so much effort into this project coming alive, we had to change up or idea mid-beginning. we are proud of the effort and positivity each member of the team brought. What we learned its not always going to be perfect, the best thing about a hackathon is the having fun What's next for StarShine finishing the app; connecting the pages and troubleshooting the auth0 page. Built With auth0 css github google-web-speech-api html python react Try it out GitHub Repo Submitted to Pearl Hacks 2022 Created by Erin Ma Jacqueline Mail Monique Reed Yue Yan"
      }
    ]
  },
  {
    "file_path": "./devposts/stack-underflow-np5dm3.html",
    "project_id": "stack-underflow-np5dm3",
    "title": "Underflow",
    "tagline": "Minimize your tech stack's developmental cost",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "cli",
      "fastapi",
      "mysql",
      "nextjs",
      "openai",
      "python",
      "react",
      "shadcn/ui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Defang Created by Maya Parthasarathy Laurence Liang Steven Su David Zhang",
      "PennApps XXVWinnerBest Use of Defang",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/039/080/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Logo 1 2 3 Inspiration Building and maintaining software is complex, time-consuming, and can quickly become expensive, especially as your application scales. Developers, particularly those in startups, often overspend on tools, cloud services, and server infrastructure without realizing it. In fact, nearly 40% of server costs are wasted due to inefficient resource allocation, and servers often remain idle for up to 80% of their runtime. As your traffic and data grow, so do your expenses. Managing these rising costs while ensuring your application's performance is critical—but it's not easy. This is where Underflow comes in. It automates the process of evaluating your tech stack and provides data-driven recommendations for cost-effective services and infrastructure. By analyzing your codebase and optimizing for traffic, Underflow helps you save money while maintaining the same performance and scaling capabilities. What it does Underflow is a command-line tool that helps developers optimize their tech stack by analyzing the codebase and identifying opportunities to reduce costs while maintaining performance. With a single command, developers can input a GitHub repository and the number of monthly active users, and Underflow generates a detailed report comparing the current tech stack with an optimized version. The report highlights potential cost savings, performance improvements, and suggests more efficient external services. The tool also provides a clear breakdown of why certain services were recommended, making it easier for developers to make informed decisions about their infrastructure. How we built it Underflow is a command-line tool designed for optimizing software architecture and minimizing costs based on projected user traffic. It is executed with a single command and two arguments: underflow <github-repository-identifier> <monthly-active-users> Upon execution, Underflow leverages the OpenAI API to analyze the provided codebase, identifying key third-"
      }
    ]
  },
  {
    "file_path": "./devposts/steakai.html",
    "project_id": "steakai",
    "title": "SteakAI",
    "tagline": "Have you ever been to a restaurant and ordered a steak, and it turns out the complete opposite of what you wanted? Well, look no further than SteakAI! Make sure you never have another lousy steak.",
    "hackathon": "",
    "built_with": [
      "css",
      "databases",
      "flask",
      "html",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/304/640/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Gordon Ramsay approved! SteakAI Introducing SteakAI, a web application that uses machine learning to correctly identify the doneness of your steak OUR STORY: Lousy steak is an issue that we have been personally affected by, and we wanted to create a solution that combats the violation of beautiful cuts of beef. Using a cutting-edge machine-learning algorithm to identify the doneness of a steak correctly, we made sure you will never have to endure a garbage steak again. In addition to this, Covid forced many people to stay home and learn how to cook, and our web application helps people cook the restaurant-quality steak of their dreams. AND THAT'S NOT ALL! The future of food service is automation and our application helps to serve the customer a perfect steak every time. FRONT END: SteakAI's front end is coded using HTML, CSS, and Flask Two pages are displayed to users: A home page giving instructions on what the user should do, and the result of the machine learning algorithm. BACK END : A machine learning algorithm is implemented using TensorFlow and Keras to identify the doneness of a steak correctly Make sure the latest versions of the following are installed for your python version: TensorFlow Keras Flask Werkzeug Built With css databases flask html python tensorflow Try it out GitHub Repo Submitted to Hack Western 9 Created by Jackson Lippert Saina Seddighpour"
      }
    ]
  },
  {
    "file_path": "./devposts/spotifyair.html",
    "project_id": "spotifyair",
    "title": "SpotifyAIR",
    "tagline": "Jamming made easier. Control your music with gestures.",
    "hackathon": "",
    "built_with": [
      "mediapipe",
      "spotify",
      "svelte",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of AI Created by Frontend Developer Ayo Fatoye Adam Teo Rita Hernandez Harshitha Marepally",
      "CodeRED: GenesisWinnerBest Use of AI",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/762/737/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Gesture tracking in action Landing page Gesture tracking page Gesture tracking in action Landing page Gesture tracking page Gesture tracking in action 1 2 3 4 Inspiration Eliminate the need to locate and interact with a specific button or screen, especially when a device is out of reach or when you're occupied with other tasks. By minimizing physical interaction with their device, users can maintain better focus on their primary task, whether it's studying, working, or simply enjoying their music without interruptions. What it does Provide more unique and engaging ways to interact with music. A user can log in to their Spotify account and enable gestures to play, pause, skip, and save songs. How we built it We utilized MediaPipe's computer vision model to recognize gestures, the Spotify API to control music, and SvelteKit and TypeScript for the web application. Challenges we ran into We had trouble with the math calculations to optimize the gesture recognition for the model, and had some issues with authorizing into the Spotify API as well. Accomplishments that we're proud of Range of features and gestures that are recognized, from skip forward to add to Liked songs. It truly is a new and unique way to interact with your music. What we learned How to use computer vision models for the first time and integrate them with Spotify API in a web application. This was a huge learning experience for all of us! What's next for SpotifyAIR Train specialized models for improved accuracy and personalized gesture recognition. Built With mediapipe spotify svelte typescript Try it out GitHub Repo Submitted to CodeRED: Genesis Winner Best Use of AI Created by Frontend Developer Ayo Fatoye Adam Teo Rita Hernandez Harshitha Marepally"
      }
    ]
  },
  {
    "file_path": "./devposts/stay-safe-sa230z.html",
    "project_id": "stay-safe-sa230z",
    "title": "Stay Safe",
    "tagline": "An interactive and fun game that spreads awareness about how to stay safe during these times of Covid-19.",
    "hackathon": "",
    "built_with": [
      "aseprite",
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/358/305/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The game window. A person who is not wearing a mask and has washed their hands. A person who is wearing a mask and has washed their hands. A person who is wearing a mask but hasn't washed their hands. A person who hasn't washed their hands and isn't wearing a mask. The game window. A person who is not wearing a mask and has washed their hands. A person who is wearing a mask and has washed their hands. A person who is wearing a mask but hasn't washed their hands. A person who hasn't washed their hands and isn't wearing a mask. The game window. 1 2 3 4 5 6 Inspiration I love to create and play games. My goal was to use my knowledge about python to create a game, to check the player's awareness about Covid-19 and how to prevent it's spread. What it does A group of sprites, which represent people, is displayed on the screen. Each sprite can be in four different states: Prepared, with a mask and washed hands. Relatively unprepared with no mask but washed hands. Relatively unprepared with a mask but no washed hands . Completely unprepared with no mask and no washed hands . The aim of the game is to make each sprite prepared. This can be done by clicking on a sprite and then pressing \"w\" (for washing hands), or \"m\", (for putting a mask on) to change its state. If you click a sprite, you cannot click another one unless you press escape, w or m. How I built it I used Python for this project, specifically by using Pygame. By using Pygame I could create a UI and render sprites. I  created the sprites by myself using Aseprite, a pixel art tool. The project starts by rendering all of the sprites, randomly choosing their states. The project then waits for the player's click input, and the subsequent keyboard input for the letters. Based on these inputs, the project re-renders the board with the updated sprites. Challenges I ran into I am relatively new to Pygame. Rendering the sprites was pretty challenging at first, but after some research (googling) I was able to figure it out."
      }
    ]
  },
  {
    "file_path": "./devposts/sportifai.html",
    "project_id": "sportifai",
    "title": "SportifAI",
    "tagline": "Ever found yourself confused during a sports event or stuck next to someone who won’t stop asking questions? Use SportifAI because everyone deserves a front-row seat to knowledge.",
    "hackathon": "",
    "built_with": [
      "bytetrack",
      "colab",
      "express.js",
      "huggingfacetransformers",
      "ipynb",
      "jupyterhub",
      "next.js",
      "python",
      "pytorch",
      "roboflow",
      "yolov8x"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Multi-Object Tracking: Identifies players, referees, and balls using bounding boxes and trajectories.",
      "bytetrack"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/282/004/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Detecting Field Key Points Screenshot of Sportif-AI Roboflow Player Image Annotation Object Detection Using Bounding Boxes Training Yolo Models Detecting Field Key Points Screenshot of Sportif-AI Roboflow Player Image Annotation Object Detection Using Bounding Boxes Training Yolo Models Detecting Field Key Points 1 2 3 4 5 6 Inspiration Sports unite cultures, but complex and unfamiliar rules can intimidate newcomers. Events like the Super Bowl or Olympics mark a significant cultural moment for bonding and entertainment, especially in the United States. However, many individuals feel left out and burdensome to friends for constantly asking what’s going on in the game. To tackle this issue, Sportif-AI was created to provide Computer Vision and Generative AI-powered sports analysis to educate anyone about the rules of the game. What it does By training object detection models and using feature engineering, Sportif-AI detects gameplay events such as when ball possession shifts (ball passes and steals). This data is then fed into OpenAI's GPT-4o-mini model to generate concise sports explanations that anybody can easily understand. Thus, Sportif-AI can also provide contextualized insights into niche sports such as cricket or curling to help further our goal of transforming passive watching into active learning. Key features: Multi-Object Tracking: Identifies players, referees, and balls using bounding boxes and trajectories. Spatiotemporal Analysis: Normalizes player/ball coordinates relative to field key points (penalty areas, corners). Contextualized LLM Commentary: Uses OpenAI's GPT-4o-mini API to explain events (“Player 10 passed backward to evade defenders – a common strategy to reset attacking momentum”). Tech Stack Dataset Curation: Kaggle, DFL Bundesliga clips (460 videos of 30 seconds) . Computer Vision: YOLOv8x (player/ball detection), Homography (field key points detection), ByteTrack (multi-object tracking), Roboflow (dataset preprocessing). NLP Pipeline: Open"
      }
    ]
  },
  {
    "file_path": "./devposts/stembition-6ocglm.html",
    "project_id": "stembition-6ocglm",
    "title": "Stembition",
    "tagline": "Aimed to educate STEM-subjects fields to underrepresented minorities and genders.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "repl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/835/054/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration STEM as we know it is one of the most unbalanced fields in terms of demographics snd financial backgrounds and prevents underrepresented groups from having the opportunity to truly feel included and requires easier access for underresourced and remote locations to learn about STEM. As it is also a profitable field, acquiring a STEM job can help lift families out of poverty. What it does Our website has an online sign up form for free workshops, links, resources, etc for young students to learn stem. How we built it Using replit as the IDE and html and css as the programming languages. Challenges we ran into Due to some of our members having other commitments, we had to compromise and work faster and harder to meet the deadline. Accomplishments that we're proud of However, we worked as we can within a shorter time limit to finish our resource website. What we learned To communicate and work quickly within time limits. Theme connection We are all high schoolers, and we are using ed tech to promote more diversity and inclusion within stem by promoting free and accessible online resources for students especially from underrepresented and underresourced backgrounds. This connects to the space theme hack specifically because we are teaching space, astronomy, and physics content and providing space-themed webinars such as with NASA to our students. What's next for Stembition To include even more STEM resources for children such as live events and webinars. Built With css3 html5 javascript repl Try it out replit.com stembition.techno-jules.repl.co Submitted to TechTogether Miami Created by I worked on the front end using HTML, CSS, and JavaScript to create a resource website for students. I created a sleek background and UI design for the home page. julia huang hackathon enthusiast and coder Nandana Nambiar Citlally Oliver Alejandra Arias just a girl trying to learn!"
      }
    ]
  },
  {
    "file_path": "./devposts/storystocks.html",
    "project_id": "storystocks",
    "title": "StoryStocks - AWS",
    "tagline": "Navigating the financial world can be complicated for beginners, but it doesn't have to be. Our illustrated storybooks use captivating stories and eye-catching art to demystify complex money topics.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "circle",
      "cohere",
      "javascript",
      "keras",
      "matplotlib",
      "midjourney",
      "nextjs",
      "openai",
      "openaid",
      "python",
      "react",
      "tailwind",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackUTD XWinnerGoldman Sachs",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/651/600/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration At Storystocks, our endeavor to simplify the investment process, we recognized the challenges faced by beginner investors, who often find it perplexing to comprehend the dynamic and intricate nature of the market. With overwhelming data and complex graphs, it's no wonder that 1 in 4 individuals struggle to grasp the intricacies of company information, especially when navigating extensive 10-K PDFs that can stretch over hundreds of pages.  We aim to revolutionize the investment landscape by making the market accessible to everyone through the power of storytelling. By integrating sentiment analysis derived from real-time news headlines, we not only provide a simplified understanding of stock dynamics but also offer insightful predictions of stock sentiment in easily understandable terms. Our platform's intuitive and engaging narratives cater to individuals from diverse backgrounds. What it does Storystocks is a comprehensive web application that simplifies complex company data for investors through intuitive storytelling. It offers a user-friendly interface and chatbot capabilities that swiftly extract insights from intricate 10-K PDFs.  Storystocks facilitates real-time sentiment analysis of news headlines, providing users with concise insights into stock sentiments alongside its core features of simplifying complex data and offering a secure SMS-based crypto exchange. How we built it The enchanting world of Storystocks was conjured into existence by a formidable ensemble of storytellers, data wizards, and tech virtuosos. We harnessed the cutting-edge Stable Diffusion and MidJourney technologies to craft mesmerizing narratives. Our virtual book interface was lovingly sculpted to recreate the authentic joy of flipping through pages. We conjured a custom machine-learning oracle to predict gas fees, and your privacy was our sacred oath. Challenges we ran into Like any epic journey, building Storystocks wasn't without its trials. We navigated the treache"
      }
    ]
  },
  {
    "file_path": "./devposts/stembition.html",
    "project_id": "stembition",
    "title": "Stembition",
    "tagline": "We provide stem resources and online workhops for free for all students, especially from underrepresented and underresourced backgrounds to increase diversity and inclusion in stem.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/835/203/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration STEM as we know it is one of the most unbalanced fields in terms of demographics snd financial backgrounds and prevents underrepresented groups from having the opportunity to truly feel included and requires easier access for underresourced and remote locations to learn about STEM. As it is also a profitable field, acquiring a STEM job can help lift families out of poverty. What it does Our website has an online sign up form for free workshops, links, resources, etc for young students to learn stem. How we built it Using replit as the IDE and html and css as the programming languages. Challenges we ran into We are from the US so our time zones are very different. It is unfortunate that we have less time to submit our project as on Friday we were in school and the majority of the hacking time conflicts with our sleeping schedule. We had to upload a demo video with no sound because everyone in my home is sleeping. Accomplishments that we're proud of However, we worked as we can within a shorter time limit to finish our resource website. What we learned To communicate and work quickly within time limits. Theme connection We are all high schoolers, and we are using ed tech to promote more diversity and inclusion within stem by promoting free and accessible online resources for students especially from underrepresented and underresourced backgrounds. What's next for Stembition To include even more STEM resources for children such as live events and webinars. Built With css3 html5 replit Try it out replit.com stembition.techno-jules.repl.co Submitted to Kurinji Hacks Created by I worked on the front-end using HTML and CSS to design the website. First time utilizing circles and horizontal boxes to provide a pleasing UI design. julia huang hackathon enthusiast and coder Citlally Oliver Alejandra Arias just a girl trying to learn!"
      }
    ]
  },
  {
    "file_path": "./devposts/stickyai.html",
    "project_id": "stickyai",
    "title": "StickyAI",
    "tagline": "taking notes from books, simplified",
    "hackathon": "",
    "built_with": [
      "ai",
      "computer-vision",
      "mediapipe",
      "opencv",
      "pytesseract"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "My first solo hack",
      "First time using OpenCV + Mediapipe (in the same project)"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/993/867/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Selected text Drag to select text Selected text Drag to select text Selected text 1 2 3 Inspiration The reading experience is far superior on a physical book compared to a pdf (also prevents eye strain), but taking notes is often a really tedious process. Say you wanted to write down a quote from a book -- you'd have to put down your book, pull up your computer to type up the quote or alternatively, write it down on paper. Both take time -- making note-taking an inconvenient process, and distracting you from the actual reading experience. Introducing StickyAI, a tool that allows you to capture notes with a simple hand gesture, simplifying your note-taking process. All you need is a book, your hand, and a camera -- you can drag your fingers along the page to select a passage to save. While the program does all the heavylifting, you can continue enjoying your book. What it does Webcam continuously captures the pages from the book Placing your index and middle fingers together, you can drag across the passage you want to save from the book Moving your middle finger away, the camera takes a picture of the current page -> sends it to the backend Shows the selected passage within the green frame Saves the quote (generated from OCR) into a text file How we built it OpenCV detect contours and adds bounding boxes for each word Words are sorted into lines based on their y-position and height, allowing the program to determine where each word is located and its order Using Mediapipe for hand landmarks, the coordinates of the index and middle finger tips are located between these points, the camera recognizes the gestures for starting and finishing the capture Using the distance between these points, the camera recognizes the gestures for starting and finishing the capture Pytesseract takes each of the bounding boxes and turns it from an image into a word, allowing the reader to select a specific passage of the page and save it into a text file (also gives higher accuracy compa"
      }
    ]
  },
  {
    "file_path": "./devposts/steglib.html",
    "project_id": "steglib",
    "title": "Steglib",
    "tagline": "A library for steganography",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "javascript",
      "pil",
      "pytorch",
      "scipy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Education Hack (Delta) Fintectual: Hack the Heat 2022 Winner People's Choice (Most Votes) Created b",
      "Best Education Hack (Delta) Fintectual: Hack the Heat 2022 Winner People's Choice (Most Votes) Crea",
      "Ignition Hacks 2022WinnerBest Education Hack (Delta)",
      "Winner",
      "This is the best hackathon project I've ever seen."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/204/819/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Upload Page Landing page Info Page About page Upload Page Landing page Info Page About page Upload Page 1 2 3 4 5 Inspiration: Steganography is a method for concealing secret data within an ordinary file, such as an image, while avoiding suspicion and detection. Since 440 BC, steganography has been used to hide secret messages in ordinary objects, and have been used by governments, terrorists, and everyone in between. Steganalysis is such a useful but dangerous medium because it is a completely closed system; there is no way of knowing whether a message being sent is malicious or not. In recent decades, terrorist groups such as Al Qaeda have been transferring secret messages under the FBI’s nose without being detected for a long period of time! Our ability to detect steganography is severely underdeveloped, and this is a glaring issue for safety on the internet. Millions of images are passed over the internet, and most of them go completely unregulated and undetected. Thus, we decided to explore and improve current steganalysis technologies, in order to enable authorities and businesses to unveil secret messages ahead of time, to avoid the possibility of causing harm to our safety. We also wanted to educated and promote the importance of steganalysis, in order to promote future research in this subject, and foster internet safety. What it does: Introducing StegLib, a encryption and decryption tool that allows anyone easy access to steganalysis image encryption and decryption. With the click of a button, anyone can check if a pertinent image has a secret message in it or not, and find out ways to detect them. We designed our website to be as simple as possible since we found that the market lacks steganalysis technology, and many don’t even know about the dangers of steganography. Our web application allows one to pass through large amounts of data and detect a secret message hidden well within the image. We want to raise people’s awareness towards steganalysis, and "
      }
    ]
  },
  {
    "file_path": "./devposts/stonks-14y6n3.html",
    "project_id": "stonks-14y6n3",
    "title": "Stonks",
    "tagline": "An investment application aimed at Gen-Z with multiple investment options and beginer friendly overviews. Aimed at young and/or inexperienced investors to help them get started.",
    "hackathon": "",
    "built_with": [
      "proto.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/207/036/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "\"A term to express a financial decision that resulted in financial gain\" Internet culture meme - Stonks, something very familiar for the Generation Z Simple login screen making the app very accessible to everyone Login confirmation screen Main overview screen that looks different for everyone Social tab allowing to connect to more experienced investors or get friends in on the app increasing it's popularity Tracking tab allowing easy overview of all stocks at any point in time and the amount of money that was invested at that time \"A term to express a financial decision that resulted in financial gain\" Internet culture meme - Stonks, something very familiar for the Generation Z Simple login screen making the app very accessible to everyone Login confirmation screen Main overview screen that looks different for everyone Social tab allowing to connect to more experienced investors or get friends in on the app increasing it's popularity Tracking tab allowing easy overview of all stocks at any point in time and the amount of money that was invested at that time \"A term to express a financial decision that resulted in financial gain\" 1 2 3 4 5 6 7 8 Stonks - https://imgur.com/odwiJbp Inspiration Recently, just a few months ago, I have gotten into stock trading and cryptocurrencies, the most common form of investment for younger folks. Looking for information about how investing works and how to do it correctly I ran into a ton of either complicated videos or literature, explaining every little detail (definitely not something made for begginers). After a while I finally stumbled upon Crypto.com, a cryptocurrency trading application that fascinated me with its simplicity. This investment assistant is definitely inspired by that app and as a beginner GenZ investor, I can assure you from experience, that an application like this does have a charm of its own. What it does It keeps track of how all of my investment areas are doing and tries to compile that data into a nice ov"
      }
    ]
  },
  {
    "file_path": "./devposts/stocktweet.html",
    "project_id": "stocktweet",
    "title": "StockTweet",
    "tagline": "Impact of tweets on companies' stock prices",
    "hackathon": "",
    "built_with": [
      "flask",
      "gensim",
      "google-cloud",
      "gpt-2",
      "matplotlib",
      "mongodb",
      "python",
      "snscrape",
      "spacy",
      "tensorflow",
      "transformers",
      "velobywix",
      "wordcloud",
      "yfinance"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/380/045/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Tweet and word cloud output Home page Preselected companies Tweet and word cloud output Home page Preselected companies Tweet and word cloud output 1 2 3 4 Inspiration Twitter tweets, without a doubt, have significant effects on the stock price of a company. The best example is Elon Musk's tweets and their wild effects on Tesla's stock price. Even more recently, the introduction of the paid verified blue tick by Twitter led to people posting tweets impersonating private companies, which in most cases led to plummets in stock prices. Considering all of this, we were interested in doing something that addressed this issue, and thus, StockTweet was born! What it does StockTweet allows users to analyze the tweets of any publicly traded company to determine keyword trends that emerge in ones that lead to a stock price uplift and ones that lead to a decrease. Users can also input a sample tweet before posting it to the world to check if it may have some potentially undesirable effect on a company's stock price and visualize the output in a beautiful word cloud. As expected, the target audience for this program would be business owners, whose company is publicly traded, or even the PR team at a large company. How we built it A project of this size, unsurprisingly, has a complex implementation. The front-end is built entirely using Velo by Wix. It serves as the face of the project and allows the user to interact with the software, such as submitting inputs like the company name, Twitter handle, and sample tweet. It is served by a Flask server, a lightweight python backend framework hosted on Google Cloud, where the heavy lifting takes place, and all other resources and endpoints of our application meet. MongoDB is used to store the tweets of the six most common companies, namely Google, Meta, Microsoft, Tesla, Amazon, and Netflix. This facilitates faster performance for what we hypothesize to be popular queries by users. If the user-entered company is not among these, the s"
      }
    ]
  },
  {
    "file_path": "./devposts/stressball-site.html",
    "project_id": "stressball-site",
    "title": "stressball.site",
    "tagline": "Find your calm with our interactive stress relief experience",
    "hackathon": "",
    "built_with": [
      "bolt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/585/122/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration What it does How we built it Challenges we ran into .bolt-badge-bottom-right {\n  position: fixed;\n  bottom: 16px;\n  right: 16px;\n  width: 80px;\n  height: 80px;\n  z-index: 50;\n  transition: transform 0.2s ease-in-out;\n} .bolt-badge-bottom-right:hover {\n  transform: scale(1.1);\n} Accomplishments that we're proud of What we learned What's next for stressball.site Built With bolt Try it out youtu.be Submitted to World’s Largest Hackathon presented by Bolt Created by Yosun Chang EPIC HACKATHON JUNKIE (XR AI 3D Hacker-Entrepreneur)"
      }
    ]
  },
  {
    "file_path": "./devposts/step-by-step-w6bmod.html",
    "project_id": "step-by-step-w6bmod",
    "title": "Step by Step",
    "tagline": "Promoting physical fitness through social gamification.",
    "hackathon": "",
    "built_with": [
      "android",
      "android-studio",
      "dart",
      "firebase",
      "flutter",
      "ios",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Health and Wellness Hack Created by I developed the front-end of Step by Step",
      "Best Health and Wellness Hack Created by I developed the front-end of Step by Step",
      "Citrus Hack 2021: Create Your ZenWinnerBest Health and Wellness Hack",
      "Winner",
      "I did the back-end of Step by Step. I also helped two new members on their first hackathon."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/481/291/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Technology has clearly made a profound impact on our society through the news, social platforms, and high-speed communications. Our group's inspiration for this project came from our own experience of seeing how big of an influence tech and social media could be on the well-being of people today, especially those who do not frequently get the opportunity to converse with people in person. However, there has always seemed to be a lack of technological influence in the realms of activity/athleticism, another vital aspect of everyone's wellness. Because of this, our group created Step by Step , a mobile app that specifically targets this issue by providing a social platform where friendly competitive exercise is encouraged. What it does Step by Step closes the divide between social media and exercise by creating a platform that provides a motivating experience to stay in shape. Basically, after the user creates their customizable account and enters benchmark data, they will be derived a rank and will have the opportunity to compete against others to improve it through tournaments. A tournament is a 24-hour window where the user gets the opportunity to improve their rank.  The user gets put into a group of 50 similarly ranked people, and those who achieve the highest scores will win. Video submissions through the app are required in order to ensure the validity of the results. Winning a tournament improves the user's rank, which can be viewed along with all other users' on the global leaderboard page. Here they can track their and their friends' ranks while comparing them to the best of the world. Here's the kicker: the user can compare their rank with others on the global leaderboard page. This way they can track their and their friends' ranks while comparing them to the best in the world. This provides the crucial incentivization of participating in Step by Step , being able to see yourself improve, and maybe even do a little bit of showing off. How we bui"
      }
    ]
  },
  {
    "file_path": "./devposts/stress-free-r23suo.html",
    "project_id": "stress-free-r23suo",
    "title": "Stress-Free",
    "tagline": "every day brings a choice: to practice stress or to practice peace",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/009/658/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "end of page initial page to welcome you solution to simple and difficult problems articles related to it and popular tags trendy tags on website popular tags and some recipes end of page initial page to welcome you solution to simple and difficult problems articles related to it and popular tags trendy tags on website popular tags and some recipes end of page 1 2 3 4 5 6 7 💡 Inspiration\nPeople work a lot and Face Stress this site will help you find real solutions to your real problems ⚙ What it does\nit provides you with every knowledge you need about stress and helps you finds solutions to it 🔧 How we built it\nBy using HTML, CSS and java script 💪 Challenges we ran into\nAs a new comer and a student in high school lack of experience was the major challenge I faced 📌 Accomplishments that we're proud of\nI got better at javascript 📚 What we learned\nmany new things about coding and environment ⏭ What's next for Stress-Freee\nexpanding it knowledge and making it more ease to use and provide more important knowledge to real life problems Built With\ncss3\ngithub\nhtml5\njavascript\nTry it out\n GitHub Repo Built With css github html javascript Created by Gourav Sharma I like to code"
      }
    ]
  },
  {
    "file_path": "./devposts/stellar-ktiy3h.html",
    "project_id": "stellar-ktiy3h",
    "title": "StellAR",
    "tagline": "Investors need an unfair advantage to seize top opportunities. Our AR platform saves clients time by enabling them to engage with financial data in real time, optimizing control like never before.",
    "hackathon": "",
    "built_with": [
      "api",
      "lens-studio",
      "openai",
      "spectacles"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/128/436/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Inspiration 🌎✨ Wealth is growing, and so is the demand for clarity in financial decisions. With over 60% of clients wanting better insights, StellAR bridges the gap with AR, transforming how investors and advisors explore financial plans together in real-time. What it does 🎯📈 StellAR brings financial data to life through AR, letting clients interact with their portfolios, visualize “what-if” scenarios, and make decisions in an immersive 3D space. Advisors can provide personalized insights, creating a deeper, more intuitive understanding of financial goals. Challenges we faced 🧩 Translating complex financial data into 3D models required innovative thinking on data accuracy, user experience, and AR functionality. Proud accomplishments 🏆 We’re proud to offer a tool that not only visualizes data but also strengthens client-advisor relationships with real-time, interactive experiences. What we learned 📖 StellAR taught us the importance of collaboration and effective communication in finance and tech. AR has incredible potential to make complex concepts accessible and engaging. What’s next for StellAR 🚀 We plan to add predictive analytics and AI-driven insights, making StellAR the go-to platform for immersive, data-driven financial planning. Built With api lens-studio openai spectacles Submitted to Immerse the Bay 2024 Created by Rian Corcino i code stuff for fun Leia Anapaula I am a CS student @ UC Berkeley, very passionate about AI, VR, and science fiction! Sahil Dhakla Construction tech-integration consulting"
      }
    ]
  },
  {
    "file_path": "./devposts/stock-predictor-rw7mpg.html",
    "project_id": "stock-predictor-rw7mpg",
    "title": "Stock Predictor",
    "tagline": "Stock Predictor helps the user maximize their return value by predicting future stock prices using machine learning",
    "hackathon": "",
    "built_with": [
      "datetime",
      "matplotlib",
      "numpy",
      "pandas",
      "python",
      "quandl",
      "sklearn",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/752/006/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Graph of predicted stock growth GUI Graph of predicted stock growth GUI Graph of predicted stock growth 1 2 Inspiration A friend of ours (Kritagya) invested his tuition money into stock using RobinHood. He ended up losing over two hundred dollars over the course of two months. As a result his mom grounded him for thanksgiving break :/ We made Stock Predictor to help the Kritagyas of the world make more informed investment choices with their money. What it does Stock Predictor helps the user increase their return on investment by giving accurate future stock predictions. How we built it We used a series of modules to build the program. The stock data used for machine learning training is obtained from the quandl database. We used sklearn to train the machine to predict future prices. Challenges we ran into Some of the websites were closed so we could not scrape web data from them. Accomplishments that we're proud of We were able to get the program to predict stock prices in the future.\nThe user only needs to enter the name of the company instead of looking up the ticker symbol and inputting that. What we learned We learned how to utilize different python modules that were new to us and to keep trying new solutions if some don't work. What's next for Stock Predictor Using a better algorithm, more aesthetic interface Built With datetime matplotlib numpy pandas python quandl sklearn tkinter Submitted to TAMUhack 2019 Created by Yile (Allen) Chen Aryan Shetty Joshua Ku"
      }
    ]
  },
  {
    "file_path": "./devposts/storymation-yvef2p.html",
    "project_id": "storymation-yvef2p",
    "title": "StoryMation",
    "tagline": "Story to Animation in seconds!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "dall-e",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Cohere Created by I worked on creating the extensive pipeline for all the APIs, enginee",
      "Hack the North 2023WinnerBest Use of Cohere",
      "Story to Animation in seconds!",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/592/407/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired to create such a project since we are all big fans of 2D content, yet have no way of actually animating 2D movies. Hence, the idea for StoryMation was born! What it does Given a text prompt, our platform converts it into a fully-featured 2D animation, complete with music, lots of action, and amazing-looking sprites! And the best part? This isn't achieved by calling some image generation API to generate a video for our movie; instead, we call on such APIs to create lots of 2D sprites per scene, and then leverage the power of LLMs (CoHere) to move those sprites around in a fluid and dynamic matter! How we built it On the frontend we used React and Tailwind, whereas on the backend we used Node JS and Express. However, for the actual movie generation, we used a massive, complex pipeline of AI-APIs. We first use Cohere to split the provided story plot into a set of scenes. We then use another Cohere API call to generate a list of characters, and a lot of their attributes, such as their type, description (for image gen), and most importantly, Actions. Each \"Action\" consists of a transformation (translation/rotation) in some way, and by interpolating between different \"Actions\" for each character, we can integrate them seamlessly into a 2D animation. This framework for moving, rotating and scaling ALL sprites using LLMs like Cohere is what makes this project truly stand out. Had we used an Image Generation API like SDXL to simply generate a set of frames for our \"video\", we would have ended up with a janky stop-motion video. However, we used Cohere in a creative way, to decide where and when each character should move, scale, rotate, etc. thus ending up with a very smooth and human-like final 2D animation. Challenges we ran into Since our project is very heavily reliant on BETA parts of Cohere for many parts of its pipeline, getting Cohere to fit everything into the strict JSON prompts we had provided, despite the fine-tuning, was often quite d"
      }
    ]
  },
  {
    "file_path": "./devposts/stu-net-just-take-it-easy.html",
    "project_id": "stu-net-just-take-it-easy",
    "title": "Stu-Net - Just take it easy",
    "tagline": "Are you struggling to find the best teammate for your university projects? Do you want to study more efficiently? To be more connected with your classmates?StuNet with its amazing AI is here for you",
    "hackathon": "",
    "built_with": [
      "auth0",
      "axum",
      "domain.com",
      "github",
      "gpt",
      "javascript",
      "json",
      "jwt",
      "mongodb",
      "openai",
      "python",
      "rust",
      "sveltekit",
      "tokio",
      "typescript",
      "websockets",
      "yake"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Use of Auth0 Created by alesordo Sordo Miika Tuominen Alex Amat JuliaAlos Alos",
      "HackUPC 2023Winner[MLH] Best Use of Auth0",
      "We had a first touch of the cool features provided by AI technologies;",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/478/474/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The IThinkUPC challenge and its possible outcomes attracted us and we decided to tackle it. \nSince we've all been freshmen, we know how frustrating and difficult it is to form project groups that fit with our skills and the project requirements.\nWe also had the desire to let the students connect and collaborate proficiently during their university years, and also to feel less alone even if far from home. What it does The main functions of the app are: Collaborative tool to share class notes. It's based on open-source AI models to analyze how good they sound and their accuracy compared to teacher's materials; Smart tool to form groups for university assignments; A messaging system to keep the group members connected. How we built it We started by designing the skeleton of the front-end in sveltkit, to get an idea of what to work on. Then, after the ideas started spreading, we moved on with developing the back-end functionalities using Python, Rust and JavaScript. All throughout the back-end development, we tested the features, firstly with some mock data, then with real data from the populated MongoDB database. Challenges we ran into Struggled with managing the authentication web tokens; Multiple obstacles were encountered during the design of the algorithms to process the data; Getting the Vueling bananas 🍌 . Accomplishments that we're proud of We're very proud to say that the demo app is ready to deploy and the basic functionalities are (almost) all operative!\nAlso, we managed to overcome all the difficulties we met. What we learned We refreshed our knowledge of MongoDB after a long time; We learned more about backend frameworks; We had a first touch of the cool features provided by AI technologies; The importance of good sleep when working hard. What's next for Stu-Net - Just take it easy We think that this idea could be developed further to get an improvement on the AI models used and find a sub-optimal group formation algorithm. Also, we could implem"
      }
    ]
  },
  {
    "file_path": "./devposts/strangers-with-us.html",
    "project_id": "strangers-with-us",
    "title": "Strangers Within Us",
    "tagline": "A ride through an unknown neighborhood reveals our misconceptions of those around us.",
    "hackathon": "",
    "built_with": [
      "photoshop",
      "ricoh",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/000/546/703/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration To explore the misconceptions we may have about unknown places and people. What it does Build empathy through a 360 video experience How I built it We used the Ricoh Theta V to film  and final cut to edit. Challenges I ran into Framing the story into the correct perspective without falling into stereotypes.  Quickly planning out and filming in locations unknown to any of the devs.  Engaging locals to participate in our video experience. Accomplishments that I'm proud of Being able to include a community in this case which was the Boys and Girls Club of Boston.  We were able to connect and have a great time with a large range of demographics and the process itself become collaborative and inclusive. What I learned Not to judge a book by its cover.  Technology has a way to connect us and immerse us into situations we would normally want to avoid due to our misunderstandings of communities we don't have regular contact with. What's next for Strangers With Us Explore more interactive manners to further explore this seem and create greater empathy and understanding.  We want to create a better sense of community. Built With photoshop ricoh unity Try it out GitHub Repo Submitted to Reality Virtually Hackathon 2017 Created by Contributed with my experience with 360 video on setting up the shots and with equipment.   Troubleshooting technical difficulties as well. Fabian Patino I worked as a VR Director of Photography www.haideralee.com Haider Ali I worked on the script and as a creative producer Ezequiellenard Musharaf Hemalt"
      }
    ]
  },
  {
    "file_path": "./devposts/strikout-spam.html",
    "project_id": "strikout-spam",
    "title": "Strikeout Spam",
    "tagline": "Use this program to help strikeout spam in your inbox. In addition, this program will also help you flag important events and any deals or coupons.",
    "hackathon": "",
    "built_with": [
      "c",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Because we are all first-time TamuHack attendees with a limited amount of coding knowledge, we decided to put our skills to the test. We agreed that making an email filter using python would be the best challenge for all of us What it does This program scans unread emails in a persons inbox for keywords about meetings, coupons, and popular spam keywords. This program will then flag the email for the user. Every 12 hours, the program will send you an email of a summary of all of the emails it flagged, and the reason it flagged the email. How we built it We used python scripts to do most of the process. We first used a python script to get emails from the email addresses' IMAP server. We then use an algorithm made in python to scan the email for keywords about meetings, spam, and coupons. If the email passes the threshold for a coupon, spam, meeting, or many of them, it will use a python script to flag that specific email. This process will run every hour. After 12 hours has passed, then it use a python script to send an email listing all of the emails it flagged, as well as the the the information on why the email was flagged. With more time, we would have finalized the HTML website to automatically run the program when a user enters their information into the website. Challenges we ran into One of the many challenges we ran into was the issue of us knowing very little. For this project, we learned how to use HTML and JavaScript to make a website. Another subject we had to learn about was about IMAP and SMTP servers. Overall, we faced many problems, but managed to come out with a final product Accomplishments that we're proud of Because we are all new programmers, the main thing we are proud of is that we were able to come out with a final product. Although it is not the most technical project, we are proud of our work What we learned We learned many skills such as HTML, JavaScript, as well as python scripting. We also learned how to work together as a te"
      }
    ]
  },
  {
    "file_path": "./devposts/stronggibberish.html",
    "project_id": "stronggibberish",
    "title": "StrongGibberish",
    "tagline": "A simple yet effective password generator that generates a 8 character strong password",
    "hackathon": "",
    "built_with": [
      "array",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/341/248/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "working and output Inspiration What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for StrongGibberish Built With array python Try it out GitHub Repo GitHub Repo Submitted to Global Hack Week: Beginners Week Day 3 Created by Sri Harshitha Anantatmula Learn ."
      }
    ]
  },
  {
    "file_path": "./devposts/street-savvy-rb2n9y.html",
    "project_id": "street-savvy-rb2n9y",
    "title": "Street Savvy",
    "tagline": "Not sure where to go on your next outing? \nSpending too much money when going out?\nWe got you covered!",
    "hackathon": "",
    "built_with": [
      "co:here",
      "css",
      "figma",
      "firebase",
      "flask",
      "html5",
      "javascript",
      "json",
      "python",
      "react",
      "requests",
      "restful"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/353/554/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "decision page preference page decision page preference page decision page 1 2 Inspiration As avid enjoyers of travellers, we often find it hard to find things to do, while staying within a budget. Just this winter, one of our group members went on vacation and went wildly over budget without realizing it. He often had trouble finding things to do every day and places to eat. So we built an app that shows the different user restaurants and things to do that fall under a certain price category. What it does We built a Web app that uses an algorithm to present different restaurants or things to do to the user. the user can then choose to save the information or pass on it. Depending on the user's choices our recommendation engine will adapt to better adapt to the user's preferences. The user can then access their saved lists as they are logged in through google authentication. How we built it Our website is hosted on Firebase, using FireStore as the database to store all the restaurants, things to do, and user data. To access our data we created a flask restful API that we can call using requests to perform queries, add data, and delete data from FireStore. Our FrontEnd was built using the react framework to create a dynamic web app for an elevated user experience. Challenges we ran into 2 challenges we ran into were figuring out how to deploy our REST API and converting our Figma designs to code. For the REST API we didn't have time to figure out how to use Azure or AWS as our hands were full with learning how to use Firebase. So we chose to resolve this by just hosting the REST API on our local computer. Our Figma Design Code came out to be impossible to work with and so we used it as a proof of concept and a learning opportunity for the future, but ultimately had to remake the web app. Accomplishments that we're proud of We learned how to implement a Database for data persistence. Gone are the days of saving data in CSV files. We also learned how to use Firebase whi"
      }
    ]
  },
  {
    "file_path": "./devposts/studify-com-3gn6v4.html",
    "project_id": "studify-com-3gn6v4",
    "title": "studify.com",
    "tagline": "A study website to help reduce burnout and ease stress for students.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "repl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "It was my first time working with these programming languages"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Inspiration for our project came from helping students avoid unnecessary stress during their study or homework time, especially due to the fact that working from home from months can take a mental toll on many of them. What it does Our website provides a daily schedule, priority list, timer and survey for studying in order to check for improvements. How I built it We used repl.it, javascript, css, and html Challenges I ran into It was my first time working with these programming languages Accomplishments that I'm proud of We were ultimately able to produce a working website! What I learned I learned a lot about these languages that I never really worked with before. What's next for studify.com With more improvements and additions, we can provide another space for students to manage their work and tasks easily. Built With css html javascript repl Try it out wizardly-northcutt-abf48b.netlify.app Submitted to Hack the North 2020++ Created by I worked on the timer and survey modules, and recorded the demo. It was challenging but interesting. Iman Umair-Qaiser UWaterloo CE '26 I created drafts for our logo and helped finalise the finished website logo. Nazifa Islam Hanatk Kidwai Meghna Goli"
      }
    ]
  },
  {
    "file_path": "./devposts/stock-stalker-4jrosz.html",
    "project_id": "stock-stalker-4jrosz",
    "title": "Stock Stalker",
    "tagline": "Changing the way that investors evaluate stocks, and invest.",
    "hackathon": "",
    "built_with": [
      "esg",
      "figma",
      "framer",
      "javascript",
      "react",
      "routerdom",
      "tailwind",
      "tradingviewidget",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH: Best Domain Name from Domain",
      "Hack the 6ix 2022WinnerMLH: Best Domain Name from Domain.com",
      "🌐 Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/195/157/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "ESG Home Page Search Page Apple Search Tesla ESG Home Page Search Page Apple Search Tesla ESG 1 2 3 4 5 6 7 🌍 Background Unlike the traditional profit-orientated approach in financial investing, responsible investing is a relatively new concept that expressly recognizes the importance of environmental, social, and governance aspects to the investor and the long-term health and stability of the market (Cambridge Institute for Sustainability Leadership, 2021). However, currently, ESG does not have a standardized evaluation system that allows investors to quickly determine the potential of the financial products. ❣️ Inspiration More recently, some have claimed that ESG standards, in addition to their social value, might protect investors from the crises that arise when businesses that operate in a hazardous or immoral manner are finally held responsible for their effects. Examples include the 2010 Gulf of Mexico oil disaster by BP and the billion-dollar emissions scandal at Volkswagen, which both had a negative impact on the stock values of their respective corporations. (Investopedia, 2022). Therefore, the demand of creating an easy-to-use ESG evolution tool for everybody is essential to address the stigma that investing, saving, and budgeting are only for privileged populations. ⚙️ Solution Inspired by the current uncertainty about ESG evaluation methods, our team proposed and implemented an online ESG evaluation platform with our recently developed algorithms called Stock Stalker that allow investors to search, manage, and see the overall ESG performance of the selected stocks associated with a built-in recommendation system. To See. To Learn. To Apply. To Earn. To Contribute. Stock Stalker redefines what it means to earn profits while ensuring the investment is making positive impacts on the environment, society, and governance. Using React, REST API, and our developed algorithms, Stock Stalker offers investors both access to real-time financial data including the "
      }
    ]
  },
  {
    "file_path": "./devposts/studious-v62gmn.html",
    "project_id": "studious-v62gmn",
    "title": "Studious",
    "tagline": "Studious is a revolutionary take on the classic calendar we all know and love, which is guaranteed to optimize success. Kitted with numerous user friendly features which none of our competitors offer!",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "Hack to SchoolWinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/209/474/datas/medium.",
    "description": [
      {
        "heading": "Description",
        "content": "Studious Logo Add Event Prompt Calendar Interface Studious Logo Add Event Prompt Calendar Interface Studious Logo 1 2 3 4 Inspiration For us working on Studious, grade 12 is just around the corner. That means that we need to really put our heads down and work to achieve top marks. But this can be difficult given the numerous task given over then course of a short period and the distractions that are present in our every day lives. This lead us to create Studious, a tool which aids in organization and time management. What it does Studious looks like a regular calendar at first glance, but the hidden gem lies within the features we have implemented. The first thing you'll notice is that you can add events to different dates so that you can keep track of what different tasks or events you have planned. The calendar also displays the current date as to limit confusion. There is a heat map where darker days are more packed and lighter days are not so the user can see what days have more events compared to others. How we built it The entire website and its functions were made using HTML, CSS, and JavaScript. The frame for everything was made using HTML and the styling and artistic aspect was created using CSS. All the features were made using JavaScript which was incorporated to the HTML code. Challenges we ran into Figuring out how to make the heat map was quite difficult in the sense that it was difficult to get what wanted to in our idea onto our paper. In addition to that, adding multiple events to one date seemed intuitive, but proved to be more complicated that we expected due to the code we sourced not easily shifting to this style. Accomplishments that we're proud of Creating the framework for the calendar seemed like a daunting task at first glance but to our pleasant surprise, we ever able to source the correct code that we needed which supplied us with the general functions that we needed to make this project come together. This project was a lot of trail and "
      }
    ]
  },
  {
    "file_path": "./devposts/studyai-ru8lf4.html",
    "project_id": "studyai-ru8lf4",
    "title": "STUDYAI",
    "tagline": "Systematic Teaching Using Dynamic Yielding and Autonomous Intelligence (StudyAI) is an advanced, voice-activated study assistant designed to aid students in learning and comprehending various subjects",
    "hackathon": "",
    "built_with": [
      "openai",
      "python",
      "reflex.dev",
      "together.ai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/646/557/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "S.T.U.D.Y.A.I *S*ystematic *T*eaching *U*sing *D*ynamic *Y*ielding and *A*utonomous *I*ntelligence Overview StudyAI is a groundbreaking, voice-activated study assistant engineered to redefine the self-study experience. Utilizing cutting-edge machine learning, voice recognition, and natural language understanding technologies, this platform offers an array of features designed to facilitate efficient and effective study sessions. Inspiration In an era flooded with information, the conventional methods of self-study are fraught with challenges like information overload, disorganized note management, and a lack of personalized learning experiences. Study AI tackles these issues head-on, offering a revolutionary approach to academic learning and comprehension. Goals Our mission is to revolutionize self-study by providing an intelligent, voice-activated assistant that delivers a seamless and intuitive user experience. Study AI aims to become the go-to platform for students, offering features like text and video summarization, explanatory image generation, educational video recommendations, and personalized note management. Built With Frontend : Reflex.dev with custom React components as plugins Backend : FastAPI (via Reflex.dev) Voice Recognition and Text-to-Speech : 11Labs, Whisper Autonomous Agents : OpenAI function calling agents Text Summarization : Using mistralai/Mistral-7B-Instruct-v0.1 from TogetherAI Image Generation : Using stabilityai/stable-diffusion-2-1 from TogetherAI Challenges Implementing real-time voice recognition and natural language understanding with minimal latency (less than 5 seconds response time) Ensuring seamless integration of multiple technologies, including machine learning models and external APIs. Achieving scalability while maintaining high performance and reliability. Ensuring data privacy and security. Accomplishments Successfully developed a voice-activated command parsing module. Implemented autonomous decision-making capabilities us"
      }
    ]
  },
  {
    "file_path": "./devposts/superagent.html",
    "project_id": "superagent",
    "title": "SuperAgent",
    "tagline": "We then looked at the rule set and discussed whether it should be like a generation or something like Stockfish.  Something like Stockfish would be better after I went to the game and came back.",
    "hackathon": "",
    "built_with": [
      "numpy",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Getting Started The rulesets were discussed, and I can type them out for you. Well, no, this is just a place where we can throw everything. It's actually so cool. She's surprisingly accurate. We then looked at the rule set and discussed whether it should be like a generation or something like Stockfish. Yes, we concluded that something like Stockfish would be better after I went to the game and came back. Minmax, minmax, minmax. Yeah, we pretty much talked about minmaxing the entire time. After that, I looked it up on ChatGPT, and ChatGPT said that training a model wouldn't be as good as just using a regular chess engine like Stockfish. Then, we set up a running game and randomly paired players to set up our testing environment. Coming Up with Basic Rewards Rewards 3 in a Row + INF If 2 pieces are ever touching + 1 Punish Losing -INF Version 1 We set up a basic model. We got a simple model going, and all it did was have a minimax function for the placement stage of the game. The minimax function would recursively go through the game. We had the evaluate function that saw if two pieces were next to each other, and it would give a positive reward if that was the case. This model had 213 Wins / 86 Losses / 1 Tie. Version 2 Version 2 implemented the other half of the algorithm. The first version only handled the placement phase of the game, but after all the pieces were placed, a new set of rules was needed for the next phase, where you pick up pieces and move them somewhere else. Version 2 had that functionality and was slightly better than Version 1, but now it's up to par with what the game should be. It had 214 Wins / 86 Losses / 0 Ties. Rewards 3 in a Row + INF If 2 pieces are ever touching + 3 Place in the center + 0.5 Breaking up Enemy Pieces + (FREE) Avoid more than 4 in a 3x3 grid (don't want too many neighbors) + 0.1 WIN CONDITION: No DOT space of any kind! Punish Losing -INF If you had 2 pieces touching and made them not touch anymore -0.3 Edges -0.3 Corners "
      }
    ]
  },
  {
    "file_path": "./devposts/studybot-bh3o71.html",
    "project_id": "studybot-bh3o71",
    "title": "StudyBud",
    "tagline": "A Discord bot that manages assignments and reminders",
    "hackathon": "",
    "built_with": [
      "discord",
      "domain.com",
      "firebase",
      "firestore",
      "google-cloud",
      "google-cloud-vision",
      "node.js",
      "typescript",
      "unity",
      "velo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Google Cloud Created by Ayush Garg Satyam Singh Kevin Zhang I am a sophomore studying C",
      "Hack to SchoolWinnerBest Use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/209/175/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Technical Mockup Technical Mockup Technical Mockup 1 2 💡 Inspiration💡 A lot of people (especially hackathon hackers) love using Discord. As long-time hackers, our team has used Discord for a long-time that it’s become second nature to on it almost constantly for communication and receiving news. However, Discord can distract us from doing school work. We wanted to mitigate this by reversing the effect; if Discord could help us as an educational tool, we get to use our loved app more productively. Discord was an easy place to keep all our stuff in one place\n-We wanted to inspire video gamers using our BETA unity application ⚙️ What it does ⚙️ We created a Discord bot. Users start from a website where they can download the Discord bot into their own server or their own Direct Message. Let’s say a student has an assignment. They can upload these assignments to Discord by simply taking a picture and uploading it to the bot! Our bot then uses Optical Character Recognition (OCR) to scan and identify the text in the assignment and instantly translates it into an easy-to-read, Discord-friendly embedded text. This can be helpful for users to see their assignments in a quick, digitized manner. Furthermore, for example, in the case of asking for a review on an assignment, a user can upload their document; reviewers can also view the text for these documents without having to tediously read through the document as an image or having to use a platform other than Discord. This is also useful for taking photos of notes, which are then digitized in Discord. Users can then easily share any of these notes with friends on Discord on the same server or other servers. Users can ask for reminders for certain tasks after a certain time, which the bot will remind you in your Discord Direct Messages (DMs) so that you can see it while staying on Discord.\n-We were wondering how to make our Discord bot more appealing and to stretch beyond the educational purpose of Discord. We then decided tha"
      }
    ]
  },
  {
    "file_path": "./devposts/sunrush.html",
    "project_id": "sunrush",
    "title": "SunRush",
    "tagline": "SunRush equips parents with an alternative to commercialized learning centers by furthering their child’s education while playing an AR mobile adventure game to combat summer learning loss!",
    "hackathon": "",
    "built_with": [
      "a-frame",
      "amazon-web-services",
      "ar.js",
      "auth0",
      "css3",
      "github",
      "github-jobs",
      "godaddy",
      "google-places",
      "html5",
      "javascript",
      "mongodb",
      "next.js",
      "react",
      "s3",
      "tailwind-css",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ElleHacks 2024Winner1st Place Team",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/771/254/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "SunRush App Design SunRush Logo SunRush App Design SunRush App Design SunRush Logo SunRush App Design SunRush App Design 1 2 3 4 💡 Inspiration We at Leche Flan Studios saw a growing need for accessible tools to combat summer learning loss aimed towards families that seek access to affordable summer learning programs for their children aged 7-10. Due to the COVID-19 pandemic, the shift to remote learning heightened academic challenges as students transitioned back to in-person settings. These challenges are heightened when considering summer learning loss. Students may lose up to 2.5 months of computational maths skills, and 2 months of reading, and by the time they’re in 6th grade can lose 18 months of learning. We found socioeconomic standing can affect which children are most likely to experience summer student loss. Quality education is something all children should have a chance at obtaining no matter their standing. 51% of families not participating in a summer program say they would if one was available to them. Therefore, we wish to bring forward an at-home, accessible, and affordable solution for students who experience a lack of resources and help break through those barriers. ⭐ What it does By harnessing children's commonly shared enthusiasm for gaming, we developed SunRush , an immersive game designed to inspire youth to embark on an exciting journey through both augmented reality and the great outdoors, all while absorbing essential educational topics. Users can explore the areas where they live or visit such as local parks, libraries, and gardens to look at the special items locationally and randomly generated around. They can tap to catch these items, and once caught the user will obtain a new item card. Item cards prompt the user to read a few sentences, strengthening their reading, critical thinking, and problem-solving skills. However, before they collect the card, the user must show that they’ve digested the new findings from the item as they are f"
      }
    ]
  },
  {
    "file_path": "./devposts/subzcat.html",
    "project_id": "subzcat",
    "title": "SubzCat",
    "tagline": "Tired of scrolling through hundreds of YouTube subscriptions to find what you are looking for? Streamline your YouTube subscriptions with our NLP-based clustering solution.",
    "hackathon": "",
    "built_with": [
      "bert",
      "flask",
      "html",
      "huggingface",
      "javascript",
      "numpy",
      "pandas",
      "python",
      "scipy",
      "sklearn",
      "transformers"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/372/939/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "one of the clusters- Workout, Health one of the clusters- Education window-1 clusters from my youtube subscriptions one of the clusters- Workout, Health one of the clusters- Education window-1 clusters from my youtube subscriptions one of the clusters- Workout, Health 1 2 3 Inspiration YouTube has a design flaw in the organization of subscriptions, making it difficult for users to navigate through their 100s or 1000s of channel subscriptions to find a particular channel. What it does SubzCat aims to solve this problem by using machine learning to cluster the user's subscribed YouTube channels into categories, making it easier to find a particular channel. \nThe steps involved are: Collection of the user's subscribed YouTube channels and their metadata along with the keywords used in their latest 50 videos. Data cleaning of the collected information. Clustering of the cleaned data using a pre-trained SentenceTransformer (\"all-mpnet-base-v2\") to embed the documents into a continuous vector space, and normalizing the embeddings to perform Agglomerative Clustering on the embeddings using Euclidean distance and Ward linkage to form clusters. Associating each cluster with a cluster label by computing the top 5 keywords for each cluster using TfidfVectorizer. Presentation of the clusters along with their cluster labels and page navigation to a new page to display the channels in the cluster. How we built it The project was built using Python for data collection, data cleaning, and server development, a bit of JavaScript and HTML for website development. The AI model was developed using Huggingface transformers, sklearn, and scipy. Challenges we ran into A team member with frontend skills dropped out last minute, but we still built a localhost web app. Optimizing and hyperparameter tuning the ML model was challenging, as it was a data-driven unsupervised clustering algorithm. Ensuring that the model is not sensitive to the clickbait keywords of the videos was challenging, an"
      }
    ]
  },
  {
    "file_path": "./devposts/studyfocus-l3ok0i.html",
    "project_id": "studyfocus-l3ok0i",
    "title": "Study BUDD-E",
    "tagline": "Stay motivated and concentrated while studying with Study BUDD-E!",
    "hackathon": "",
    "built_with": [
      "gpt",
      "mmaction2",
      "openai",
      "opencv",
      "python",
      "raspberry-pi",
      "react",
      "ssh",
      "viam",
      "whisper",
      "yolov8"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of Statistics -- Sponsored by SIG Created by Neel Adwani yeet Justus Beck Shreyasvi Natraj Heyo",
      "Best use of Statistics -- Sponsored by SIG Created by Neel Adwani yeet Justus Beck Shreyasvi Natraj",
      "PennApps XXIVWinnerBest use of Statistics -- Sponsored by SIG",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/581/831/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "⭐ Inspiration We've all been there—sitting in a quiet room with a mountain of notes, textbooks sprawled open, and suddenly a nagging question pops into your mind. You're tempted to pick up your phone, but you know one search might lead to an hour on social media. Then there's that longing for a little treat after a focused study session. Cue the birth idea of the \"Study BUDD-E\", a result of collective student experiences, caffeine highs, and a dash of techy magic. 🍭 What it does Introducing \"Study BUDD-E\", not just a study companion, but your own personal Q&A machine: Concentration Tracking : Through its advanced sensors, Study BUDD-E is in sync with your study dynamics. Detecting your reading, typing, or pondering moments, it differentiates between genuine focus and those wandering-mind intervals. Question & Answer Buddy: Hit a snag? Unsure about a concept? Just ask! With a vast database and smart processing, \"Study BUDD-E\" provides you with answers to your academic queries. No need to browse the web and risk distractions. Your BUDD-E's got your back. Study Stats: After wrapping up your study session, prepare for some insights! \"Study BUDD-E\" showcases stats on your concentration levels, time well spent, and moments of diversion, helping you understand your study patterns and where you can improve. Reward System: All work and no play makes Jack a dull boy. For every successful, focused study session, \"Study BUDD-E\" cheers you on by dispensing a sweet candy treat. Your academic achievements, no matter how small, deserve a sweet celebration. In a digital age where every beep and buzz can sidetrack our study mojo, \"Study BUDD-E\" stands as a beacon of focus, ensuring you stay on track, get answers in real-time, and celebrate the small victories. 🔧 How we built it Building the \"Study BUDD-E\" was a blend of robotics, software development, and a sprinkle of sweet creativity. Here's a behind-the-scenes look at our construction journey: Robot Base: At the heart of \"Study BU"
      }
    ]
  },
  {
    "file_path": "./devposts/summarizr-hczls7.html",
    "project_id": "summarizr-hczls7",
    "title": "Summarizr",
    "tagline": "Save time, learn more, learn better -- This won the *College Education prize*; The College and HS prize was switched unintentionally.",
    "hackathon": "",
    "built_with": [
      "assemblyai",
      "flask",
      "html5",
      "material-ui",
      "python",
      "react",
      "tailwind-css",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "PeddieHacks 2022WinnerPassion PrizeWinnerEducation High School Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/211/969/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "College Track Inspiration When COVID 19 hit, online learning tools like Youtube became more prevalent and accessible. With lectures and lessons being posted online, it fed into what Gen Z's like John enjoyed and learned better with. Using Youtube for learning offered agency that students have for controlling the instructional delivery by pausing, rewinding, or forwarding so that they can work at their own pace and focus specifically on where they need support. Especially in the sciences when students took hands-on lab courses via Youtube videos, studies show that 91% of students report that teachers should use online science instructional videos with their students when classes are taught in-person. Across other disciplines, the majority of students would like to see videos continue to be included as legitimate resources for science learning ecosystems post-pandemic. This shifting preference is now driving curricula and technological changes in some schools to support increased demands on teachers leveraging Youtube to support curriculum-based instruction. What it does That's why we created Summarizr. Summarizr leverages AssemblyAI's API to divide Youtube video into chapters so that students can head right ot the topics that interest them. Instead of having to rewind to catch what's narrated or said in the video, videos are also transcribed so that students can easily copy and paste what was said. Of course, our app also summarizes and extracts main points in the video and tells users the timestamp durations that the summary is for. This is especially useful when students need to cover a lot of ground fast. Additionally, Summarizr has a trained machine learning model from Tensorflow to help answer questions about facts drawn from content in the Youtube video. So if a video covers how recommendation systems work, you can ask a question about how markov chains work, and our app would excerpt a relevant section of the video and summarize how markov chains were explaine"
      }
    ]
  },
  {
    "file_path": "./devposts/swiftxplore.html",
    "project_id": "swiftxplore",
    "title": "SwiftXplore",
    "tagline": "SwiftXplore does all the day trip planning for you! Choose from Toronto's sights, and find the most efficient and safe route for your trip!",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Google Maps lets you find directions but not plan a trip. It's reading week and first year students are dying to explore the city. Our project allows them to explore in the fastest and safest way possible. What it does Our project uses a genetic algorithm to calculate the safest and most efficient route between a list of attractions that a user inputs into our website. It then uses Google API to display this most efficient route and directions. How we built it We built our project using Python, HTML/CSS, and JavaScript. Challenges we ran into None of use had used Maps API before and neither had we been in a Hackathon where we had to create a project in such a short time frame. Accomplishments that we're proud of We managed to create a working genetic algorithm, a working user interface, and a working representation of each route. What we learned We need to use frameworks like React.js and Django to integrate the various parts of our project so that everything works in unison, seamlessly. What's next for SwiftXplore Creating the frameworks described above, and expanding SwiftXplore to include more attractions across different cities. Built With css html javascript python Try it out GitHub Repo Submitted to NewHacks 2022 Created by I worked on integrating Google Maps API, which I had never used before. It required a lot of research, but worth it! Maryam Taj I worked on the front-end. Kashish Mittal Pratibha Thakur"
      }
    ]
  },
  {
    "file_path": "./devposts/swype-ovuzd4.html",
    "project_id": "swype-ovuzd4",
    "title": "Swype",
    "tagline": "Swype is an engaging app where students watch short videos with live multiple-choice questions to train their math skills. With leaderboards and quests, Swype keeps learning fun and competitive!",
    "hackathon": "",
    "built_with": [
      "canva",
      "git",
      "github",
      "jamboard",
      "swift",
      "swiftui"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/991/655/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Personal profile Home Page, where the quick quizzes are viewed Inter-school leaderboard In-class leaderboard Daily quests Personal profile Home Page, where the quick quizzes are viewed Inter-school leaderboard In-class leaderboard Daily quests Personal profile 1 2 3 4 5 6 Inspiration The rise of short-form video content on popular social media platforms and how it poses a challenge for future generations of students and their brains as aptitude for learning and attention spans decline was the inspiration behind Swype. We wanted to tackle this problem not by viewing short-form videos as the problem, but rather a medium that could serve as a vehicle for education and learners. What it does Swype revolutionizes the educational experience by gamifying learning. The app is designed to make math practice engaging and fun for students. It includes features such as: Classroom Support -\nTeachers can integrate Swype into their lesson plans, using it as a supplementary tool to reinforce math concepts taught in class. Competition -\nStudents can compete against their peers within their school as well as for their school, fostering a healthy competitive spirit and encouraging them to improve their skills. Streak System -\nTo encourage consistent practice, Swype rewards students for maintaining streaks of daily activity, motivating them to keep up with their learning. Teacher Preference Controls -\nTeachers have the ability to customize the app’s settings to align with their teaching methods and curriculum, ensuring that the content is relevant and effective for their students. How we built it The development of Swype involved several key steps. Brainstorming and Structuring -\nWe used Jamboard and Canva to brainstorm ideas and structure our concept into a viable product. These tools helped us visualize our ideas, organize our thoughts and plan the app’s features and design. Collaboration -\nOur team collaborated using GitHub, which facilitated version control and seamless sharing of "
      }
    ]
  },
  {
    "file_path": "./devposts/supplyrowdy.html",
    "project_id": "supplyrowdy",
    "title": "Coivd - 4seen",
    "tagline": "The best to app assist you in preparing for Covid - 19",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "dart",
      "flutter",
      "google-maps"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The best to app assist you in preparing for Covid - 19"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/174/857/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "COVID - 4seen by: Michael Mohn (MichaelMohn624#6613), Taemin Ha (Taemin#1466), Ian Kim (Ian K#8258) Link to our github => link Link to our Youtube Video => link We all know that the spread of Covid-19 is causing a lot of problems, especially with how food is distributed and whether or not people have enough for their family. It was this growing issue and the fact that it affected everyone that inspired me, Taemin, and Ian to design Covid - 4seen. Here is how it works: Covid - 4seen allows the user to track and project how long their remaining food supplies will last, based on the size of their family. We use the recommended meal plan by Mayo Clinic to determine this. This way, we are not only capable of telling you how much time you have left in general, but which food groups will run out first, and which you have the most of, further allowing you to have a balanced diet as well. Once the user gets the information, Covid - 4seen provides you with a google maps page displaying the nearest grocery stores in your area. This allows the user to go from store to store as efficiently as possible and ensuring they get exactly what they need. This is especially useful to have handy as many stores are out of stock on various items, which other stores might have plenty of. In order to do this in only 24 hours, we had to divide and conquer! I focused on the front end while Ian and Taemin contributed with the back end and implementation of the google maps. I grew so much faster at design UI templates and Taemin and Ian learned the different capabilities of google maps APIs and how to access them. However, we all learned about the importance of communication and teamwork is. This brings me to my next point, our challenges. As it turned out the most challenging part was not the coding itself but coding in a way that allowed other's work to be implemented together, rather than 3 different projects. We became confused over time exactly what the plans for the app were and had to stop"
      }
    ]
  },
  {
    "file_path": "./devposts/stuq.html",
    "project_id": "stuq",
    "title": "StuQ",
    "tagline": "Answers to your questions, finding tutors and roommates! Connect with your peers on our site. With our tools, you can elevate your university experience!",
    "hackathon": "",
    "built_with": [
      "dynamicxyz",
      "express.js",
      "mongodb",
      "nextjs",
      "node.js",
      "pushprotocol",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of MongoDB Atlas Created by Worked on the finding roommate feature and integrated dynamic",
      "Web3AppsWinnerBest Use of MongoDB Atlas",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/829/713/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Dynamic xyz wallet Landing page Log in Sign up Forum Making a post made the post interest match Dynamic xyz wallet Landing page Log in Sign up Forum Making a post made the post interest match Dynamic xyz wallet 1 2 3 4 5 6 7 8 9 Inspiration What inspired us When we think about the process of asking a question in university it felt daunting due to the amount of sources one would have to go through to find a satisfactory one, from joining multiple discord servers to asking around only for your question to be buried, this is our solution to that Why did we go with StuQ as our project name? It is a shortened handle for Student Questions as that was the foundational issue we were trying to address with this application. Throughout developing the application we started calling it StuQ to shorten it, but it ended up sticking after one of our developers said \"Stuck? Use StuQ\" and as its namesake suggests it StuQ with us. What it does The site offers you a range of uses. It serves as a forum/thread for students to access and find answers to their questions since as of now at the University of Regina it is very difficult to do so, let's say you want to know something about a course you'd have to navigate through multiple discords, asking people and look everywhere for that piece of information but with this, we hope to centralize the information allowing people to more easily find the answers. It can also help you find roommates/tutors through the use of the community that would be established through it, helping you sort out through the student body to find who you feel strongly about and giving you the resources to find tutors to help assist you in your academic success. How we built it We used Mongodb to implement a custom recommendation algorithm for students to find roommates with similar interests using MongoDB aggregation, we used NextJs with Typescript and tailwindcss for the frontend and used dynamic xyz for wallet generation with university email id, we used NodeJs "
      }
    ]
  },
  {
    "file_path": "./devposts/swarmaid.html",
    "project_id": "swarmaid",
    "title": "SwarmAid",
    "tagline": "Feeding communities, reducing waste with Swarm intelligence",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "openai",
      "python",
      "swarm"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack Dearborn: Rewind RealityWinner2nd Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/077/214/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "User Dashboard Mission Control Mission Control User Dashboard Mission Control Mission Control User Dashboard 1 2 3 4 🧠 Inspiration The staggering fact that one-third of all food produced globally is wasted while millions go hungry is heartbreaking. This project was born out of the urgent need to bridge that gap—connecting those with surplus to those in need. We were inspired by Swarm's multi-agent orchestration, envisioning a future where intelligent collaboration could turn food waste into sustenance for communities. 🌍🍽️ 🌟 What it does SwarmAid connects food suppliers with surplus—like restaurants, grocery stores, and farms—to food banks and shelters in real-time. It uses intelligent agents that automatically detect surplus food, match it with demand, optimize logistics for transportation, and ensure compliance with health standards. By facilitating fast, efficient redistribution, SwarmAid not only reduces food waste but helps feed those in need. ❤️🍲 🔧 How we built it We leveraged Swarm's multi-agent orchestration framework, building out a modular system where agents collaborate seamlessly: Supply Agents detect surplus food. Demand Agents match available surplus with food banks. Logistics Agents plan efficient routes to minimize environmental impact. Compliance Agents ensure all food handling follows safety regulations. Using Python for the backend, Leaflet.js for the interactive map, and APIs for real-time communication, we created a proof-of-concept that simulates these interactions and highlights the power of decentralized coordination. 💻🗺️ 🧗‍♂️ Challenges we ran into One of the biggest challenges was ensuring seamless communication between agents without creating bottlenecks. Coordinating real-time logistics and compliance while keeping the system lightweight and scalable also proved tricky. We had to experiment with different architectures and APIs to get it just right. 🚧🤔 🎉 Accomplishments that we're proud of We’re incredibly proud of building a working proof"
      }
    ]
  },
  {
    "file_path": "./devposts/swiftcare-jsrne9.html",
    "project_id": "swiftcare-jsrne9",
    "title": "SwiftCare",
    "tagline": "Enhancing Patient Safety through Triage and Management",
    "hackathon": "",
    "built_with": [
      "css",
      "django",
      "github",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/658/678/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "We're swift to care We're swift to care We're swift to care 1 2 Inspiration We got inspired to create this project by interviewing healthcare providers. We interviewed healthcare providers on inconveniences they experienced and became inspired to increase patient safety by combating those inconveniences. What it does For our project we built a webapp that assists healthcare professionals in Patient tracking and Triage in order to reduce response time and errors in the emergency room. How we built it We used ReactJS to create the structure and functionality of our webapp. We also used CSS to define the layout and design the webapp. Additionally, we used Django for building the backend of our web application. We utilized Django for URL Routing and Admin Interface. Challenges we ran into Some of the challenges that we ran into was getting out webapp to interact with our API.  It was our first time working with the Cross-origin resource sharing (CORS) mechanism and had a difficult time doing the configuration. Accomplishments that we're proud of Some of the accomplishments that we are proud of is having an concept that is applicable to real life and is beneficial to people in need. What we learned Throughout this project, we learned how to create a web application using ReactJS and also got to learn about CORS. What's next for SwiftCare We want to implement more features such as tracking patients vitals or the probability they are to fall and how we can prevent it. Built With css django github react Submitted to HackUTD X Created by Connor Carey Amrita Thapa Ayusha Timalsena Siddharth Radhakrishnan"
      }
    ]
  },
  {
    "file_path": "./devposts/sustainify-8a2pq3.html",
    "project_id": "sustainify-8a2pq3",
    "title": "Sustainify",
    "tagline": "Sustainify is a web app where users can track their carbon footprint usage and gain meaningful feedback on their emission habits using AI.",
    "hackathon": "",
    "built_with": [
      ".tech",
      "axios",
      "css",
      "firebase",
      "firestore",
      "flask",
      "html",
      "javascript",
      "openai",
      "postman",
      "python",
      "react",
      "tailwindcss",
      "yarn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "(MLH) Best",
      "Hack the Valley 8Winner(MLH) Best .Tech Domain Name",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/619/336/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sustainify Green Logo Sign in page Home page + stats + previous survey results Survey with result Survey with smart feedback EcoGuide Chatbot using AI to generate the responses GIF Our mascot Eco as a cute gif waving Sustainify Logo Sustainify Green Logo Sign in page Home page + stats + previous survey results Survey with result Survey with smart feedback EcoGuide Chatbot using AI to generate the responses GIF Our mascot Eco as a cute gif waving Sustainify Logo Sustainify Green Logo 1 2 3 4 5 6 7 8 9 Inspiration 🌎 On Average, each person produces 4.7 tonnes of carbon dioxide each year worldwide. This is roughly the size of an adult African elephant in just CO₂ gas. Carbon dioxide is the main greenhouse gas which causes global warming. Since 1961 humanity’s carbon footprint has increased over eleven times. This Hack The Valley our team wanted to innovate saving the environment using AI. What it does 🤔 Sustainify is a web app where users can track their carbon footprint usage and gain meaningful feedback on their emission habits using AI. The user is prompted to complete a short survey, the survey consists of questions related to the user's household, transportation, and consumption practices. Once met the results get processed into our language model to give intelligent recommendations on how the user can improve on reducing emissions. Sustainify also provides insights into how your habits compare to those of other users, showcasing the distinctions in your data. If your habits change you can retake the survey to get a new rating. But wait that's not all, with Sustainify we incorporate our very own chatbot, Eco! Eco is our cute and friendly mascot who will answer any of your questions related to the environment. For example, we can ask Eco “How can I reduce my carbon emissions if I am a frequent automobile driver?”. Then Eco will provide a variety of solutions to your problem. Be aware though that Eco will only answer questions related to sustainability. So if we ask"
      }
    ]
  },
  {
    "file_path": "./devposts/superstage.html",
    "project_id": "superstage",
    "title": "SuperStage",
    "tagline": "Take your presentations to the next dimension!",
    "hackathon": "",
    "built_with": [
      "c#",
      "figma",
      "github",
      "oculus",
      "powerpoint",
      "unity",
      "vr"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Winner Finalist Created by Carolyn Zhang Justin Lin UW SE Lily Ni",
      "First Place Overall Winner Finalist Created by Carolyn Zhang Justin Lin UW SE Lily Ni",
      "Hack Western 10WinnerFirst Place OverallWinnerFinalist",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/682/847/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Celebrate a successful pitch with special effects, summoned by a simple gesture! Welcome to SuperStage, where anyone can give an epic keynote. Use full hand-tracking gestures to present your content in VR. Oh no!! So dramatic. Access 3D models that go along with your slides. Teachers can engage a classroom using live demonstrations. What it looks like through the presenter's eyes: just like presenting IRL. Celebrate a successful pitch with special effects, summoned by a simple gesture! Welcome to SuperStage, where anyone can give an epic keynote. Use full hand-tracking gestures to present your content in VR. Oh no!! So dramatic. Access 3D models that go along with your slides. Teachers can engage a classroom using live demonstrations. What it looks like through the presenter's eyes: just like presenting IRL. Celebrate a successful pitch with special effects, summoned by a simple gesture! 1 2 3 4 5 6 7 8 Inspiration 💥 Let's be honest... Presentations can be super boring to watch— and to present.\nBut, what if you could bring your biggest ideas to life in a VR world that literally puts you in the PowerPoint? Step beyond slides and into the future with SuperStage! What it does 🌟 SuperStage works in 3 simple steps: Export any slideshow from PowerPoint, Google Slides, etc. as a series of images and import them into SuperStage. Join your work/team/school meeting from your everyday video conferencing software (Zoom, Google Meet, etc.). Instead of screen-sharing your PowerPoint window, screen-share your SuperStage window! And just like that, your audience can watch your presentation as if you were Tim Cook in an Apple Keynote. You see a VR environment that feels exactly like standing up and presenting in real life, and the audience sees a 2-dimensional, front-row seat video of you on stage. It’s simple and only requires the presenter to own a VR headset. Intuition was our goal when designing SuperStage: instead of using a physical laser pointer and remote, we used full-hand "
      }
    ]
  },
  {
    "file_path": "./devposts/table-soccer-mv0fol.html",
    "project_id": "table-soccer-mv0fol",
    "title": "Table Soccer",
    "tagline": "A mixed reality multiplayer table top soccer game.\nA great party game to play with friends, especially if they are soccer fans!",
    "hackathon": "",
    "built_with": [
      "c#",
      "metaxrsdk",
      "photon",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/892/018/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Table Soccer Cover Image Table Soccer Cover Image Table Soccer Cover Image 1 2 3 4 Inspiration Bam (The mixed reality same room multiplayer game for Quest) Soccer (The sport) What it does Provides a fun party game to play with friends in the same room in mixed reality. It's like playing holographic tabletop board games with friends, except you are controlling little soccer players around a soccer field and kicking the ball trying to score goals. How we built it Unity, Blender, Maya, Meta Presence Platform, Photon Challenges we ran into Soccer ball physics. Unity's physics engine doesn't quite simulate the ball physics the way we expected. Ideally we would implement some custom physics code to make it more realistic or figure out how to make Unity's physics engine simulate realistic soccer ball physics better. Multiplayer - syncing all the player's movements and kick actions, who has possession of the ball, who scored, what the current score is, ect. Having the same physics for every player. Shared spatial anchors and collocated multiplayer - learning how to implement this in the project, figuring out how to merge the sample project into my project to get this working. Accomplishments that we're proud of Getting same room mixed reality multiplayer working Getting some nice sound effects. Like when the ball hits different objects in the game, it makes different sounds based on what type of object it hit. Like if it hits a metal object it will make a loud clang, if it hits a plastic wall it will make a more muffled thunk, if it hits the soccer net it will make a soccer net hit sound. What we learned How to make a mixed reality co-located multiplayer game using the Meta Presence platform and shared spatial anchors.\nHow to use Meta Presence Platform spatial audio to make the soundscape of the game feel more immersive and present. What's next for Table Soccer Add AI players, add passing mechanics where you can pass to another player on your team and then control that char"
      }
    ]
  },
  {
    "file_path": "./devposts/symptoai.html",
    "project_id": "symptoai",
    "title": "SymptoAI",
    "tagline": "Enter in your symptoms, get results immediately!",
    "hackathon": "",
    "built_with": [
      "clerk",
      "flask",
      "mysql",
      "next.js",
      "openai",
      "pinecone",
      "prisma",
      "python",
      "stripe",
      "tailwind",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/489/231/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Results Page Homepage User Info Loading Screen Results Page Homepage User Info Loading Screen Results Page 1 2 3 4 5 Inspiration Our inspiration came from one of our teammates. He had recently injured his ankle during soccer practice. The next available appointment for him was in 3 days. He didn’t know what to do, or how to ease the pain. When he shared this story with us, we realized the problem with current Healthcare: The results arrive very slow. Then after hearing about this hackathon’s prompt, and how it coincided with our problems, we decided we wanted to make an app that would accurately deliver results within 2 minutes, with minimal information from the user. It can also give the user some information on their medical problem, and people they could contact. What it does Firstly, the user will login through their google account. Then they will receive some free credits to start with, 10000 credits, which they receive from their profile. After that, they can enter in some information in a box, which will pop up a lot of things to enter, but it’s very quick. After the user info has been entered, it will take some time to process and deliver results. The results will show 5 possible problems the user could have. As they read through, they can see which one corresponds the most according to their symptoms, and contact doctors according to it. How we built it We built our project by creating a Next.js frontend that’s wired up to a Flask server that uses OpenAI’s APIs and a vector DB that we set up using pinecone, which would match the results from the OpenAI API, to the metadata from the pinecone index. We also use OpenAI, to process the user info, and give us results in the format of a dictionary. We also had a MySQL database provisioned on PlanetScale for storing user data that was connected to using Prisma from the Next.js Node.js Vercel Lambda functions. For handling payments, we used Stripe as it handled a lot of the international problems, taxing, and sever"
      }
    ]
  },
  {
    "file_path": "./devposts/talk2doc.html",
    "project_id": "talk2doc",
    "title": "Talk2Doc",
    "tagline": "A convenient app to connect patients-in-need and doctors",
    "hackathon": "",
    "built_with": [
      "ajax",
      "axios",
      "bootstrap",
      "css3",
      "flask",
      "html5",
      "javascript",
      "jquery",
      "python",
      "sqlite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/620/532/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "homescreen login page homescreen login page homescreen 1 2 3 Inspiration Living in a COVID pandemic has brought increased attention towards the healthcare system, so we thought up an app that would make connecting patients with doctors an easy and painless process. Our goal was to come up with an app that can facilitate this process by helping people overcome the one of biggest barriers in preemptively reaching out to doctors: inconvenience. What it does Talk2Doc allows patients to match up with an available doctor who will provide medical advice based on the severity of their symptoms over the next few weeks. New patients can choose doctors based on rating and the time they will be available for a live consultation. Patients will then login daily to enter the severity of their symptoms, as well as any concerns they have with their current treatments. The doctor can view the symptom history for assigned patients, update their prescription and p. How we built it We split our 4-man team into 2 groups: front-end and back-end. Nihal and Harvey worked on designing the front-end UI, beautifying it with Bootstrap and custom CSS, and also implementing JS to help connect the frontend to the backend. Kevin worked primarily on implementing the Axios HTTP Client in JS to allow the frontend to send requests to the backend. Victor used Python with the Flask framework to develop the backend server and connect it to an SQLite database. Challenges we ran into We were unsure of how to coordinate the workload at first because we didn’t really know how much work the frontend and backend each required. It was also challenging to manage our differences in proficiency in coding languages. Victor specializes in backend work with Python and Flask while Kevin works mainly with HTML, CSS, and JS but with the React framework and Node JS as a fullstack developer. Nihal and Harvey both had limited familiarity with how the backend works and instead dedicated most of their energy into designing th"
      }
    ]
  },
  {
    "file_path": "./devposts/t-soding.html",
    "project_id": "t-soding",
    "title": "T-soding",
    "tagline": "yes",
    "hackathon": "",
    "built_with": [
      "bash"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration meow What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for T-soding Built With bash Submitted to TAMUhack X Created by Lucian Chauvin"
      }
    ]
  },
  {
    "file_path": "./devposts/symptom-buddy.html",
    "project_id": "symptom-buddy",
    "title": "Symptom Buddy",
    "tagline": "Symptom Buddy is a chatbot that uses AI to diagnose medical diseases",
    "hackathon": "",
    "built_with": [
      "keras",
      "nltk",
      "python",
      "scikit-learn",
      "tensorflow",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/383/481/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Since doctors, ERs, ICUs, and hospitals are overloaded with coronavirus patients, we decided to build a program that helps diagnose people with diseases. This means that the people won't need to go to the doctors which would further overload ERs, hospitals, and increase their risk of spreading COVID-19. What it does Symptom Buddy is a chatbot that helps diagnose your symptoms and provides suggestions for the best course of action based on the severity of your diagnosis. How we built it We created a deep neural network for predicting diagnoses based on symptoms We created a chatbot application that interacts with the user and determines the disease using the ML model built in part 1 We created a tkinter GUI frontend for the chatbot Challenges we ran into Mapping and preprocessing our data for our DNN Minimizing the loss function for our machine learning model Integrating our trained models to the front-end Accomplishments that we're proud of Creating a usable program within 2 days Using multiple ML models Having an interactive GUI for users What we learned How to format data for a model to train on How to create and train a ML model How to build a chatbot Integrating the frontend with a backend trained models What's next for Symptom Buddy Better NLP so the chatbot can continue a conversation Have Symptom Buddy provide resources and further reading/articles to the user about the diagnosed disease Pull location services to suggest the appropriate clinic, support groups, hospital, or urgent care centre in your local neighbourhood Built With keras nltk python scikit-learn tensorflow tkinter Try it out GitHub Repo Submitted to MacHacks Created by Raj Zala 3rd year nanotechnology engineering @UW, nanoelectronics researcher, R&D engineer Ryan Lam UWaterloo Physics Mihir Kakkar Nanotechnology Engineering @ UWaterloo KellieChong"
      }
    ]
  },
  {
    "file_path": "./devposts/t-soding-tz0qdn.html",
    "project_id": "t-soding-tz0qdn",
    "title": "T-soding",
    "tagline": "A small terminal game to demonstrate Turing machines.",
    "hackathon": "",
    "built_with": [
      "bash",
      "bubbletea",
      "charm",
      "git",
      "github",
      "go"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/742/839/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "edit mode palindrome matching level title page edit mode palindrome matching level title page edit mode 1 2 3 4 Inspiration We created T-soding out of love for the terminal and also Turing machines! Our goal was to create an interactive terminal game that anyone can run and learn what and how Turing machines are used! What it does This game simulates a Turing machine so users can actually get intuition about how to build algorithms with Turing machines. How we built it We used the bubbletea framework, which is made in Golang, and provides a pretty nice toolset for making terminal applications. Challenges we ran into Neither of us has ever worked in Go, so we had to learn it from scratch.\nThe library that renders the state table was not able to select individual cells, so we had to edit it to implement it ourselves. Accomplishments that we're proud of We did it! We've created a functional, interactive, edit-able Turing machine! What we learned Go. Lots and lots of Go. (Also the bubbletea framework.) What's next for T-soding Add level selection (and levels) with a difficulty curve. Also, add a full-fledged tutorial so users aren't daunted by a state table, and some way to actually distribute this program to different platforms.\nFinally, extend the code to be able to accept arbitrarily many states and symbols, rather than the 6 states and 3 symbols currently hardcoded in. Built With bash bubbletea charm git github go Try it out GitHub Repo Submitted to TAMUhack X Created by I extended the tables source code to have the functionallity we needed. I also emplemented the logic for the Turing machine. It was really fun and I enjoyed working with Mckinley!! Lucian Chauvin We both worked on a lot of this project! I implemented a lot of the I/O (like the ability to edit tables, and the display of the tape) and much of the formatting to make everything look pretty (like the moving highlight to show the execution of the machine) Mckinley Xie"
      }
    ]
  },
  {
    "file_path": "./devposts/tabl3-w0n39h.html",
    "project_id": "tabl3-w0n39h",
    "title": "TABL3",
    "tagline": "TABL3 is a new and immersive front-end UI for visualizing blockchain transactions and interacting with crypto assets.",
    "hackathon": "",
    "built_with": [
      "c#",
      "oculus",
      "solana",
      "solana-unity-wallet",
      "solidworks",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/880/844/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Screenshot of TABL3. Screenshot of TABL3. Screenshot of TABL3. 1 2 Inspiration Blockchains and crypto are relatively new. They can seem foreign and a little scary. Yet, Web3 is one of the hottest tech topics today, and the people building it have a vision: to make it more inclusive and diverse than Web 2; to use decentralized technologies to empower more people to build, create, and own applications and data; and to transcend the boundaries and borders that define traditional finance. The main benefit of decentralization, in this case, is that by removing the intermediary and allowing people to operate peer-to-peer, more value accrues on both sides of any transaction. There are fewer entities in between taking a cut. However, the digital currencies and tokens that power Web3 are incredibly difficult for most people to understand. If we don’t provide people with the foundational education they need to participate in the crypto economy, Web3 will ultimately be no different than Web 2. Crypto is a game of self-fulfilling belief and in order to bootstrap a new blockchain or app, we need to convince people that other people will also use that blockchain or app. The best blockchain technology in the world is useless without people building on top of it. So for all of the talk about technology, decentralization, and trustlessness, the success of any crypto project relies – to a surprisingly high degree – on people. This project, TABL3, was built with the vision to give more people “a seat at the table” when it comes to building Web3. What it does TABL3 is a new and immersive front-end UI for visualizing blockchain transactions and interacting with crypto assets. Our proof of concept demo leverages the Solana Wallet to give participants an interactive experience of purchasing their first cryptocurrency (SOL, the Solana token). Solana is a Layer 1 protocol, or blockchain, like Bitcoin, Ethereum, or a number of others. Technically, what makes Solana interesting is that its ra"
      }
    ]
  },
  {
    "file_path": "./devposts/synthmining.html",
    "project_id": "synthmining",
    "title": "SynthMining",
    "tagline": "A platform that solves some of the biggest roadblocks in image-based data science by combining collaborative outsourced datamining with synthetic image generation.",
    "hackathon": "",
    "built_with": [
      "anaconda",
      "express.js",
      "flask.py",
      "github",
      "javascript",
      "matplotlib",
      "mithril",
      "mongodb",
      "numpy",
      "python",
      "pytorch",
      "typescript",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of MongoDB Atlas Winner Best Domain Name from Domain",
      "Best Use of MongoDB Atlas Winner Best Domain Name from Domain",
      "TAMUhack 2023WinnerBest Use of MongoDB AtlasWinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Currently, one of the largest issues in image-based data science - specifically image generation and machine learning - is the lack of large amounts of data necessary for data mining, and the time necessary to train them.  To provide a solution, we created an online platform that allows collaborative outsourced data mining that connects contributors to those with immature algorithms . What it does Such contributors are paid to submit valid data samples to those who need data sets to train machine learning via a built-in Generating Adversarial Network (GAN). Those wising to train networks are able to search by tags in order to find the right data sets needed, while data providers and paid to submit valid data sets, e.g. images. The project consists of two main parts, the GAN itself, and the platform it is hosted on. Challenges we ran into Tackling machine learning and creating a project around it was definitely a struggle, as most of us had little prior experience with understanding the concepts and applying it to code in a 24-hour timeframe. Accomplishments that we're proud of Despite the complexity of the subject we chose, our ambition paid off and we managed to complete the What we learned We learned that the incredible versatility of code, and that coding is ultimately an application of the knowledge that others have put out, with a myriad of powerful results. What's next for SynthMining SynthMining still has several areas that could be refined, and polished, but the next long term plan is to increase its accessibility and appeal. The quality and benefits of using the platform would only increase as time continues, and in this lies the next step to breaking through one of the roadblocks facing data scientists today. Built With anaconda express.js flask.py github javascript matplotlib mithril mongodb numpy python pytorch typescript vscode Try it out GitHub Repo Submitted to TAMUhack 2023 Winner Best Use of MongoDB Atlas Winner Best Domain Name from Dom"
      }
    ]
  },
  {
    "file_path": "./devposts/tab-6pytkv.html",
    "project_id": "tab-6pytkv",
    "title": "FundChain",
    "tagline": "FundChain: Revolutionizing e-commerce with NEAR blockchain, ensuring secure transactions for 1.7M+ Shopify merchants, combating $56B fraud, while promoting mental health through AI chatbot support.",
    "hackathon": "",
    "built_with": [
      "c",
      "coingeckoapi",
      "css3",
      "gpt4",
      "helius",
      "html",
      "html5",
      "jackal",
      "javascript",
      "natural-language-processing",
      "near",
      "openai",
      "shell",
      "shopifyapi",
      "solana",
      "typescript",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "and the Best Use of NEAR title: Creativity of the Solution: FundChain isn't merely a standard block"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/484/463/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 🤔 Problem Statement The e-commerce industry is evolving rapidly, and there is an increasing demand for decentralized payment solutions. - Shopify, one of the biggest players in the e-commerce industry with over 1.7 million active merchants, processed more than $79.5 billion in sales in 2021. However, it lacks a good way of processing crypto transactions without resorting to centralized exchanges. Payments made through centralized exchanges are ultimately settled in US Dollars, limiting the options for merchants and their customers. This lack of an integrated, decentralized payment solution restricts the growth potential of businesses in the new digital economy. Consumer fraud is a significant issue in e-commerce. The existing system does not provide a reliable guarantee that goods purchased will be authentic or that they will even be delivered, leading to increased mistrust among online shoppers. The Federal Trade Commission reported 2.2 million instances of fraud in 2020, leading to a total financial loss of $3.3 billion. This prevalent problem of fraud continues to dent customer trust and affects the overall growth and reputation of the e-commerce industry. There is an urgent need for a system that provides a clear, unalterable proof of purchase to protect consumers from fraud. The current systems in place lack this capability, which increases the risk for consumers when purchasing goods online. Lastly, mental health issues associated with financial scams and frauds are rising. A personal incident wherein a friend suffered from mental health problems after being scammed emphasizes the urgent need to address this issue and contribute to mental health causes. 💡 Inspiration Shopify, a major e-commerce platform with over 1.7 million active merchants, processed more than $79.5 billion in sales in 2021. Yet, it lacks a system for processing crypto transactions, which represents a significant gap in the market. In 2021, the global cryptocurrency market cap crossed th"
      }
    ]
  },
  {
    "file_path": "./devposts/task-market.html",
    "project_id": "task-market",
    "title": "Task Market",
    "tagline": "Practice self care. Earn food. What could be better?",
    "hackathon": "",
    "built_with": [
      "android-studio",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/256/475/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Early brainstorming Task Market's cookbook - what food will you unlock next? Recipe drops and recipe info screens Early brainstorming Task Market's cookbook - what food will you unlock next? Recipe drops and recipe info screens Early brainstorming 1 2 3 4 Inspiration 💭 As busy engineering students, we know all too well how easy it is to forget to take care of yourself. There exist many self-care apps out there, but over time we found ourselves not motivated enough to use them. We wanted to bring a fun and new way to reward yourself for prioritizing your mental health. Thus came Task Market! What it does 🤖 Our app allows you to complete daily good habits, and as an incentive, you can gain coins and stars! Coins are used to buy ingredients from the market, whereas stars let you roll for recipes. Once you've obtained a recipe, you can learn more about its diverse history and culture. How we built it 🛠️ We used React Native to build a cross-platform game-slash-self-care-tracker. As both members of our team own Windows laptops, we needed to use Android Studio to emulate the app on Android. Additionally, we used various node modules, one of them being React Native Elements as a component library. Challenges we ran into 📉 Although we both had experience with React, neither of us had touched React Native - nor mobile development at all. The syntax was somewhat familiar, but the more complicated development environment led to a steep learning curve. Still, we managed to persevere (with five hours of sleep!) and learn a lot from this experience :) Accomplishments that we're proud of 🏆 Overall, we're proud of how the application looks, as well as its functionality. It was a difficult 36 hours, but we made exponential progress towards the end. Our proudest moment is when we finally got our storage system to work, allowing us to save the data gained from rolling for recipes. What's next for Task Market 🏃‍♂️ In the future, we plan to add custom graphics, including 2D animation in"
      }
    ]
  },
  {
    "file_path": "./devposts/talkbiz.html",
    "project_id": "talkbiz",
    "title": "TalkBiz",
    "tagline": "The ultimate web conferencing platform where productivity is no concern, just with a click of button and a functional mic and webcam, conversing with anyone around the world has never been easier.",
    "hackathon": "",
    "built_with": [
      "azure",
      "cohere",
      "css",
      "django",
      "elevenlab",
      "google-translate",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/716/965/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Language barriers have always a hindering factor to conversation quality, especially in businesses. When two businesses of different demographics are attempting to make something work, the general solution is to make the gold standard of business languages to be English. However, many successful businesses have found success in growth with the primary usage of other languages within the company such as Japan's Honda . However, with English as the gold standard, companies are forced to adapt to this business system as there is not an easy way to directly communicate company to company with distinctive cultures. The heart of a business is the foundation and structure of their unique culture, and adaptation to compensate for language barriers can be an inconvenience or in worst-case, stray the company away from its roots. So instead of tens of millions of companies around the world constantly adapting to new standards, why not allow companies stick to their own cultures while still cultivating growth with other businesses with a simplistic communication software that allow people from all over the world to communicate in any language they are comfortable with. This is TalkBiz. What it does TalkBiz is in summary a web conference platform like Zoom or Microsoft Teams with more complex ai-based features implemented to increase productivity with little adaptation needed for businesses. This software is designed to help businesses stay true to their own ways while having a powerful communication tool to talk business with others no matter what language they speak. Other than the typical elements you see in a web conferencing application, TalkBiz features 2 major elements.\nThe first feature is a voice cloning element where speaking into the mic in a certain language will output the same phrase translated into another language with the same voice. Yes, if you speak into the mic in english and you want to talk to your kpop idol over TalkBiz, they will hear you spea"
      }
    ]
  },
  {
    "file_path": "./devposts/table-61.html",
    "project_id": "table-61",
    "title": "3Datalyze [Team B306, Table 61]",
    "tagline": "Reimagining business modeling and downstream decision forecasting using 3D visualization and node-based data relationships.",
    "hackathon": "",
    "built_with": [
      "meta",
      "quest",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/742/874/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What will make your indie game take off faster - adding 3 marketers or 3 more devs? What will keep the company alive longer, 10 more devs or 10 sales people? We were inspired by our first-hand difficulty forecasting the effects of decisions in small businesses - without access to enterprise-level BI tools and consultants. What it does Unlimited node-based relationships between resources and activities and a 3D visualization of resources flowing around over time based on business decisions made. Ability to run unlimited scenarios over and over. How we built it Unity, Meta Presence Platform Special Thanks Reality Hack 2024 mentor Dr. Mark Frederiksen:\n\"I’m intrigued.If I had come across something like this in the last 20 years, I would have remembered it.\" Built With meta quest unity Submitted to MIT Reality Hack 2024 Created by Worked on the Unity stuff while pair programming with my awesome teammates. Tom Ortega II SeantheBomb Feeser Molly Roux Emerging tech and engineering enthusiast. CEO of Brain Spice Labs. XR / AI / Rapid Prototyping Andrew Bustos dillanhoyos Hoyos"
      }
    ]
  },
  {
    "file_path": "./devposts/task-manager-application.html",
    "project_id": "task-manager-application",
    "title": "Task Manager Application",
    "tagline": "This is an app to help manage tasks and make employees more productive in the workplace.",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "html",
      "javascript",
      "ruby",
      "ruby-on-rails"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Japanese Manscript Writing Cafe What it does Allows user to input a task, start time, and end time, and lists these tasks for them How we built it Using Ruby on Rails, PostgreSQL, HTML, CSS, JS, and GitHub Challenges we ran into Had trouble displaying a count down clock, and merging front end with back end, and the edit button suddenly failing in our video demo Accomplishments that we're proud of Having a functional website that updates to a database What we learned Set up environment beforehand (downloading software took up a good portion of our time) What's next for Task Manager Application Implement countdown clock and merge backend and frontend Built With css github html javascript ruby ruby-on-rails Try it out urldefense.com Submitted to TAMUhack 2023 Created by I worked on the front end. Ty Sanders mariaem21 Matamoros John"
      }
    ]
  },
  {
    "file_path": "./devposts/talkmoney.html",
    "project_id": "talkmoney",
    "title": "TalkMoney",
    "tagline": "Improving the readability of financial text for everyone.",
    "hackathon": "",
    "built_with": [
      "keras",
      "numpy",
      "pandas",
      "python",
      "pytorch"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Wolfram Award Winner $200 The Alley Gift Card Winner Hack the North 2020 Auto Acceptance Created by",
      "Winner $200 The Alley Gift Card Winner Hack the North 2020 Auto Acceptance Created by Idea creation",
      "FinHacksWinnerWolfram AwardWinner$200 The Alley Gift CardWinnerHack the North 2020 Auto Acceptance",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration One of our friends was misled into believing that Apple Card had a low-interest rate and amazing benefits because they did not read the terms and conditions text. We decided to help solve this important issue by using NLP to automatically simplify and obtain the main points of terms and conditions texts. What it does TalkMoney uses NLP to read + analyze the terms of services of companies that offer financial services and summarizes it for people to understand How we built it Challenges we ran into Training the model was incredibly hard as we only had a couple of hours. We had to constantly watch over it while we were training it. We also had to do some manual work to differentiate between \"important\" and \"less important\" information. Accomplishments that we're proud of What we learned What's next for TalkMoney TalkMoney was only trained on 1 PDF. For now, we can train TalkMoney with more PDFs and in the future, we can possibly use TalkMoney for financial documents such as the quarterly earnings of public companies Built With keras numpy pandas python pytorch Submitted to FinHacks Winner Wolfram Award Winner $200 The Alley Gift Card Winner Hack the North 2020 Auto Acceptance Created by Idea creation, business/logistics, scalability/viability, market research, a bit of web development Ryan Lam UWaterloo Physics Michelle Lai George Shao University of Waterloo Computer Science Student Silen Naihin Michelle Lai"
      }
    ]
  },
  {
    "file_path": "./devposts/talk2hands.html",
    "project_id": "talk2hands",
    "title": "Talk2Hands",
    "tagline": "Talk2Hands: a web app breaking down communication barriers for the hearing-impaired with speech-to-sign language translation.",
    "hackathon": "",
    "built_with": [
      "flask",
      "javascript",
      "nextjs",
      "python",
      "whisper"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/394/513/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our home page Our Slideshow The actual translation Our home page Our Slideshow The actual translation Our home page 1 2 3 4 Inspiration Our inspiration for this project is to promote equal communication opportunities and create a more inclusive world for the deaf and hard-of-hearing communities. By breaking down communication barriers and providing a tool to facilitate effective communication, we aim to reduce instances of bullying and promote a more accepting and diverse society. What it does This web application utilizes Whisper to transcribe speech to text, which is then translated into American Sign Language (ASL) and displayed on screen. While it can convert English, Spanish, and Italian, it currently only supports displaying the translations in ASL. How we built it For the web-page, we utilized Nextjs, while the Flask server powered the Whisper model to enable accurate translations. Additionally, we leveraged MongoDB to store all past data obtained from the app, ensuring an efficient and seamless user experience. Challenges we ran into As this was our team's first experience working with audio files, we encountered challenges around sending and receiving audio files from the client. Similarly, our use of Whisper was also new, and we had to familiarize ourselves with the documentation and conduct extensive testing and debugging to ensure the functionality of our code. Accomplishments that we're proud of Our team takes great pride in the potential impact of this app, as it has the power to break down communication barriers for individuals who are hard of hearing. By providing speech-to-sign language translation, our web-app has the potential to promote inclusivity, understanding, and equal communication opportunities for all. We are honored to contribute to a more accessible and accepting world, and we are committed to expanding and improving our app to maximize its positive impact. What we learned Throughout the development of this app, our team gained valuable"
      }
    ]
  },
  {
    "file_path": "./devposts/taggies-github-io.html",
    "project_id": "taggies-github-io",
    "title": "taggies.github.io",
    "tagline": "https://www.youtube.com/watch?v=DzAtgiNJ65k&t=1s",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "tsql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/766/084/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "An updated recording was done after the time to showcase all features: https://youtu.be/M5mLASVoOoo https://www.youtube.com/watch?v=DzAtgiNJ65k&t=1s - Recording done before 12:15PM Inspiration Our group was inspired to create Taggies due to recent circumstances surrounding the pandemic. Due to the outbreak, many Aggies are studying from home and there are several strict rules and regulations regarding in-person meetings. Because of this, several Aggies, especially freshman or transfer students, may find it difficult to start friendships with so many restrictions. Thus, Taggies was born! Taggies makes it easy to create a profile (a tag!) and start meeting fellow Aggies via an exclusive online platform. It's an excellent way to start chatting with people in the same major, dorm, or year! Challenges We Faced As a beginner group, our team had exactly zero experience with the Backend (Azure,SQL,Express) and the front end (HTML,CSS,Node.js). Thus, we had to learn during the hackathon as we programmed our very first web page together. We read and watched a variety of tutorials and instructional videos on learning the basics of how to create websites. While one member was learning how to link pages together to create working buttons on the site, another was learning how to link the inputted information to the server. The stakes were definitely high, but we managed to pull through together! What We Learned For starters, we learned a lot about programming in HTML/CSS as well as how to create a server with AzureDB and SQL for our page along with deploying it via AzureVM. Not only this, but we also gained a lot of experience working together as a team and supporting one another. Because no one on our team had prior experience working with these languages, we had to communicate our errors constantly and help each other solve the various issues we faced. Built With css html javascript tsql Try it out GitHub Repo Submitted to HowdyHack 2020 Created by Joshua Chong Lexie Kwon Priva"
      }
    ]
  },
  {
    "file_path": "./devposts/taskman.html",
    "project_id": "taskman",
    "title": "ToDo",
    "tagline": "A desktop application that stores tasks that need to be completed in a convenient and easy to use way.",
    "hackathon": "",
    "built_with": [
      "pyqt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "taskman keeps track of all the things you need to get done!"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration As a busy college student, productivity tools are always needed, thus we made taskman! What it does taskman keeps track of all the things you need to get done! How we built it We built task man using the PYQT5 framework. Challenges we ran into Some challenges we ran into was getting individual tasks to act properly once they were added. Accomplishments that we're proud of We are proud to have a complete project that can easily be improved upon. What we learned We learned how to use the PYQT5 framework! What's next for taskman The next steps for taskman is to create individual accounts that are stored in googles firebase that can be used on any machine able to run taskman! Built With pyqt Submitted to BeachHacks 7.0 Created by Michael Glider Prajwal Sharma Mirlan Boroshilov Monkey D. Mirlan"
      }
    ]
  },
  {
    "file_path": "./devposts/take-care-of-your-skin-health.html",
    "project_id": "take-care-of-your-skin-health",
    "title": "Take care of your skin health",
    "tagline": "Your health is so important to you as the skin cancer rating is increasing each year through sun exposure, what will you do to protect your skin?",
    "hackathon": "",
    "built_with": [
      "anvil",
      "google",
      "jupyter",
      "notebook"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/702/925/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "After image upload, skin condition is shown on screen Take Care of Your Skin Health home page After image upload, skin condition is shown on screen Take Care of Your Skin Health home page After image upload, skin condition is shown on screen 1 2 Inspiration My great grandma died of skin cancer when she was only about 50 years old. It had a great impact on my grandma and my mom. They have been on top of protecting their family on skin health since then. I would like to dedicate this app to help people check their skin conditions regularly and take actions accordingly. What it does This app will allow users to upload a skin image then identify the common skin conditions based on the image. I hope it can help people understand more about their skin condition and take actions to take care of their skin health. How we built it I used machine learning with CNN model to train on different type of skin conditions. Then I built a web UI using Anvil to allow a user to upload an image to the model to predict what skin condition it may be. Challenges we ran into Trying different parameters on the CNN model and training it took a lot of time. Accomplishments that we're proud of Finally the machine learning model can predict images with over 90% accuracy on 7 different type of skin conditions. What we learned persistence is the key What's next for Take care of your skin health I hope to convert the web app to a mobile app in the future so it's easier for people to use Built With anvil google jupyter notebook Try it out imagechecker.anvil.app Submitted to MHacks 14 Created by I used Python for my code, preprocessing techniques such as data augmentation for the skin cancer images in the dataset, and an RMSProp and CNN model for training and testing. My accuracy was above 90%. julia huang hackathon enthusiast and coder"
      }
    ]
  },
  {
    "file_path": "./devposts/tabula-z95t0u.html",
    "project_id": "tabula-z95t0u",
    "title": "Tabula",
    "tagline": "A virtual replacement for classroom blackboards and whiteboards.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "heroku",
      "javascript",
      "node.js",
      "react",
      "reactionic",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Hack Winner Best Education Hack Winner Top 5 Teams Created by I worked on the Ionic mobile",
      "Best Overall Hack Winner Best Education Hack Winner Top 5 Teams Created by I worked on the Ionic mo",
      "Silicon Valley HacksWinnerBest Overall HackWinnerBest Education HackWinnerTop 5 Teams",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/050/905/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration A great piece missing from online classrooms is the large whiteboard/blackboard normally at the front of the class. These boards provide the teacher with a large amount of space to show their work to the class during a math calculation, or to draw supply-and-demand diagrams for economics. In any case, these whiteboards/blackboards provide immense value to a classroom, and there's no real replacement for them in an online setting. Teachers could write on their desktop screen with their mouse, but it becomes difficult to do so cleanly and efficiently, especially for larger diagrams/equations. Many teachers turn to a touch screen device for these purposes, but not every teacher has access to a tablet or a large touch screen device. Currently, the most practical solution is using a small drawing app on a phone. However, it is difficult to write long math equations without needing to have to constantly erase the screen, which can be tedious and also prevents a thorough review of the concepts at the end of the equation, whereas with a large board, you can write out the entirety of an equation and are able to easily go back to certain steps in case students have questions are need clarification. Thus, there arose the need for Tabula. What it does Tabula comes in a web app and a mobile app. The two main users of Tabula are the students and teachers. The teachers create a room using the web app and connect to that room with their mobile device, using the mobile app. They are able to draw on the room's canvas with their device and configure settings (e.g. brush color and brush size) from the web app. The students join a room with a room ID and a room password, and they are able to see the canvas which the teacher controls. They are able to see which part of the canvas the teacher is focused on, and get updates when the teacher writes on the canvas in real-time. At the end of a lesson, they are also able to save the canvas to an image file on their computer. The ca"
      }
    ]
  },
  {
    "file_path": "./devposts/task-tango.html",
    "project_id": "task-tango",
    "title": "Task Tango",
    "tagline": "AI + Task Management. Reach Your Goals Faster. Coordinate Tasks Efficiently.",
    "hackathon": "",
    "built_with": [
      "coda"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/537/018/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Task Tango was inspired by the desire to enhance agile project management and provide a streamlined solution for individuals and teams. The aim was to create a versatile tool that enables efficient multi-tasking, collaboration, and adaptability within the dynamic realm of project management for any field. What it does Task Tango revolutionizes the way projects are managed by offering a comprehensive Coda template. It facilitates seamless multi-tasking between projects, prioritization of tasks, and effortless collaboration with team members. The template embraces the principles of SCRUM, allowing users to navigate tasks, sprint planning, backlog management, and progress tracking in a harmonious and efficient manner. How I built it Task Tango required lots of time in understanding Coda fundamentals and formulas, which mostly consisted of going through many guides and video tutorials. The template was also designed to be adaptable and customizable, catering to a wide range of project management needs. Challenges we ran into Throughout the development process, various challenges emerged, such as issues when making formulas work properly, and integrating advanced features like Coda AI for task generation. Overcoming these obstacles required creative problem-solving, collaboration, and continuous refinement. Accomplishments that I am proud of I am immensely proud of creating Task Tango, a powerful and user-friendly tool that simplifies agile project management. The template's ability to facilitate effective multi-tasking, provide real-time collaboration, and empower users to adapt their workflow has been a significant achievement. Additionally, incorporating Coda AI for automated task generation and assignment adds a layer of innovation that sets Task Tango apart. This was my first time using Coda and I am really happy that I learned so much and had so much fun making this template. What I learned Developing Task Tango was my first experience using Coda, and i"
      }
    ]
  },
  {
    "file_path": "./devposts/tbd-cyhez1.html",
    "project_id": "tbd-cyhez1",
    "title": "stemlings",
    "tagline": "gamifying K-12 STEM education with AI",
    "hackathon": "",
    "built_with": [
      "ai",
      "auth0",
      "cloudflare",
      "machine-learning",
      "natural-language-processing",
      "nextjs",
      "react",
      "redis",
      "tailwind-css",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/736/777/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "stemlings banner stemlings banner stemlings banner 1 2 💡 Inspiration Our inspiration for stemlings was the desire to create a fun service that encourages K-12 students to cultivate an interest in STEM and to encourage them to come back each day to prepare for it. ✨ What is stemlings ? stemlings provides a website platform for students to login each day and practice solving a daily STEM related problem, generated by AI. In doing so, they can grow their stemling and earn accomplishments for their consistent practice. ⚒️ How we built it We built stemlings using Next.js , a framework for creating server-rendered React websites, Tailwind CSS , a CSS framework with many pre-designed utility classes that can be used to build robust UIs, Auth0 , an identity and access management (IAM) platform used for authentication and authorization, .Tech Domains , Upstash Redis, a cloud-based managed Redis database, and Vercel , a cloud platform for deploying web applications. 💢 Challenging moments When using Auth0, we had challenges with navigating the different Development and Production client keys. In addition, we realized that the Redis database we had chosen to use did not seamlessly integrate with certain map requests from our application. This caused friction when integrating the authentication with the comment-post functionality in our main service. Ultimately, we remediated this by refactoring our Redis database files such that they would support the requests that we were originally unable to make. 🥂 Accomplishments that we're proud of We are especially proud of our UI/UX on our front-end. The interface represents a fun, friendly, and visually appealing design for young learners to navigate. The visual theme and cohesiveness support our application's primary purpose of motivating young learners to enjoy the process of daily STEM career preparation. 🧠 What we learned Throughout the challenges and successes that we faced with our hack, we learned a lot about the complexities of "
      }
    ]
  },
  {
    "file_path": "./devposts/tasty-blocks.html",
    "project_id": "tasty-blocks",
    "title": "3leven",
    "tagline": "An endless source of entertainment for number lovers and strategy lovers alike... challenge your friends to see who can get to 177147 first!",
    "hackathon": "",
    "built_with": [
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "winner, chicken dinner Instruction screen Winner winner, chicken dinner Instruction screen Winner w",
      "The game actually works: we didn't expect our first game to go this smoothly",
      "First time working with Pygame, pretty happy with the result!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/000/125/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Winner winner, chicken dinner Instruction screen Winner winner, chicken dinner Instruction screen Winner winner, chicken dinner 1 2 3 Inspiration The pandemic has resulted in a massive influx in the gaming community, but it's hard to find any game on par with the classic 2048. We wanted to make something more challenging and modern, but still with the same charm as the authentic version. There are already countless variations and versions of 2048, like 1024, Threes, and many more. But they're always too similar, and we thought a unique little twist would keep people entertained for just a little longer. The reason as to why we're coming back to 2048 after all this time (as many still do) is because playing the game is beneficial to our mental health. According to neurologist Judy Willis, the game has two dopamine boosters: the opportunity to make predictions, and the sense of achievement. The brain loves to make predictions, even if they aren't always right—and with new blocks spawning after every move you make, the possibilities are endless. Furthermore, the game is challenging (and slightly dependent on luck), but just enough that it's entertaining and rewarding at the same time. What it does This upscaled version of the original tile-sliding game has a twist: two identical blocks can only merge if exactly one block separates them! Players use the arrow keys to slide numbered blocks around, with the goal of merging the blocks into 177147 (which is 3^11) or more. Try to get the highest score as well! Merging specifics The new value of the merged block is the next power of 3. The middle block remains where it is, and the merged block appears in the direction the player slid the blocks in. For example, if a row of three consecutive blocks 3 9 3 were slid to the left, it would become 9 9 0 (the 0 is a placeholder), whereas if it were slid to the right, it would become 0 9 9 instead. Score specifics Your score goes up by the value of the new block(s) merged. For exampl"
      }
    ]
  },
  {
    "file_path": "./devposts/tba-asjk6y.html",
    "project_id": "tba-asjk6y",
    "title": "Ripply",
    "tagline": "Effortlessly unlock the world of crypto. A seamless chatbot experience that revolutionizes Ripple wallet management, making it accessible to billions. It's as easy as texting your best friend! 💬",
    "hackathon": "",
    "built_with": [
      "ai",
      "amazon-web-services",
      "blockchain",
      "canva",
      "chatgpt",
      "cohere",
      "crypto-change",
      "css3",
      "domain.com",
      "flowchart",
      "generative",
      "html5",
      "llm",
      "machine-learning",
      "microsoft-cloud",
      "nft",
      "ripple",
      "token",
      "voiceflow",
      "xrpl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of Co:here, Best use of XRP, Healthcare Hack, Sustainability Hack, Best use of Domain",
      "use of Microsoft Cloud, and Best Sustainability Hack",
      "Sustainability Hack:",
      "s at this hackathon, including the Best use of Co:here, Best use of XRP, Healthcare Hack, Sustainabi",
      "MetHacks 2023WinnerBest use of XRP",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/472/458/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 🤔 Problem Statement Cryptocurrencies and NFTs are growing rapidly, offering investment and asset management opportunities.\nHowever, challenges like complexity and unfriendly interfaces in platforms such as Ripple hinder their widespread adoption. Only 16% of Americans own cryptocurrencies, and lack of understanding is the primary reason for non-ownership. The steep learning curve of platforms like Ripple affects efficiency and productivity and creates frustration among users. The industry needs to develop more accessible and user-friendly interfaces for both novice and experienced users. Lack of user-friendly interfaces inhibits the growth of Ripple, NFTs, and financial inclusion. Addressing this issue is critical for the growth of the digital asset market and the promotion of financial inclusion. Developing accessible and user-friendly interfaces would streamline user experience, empower individuals to participate in the digital economy, and drive innovation. 💡 Inspiration The inspiration for Ripply is the need to address the challenges faced by millions of people trying to navigate the complex world of cryptocurrencies and NFTs. The current platforms, including Ripple, are not user-friendly or accessible enough, with lack of understanding being the primary reason for non-owners. The goal is to revolutionize the way people interact with Ripple and manage their NFTs by introducing an innovative alternative chatbot UI that simplifies the entire process. The solution aims to make Ripple transactions and NFT management effortless for users of all ages and backgrounds, eliminating the steep learning curve and confusion commonly associated with existing interfaces. The project aims to increase the adoption rate of cryptocurrencies and NFTs, ultimately promoting financial inclusion and driving the growth of the digital asset market. The project is motivated by the potential to have a substantial impact on the lives of countless individuals, includi"
      }
    ]
  },
  {
    "file_path": "./devposts/tax-the-width.html",
    "project_id": "tax-the-width",
    "title": "IntelliPark",
    "tagline": "Parking spaces are all the same size, but cars are not. We 3D measure cars at the gate and dynamically adjust the size of parking lots. Therefore, you only occupy the space your car needs.",
    "hackathon": "",
    "built_with": [
      "opencv",
      "pygame",
      "python",
      "raspberry-pi",
      "scikit-learn",
      "scipy",
      "time-of-flight-camera"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Winner - Free Track Created by Justus Beck Julius Hege D Schlichting",
      "Track Winner - Free Track Created by Justus Beck Julius Hege D Schlichting",
      "Hackaburg 2023WinnerTrack Winner - Free Track",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/489/359/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Originating from Munich, a city with its fair share of parking issues, our team recognized a pervasive problem. Everyone has a right to drive and park in the city, but the current system lacks efficiency. Cars vary greatly in size, yet the parking spaces allocated for them do not. This discrepancy leads to inefficient use of space and often favors larger vehicles, which occupy more space but pay the same rate. We envisioned an intelligent parking system that could optimize space use and promote environmental sustainability. This concept led us to develop IntelliPark.\nIntelliPark is designed to dynamically size parking lots to accommodate the actual size of cars. This approach not only maximizes the utilization of parking space but also encourages the use of smaller, more eco-friendly vehicles. In creating IntelliPark, our goal is to improve urban commuting, reduce environmental impact, and bring innovation to the parking industry. What it does IntelliPark revolutionizes parking by implementing a dynamic parking system at the entrance of each lot. Equipped with a state-of-the-art 3D camera developed by Infineon ( https://www.infineon.com/cms/en/product/sensor/tof-3d-image-sensors/ ), the system scans incoming vehicles to determine their dimensions including height and width. This is achieved through sophisticated computer vision algorithms.\nAfter assessing each vehicle's size, IntelliPark assigns an appropriately sized parking space, optimizing the use of available space. In a departure from traditional parking fee structures, our system calculates parking costs based on the actual space a vehicle occupies. This means larger vehicles incur higher parking fees.\nThis approach has a two-fold benefit: it discourages the use of larger vehicles in the city, thus reducing congestion, and it promotes efficient use of urban space. This is a Pigouvian tax similar to carbon taxation. By incentivizing smaller, more fuel-efficient cars, IntelliPark also contributes to"
      }
    ]
  },
  {
    "file_path": "./devposts/tateism.html",
    "project_id": "tateism",
    "title": "Tateism",
    "tagline": "Take the red pill with Tateism",
    "hackathon": "",
    "built_with": [
      "clerk",
      "go",
      "next.js",
      "render",
      "retell",
      "shadcn",
      "tailwindcss",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall, Most Likely Meme Startup, WBUOT, LAKOG, WPPOIL, Most IQ Points lost, Bill Zhang's x Retell",
      "s Winner (TPIA) this project is awesome Created by I worked on front-end of some of the website page",
      "brainrot jia.seed hackathon ($5,772) in prizesWinner(TPIA) this project is awesome",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/165/093/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Chill Guy Zone Main page Sign-up page with GIF Login page with GIF Welcome Page Chatbot/Caller Page GenZ Quiz V-Bucks Chill Guy Zone Main page Sign-up page with GIF Login page with GIF Welcome Page Chatbot/Caller Page GenZ Quiz V-Bucks Chill Guy Zone 1 2 3 4 5 6 7 8 9 Project Categories for submission: Best Overall, Most Likely Meme Startup, WBUOT, LAKOG, WPPOIL, Most IQ Points lost, Bill Zhang's x Retell Best Conversational AI, I'm just a chill guy, UI/UX most kawaii, nosu.io If you do call the AI, please keep the conversation under 2 mins. If it doesn’t work at first, please try calling again a couple more times. It’s hosted on render where it gets suspended temporarily if it hasn’t been called for 15 mins. Inspiration By the oncoming downfall of our braincells and the coming generation and recent controversies of Andrew Tate . What it does Encourage brainrot and your ability to fit into the gen-z norms How we built it First of all, we would like to thanks Beyonce because, without her, this project is almost impossible to make.\nSecondly, we built the front-end using NextJS, Tailwind CSS and permanently borrowing some UI components from Shadcn. For calling the Top G we used GO for the backend coz duh! what else? Challenges we ran into It was kinda hard at first to deploy the go backend on render.com. In addition, the call feature may only work for some limited time which is to be noted (1 hr free trial). Accomplishments that we're proud of We successfully developed and deployed a live voice agent using Twilio and Retell AI to facilitate AI phone calling all in a fleshed out web app integrating a chatbot, clerk for authentication and lots of meme easter eggs. What we learned We learned more about using Shadcn with Next.js and how to successfully implement a server that facilitates a conversation between an AI and user. What's next for Tateism What’s next, is to explore further the capabilities of retell AI’s features like its transcripts and audio storage and also t"
      }
    ]
  },
  {
    "file_path": "./devposts/tbd-7wax6h.html",
    "project_id": "tbd-7wax6h",
    "title": "FridgeSmartly",
    "tagline": "Manage your fridge smartly anytime, anywhere",
    "hackathon": "",
    "built_with": [
      "echo3d",
      "express.js",
      "javascript",
      "mongodb",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Lifestyle Track Prize Best Use of Echo3D Prize Main Frame Individual Item Detailed View Input User",
      "USE OF ECHO3D AND BEST LIFESTYLE TRACK FridgeSmartly (and how can I eat food more sustainably?) Wha",
      "“Lifestyle” Hack Winner Best Echo3d AR Hack Created by Shrey Kharbanda Vivi Wei Brayton Lordianto K",
      "OF BEST USE OF ECHO3D AND BEST LIFESTYLE TRACK FridgeSmartly (and how can I eat food more sustainab",
      "Best “Lifestyle” Hack Winner Best Echo3d AR Hack Created by Shrey Kharbanda Vivi Wei Brayton Lordia",
      "Best Use of Echo3D Prize Main Frame Individual Item Detailed View Input User Form when clicked on '",
      "DivHacks 2022: GreenscreenWinnerBest “Lifestyle” HackWinnerBest Echo3d AR Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/236/608/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Working of echo3D in our App to know what's in the Fridge quickly Best Lifestyle Track Prize Best Use of Echo3D Prize Main Frame Individual Item Detailed View Input User Form when clicked on '+' button Working of echo3D in our App to know what's in the Fridge quickly Best Lifestyle Track Prize Best Use of Echo3D Prize Main Frame Individual Item Detailed View Input User Form when clicked on '+' button Working of echo3D in our App to know what's in the Fridge quickly 1 2 3 4 5 6 7 WINNER OF BEST USE OF ECHO3D AND BEST LIFESTYLE TRACK FridgeSmartly (and how can I eat food more sustainably?) What it does The FridgeSmartly app is a tracker app that teaches its users to become less wasteful food consumers by keeping track of their fridges. It allows users to manage their fridges anytime, anywhere, so they won't buy extra food or forget about expiring food. Users can add items to the fridge list when they do grocery. The list will keep track of items in the fridge and could also alert the user when an item in the fridge is going to expire. How we built it We used Swift to build an app allowing users to input food items they buy, along with their quantity, and expiry date into a form (using the '+' button). Once they input their items into the app, the app inputs expiry dates into a server (built through Express) and adds the expiry date into the item's data on the app. The user can also then click on a particular object to get a detailed view of the food they purchased. Later, they can also access the AR - 3D models (built through Echo3D) to better visualize their foods. This way the user can utilise the food items based on the number of days to expiry and prevent food and monetary wastage. Challenges we ran into Within just 24 hours, we had some problems connecting the front end to the backend because we built them in different technologies and languages, and the requests sent to the backend from the frontend could be difficult to implement. We also had some problems with"
      }
    ]
  },
  {
    "file_path": "./devposts/tba-z5dkvc.html",
    "project_id": "tba-z5dkvc",
    "title": "MintBuddy",
    "tagline": "MintBuddy makes minting NFTs so easy, even your grandma can do it.Unleash the power of LLM, Generative AI, NLP, and Blockchain in a user-friendly package to make NFTs accessible to everyone!",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "chatbot",
      "cloudfront",
      "crypto",
      "css",
      "css3",
      "domain.com",
      "flowchart",
      "generative",
      "github",
      "html",
      "llm",
      "midjourney",
      "mint",
      "natural-language-processing",
      "openai",
      "verbwire",
      "voiceflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Generative AI, Best Blockchain Hack, Best Use of Verbwire, and Best Accessibility Hack",
      "Blockchain Hack: We've successfully tackled the problem of complexity and lack of accessibility in",
      "Accessibility Hack: We've made creating and generating NFTs easy, even for people without any techn",
      "s at this hackathon, including the Best Generative AI, Best Blockchain Hack, Best Use of Verbwire, a",
      "DeerHacks 2023WinnerBest Blockchain Project Using Hedera",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/468/962/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 🤔 Problem Statement The complexity of cryptocurrency and blockchain technology can be intimidating for many potential users. According to a survey by Finder, 36% of Americans are not familiar with cryptocurrencies, and 29% find it too complicated to understand. BitBuddy aims to create an easy-to-use, AI-driven chatbot that simplifies transactions and interactions with cryptocurrencies, using natural language processing and cutting-edge technology like OpenAI and ChatGPT. Research shows that 53% of people feel intimidated by the complexities of cryptocurrency and blockchain technology. BitBuddy aims to make crypto accessible to everyone by creating a system that allows users to send funds, mint NFTs, and buy crypto through a simple chat interface. BitBuddy aims to break down the barriers to entry that have traditionally limited the growth and adoption of crypto, making it more accessible to a wider range of people. 💡 Inspiration Shared passion for blockchain technology and its potential to revolutionize finance. Desire to simplify the process of interacting with cryptocurrencies and make it accessible to everyone. Belief in the potential of chatbots and natural language processing to simplify complex tasks. 🤖 What it does MintBuddy is a blockchain chatbot that simplifies the process of minting NFTs. It guides users through the process step-by-step using Voiceflow and Midjourney APIs. Users provide name, description, wallet address, and image URL or generate an NFT using Midjourney. The bot will mint the NFT and provide a transaction hash and ID, along with URLs to view the NFT on block explorers and OpenSea. It is compatible with various different chains and eliminates the need for users to navigate complex blockchain systems or switch between platforms. MintBuddy makes minting NFTs easy and accessible to everyone using AI-driven chatbots and cutting-edge APIs. 🧠 How we built it MintBuddy simplifies the process of interacting with cryptocurrencies and"
      }
    ]
  },
  {
    "file_path": "./devposts/tba-ryu6en.html",
    "project_id": "tba-ryu6en",
    "title": "MintBuddy",
    "tagline": "MintBuddy makes minting NFTs so easy, even your grandma can do it! Unleash the power of LLM, Generative AI, NLP, and Blockchain in a user-friendly interface to make NFTs accessible to everyone!",
    "hackathon": "",
    "built_with": [
      "ai",
      "amazon-web-services",
      "canva",
      "chatbot",
      "chatgpt",
      "cloudfront",
      "crypto",
      "css",
      "domain.com",
      "flowchart",
      "generative",
      "github",
      "html",
      "llm",
      "midjourney",
      "mint",
      "natural-language-processing",
      "openai",
      "s3",
      "stablediffusion",
      "token",
      "verbwire",
      "voiceflow",
      "yaml"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Generative AI, Best Blockchain Hack, Best Use of Verbwire, and Best Accessibility Hack",
      "Blockchain Hack: We've successfully tackled the problem of complexity and lack of accessibility in",
      "Accessibility Hack: We've made creating and generating NFTs easy, even for people without any techn",
      "Use of Verbwire Winner 2nd Place (One for Generative AI and One for Blockchain) Created by Built ou",
      "Best Use of Verbwire Winner 2nd Place (One for Generative AI and One for Blockchain) Created by Bui",
      "s at this hackathon, including the Best Generative AI, Best Blockchain Hack, Best Use of Verbwire, a",
      "Treasure Hacks 3.5WinnerBest Use of VerbwireWinner2nd Place (One for Generative AI and One for Blockchain)",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/468/963/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Problem Statement The complexity of cryptocurrency and blockchain technology can be intimidating for many potential users. According to a survey by Finder, 36% of Americans are not familiar with cryptocurrencies, and 29% find it too complicated to understand. BitBuddy aims to create an easy-to-use, AI-driven chatbot that simplifies transactions and interactions with cryptocurrencies, using natural language processing and cutting-edge technology like OpenAI and ChatGPT. Research shows that 53% of people feel intimidated by the complexities of cryptocurrency and blockchain technology. BitBuddy aims to make crypto accessible to everyone by creating a system that allows users to send funds, mint NFTs, and buy crypto through a simple chat interface. BitBuddy aims to break down the barriers to entry that have traditionally limited the growth and adoption of crypto, making it more accessible to a wider range of people. Inspiration Shared passion for blockchain technology and its potential to revolutionize finance. Desire to simplify the process of interacting with cryptocurrencies and make it accessible to everyone. Belief in the potential of chatbots and natural language processing to simplify complex tasks. What it does MintBuddy is a blockchain chatbot that simplifies the process of minting NFTs. It guides users through the process step-by-step using Voiceflow and Midjourney APIs. Users provide name, description, wallet address, and image URL or generate an NFT using Midjourney. The bot will mint the NFT and provide a transaction hash and ID, along with URLs to view the NFT on block explorers and OpenSea. It is compatible with various different chains and eliminates the need for users to navigate complex blockchain systems or switch between platforms. MintBuddy makes minting NFTs easy and accessible to everyone using AI-driven chatbots and cutting-edge APIs. How we built it MintBuddy simplifies the process of interacting with cryptocurrencies and blockchain te"
      }
    ]
  },
  {
    "file_path": "./devposts/tbd-p9xqhv.html",
    "project_id": "tbd-p9xqhv",
    "title": "LocalEyes",
    "tagline": "Discover and support with the 400 million local businesses around the world for both a healthy economy and a healthy planet - hyper personalized to every user, while getting rewarded for it! 💹🌎",
    "hackathon": "",
    "built_with": [
      "cohere.ai",
      "daisyui",
      "fastify",
      "geojson",
      "google-places",
      "json-web-token",
      "jsonschema",
      "mapbox",
      "mongodb",
      "sveltekit",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Sustainable Travel Hack Created by Formulated the business plan, helped build the frontend, and fil",
      "First Overall Winner Best Sustainable Travel Hack Created by Formulated the business plan, helped b",
      "MapHacks 2WinnerFirst OverallWinnerBest Sustainable Travel Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/480/468/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "If the answer is incorrect, as displayed here, the quiz will display the correct answer. This promotes user experience and education. This is our landing page. Nearby locations are displayed, as well as displaying our Home, Leaderboard, Login and Filters buttons. The dropdown menu on the right displays filters such as \"Wheel Chair Accessibility\" as well as potential points of interest. At the core of our website are the nearby attractions, which at quick glance provides general info to help compare with one another. Once a location is selected, a title, image, detailed description, location, rating, and distance from current location is displayed. Underneath the location's core information is a map displaying the location with a \"black pin\" and the user with a \"red pin\" Once you are within 1km of the location, a quiz will appear as displayed in this image, prompting the user to submit an answer. If the answer is incorrect, as displayed here, the quiz will display the correct answer. This promotes user experience and education. This is our landing page. Nearby locations are displayed, as well as displaying our Home, Leaderboard, Login and Filters buttons. The dropdown menu on the right displays filters such as \"Wheel Chair Accessibility\" as well as potential points of interest. At the core of our website are the nearby attractions, which at quick glance provides general info to help compare with one another. Once a location is selected, a title, image, detailed description, location, rating, and distance from current location is displayed. Underneath the location's core information is a map displaying the location with a \"black pin\" and the user with a \"red pin\" Once you are within 1km of the location, a quiz will appear as displayed in this image, prompting the user to submit an answer. If the answer is incorrect, as displayed here, the quiz will display the correct answer. This promotes user experience and education. 1 2 3 4 5 6 7 8 Inspiration: The inspiration beh"
      }
    ]
  },
  {
    "file_path": "./devposts/teachmate.html",
    "project_id": "teachmate",
    "title": ".",
    "tagline": ".",
    "hackathon": "",
    "built_with": [
      "."
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": ". Built With . Submitted to CruzHacks 2024 Created by Vedant Garg Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Kosei Tsukamoto"
      }
    ]
  },
  {
    "file_path": "./devposts/tbd-kvpb91.html",
    "project_id": "tbd-kvpb91",
    "title": "Sign Ease",
    "tagline": "Let's cut the barriers to communication!",
    "hackathon": "",
    "built_with": [
      "github",
      "mediapipe",
      "opencv",
      "python",
      "react",
      "scikit-learn",
      "streamlit",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Third Overall Created by Tanish S Arihan Varanasi Full-Stack ML Developer with a knack for design a",
      "Hack Your PortfolioWinnerThird Overall",
      "integrating with Streamlit, it was our first time",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/496/730/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "MongoDB Database to store Quiz Results Sign Ease React Web Homepage React Web Dashboard Quiz Question Quiz Results MongoDB Database to store Quiz Results Sign Ease React Web Homepage React Web Dashboard Quiz Question Quiz Results MongoDB Database to store Quiz Results 1 2 3 4 5 6 7 💡 Inspiration As developers, we've always been passionate about using technology to make a positive impact on society. When we learned about the challenges faced by people who use sign language to communicate, and the difficulty they often have in accessing technology that can help them, it really struck a chord with us. We were inspired by the incredible resilience and creativity of people who use sign language to communicate every day, despite facing significant barriers in their daily lives. We knew that there had to be a way for technology to help bridge this gap and enable more people to communicate more easily, more confidently, and more comfortably. That's what led us to start working on this project. By using machine learning to identify sign language gestures, we believe that we can create a tool that is truly transformative for people who use sign language. It has the potential to break down barriers, to enable more inclusive communication, and to empower individuals to express themselves in ways they may not have thought possible before. This project has brought together our passion for technology with our commitment to inclusivity , accessibility , and social impact . We are proud to be working on something that has the potential to make a real difference in people's lives, and we're excited to see where it goes from here As we continued to work on this project, we were struck by the potential for it to create opportunities for people who use sign language. By providing a more accurate and robust way to interpret sign language gestures, we believe that our system can open up new possibilities for communication, education, and employment. Imagine being able to attend a lecture "
      }
    ]
  },
  {
    "file_path": "./devposts/team-058.html",
    "project_id": "team-058",
    "title": "StockOverflow",
    "tagline": "Markets are made by the fastest: We analyze news and the market way faster than a large language model ever could.",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "hackaTUM 2023WinnerOptiver",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "After countless late-night coding sessions fueled by caffeine and determination, our team proudly presents a market-making solution that is both very simple and effective. In a world where risk-taking is the norm, we decided to play it smart by operating in the background, orchestrating the market to churn out profits. Our main strategy is as straightforward as it gets—we aim to be the Usain Bolt of trading, the fastest in the game. Our bread and butter? Arbitrage from dual-listed stocks. We've fine-tuned a simple approach that cuts through the noise, allowing us to ride the waves of market discrepancies with precision. No fancy language models here—those take up too much precious time and performance. Instead, we opted for well-tuned classic machine learning algorithms, quick and efficient like a well-oiled machine. How did we pull it off? Picture a motivated, sleep-deprived team of four, each laser-focused on their part of the puzzle. We dived into a sea of experiments, optimizing and tuning our simple algorithm until it was as sharp as a razor's edge. Along the way, we explored various ML approaches, discarding the complex ones for the sweet spot of performance and speed. Challenges? Oh, we had our fair share. Perfecting the ML model was like walking on a tightrope—little training data, big expectations. Testing our market simulation theories in a constantly changing landscape added another layer of complexity. But hey, challenges are just opportunities in disguise, right? Our proudest accomplishment? We're almost always holding no stock at all. We're not risking it all; we're making the market itself. What did we learn? Market making and quantitative trading became our second language. We also learned the art of persistence in a cutthroat environment. Never giving up became our mantra, and it paid off. Built With python Submitted to hackaTUM 2023 Winner Optiver Created by Paskal Thomas Samuel Leßmann Marius Jacobs Niels Glodny"
      }
    ]
  },
  {
    "file_path": "./devposts/td-hospital-exploration-81se7k.html",
    "project_id": "td-hospital-exploration-81se7k",
    "title": "TD Hospital Exploration",
    "tagline": "the TD Hospital Exploration Prompt",
    "hackathon": "",
    "built_with": [
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/643/841/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Loss per Iteration Graph Accuracy Per Iteration Graph Loss per Iteration Graph Accuracy Per Iteration Graph Loss per Iteration Graph 1 2 The Journey through TD Hospital Exploration Everyone in the group is pretty new to machine learning as a whole. For us, this is the first time making any kind of model that could actually have real-world applications. The sample code was very useful. ChatGPT was a very useful tool to learn what each section of code did, and it was a big help in teaching us how to use things like TensorFlow. Over the course of the challenge, the code and strategy changed quite a bit. At first, we used linear regression to select data columns that could be useful for this application. One of us decided to experiment with the training code and, after inputting some values into the model_train.py file, they had to show everyone else how to use it. The first strategy employed by us was to randomly select values to plug into the training function. We experimented with picking random values and learning more about how the two files are supposed to interact. The only real problem was that the accuracy was quite low. After some time, we decided to ask ChatGPT for some tips on how to choose better values. One of the suggestions we got was to use SelectKBest (for Classification/Regression). There were some data issues where some values were objects. We learned that objects can't be used as inputs for a model, and they have to be floats. So, we used the pandas library to map certain values like \"male\" to 1 and \"female\" to 0. After imputing all the NaN values from the dataset, we were ready to train the bot. Once the data was converted into float values, they could be used to train the model as well. From what we understood, SelectKBest seems to be a decent algorithm for taking a column and comparing it to another column (the death column). We made it select the top 10 values that are most correlated with the death column. As stated previously, our first strate"
      }
    ]
  },
  {
    "file_path": "./devposts/teamnamenumber5.html",
    "project_id": "teamnamenumber5",
    "title": "COVID-Chat",
    "tagline": "This is the COVID-19 chatbot created for the NIV Hawaii by TeamNameNumber5",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Copyright (c) 2020 TeamNameNumber5 Permission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software. THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE. Built With css html javascript Try it out GitHub Repo Submitted to HACC 2020 Created by I worked on the javascript aspect of the project along with Xhavier pertaining to the questions and responses the bot will reply to. I also worked on the l overview video of this project. Joss Mikeal Picardal Xhavier Teocson destinyshishido"
      }
    ]
  },
  {
    "file_path": "./devposts/techtutor.html",
    "project_id": "techtutor",
    "title": "TechTutor",
    "tagline": "Our voice-activated app is designed to make technology accessible and easy for everyone regardless of their experience. Get answers to all your questions from basic computer skills to advanced topics.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "figma",
      "flask",
      "python",
      "pytorch",
      "react",
      "react-speech-kit",
      "sqlalchemy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of NLP with Cohere Winner Google Developers Student Club Challenge Created by Sungjin Hong Naye",
      "Best Use of NLP with Cohere Winner Google Developers Student Club Challenge Created by Sungjin Hong",
      "Hackville 2023WinnerBest Use of NLP with CohereWinnerGoogle Developers Student Club Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/378/700/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration A desire to help close the digital divide between older and younger generations and ensure that everyone has access to the benefits of technology. The goal of the voice assistant would be to provide a user-friendly, accessible, and efficient way for elderly people to learn about and use technology. By making technology more accessible, the aim is to empower older people to stay connected with loved ones, access important information, and improve their quality of life. What it does With simple voice commands you can get specialized answers to all your tech questions based on the given inputs about your comfort levels with various technologies. It also lets you take a picture of the tech you are struggling with to classify it for a more customized response. The web app is very easy to use with an intuitive UI and large and easy-to-read text. How we built it The backend was built using Python-Flask and SQLAlchemy. We trained Cohere's generate API using sample inputs and the user's inputs about their comfort levels for more customer responses. We used a convolutional neural network built using PyTorch and trained it with the CIFAR-100 dataset with 60000+ classified images for the image classification. We used React for the frontend and did the text-to-speech and speech-to-text using React-Speech-Kit. We also used React to take an image and send it to the backend for classification. The frontend UI was based on a prototype designed using Figma. Challenges we ran into We struggled a lot with building the neural network from scratch. This was our first time making our own machine learning model and in the past, we had always just called APIs. Converting the image into a numerical tensor of an appropriate shape to fit the first layer of the neural network was also something we struggled with. Finally, we struggled with using React to access the camera to take an image. It was also difficult to send it to the backend in an appropriate format for processing. Accom"
      }
    ]
  },
  {
    "file_path": "./devposts/teammate-hbyslf.html",
    "project_id": "teammate-hbyslf",
    "title": "Teammate",
    "tagline": "Friends that help you move forward",
    "hackathon": "",
    "built_with": [
      "cocoapod",
      "figma",
      "firebase",
      "firestore",
      "swift"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/283/615/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "UI/UX wireframes Inspiration State universities tend to be very large. In-state students go in already having an established network with their friends from childhood and high school, who can introduce them to their other friends. Out-of-state and international students have a much harder time as they come in without any existing network. Teammate removes a need for an established connection and help people make friends that can help them move forward. In the larger scheme of things, Teammate also helps foster a more collaborative university environment by connecting users with people sharing their academic and personal interests. What it does During the onboarding process, users input the classes they are currently enrolled in, clubs and organizations they are involved in, and their interests, all of which is used to match users with others of similar interests. Users are then prompted to enter a short bio about themselves. After a user is fully onboarded, they can then swipe through potential teammates. Matching classes, clubs, or interests will be shown to each user, along with the user’s bio. Users can elect to message potential teammates through our chat service and connect with them, but if they are not interested then they can continue swiping through their matches. Once a user messages a potential teammate, the conversation shows up in the inbox page. This is also where users can message specific users on the platform to get to know them better, learn from them, and schedule in-person meetings. How we built it The user experience makes or breaks an application, which is why we started by designing the flow of our app before thinking about anything else. We used Figma to create wireframes of the UI and develop an experience that is simple and intuitive to use. Using the UX flow we created in Figma, we designed our database in Firestore. In addition, we used Firebase’ authentication solution to manage users. We set up a domain restriction that only allows user"
      }
    ]
  },
  {
    "file_path": "./devposts/team-representative-assistant.html",
    "project_id": "team-representative-assistant",
    "title": "Team Representative Assistant",
    "tagline": "Skip the meeting, not the insight—let AI be your team’s voice.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "firebase",
      "gemini",
      "mongodb",
      "python",
      "selenium",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/331/428/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration In today's fast-paced work environment, inefficient meetings consume valuable time and resources, leading to reduced productivity and increased costs. This solution aims to streamline the meeting process by leveraging AI to reduce unnecessary discussions, ensuring better-prepared sessions and more effective collaboration. What it does Request Team Agent : Users can request a meeting with a team agent through the platform. Booking Appointments : The system facilitates scheduling appointments with the requested team agent. Pre-Meeting Preparation : The requested team receives the meeting questions in advance, allowing them to prepare effectively. They can upload relevant documents, which the AI agent uses for training. During the meeting, the AI agent can assist by providing answers and insights based on the uploaded notes, ensuring a productive session. How we built it Gemini AI : Used for natural language processing and document comprehension, allowing the AI assistant to analyze and respond to meeting-related queries efficiently. Streamlit : Built the user interface, providing an interactive and user-friendly web experience where users can request meetings, upload documents, and interact with the AI. Flask : Served as the backend framework, managing meeting requests, booking logic, and integrating the AI training pipeline to process and learn from uploaded documents. Firebase : Utilized for real-time data storage, authentication, and seamless synchronization of meeting schedules and document uploads across users, ensuring a smooth experience. Challenges we ran into Complex Integration : Merging the AI agent, booking system, and document processing pipeline posed a challenge, requiring efficient data flow and synchronization. Real-Time AI Training : Training the AI on uploaded documents dynamically before the meeting required efficient data handling and processing. Accomplishments that we're proud of We successfully completed the project,"
      }
    ]
  },
  {
    "file_path": "./devposts/teddy-ai.html",
    "project_id": "teddy-ai",
    "title": "Teddy.ai",
    "tagline": "Teddy.ai is the future of companionship, empowering children with the magic of blockchain through NFTs and FLOW, ensuring no child feels alone.",
    "hackathon": "",
    "built_with": [
      "audio/video",
      "beautiful-soup",
      "flow",
      "hardware",
      "openai",
      "opencv",
      "python",
      "starknet",
      "verbwire",
      "wearable"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Use of Flow Created by Integrated FLOW transactions, Verbwire NFT minting, and Starknet",
      "DeltaHacks XWinner[MLH] Best Use of Flow",
      "Working with Cadence as well as Flow Client Library for the first time. 💻",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/717/165/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Starknet Teddy.ai NFT collection! Teddy Prototype Mint NFT Verbwire API Send FLOW with Teddy Starknet Teddy.ai NFT collection! Teddy Prototype Mint NFT Verbwire API Send FLOW with Teddy Starknet Teddy.ai NFT collection! 1 2 3 4 5 6 7 Inspiration 🌈 According to mentalhealth.uk, over 45% of children asked said they felt lonely 'often' or 'some of the time'. That is way too high in our team's opinion. At Teddy.ai, our inspiration is simple yet powerful: to ensure that no child or individual ever feels lonely. We believe in harnessing the potential of technology to create companionship, connection, and a brighter future for everyone. 🤗 What It Does 🐻 Teddy.ai is not just a teddy bear; it's a gateway to a world of possibilities. 🌌 It leverages the blockchain to introduce children to concepts like NFTs and FLOW tokens through fun and interactive experiences, while also leveraging Starknet to ensure privacy and scalability. 🧸🔗 Teddy.ai is your child's snuggable best friend who understands them, rewards positive behavior, and ensures no child feels alone. 🎉 With Teddy.ai, you can now seamlessly integrate your social media links and personal websites, allowing the bear to know all the details about its owner's life. It's like having a friend who truly understands you! 📱🌐 How We Built It 🛠️ We built Teddy.ai with a combination of cutting-edge technologies: Verbwire API : Utilized for minting NFTs of precious memories in real-time. 🖼️ Flow Blockchain : Integrated to enable transactions through speech, making it accessible for children. 🗣️ OpenAI Language Models (LLMs) : Utilized OpenAI's language models for understanding and responding to users. 🤖 OpenAI Whisper : Employed for Speech-to-Text (STT) functionality. 🎤 Beautiful Soup : Used for web scraping to gather information. 🕸️ Elevenlabs : Leveraged for Text-to-Speech (TTS) capabilities. 🔊 OpenCV : Captured memories with a user's webcam. 📸 Sounddevice : Recorded audio from interaction between the user and their teddy. 🎶 Stark"
      }
    ]
  },
  {
    "file_path": "./devposts/teambuilder-qst0jm.html",
    "project_id": "teambuilder-qst0jm",
    "title": "SoftSkillBoost",
    "tagline": "Enhancing Job Seekers' Soft Skills and Team Dynamics in the 21st Century Job Market",
    "hackathon": "",
    "built_with": [
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/397/533/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In today's job market, possessing both technical and soft skills like communication, critical thinking, and problem-solving abilities is crucial for success. However, many job seekers struggle to showcase their soft skills during the interview process, and employers often lack effective tools to assess and train their employees in these areas. That's why the SoftSkillBoost, formerly Team InterviewerReviewer and Team Recruiter Skills, projects were born - to provide innovative and comprehensive tools to bridge this gap and help job seekers and employers succeed. What it does InterviewerReviewer is an AI-powered tool that simulates a natural feeling interview environment and evaluates interviewee's responses while providing constructive feedback. The tool assesses not just what candidates say, but also how they say it and how they respond to difficult questions. Additionally, InterviewerReviewer offers interview education resources to help candidates prepare and present their best selves during the interview process. The ultimate goal of InterviewerReviewer is to help job seekers improve their communication skills and increase their chances of success in landing their dream job. Team Recruiter Skills is an educational tool that helps job seekers understand the mindset of an interviewer and improve their job search strategies. It provides a series of interactive modules that teach job seekers how to research job openings, tailor their resume and cover letter to specific job postings, prepare for interviews, and negotiate job offers. Team Recruiter Skills also offers resources for employers to assess and train their employees in these areas. The ultimate goal of Team Recruiter Skills is to help job seekers and employers understand each other's perspectives and succeed in the hiring process. How we built it InterviewerReviewer utilizes advanced technologies such as Cohere NLP API and Google Cloud speech-to-text to create a natural feeling interview environmen"
      }
    ]
  },
  {
    "file_path": "./devposts/ted-the-bear-therapeutic-robot.html",
    "project_id": "ted-the-bear-therapeutic-robot",
    "title": "TED the Bear - Therapeutic Robot",
    "tagline": "TED the Bear is an AI-powered therapy robot designed to provide emotional support through speech recognition, real-time emotional analysis, and personalized AI-driven counseling.",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c++",
      "fastapi",
      "javascript",
      "opencv",
      "python",
      "raspberry-pi",
      "react",
      "steppermotors",
      "supabase",
      "typescript",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/255/697/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 🧸 TED the Bear – AI-Powered Therapy Robot 🔹 Inspiration Mental health challenges are increasing, yet access to therapy remains limited. We wanted to create an AI-driven emotional support companion that provides comfort, conversation, and personalized counseling. TED the Bear is designed to hug users, recognize emotions, and generate AI-driven responses, making therapy more accessible and engaging. 🔹 What We Learned Building TED the Bear pushed our understanding of multimodal AI, robotics, and real-time interaction systems. We explored:\n✅ Emotion recognition to tailor responses\n✅ Speech-to-text & text-to-speech for natural conversation\n✅ AI-generated counseling with voice cloning\n✅ Lip-syncing avatars for immersive interaction\n✅ Motorized gestures for physical comfort This project gave us hands-on experience in integrating hardware with AI-driven software, requiring careful synchronization of sensors, motors, databases, and APIs. 🔹 How We Built It TED the Bear combines AI, robotics, and real-time processing to create an interactive therapy experience. Frontend: 🔹 React + Vite Backend: 🔹 FastAPI (CRUD functions) AI & Lip Sync: 🔹 Gooey.AI – Real-time lip-syncing avatar\n🔹 OpenCV + DeepFace – Facial & emotion recognition\n🔹 Whisper AI – Speech-to-text conversion Database: 🔹 Supabase (PostgreSQL) Robotics Integration with AI: 🔹 Raspberry Pi 4B – Wi-Fi-connected for real-time data exchange\n🔹 Microphone & Speaker – Captured user speech and played AI-generated responses\n🔹 Raspberry Pi Camera – Analyzed facial expressions for personalized responses\n🔹 Arduino – Controlled stepper motors & depth sensors (ultrasonic) for hugs 🔹 Challenges We Faced 🚧 Real-time processing – Ensuring smooth speech-to-text and AI-generated responses without noticeable lag.\n🚧 Emotion recognition accuracy – Fine-tuning DeepFace to recognize subtle facial expressions across different lighting conditions.\n🚧 Hardware synchronization – Coordinating Arduino, Raspberry Pi, and AI APIs for a s"
      }
    ]
  },
  {
    "file_path": "./devposts/team-burgerts-r6ongy.html",
    "project_id": "team-burgerts-r6ongy",
    "title": "Team Burgerts",
    "tagline": "Virtual reality toy car",
    "hackathon": "",
    "built_with": [
      "arduino"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Challenges we ran into: we could not configure the oculus as this were the first time we were using the oculus headset."
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration: We had all the machining tools that we could use up to come up with a great working project which could be helpful for all drivers while maintaining safety while driving. What it does: We basically created a virtual reality toy car How we built it: We machined the pedal and acceleration along with the handle which we created by laser cutting it. We added sensors which can detect the pressure onto the acceleration. We hard coded it using the arduino and udoo (for vision processing). Challenges we ran into: we could not configure the oculus as this were the first time we were using the oculus headset. Accomplishments that we're proud of: We were able to complete almost all of the project being something we indulged ourselves into for the first time like making something out using devices and mechanical technicalities. What we learned: Working as a large team, we learned rapid prototyping. What's next for Team Burgerts: We can just integrate everything with the actual computer part and improve some of the actual mechanical parts. Built With arduino Try it out GitHub Repo Submitted to MakeHarvard 2018 Created by I helped around in all the departments as this was first makethon, I got to learn a lot about the mechanical things that took place in the project and also tried confirguring the oculus to give user and experience with the virtual environment. Neha Jinwala I created the zed wifi link and engineered structural components Ryan Burgert I don’t have background in mechanical engineering, but I learned a lot from my peers and from the workshops that I attended yesterday. I helped around and learned how to work in machine shop. Trangle991 Mechanical engineer of the team. Worked on CAD designs and machining of the parts Oumaima Lamaakel Worked machining the pedal and breaks with takktile sensor Also worked on connecting the oculus rift to Facebook in order to connect to the car Yuki Yoshinaga Karishma Daga Brendan  Zotto"
      }
    ]
  },
  {
    "file_path": "./devposts/tenacity-icmohr.html",
    "project_id": "tenacity-icmohr",
    "title": "Tenacity",
    "tagline": "Be strong in the face of brutal insults.",
    "hackathon": "",
    "built_with": [
      "assemblyai",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Ever stared at an audio recording of a project for a class wondering if it was \"too mean\" or if you \"accidentally\" let an inappropriate joke slip out of your mouth? Tenacity is here to validate you! Our application will scan your audio file for a variety of different metrics - tone of voice, words that would get you fired, and even the number of times you stuttered. What it does Tenacity analyzes audio clips submitted by users and displays some of the more relevant insights for users to decide what to do with the clip. How we built it We built Tenacity with Vite and Create React App with the AssemblyAI API. We used Tailwind for styling and react-router for routing. Challenges we ran into Some misbehaving asynchronous Javascript was difficult to debug, and the loading states of the applications were occasionally difficult to manage when the files were too large. Accomplishments that we're proud of We're proud with our task delegation, Git management, and the funny reactions we got from friends when they were able to upload their own audio clips. Built With assemblyai react typescript Try it out GitHub Repo Submitted to Hack the North 2022 Created by Max Jiang Daniel Chen Andrew Chen Sophia Sun"
      }
    ]
  },
  {
    "file_path": "./devposts/ted-med-o2k789.html",
    "project_id": "ted-med-o2k789",
    "title": "Ted Med",
    "tagline": "The Teddy Bear That Cares.",
    "hackathon": "",
    "built_with": [
      "deepface",
      "fastapi",
      "langchain",
      "mediapipe",
      "opencv",
      "rag",
      "react",
      "robert",
      "supabase",
      "tailwind",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/292/310/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Hospitals can be overwhelming and even terrifying for children-- and for 93% of children it is. The sterile environment, unfamiliar faces, and intimidating medical procedures often make kids too scared, shy, or nervous to express what they’re feeling. This lack of communication leads to missed symptoms, delayed diagnoses, and inaccurate health records—problems that can directly impact a child’s health and well-being. I saw the severity of this issue firsthand through my brother, who worked as a patient care assistant for five years at the best children’s hospital in the U.S. When I spoke with him on friday, he told me that one of the biggest challenges he faced daily was getting children to communicate their symptoms. Kids, especially those who were sick, scared, or in pain, often couldn’t or wouldn’t talk about what was wrong. In response, his hospital had a dedicated system in place where patient care assistants, like my brother, would spend days at a time getting to know patients, building trust, and slowly extracting the critical health information needed for doctors to make informed decisions. But here’s the problem: 🚨 Most hospitals do not have the resources to do this.\n🚨 Doctors don’t have the time to spend hours earning a child’s trust.\n🚨 Missed or delayed diagnoses caused by communication gaps can be life-altering.\nAll children deserve a friend as approachable as my brother to communicate their medical needs. Ted Med is that solution. By combining AI, robotics, and best practices from literature, Ted helps kids open up about their symptoms in a way that feels natural, safe, and even fun—allowing doctors to focus on treatment rather than struggling to get answers. This isn’t just about making hospitals less scary. It’s about solving a real and urgent problem that affects millions of children every year. What It Does Ted Med is a breakthrough AI-powered interactive teddy bear that redefines pediatric healthcare by transforming the way children com"
      }
    ]
  },
  {
    "file_path": "./devposts/ted-med.html",
    "project_id": "ted-med",
    "title": "Ted Med",
    "tagline": "The Teddy Bear That Cares.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "deepface",
      "fastapi",
      "huggingface",
      "langchain",
      "mediapipe",
      "next.js",
      "opencv",
      "play.ht",
      "python",
      "raspberry-pi",
      "roberta",
      "supabase",
      "tailwind",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/283/724/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "MedSafetyBench Benchmark for Safety Architectural Diagram MedSafetyBench Benchmark for Safety Architectural Diagram MedSafetyBench Benchmark for Safety 1 2 3 Inspiration Hospitals can be overwhelming and even terrifying for children-- and for 93% of children it is . The sterile environment, unfamiliar faces, and intimidating medical procedures often make kids too scared, shy, or nervous to express what they’re feeling. This lack of communication leads to missed symptoms, delayed diagnoses, and inaccurate health records—problems that can directly impact a child’s health and well-being. I saw the severity of this issue firsthand through my brother, who worked as a patient care assistant for five years at the best children’s hospital in the U.S. When I spoke with him on friday, he told me that one of the biggest challenges he faced daily was getting children to communicate their symptoms. Kids, especially those who were sick, scared, or in pain, often couldn’t or wouldn’t talk about what was wrong. In response, his hospital had a dedicated system in place where patient care assistants, like my brother, would spend days at a time getting to know patients, building trust, and slowly extracting the critical health information needed for doctors to make informed decisions. But here’s the problem: 🚨 Most hospitals do not have the resources to do this. 🚨 Doctors don’t have the time to spend hours earning a child’s trust. 🚨 Missed or delayed diagnoses caused by communication gaps can be life-altering. All children deserve a friend as approachable as my brother to communicate their medical needs. Ted Med is that solution. By combining AI, robotics, and best practices from literature, Ted helps kids open up about their symptoms in a way that feels natural, safe, and even fun—allowing doctors to focus on treatment rather than struggling to get answers. This isn’t just about making hospitals less scary.\nIt’s about solving a real and urgent problem that affects millions of childre"
      }
    ]
  },
  {
    "file_path": "./devposts/temptalk-pdw2o6.html",
    "project_id": "temptalk-pdw2o6",
    "title": "ArguMentor",
    "tagline": "ArguMentor is an educational tool where inter-AI debates hone users' critical thinking and media literacy, offering an interactive platform to master the skill of distinguishing fact from fiction.",
    "hackathon": "",
    "built_with": [
      "flask",
      "openai",
      "python",
      "react",
      "sqlite",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of AI in Education Created by Michael Zhao Jonathan Vincentius Yenah Lee",
      "NewHacks 2023WinnerBest Use of AI in Education",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/662/004/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration In the era of digital education, students often seek innovative ways to reinforce their knowledge and enhance their understanding of complex subjects. To address this need, we embarked on a journey to create \"ArguMentor,\" a web application that offers an engaging and educational experience by harnessing the power of AI-driven chatbots. ArguMentor is designed to assist students in their revision process, making it more interactive and enjoyable. What it does ArguMentor is an innovative web application designed to transform the way students approach their revision process. By leveraging the power of AI-driven chatbots, ArguMentor provides students with an effective and engaging method to reinforce their knowledge and enhance their understanding of complex subjects. Key Features: Interactive Revision: ArguMentor offers an interactive platform for students to revise specific subject topics in a dynamic and engaging way. AI-Driven Debates: The platform harnesses the capabilities of AI language models to simulate debates on the chosen topics, challenging students to think critically and evaluate information. Critical Thinking: ArguMentor encourages students to critically evaluate the debates in order to identify inaccuracies and inconsistencies in the presented information. Constructive Feedback: To further enhance the learning process, the platform provides constructive feedback to students, aiding them in consolidating their current knowledge and addressing areas of improvement. How we built it ArguMentor was crafted by our dedicated team using a combination of cutting-edge technologies and innovative design. Here's a glimpse of the tools and technologies that powered our project: ReactJS: Our front-end is built using ReactJS, a popular JavaScript library for dynamically building user interfaces. It provides a dynamic and responsive user experience, making ArguMentor easy to navigate and interact with. Animations were created using Lottie React, Text"
      }
    ]
  },
  {
    "file_path": "./devposts/temptemp.html",
    "project_id": "temptemp",
    "title": "Frody",
    "tagline": "Frody is a distributed real-time credit card fraud detection service",
    "hackathon": "",
    "built_with": [
      "bigquery",
      "dbt",
      "gcp",
      "google-bigquery",
      "google-cloud-function",
      "java",
      "machine-learning",
      "pubsub",
      "python",
      "react",
      "spring",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Distributed Systems Hack -- Sponsored by Five Rings Created by I worked on integrating the BigQuery",
      "Most Technically Complex Hack Winner Best Distributed Systems Hack -- Sponsored by Five Rings Creat",
      "PennApps XXIVWinnerMost Technically Complex HackWinnerBest Distributed Systems Hack -- Sponsored by Five Rings",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/580/589/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "System Design Logo Landing Page System Design Logo Landing Page System Design 1 2 3 Inspiration According to the Federal Trade Commission (FTC), credit fraud is the most common form of identity fraud.  The increasing volume and frequency of trade pose a difficult challenge for firms in financial services to analyze real-time data to detect fraudulent transactions. A scalable and distributed data solution allows these business users to alert their customers, assuring the users that their transactional information is managed securely. What it does Frody is a microservice on the Google Cloud Platform that uses machine learning to flag and inform users on real-time transactional data. The user can \"subscribe\" to the transactional activities for multiple cards on a centralized dashboard, where they can monitor their transactional activities. If suspicious activity is detected with Frody's fraud detection model,  the users will be informed via text message immediately. How we built it We simulated real-time messaging service with Google Cloud Pub/Sub, using Java Spring Boot as a server-side application to stream randomly generated transactional data. Once the consumer of Pub/Sub persists the message to the Google Big Query database, then the message is checked for fraud via the machine learning model. If a fraudulent transaction is detected, the user will receive the transaction information on their phone via Twilio. Lastly, our centralized dashboard where users can \"subscribe\" to and monitor transactional activities for multiple cards is built using React. Challenges we ran into We had to learn how to use services of Google Cloud Platform and Twilio. These services brought us much difficulty as creating a microservice on GCP was not as simple as we thought. What's next A future development would be to further optimize our machine learning model for even more accurate detection of suspicious activity. We also intend to expand our microservice to other transaction methods "
      }
    ]
  },
  {
    "file_path": "./devposts/test-p7v9j5.html",
    "project_id": "test-p7v9j5",
    "title": "test",
    "tagline": "tesste",
    "hackathon": "",
    "built_with": [
      "test"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does How we built it tes Challenges we ran into Accomplishments that we're proud of What we learned What's next for test Built With test Created by Archimedes Li"
      }
    ]
  },
  {
    "file_path": "./devposts/test-project-5pxd1l.html",
    "project_id": "test-project-5pxd1l",
    "title": "Test Project",
    "tagline": "Test pitch",
    "hackathon": "",
    "built_with": [
      "test"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Test What it does Tes How we built it Test Challenges we ran into Test Accomplishments that we're proud of Test What we learned Test What's next for Test Project Test Built With test Created by Official TAMUhack"
      }
    ]
  },
  {
    "file_path": "./devposts/test-35onfk.html",
    "project_id": "test-35onfk",
    "title": "Ice Pick",
    "tagline": "Never worry about ice-breaking again! Let Ice Pick get the ball rolling while you sit back and let your personality shine!",
    "hackathon": "",
    "built_with": [
      "discord.py",
      "git",
      "github",
      "google-cloud",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Understanding how to use discord.py also took some time as it was the first time any of us had used this library."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/986/645/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "... and MORE memes Never worry about ice-breaking again! Play a Trivia Game with others in the discord server. See the points for each round of question. And see who will be the one to top the Leaderboard!! Play Would You Rather and get to know others! Get Funny Memes. Sit back, relax and laugh together! ... and MORE memes Never worry about ice-breaking again! Play a Trivia Game with others in the discord server. See the points for each round of question. And see who will be the one to top the Leaderboard!! Play Would You Rather and get to know others! Get Funny Memes. Sit back, relax and laugh together! ... and MORE memes 1 2 3 4 5 6 7 8 Inspiration Have you ever joined a discord server, excitedly introduced yourself, then received a dead response? Or feel so hopelessly awkward that you just wish there was an easier way to break the ice and meet new people?\nFret not, Ice Pick is here to save the day! Simply type in commands like trivia or wur and Ice Pick will break the ice for you. Now you just have to let your personality shine! What it does Ice Pick is an ice-breaker bot designed to be used in groups. It offers fun group ice breaking games like trivia quiz , where you can compete to be the highest scorer and typical ice-breaker games like Would You Rather where you get to not only learn about others but also yourself. Not only that, if you are tired of typing, you can switch it up a bit and look at some memes together. Ice Pick will be responsible for getting you random memes from subreddit r/programmerhumour. How we built it This bot was built with python using the discord.py library.\nTo make it extensible, we decided to modularize our code, making each command standalone. \nTo keep our bot running 24/7, we deployed it on Google Cloud Platform. Feel free to join our test server and try the bot for yourself! Challenges we ran into Firstly, we faced some issues in finding an api that we can use (many of which either have limited calls or restricted our access). We"
      }
    ]
  },
  {
    "file_path": "./devposts/test-n23quv.html",
    "project_id": "test-n23quv",
    "title": "project dave",
    "tagline": "Cut the crap. Focus on real human interactions.",
    "hackathon": "",
    "built_with": [
      "apollo.io",
      "browserbase",
      "container",
      "dain",
      "docker",
      "fetch-ai",
      "firestore",
      "flask",
      "gcp-artifact",
      "gemini",
      "google-dork",
      "google-oauth",
      "ingress",
      "kubernetes",
      "langchain",
      "linkd",
      "mongodb",
      "nginx",
      "ngrok",
      "novnc",
      "playwright",
      "python",
      "react",
      "rest-api",
      "selenium",
      "vercel",
      "vite"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "DAIN Challenge: AI Agent Excellence & Innovation Awards Created by i ate a lot Alvin Tan Yang Gao D",
      "LA Hacks 2025WinnerDAIN Challenge: AI Agent Excellence & Innovation Awards",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/394/641/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 6 7 Project Dave — Human Connections, Automated with Heart ❤️ Inspiration We built Project Dave because we were frustrated . Building real relationships is one of the most valuable things we do — but it’s buried under endless repetitive tasks: finding people, cold messaging/Networking on LinkedIn, sending 100s of emails, DM-ing on Twitter/X, following up manually. It wastes time, feels transactional, and leaves real human connection behind. As students hunting for jobs, founders growing companies, and creators building communities, we felt the pain ourselves — and Project Dave is our answer: Let humans focus on humans, and let Dave handle the grind. Dave isn’t just a CRM or outreach tool — it's your personal agent for real connection . What it does Project Dave helps you find , organize , and deepen your professional and personal relationships — across LinkedIn, Twitter (X), Email, and DMs on any platform. ✅ Find anyone, anywhere — LinkedIn, Twitter, Instagram, websites ✅ Automate cold outreach — LinkedIn connection requests, Twitter DMs, personalized emails ✅ Personalize at scale — Dave crafts individualized outreach at scale (not spam) ✅ Voice-enable everything (multilingual) — Type or talk to Dave in English, French, Hindi, and many more languages ✅ Build relationships over time — Not just one-and-done messaging Dave empowers you to grow your network like a human, but scale like a team. How we built it Frontend : React + TailwindCSS + Butterfly UI (DAIN-powered) Vercel for fast deployments Backend : Linkd API for Linkedin profile querying DAIN For querying endpoints and building the agent Fetch.ai’s ASI-1 Mini model fine-tuned for cross-platform people search Proprietary search engine (Dockerized, scalable) Voice-enabled DAIN agents (multilingual: English, French, Hindi, and more) GCP Kubernetes cluster for scalable infrastructure GCP Firestore for secure OAuth and user data storage GCP Artifact Registry + Cloud Run for deployments Gemini models"
      }
    ]
  },
  {
    "file_path": "./devposts/the-defender.html",
    "project_id": "the-defender",
    "title": "The Defender",
    "tagline": "We use ML to say if a person is wearing a mask.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "flask",
      "python",
      "react-native",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration An inspiration was when COVID started we couldn't go anywhere, people were being stupid and not wearing mask. We created this app, so kids will be able to go outside and have fun creating safe and healthy environment What it is supposed to do When you take a picture on the app, the app checks the picture, says if they are wearing a mask. If they are not it will alert the store keeper How we built it We used machine learning to check if a person is wearing a mask. We used TensorFlow, Flask, ExpressJS and React Native Challenges we ran into We couldn't connect the Machine Learning to the camera. This took us a while to figure out. We also couldn't get a live feed Accomplishments that we're proud of We are proud of our teamwork, and also proud of the effort we put in. We are really proud of creating our own ML model for the first time, and we think we could update it and make it better. What we learned We learned that we can use camera's to detect stuff. We also learned that teamwork is key to success. Skill isn't the only thing that matters. What's next for The Defender We will add a live camera feed, and we will retrain our ML algorithms/models. We will also connect this to Google Cloud so we can add this onto the App Store and the Google Play Store for worldwide use. Built With express.js flask python react-native tensorflow Try it out GitHub Repo Submitted to NextStep Hacks 2021 Created by I worked on the Frontend and the backend(ExpressJS). I created an actual working sign in and sign out by using JWT Aravindkrishna Arivudainambi Veerrohit Veeravadivel Ponkarthikeyan Saravanan"
      }
    ]
  },
  {
    "file_path": "./devposts/the-gamers-hub-v0mdx9.html",
    "project_id": "the-gamers-hub-v0mdx9",
    "title": "The Gamers Hub",
    "tagline": "The one stop hub for all gamers to interact and build a community!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "deso",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack by Fidelity : There are many ways our app is accessible"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/281/618/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Viewing Events Minecraft Client Creating an event Viewing Events Minecraft Client Creating an event Viewing Events 1 2 3 4 🌐 Domain Name: https://the-gamers-hub.tech/ ☁️ Inspiration Numerous gamers want to connect with others and get good at a game. On the other hand, gamers want to host events to bring the community together and gain connections. We, as gamers ourselves, wanted to create a platform where all gamers could connect with each other in a safe environment. Also, gamers who wanted to quickly stream but didn't want to set everything up can use our plugin to connect their Minecraft client with twitch. 🚧 What It Does Our app is consisted of 2 parts: The Actual App which is a community for gamers to get to know each other through events. Using firebase 's easy login with google, we implement a user authentication system. We have a homepage of events which users can browse through and be invited to. Gamers can join each others events and get various information such as location, time, and the description. Minecraft+Twitch : Currently, twitch requires you to download a native app and do numerous steps to setup your stream. We reduce all these steps into one step. The gamer just installs our plugin, and they can easily start streaming with one command. Chat messages are also streamed both ways. 👨🏾‍💻 How We Built It Google Cloud : With firebase , we were easily able to create a full fledged authentication system. It saved us the hassle of manually managing provides and users. We also used firestore , which allowed us to easily and securely store our user's data. Firestore 's easy to use API enabled us to implement more features into our application because of it's extensibility. Finally, we used the cloud VM feature to test our code and make sure streams and sign ups were working on another machine, imitating an actual user coming to our website. Deso : Deso played a big role in our application. It helped us secure our app against cyber threats using blockchain t"
      }
    ]
  },
  {
    "file_path": "./devposts/testing-123-4qxvja.html",
    "project_id": "testing-123-4qxvja",
    "title": "Example Project",
    "tagline": "This project is a demo for ThetaHacks",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ThetaHacksWinnerEveryone",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/357/726/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Volunteers Home Schedule Volunteers Home Schedule Volunteers 1 2 3 4 Inspiration We were inspired because hackathons are really fun to lead! What it does It is an epic hackathon website. We made it with HTML/CSS/Javascript. It is used for attendees, sponsors, and volunteers to learn more about our event and sign up for it! It has super nice buttons. console.log(\"Hello World!\") How I built it We built it with HTML/CSS/Javascript and used tons of libraries too. It is a fully static website . Challenges I ran into Making the site responsive was very tedious, as we had so many elements to it. Accomplishments that I'm proud of The site looks epic and we got over 500 signups :D. What I learned We learned more about hackathons What's next for Testing 123 We want to make the site a PWA (well, maybe) and add a backend login/signup! Built With javascript Try it out thetahacks.tech GitHub Repo Submitted to ThetaHacks Winner Everyone Created by I breathe Anshul Gupta building things @ mit I made nothing and won the minecraft tournament. Kai Devrim i subscribed to technoblade Andy Li i live Rohan Bansal declare variables, not war"
      }
    ]
  },
  {
    "file_path": "./devposts/text-extraction-with-ocr.html",
    "project_id": "text-extraction-with-ocr",
    "title": "Text extraction with OCR",
    "tagline": "Using EasyOCR our project can take in an image file, detect text in English, process, and output the text as a string along with the coordinates of each character.",
    "hackathon": "",
    "built_with": [
      "colab",
      "cv2",
      "easyocr",
      "matplotlib",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our main source of inspiration was finding similar projects online on websites such as stack overflow or GitHub and we found 2 main programs to try in our code which is Pytesseract and EasyOCR. What it does What our program does is first installs EasyOCR, then imports EasyOCR, MatPlotLib, cv2, etc. Next, it takes in the path to an image of your choice, displays it, then proceeds to output all detected English text line by line with the coordinates of the line, and the confidence that the text is correct. How we built it We built it by doing research on EasyOCR, how to use it, what methods to use, and what it outputs. After that, we were able to import it into our file, run the correct method with the image path, and successfully have some interpreted text. Challenges we ran into The main challenge that we ran into was that when you use an application like that it's not completely accurate for the font that was given on the comic strips and the only way we would be able to fix it is if we change the source code of EasyOCR which would be very difficult. Accomplishments that we're proud of Although we may not have gotten the interpretation to be as accurate as we would've liked we are proud that we were at least able to accomplish what we did when we came to this competition with almost no knowledge of image processing or machine learning. What we learned We learned how to process images and do different things with them through python along with different applications we can use in python and how to import and use them which expanded our knowledge immensely from what it was when we came into this competition. What's next for Text extraction with OCR Next for text extraction with OCR would be doing more research into EasyOCR and either finding a way to edit the code to be able to interpret the font we were given better or using that code to start a new application from scratch for OCR to do exactly what we want. Built With colab cv2 easyocr matplotlib pytho"
      }
    ]
  },
  {
    "file_path": "./devposts/the-gamers-hub-qvw46h.html",
    "project_id": "the-gamers-hub-qvw46h",
    "title": "The Gamers Hub",
    "tagline": "The one stop hub for all gamers to interact and build a community!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "deso",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack by Fidelity : There are many ways our app is accessible",
      "TigerHacks 2022WinnerBest Use of DeSo",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/281/614/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Viewing Events Minecraft Client Creating an event Viewing Events Minecraft Client Creating an event Viewing Events 1 2 3 4 🌐 Domain Name: https://the-gamers-hub.tech/ ☁️ Inspiration Numerous gamers want to connect with others and get good at a game. On the other hand, gamers want to host events to bring the community together and gain connections. We, as gamers ourselves, wanted to create a platform where all gamers could connect with each other in a safe environment. Also, gamers who wanted to quickly stream but didn't want to set everything up can use our plugin to connect their Minecraft client with twitch. 🚧 What It Does Our app is consisted of 2 parts: The Actual App which is a community for gamers to get to know each other through events. Using firebase 's easy login with google, we implement a user authentication system. We have a homepage of events which users can browse through and be invited to. Gamers can join each others events and get various information such as location, time, and the description. Minecraft+Twitch : Currently, twitch requires you to download a native app and do numerous steps to setup your stream. We reduce all these steps into one step. The gamer just installs our plugin, and they can easily start streaming with one command. Chat messages are also streamed both ways. 👨🏾‍💻 How We Built It Google Cloud : With firebase , we were easily able to create a full fledged authentication system. It saved us the hassle of manually managing provides and users. We also used firestore , which allowed us to easily and securely store our user's data. Firestore 's easy to use API enabled us to implement more features into our application because of it's extensibility. Finally, we used the cloud VM feature to test our code and make sure streams and sign ups were working on another machine, imitating an actual user coming to our website. Deso : Deso played a big role in our application. It helped us secure our app against cyber threats using blockchain t"
      }
    ]
  },
  {
    "file_path": "./devposts/test-9g43cz.html",
    "project_id": "test-9g43cz",
    "title": "SharePlate",
    "tagline": "SharePlate aims to foster communities by empowering people to share and barter produce, meals, and other food products!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "css3",
      "express.js",
      "mongodb",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/669/140/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our Logo, \"Share and Save Food!\" Our Market Page Our \"Add an Item\" Page Our Logo, \"Share and Save Food!\" Our Market Page Our \"Add an Item\" Page Our Logo, \"Share and Save Food!\" 1 2 3 4 5 💡Inspiration With rising food scarcity and food waste on the rise, it is becoming increasingly more difficult to get affordable, healthy, and locally sourced produce on the dinner table. \"Globally, 1.3 billion tonnes of edible food is wasted or lost every year.\" ⁠— Made In CA, 2023 This is becoming an ever-increasing problem as the population continues to increase while arable and fertile land continues to decrease. “SharePlate” aims to solve this by allowing locals to barter or give away locally sourced food and produce that they may not need or have an excess of. ❓What it does \"Share Plate\" is a peer-to-peer food bartering website that offers a sustainable and community-driven alternative to traditional supermarkets. Centred on locally sourced food, this platform is not merely about affordability; it's fundamentally about nurturing a robust sense of community and curtailing food waste. By enabling users to share or barter their surplus food within local communities, \"Share Plate\" fosters an environment of mutual support and connection. This initiative emphasizes the importance of sustainability and local engagement in our fast-paced modern world. It promotes a more communal and environmentally conscious approach to food consumption and distribution. ⚙️ How we built it We're using ReactJS and Vite for our front-end\nAuthentication is done through Firebase\nOur front-end is linked with MongoDB and NodeJS on the backend 💪 Challenges we ran into Theming: It was a challenge creating a consistent UI for our users while working remotely Linking the Front-End to the Back-End with only a few hours left Adding multiple features in this small amount of time No pizza since we were virtual 😢 👏 Accomplishments that we're proud of We’re proud of creating a fully functioning full-stack product that"
      }
    ]
  },
  {
    "file_path": "./devposts/the-gamers-hub-wp586r.html",
    "project_id": "the-gamers-hub-wp586r",
    "title": "The Gamers Hub",
    "tagline": "The one stop hub for all gamers to interact and build a community!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "deso",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack by Fidelity : There are many ways our app is accessible",
      "Best Domain Name from Domain",
      "Hack-Cade 2WinnerBest Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/281/612/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Viewing Events Minecraft Client Creating an event Viewing Events Minecraft Client Creating an event Viewing Events 1 2 3 4 🌐 Domain Name: https://the-gamers-hub.tech/ ☁️ Inspiration Numerous gamers want to connect with others and get good at a game. On the other hand, gamers want to host events to bring the community together and gain connections. We, as gamers ourselves, wanted to create a platform where all gamers could connect with each other in a safe environment. Also, gamers who wanted to quickly stream but didn't want to set everything up can use our plugin to connect their Minecraft client with twitch. 🚧 What It Does Our app is consisted of 2 parts: The Actual App which is a community for gamers to get to know each other through events. Using firebase 's easy login with google, we implement a user authentication system. We have a homepage of events which users can browse through and be invited to. Gamers can join each others events and get various information such as location, time, and the description. Minecraft+Twitch : Currently, twitch requires you to download a native app and do numerous steps to setup your stream. We reduce all these steps into one step. The gamer just installs our plugin, and they can easily start streaming with one command. Chat messages are also streamed both ways. 👨🏾‍💻 How We Built It Google Cloud : With firebase , we were easily able to create a full fledged authentication system. It saved us the hassle of manually managing provides and users. We also used firestore , which allowed us to easily and securely store our user's data. Firestore 's easy to use API enabled us to implement more features into our application because of it's extensibility. Finally, we used the cloud VM feature to test our code and make sure streams and sign ups were working on another machine, imitating an actual user coming to our website. Deso : Deso played a big role in our application. It helped us secure our app against cyber threats using blockchain t"
      }
    ]
  },
  {
    "file_path": "./devposts/the-evolution-of-trade.html",
    "project_id": "the-evolution-of-trade",
    "title": "The Evolution of Trade",
    "tagline": "Wendy’s interview at the National Bank of Canada becomes a journey through eras, forcing her to make game-changing decisions that shape the evolution of trade and currency in the modern world.",
    "hackathon": "",
    "built_with": [
      "figma",
      "photoshop",
      "python",
      "ren'py"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall NBC Challenge Project Created by Kelvin Nguyen Katrina Jin Daniel Yu jasonchencode Chen",
      "Best Overall NBC Challenge Project Created by Kelvin Nguyen Katrina Jin Daniel Yu jasonchencode Che",
      "QHacks 2025WinnerBest Overall NBC Challenge Project",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/232/056/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Inspiration Our game, Evolution of Trade is inspired by the rich history of how trading has evolved over different eras. Using a time machine to travel back, players navigate pivotal trade decisions across eras, creating a story of evolution and economic change. Each choice reflects the real-world consequences of our actions, allowing players to think critically about how our economy worked in the past, how it is currently working, and how it may work in the future. What it does Evolution of Trade is an interactive narrative choice game where players use a time machine to explore the history of finance and trade. The game presents players with decisions that open up new parts of our intricate story and unlock different paths that guide the narrative forward. They may also encounter bonus choices that offer deeper engagement and multiple outcomes. The story evolves based on the player’s decisions where their decisions will gain them or lose them points. Through this system, players not only influence the character’s journey but also learn about the impact of decisions on trade, growth, and society over time. How we built it We built Evolution of Trade primarily using Ren’Py. None of us had prior experience with Ren’Py, so we spent time understanding its features, experimenting with its capabilities, and learning how to translate our ideas into a functional game. Our process began with writing the script and constructing a captivating storyline. Then, we translated the script into code, bringing the branching paths and decision points to life. To enhance the player experience, we created visuals using Photoshop and Figma. Challenges we ran into Understanding and correctly implementing the Ren’Py scripting language. Ensuring our front-end elements and designs connected to the logic and data flow. Designing and developing a responsive layout for text and images that adjusted dynamically during gameplay. Debugging issues with character movements, transi"
      }
    ]
  },
  {
    "file_path": "./devposts/texify-ntedrf.html",
    "project_id": "texify-ntedrf",
    "title": "Texify",
    "tagline": "Transform your messy handwritten notes and sketches seamlessly into pristine, verbatim LaTeX documents and PDFs, powered by intelligent LLM-based agents—preserving every detail effortlessly.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "gemini",
      "python",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/502/321/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Texify Output Example Texify Workflow Diagram Texify UI Texify Output Example Texify Workflow Diagram Texify UI Texify Output Example 1 2 3 4 Inspiration We’ve all been there — spending hours typing LaTeX just to get a clean-looking homework or report. It’s slow, picky, and kind of a pain, especially when some classes require everything in LaTeX. On top of that, turning your scratch paper sketches into polished figures for papers or slides is another time sink.\nExisting handwriting-to-LaTeX conversion tools focus on processing single equations or short expressions. While useful for small tasks, they fall short when it comes to full derivations, structured proofs, or entire documents. These systems often lack contextual understanding, leading to errors when symbols are ambiguous or when spatial layout carries meaning. Additionally, requiring users to process one equation at a time interrupts workflow and becomes cumbersome. As a result, they provide only marginal assistance and fail to reduce the effort required to write and format LaTeX documents, especially in academic or technical settings.\nThat’s why we built Texify . It takes your handwritten notes and diagrams and turns them into high-quality LaTeX PDFs, automatically. No more retyping math or redrawing figures — just write like you normally would, and Texify does the rest. What it does Texify takes user handwritten notes, figures, problem solutions, or even scratch work, and converts them into PDF format. Texify cleans up and smoothes out the logical flow within the derivation, inserting English explanations for better reader understanding even when the user inputs only handwritten math. How we built it Texify generates a polished LaTeX PDF by running two pipelines in parallel: text processing and figure rendering. Users can upload either individual images or a full PDF; images are first converted into a unified PDF for consistency. The text pipeline uses Gemini 2.5 Pro to extract handwritten content and conve"
      }
    ]
  },
  {
    "file_path": "./devposts/textport-uc3dqx.html",
    "project_id": "textport-uc3dqx",
    "title": "textport.",
    "tagline": "reimagining copy-paste",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/236/954/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration test College students and professionals alike have been adjusting to work-from-home during the pandemic. While conducting research for a report or paper, students and employees often spend much of their time simply copy-pasting information and collecting sources, rather than actually writing the report. In order to help with productivity, we decided to develop a Chrome extension that could take care of collecting sources and direct quotes to give people more time to do their work. What it does textport is a Google Chrome extension that allows users to highlight article information in different colors and export this information, along with the source URL, to a Google Document. It is intuitive and simple to use, and anyone can download it from the Google Chrome Web Store. How we built it textport was coded using HTML/CSS and JavaScript. Prior to the hackathon, no one on our team had ever made a Chrome extension before, so we watched online tutorials and read through existing Github repositories for inspiration. During the hackathon, our team split the work into front-end and back-end work, and we uploaded our contributions to a shared Github repo. Challenges we ran into Unfortunately, we were not able to complete the functionality of the extension that collects the current URL and exports everything to a Google Doc within the time allotted for IvyHacks. Our project proved to be a bit more time-consuming than anticipated. However, our team plans to continue working on the extension even after IvyHacks is over. Accomplishments that we are proud of We are proud of learning how to develop a Chrome extension in a relatively short amount of time, even though none of us had ever had exposure to this before. Additionally, we are proud of the product we have developed, as we hope it will be downloaded and enjoyed by other people! What we learned We learned a lot about the process of developing a Chrome extension, as well as how to collaborate with teams through Gi"
      }
    ]
  },
  {
    "file_path": "./devposts/the-good-samaritan.html",
    "project_id": "the-good-samaritan",
    "title": "The Good Samaritan",
    "tagline": "A platform-independent application to connect organizations and entities with willing volunteers.",
    "hackathon": "",
    "built_with": [
      "auth0",
      "dart",
      "flask",
      "flutter",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Impact Hack Created by Neel Adwani yeet",
      "SBUHacksWinnerImpact Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/668/720/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration For non-profit organizations and even some helpless individuals, it is difficult to find people who are willing to help with simple or daunting tasks. For someone who is willing to contribute to society, it can be difficult to find work to fill the time. What it does The Good Samaritan is a platform-independent application where entities and volunteers can sign up and help each other. How I built it Front-end: Flutter, Dart Back-end: Python-Flask Authentication and API security: Auth0 Challenges I ran into Connecting the Flask server to Auth0 was challenging at first, but I was able to do it after going through the documentation. Accomplishments that I'm proud of This is the first time that I've built a mobile application (or used flutter), so I'm proud of being able to learn it and build a project within 24 hours. What I learned I learned about Flutter, front-end development, and Authentication for securing APIs using Auth0. What's next for The Good Samaritan Adding Location access and Twilio Messaging to it, as it can notify the closest volunteers about anyone who needs help. Built With auth0 dart flask flutter python Try it out GitHub Repo GitHub Repo Submitted to SBUHacks Winner Impact Hack Created by Neel Adwani yeet"
      }
    ]
  },
  {
    "file_path": "./devposts/the-gamers-hub-2ifv6j.html",
    "project_id": "the-gamers-hub-2ifv6j",
    "title": "The Gamers Hub",
    "tagline": "The one stop hub for all gamers to interact and build a community!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "deso",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack by Fidelity : There are many ways our app is accessible"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/281/616/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Viewing Events Minecraft Client Creating an event Viewing Events Minecraft Client Creating an event Viewing Events 1 2 3 4 🌐 Domain Name: https://the-gamers-hub.tech/ ☁️ Inspiration Numerous gamers want to connect with others and get good at a game. On the other hand, gamers want to host events to bring the community together and gain connections. We, as gamers ourselves, wanted to create a platform where all gamers could connect with each other in a safe environment. Also, gamers who wanted to quickly stream but didn't want to set everything up can use our plugin to connect their Minecraft client with twitch. 🚧 What It Does Our app is consisted of 2 parts: The Actual App which is a community for gamers to get to know each other through events. Using firebase 's easy login with google, we implement a user authentication system. We have a homepage of events which users can browse through and be invited to. Gamers can join each others events and get various information such as location, time, and the description. Minecraft+Twitch : Currently, twitch requires you to download a native app and do numerous steps to setup your stream. We reduce all these steps into one step. The gamer just installs our plugin, and they can easily start streaming with one command. Chat messages are also streamed both ways. 👨🏾‍💻 How We Built It Google Cloud : With firebase , we were easily able to create a full fledged authentication system. It saved us the hassle of manually managing provides and users. We also used firestore , which allowed us to easily and securely store our user's data. Firestore 's easy to use API enabled us to implement more features into our application because of it's extensibility. Finally, we used the cloud VM feature to test our code and make sure streams and sign ups were working on another machine, imitating an actual user coming to our website. Deso : Deso played a big role in our application. It helped us secure our app against cyber threats using blockchain t"
      }
    ]
  },
  {
    "file_path": "./devposts/the-gamers-hub.html",
    "project_id": "the-gamers-hub",
    "title": "The Gamers Hub",
    "tagline": "The one stop hub for all gamers to interact and build a community!",
    "hackathon": "",
    "built_with": [
      "cohere",
      "deso",
      "firebase",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Accessibility Hack by Fidelity : There are many ways our app is accessible"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/281/603/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Viewing ESports Events Minecraft Client Create a new event Viewing ESports Events Minecraft Client Create a new event Viewing ESports Events 1 2 3 4 🌐 Domain Name: https://the-gamers-hub.tech/ ☁️ Inspiration Numerous gamers want to connect with others and get good at a game. On the other hand, gamers want to host events to bring the community together and gain connections. We, as gamers ourselves, wanted to create a platform where all gamers could connect with each other in a safe environment. Also, gamers who wanted to quickly stream but didn't want to set everything up can use our plugin to connect their Minecraft client with twitch. 🚧 What It Does Our app consists of 2 parts: The Actual App which is a community for gamers to get to know each other through events. Using firebase 's easy login with google, we implement a user authentication system. We have a homepage of events that users can browse through and be invited to. Gamers can join each other's events and get various information such as location, time, and description. Minecraft+Twitch : Currently, twitch requires you to download a native app and do numerous steps to setup your stream. We reduce all these steps into one step. The gamer just installs our plugin, and they can easily start streaming with one command. Chat messages are also streamed both ways. 👨🏾‍💻 How We Built It Google Cloud : With firebase , we were easily able to create a full fledged authentication system. It saved us the hassle of manually managing provides and users. We also used firestore , which allowed us to easily and securely store our user's data. Firestore 's easy to use API enabled us to implement more features into our application because of it's extensibility. Finally, we used the cloud VM feature to test our code and make sure streams and sign ups were working on another machine, imitating an actual user coming to our website. Deso : Deso played a big role in our application. It helped us secure our app against cyber threats "
      }
    ]
  },
  {
    "file_path": "./devposts/the-night-sky-8pe14k.html",
    "project_id": "the-night-sky-8pe14k",
    "title": "The Night Sky",
    "tagline": "The Night Sky is a website that allows all the space enthusiasts to explore the 3D models and AR views of different planets and space missions.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "react",
      "tailwind",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MLH Prize- Best Space App powered by Space Force Created by Private user AMOGH SARANGDHAR Cassidy L",
      "- Best Space App powered by Space Force Created by Private user AMOGH SARANGDHAR Cassidy Lee Nichola",
      "Cornell BigRed//Hacks 2021WinnerMLH Prize- Best Space App powered by Space Force",
      "🌌 Best Space App powered by Space Force",
      "🎨 Best use of Figma",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/669/168/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Smart chatbot assistance Welcome to The Night Sky Home page Explore more about space Interactive 3D Model and AR of all planets AR in action Interactive 3D Model and AR of space missions Smart chatbot assistance Welcome to The Night Sky Home page Explore more about space Interactive 3D Model and AR of all planets AR in action Interactive 3D Model and AR of space missions Smart chatbot assistance 1 2 3 4 5 6 7 8 💡 Inspiration Lack of interactive and engaging methods to learn about space exploration No good visualization of planets and spacecraft Dull and outdated style of teaching This inspired us to create a platform that would allow users to explore more about planets and space missions 💻 What it does Interactive website to explore planets and space missions It includes 3D models that can be viewed with AR Lots of freedom to explore the intricacies of space Chatbot for another layer of interactivity 🔨 How we built it React Js: For the frontend Firebase: For user authentication and database Three Js: For rendering 3D Models Tailwind CSS: For styling 📶 Domain registered with Domain.com explorespacewithus.tech ⛅ Use of Google Cloud We built The Night Sky's authentication system with Google Cloud's Firebase. We chose this because we wanted to make an application that was very very secure. We learned how robust & fast Google Cloud services are and seeing that Firebase had a free plan that was great for us student hackers, using Google Cloud was kind of a no-brainer. Additionally, Firebase Authentication provided a backend service, easy-to-use SDKs, and ready-made UI libraries, and the ability to authenticate using passwords, phone numbers, Google, Facebook and Twitter, and the like. Thus, implementation was easy and we are pretty sure we made it incredibly convenient for our users while keeping it secure. 🌌 Best Space App powered by Space Force Explore more about space with the help of interactive 3D Models and AR. 🎨 Best use of Figma We have used Figma for building the"
      }
    ]
  },
  {
    "file_path": "./devposts/the-timeless-clock.html",
    "project_id": "the-timeless-clock",
    "title": "The Timeless Clock",
    "tagline": "A clock that tells you the time without telling you the time!",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "category and looked into how we can over-complicate a simple tool to make it inefficient"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/402/664/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Our inspiration came from the fact that we wanted to create something that was simultaneously useful and not useful at the same time. We also wanted to compete in the \"most useless hack\" prize category and looked into how we can over-complicate a simple tool to make it inefficient. What it does The timeless clock tells you the current time relative to the time of a past event. For example, it'll tell you that the time is 57 days, 4 hours, and 30 minutes relative to the start of the 2010 winter Olympics. This way, it is able to tell you the current time without telling you the current time! How we built it We compiled a database of past events and their date+time. Then we built a backend that calculates the time difference between the current time and the past event. We then have a website (frontend) to display the time relative to the event and to change the background image Challenges we ran into Finding data of events that had date and time (HH:MM:SS) Connected the backend to the frontend with Flask Accomplishments that we're proud of Having a responsive frontend and a time counter Having an idea that's so stupid that it works What we learned Learned how to make a responsive frontend Learned how to connect front and backend using Flask What's next for The Timeless Clock Make it work for times/events that are in the future Make it work with times/events that happened in BC (before AD) Make events editable so people can use it as a deadline counter Built With css flask html5 javascript python Try it out GitHub Repo Submitted to RevolutionUC Created by Worked with the backend and created python functions for the frontend to call on Ryan Lam UWaterloo Physics Jax Wang uwo 24' intermediate FE Xinming Zhang"
      }
    ]
  },
  {
    "file_path": "./devposts/the-math-machine-pg4bew.html",
    "project_id": "the-math-machine-pg4bew",
    "title": "The math machine",
    "tagline": "The math machine",
    "hackathon": "",
    "built_with": [
      "pygame",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "This was our first project. I can't even believe that a bunch of middle schoolers(us) made such a big project!"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "here is the link for our submission: https://youtu.be/RxVB81NwCw4 Built With pygame python Try it out adoring-goodall-5a9046.netlify.app Submitted to AngelHacks 2.0 Created by This was our first project. I can't even believe that a bunch of middle schoolers(us) made such a big project! Veerrohit Veeravadivel This was a super fun project! I mostly worked on the assets for the game (Sounds, Art, etc). But I got a good luck inside what it takes to make a game! Mr. SeBo Currently working on The Math Machine. me.fast. Learn"
      }
    ]
  },
  {
    "file_path": "./devposts/the-schedule-maker.html",
    "project_id": "the-schedule-maker",
    "title": "The Schedule Maker",
    "tagline": "Productivity is key to excellence. Our code is key to excellence",
    "hackathon": "",
    "built_with": [
      "css",
      "htmls",
      "javascript",
      "repplit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The lack of productivity and increase of distraction in the world. What it does It gives the user a strong, well built sense of accomplishment as they advance from novice to nobility by completing daily goals. So, it serves a dual purpose of proudness and completing all your tasks How we built it We started with designing the home page with had a button and lead to the actual schedule, this home page would also contain the details about becoming a higher class. Then, we designed the page that the button would take you to. It consisted of the schedule in which the user would input all their goals for the day and then once they were completed they would come back to check it off, giving them ten points per objective completed. Afterwards, the user had an additional option to take their previous amount of points and spin a while. The goal of doing this was to add a sot of gambling that would make the game addicting so the user would continue to come back to the app. It would also ensure that they are getting all their daily tasks done. The spinner would make it so that they could either, based on what they landed on, gain or lose points. Each spin costed ten points. Challenges we ran into One of the teachers said that the fun in the hackathon was running  into problems; if that's the case we had a very enjoyable time. The first problem that we ran into was that we could not decide what language/ program to use. We jumped back and fourth between Swift, Swift UI, Figma,HTML. JS, python, and more. Our second problem was that our syntax was really bad. So we would have to google some command midway. This lead to another problem, we were not always 100% sure on how to use it correctly, and repplit( the website we were using to type HTML/ JS code) would not tell us when we had an error or used a command incorrectly. Resulting in us having to decipher issues that we didn't know existed on our own. Another issue was that HTML is not the easiest code to parse/ read "
      }
    ]
  },
  {
    "file_path": "./devposts/the-magician-s-marketplace-svd3h8.html",
    "project_id": "the-magician-s-marketplace-svd3h8",
    "title": "The Magician's Marketplace",
    "tagline": "The perfect place for magicians to get hired, attend competitions, meet up with others, and have fun!",
    "hackathon": "",
    "built_with": [
      "codesandbox",
      "css",
      "deso",
      "domain.com",
      "javascript",
      "python",
      "react",
      "replit",
      "sandbox"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/188/266/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "IGNORE THIS PROJECT, IS A DUPLICATE 🌐 Domain Name: https://magicians-marketplace.tech/ ☁️ Inspiration Magician's have real talent...they fool us into universe defying moves just with their hands. From close-up to big, there are many types of magicians. Unfortunately, there isn't a \"magician\" job, and many magicians can't pay bills or are homeless because they can't find work. Our app strives to solve this by creating a platform where magicians and employers can meet. 🚧 What It Does Our application is a place where magicians and employers meet. Magicians can view competitions, jobs, and even meet others all from the site. Magicians have profiles to network with others. Employers can create custom questionnaires when a magician is applying for a job. On top of all this, thanks to Deso , everything is cryptographically secure on the blockchain, and magicians can keep collaborating. 👨🏾‍💻 How We Built It The frontend used ReactJS. The backend used many different technologies. For the server, we used flask . Database and hosting wise, we used replit . As markdown appeals to more hackers, we implemented a markdown to html engine. Finally, we used Deso in a big way. Even if magic is so fun, it still can’t protect our app from cyber threats, but Deso can. By saving our data and images on their blockchain network, we guarantee ultimate protection to anyone using the application. Deso really helped us build the app. All in call, we used numerous technologies. 👷 Challenges We Ran Into We faced too many issues to count. Firstly, the CSS on the main app kept crashing. On top of that, our jsx kept causing errors. As it was our first time using firebase , integrating google auth took quite a bit of time, especially configuring \"Authorized Domains\". On the backend, we had some issues with Deso. As it was our first time using it, finding our publicKey and seedHex was hard. After inspecting and debugging for a long time, we finally fixed everything! 🎉 Accomplishments That We're Proud "
      }
    ]
  },
  {
    "file_path": "./devposts/the-touch-of-god.html",
    "project_id": "the-touch-of-god",
    "title": "a helping hand",
    "tagline": "your third arm",
    "hackathon": "",
    "built_with": [
      "arduino",
      "c++",
      "opencv",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hardware Hack Created by I worked on implementing the hand tracking AI",
      "Best Hardware Hack Created by I worked on implementing the hand tracking AI",
      "JAMHacks 7WinnerBest Hardware Hack",
      "your third arm",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/506/154/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration 💡 The inspiration behind our project was driven by the need to address the challenges and risks associated with dangerous tasks that humans often face, such as firefighting or inaccessibility to surgery. These activities involve hazardous environments where human presence can be life-threatening. By utilizing a computer-aided vision system in conjunction with a robotic arm, we sought to create a solution that can perform these tasks with precision and efficiency while keeping humans out of harm's way. What it does ✅ The helping hand is essentially a hand which helps people from afar. It uses computer vision which maps out the points on the user's hand and then translates that information in the robotic arm. It uses servos to accurately and precisely mirror the user which helps maintain consistency and efficiency. How we built it 🛠 We built it using OpenCV and Arduino where the computer sends a value to the Arduino depending on the location/joints on your finger. This is then used to determine the angle on the servos to accurately move and grab things. Challenges we ran into 🚧 Challenges we ran into was mounting the arm on the servo, it was a lot of weight to handle on a small motor. We also accidentally broke one of our motors when we were about to finish up which left crying trying to troubleshoot this problem at 4 am. The arm would keep spasming and we struggled to find a root why, we eventually resolved this problem and left us empty as we had 2 hours of sleep left. Accomplishments that we're proud of 🏔 For many of us, it was our first time working with OpenCV where when it finally worked we were ecstatic. The whole project was really fun to make, seeing our innovation work in full glory was truly worth the 2 hours of sleep this weekend. What we learned 🎓 We've learned a lot throughout this hackathon, from computer vision to assembling hardware it was a treacherous journey for all. We've learned how important sleep is as it can totally affect your"
      }
    ]
  },
  {
    "file_path": "./devposts/the-totally-best-project.html",
    "project_id": "the-totally-best-project",
    "title": "Ignore This Project",
    "tagline": "We had to restart our devpost and you cannot delete entries",
    "hackathon": "",
    "built_with": [
      "nothing"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/155/217/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "This project is empty. Please go to fitness market place instead. Sorry for the inconvenience. Built With nothing Created by I did absolutely nothing lol Ian Kim Michael Mohn High Schooler interested in CS. Member of CRHS Idea Vincent Do Abdur Aziz Plane enthusiast. Car enthusiast. Highly motivated. Samuel Yuan Prasann Singhal AI Researcher | Full-stack Dev| Innovator"
      }
    ]
  },
  {
    "file_path": "./devposts/the-tarc.html",
    "project_id": "the-tarc",
    "title": "The TARC",
    "tagline": "The TARC is an idea to refine safety for middle and lower-class families, by making affordable technology that can be placed inside their vehicles. My motto is \"Ensuring Tommorow, Savings Lives Today\"",
    "hackathon": "",
    "built_with": [
      "recording",
      "research",
      "slideshow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "No Code Empower Hacks 2",
      "Best No Code Empower Hacks 2",
      ") Motus Hacks FutureForge HackEMinds 2025 Created by Akhil Nimmagadda",
      "IngeniumSTEM Summer Hacks 1.0WinnerBest No Code",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration When I was driving home with my mother one day, a car rear-ended us, crashing into us with so much force that both the cars bumpers fell off. After the accident, the police and ambulance took quite a while to arrive, leading me to worry about what would have happened if anyone had gotten seriously hurt. I wanted to create a way so that the EMS services could arrive at accident sites faster, to prevent unnecessary deaths. What it does The TARC is an idea that quickly locates the location of an accident and immediately sends a signal with the location to the local authorities (Police, Fire Station, Hospital) so they can arrive as fast as possible. How we built it I used the research I did to create the google slides for the presentation. I used XBOX Gamebar to actually record the presentation. Challenges we ran into One challenge I ran into was that the installation of a satellite for this purpose would be somewhat expensive, so I was trying to find a way around using a satellite. Another issue that came up is trying to find a way to make it so that the TARC only sends a signal when there's an accident, rather than constantly sending a signal and stopping the signal when an accident occurs. Accomplishments that we're proud of I'm proud of making an entire presentation, and recording it into a video from the research I did. What we learned I learned a lot about unnecessary deaths that could have been prevented by quicker EMS response times. What's next for The TARC I plan to make more videos about the specifics of the TARC, then make a working prototype in the near future. Built With recording research slideshow Try it out docs.google.com Submitted to IngeniumSTEM Summer Hacks 1.0 Winner Best No Code Empower Hacks 2.0 Hacktivism Solstice by APEERS KatyYouthHacks 2024 Kite Hacks 2.0 Fresh Hacks SOASH 2024 Hackathon New Type Works Hacks Nova Hacks I - (Internship, Project Article, $24K Non-Cash Prize) Motus Hacks FutureForge HackEMinds 2025 Created by Akhil N"
      }
    ]
  },
  {
    "file_path": "./devposts/the-magician-s-marketplace.html",
    "project_id": "the-magician-s-marketplace",
    "title": "The Magician's Marketplace",
    "tagline": "The perfect place for magicians to get hired, attend competitions, meet up with others, and have fun! Avada kedavra your worries!!!",
    "hackathon": "",
    "built_with": [
      "css",
      "deso",
      "domain.com",
      "javascript",
      "python",
      "react",
      "replit",
      "sandbox"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/186/882/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Other Candidates Page Login Page Home Page Profile Page Jobs Page Other Candidates Page Login Page Home Page Profile Page Jobs Page Other Candidates Page 1 2 3 4 5 6 🌐 Domain Name: https://magicians-marketplace.tech/ ☁️ Inspiration Magician's have real talent...they fool us into universe defying moves just with their hands. From close-up to big, there are many types of magicians. Unfortunately, there isn't a \"magician\" job, and many magicians can't pay bills or are homeless because they can't find work. Our app strives to solve this by creating a platform where magicians and employers can meet. 🚧 What It Does Our application is a place where magicians and employers meet. Magicians can view competitions, jobs, and even meet others all from the site. Magicians have profiles to network with others. Employers can create custom questionnaires when a magician is applying for a job. On top of all this, thanks to Deso , everything is cryptographically secure on the blockchain, and magicians can keep collaborating. 👨🏾‍💻 How We Built It The frontend used ReactJS. The backend used many different technologies. For the server, we used flask . Database and hosting wise, we used replit . As markdown appeals to more hackers, we implemented a markdown to html engine. Finally, we used Deso in a big way. Even if magic is so fun, it still can’t protect our app from cyber threats, but Deso can. By saving our data and images on their blockchain network, we guarantee ultimate protection to anyone using the application. Deso really helped us build the app. All in call, we used numerous technologies. 👷 Challenges We Ran Into We faced too many issues to count. Firstly, the CSS on the main app kept crashing. On top of that, our jsx kept causing errors. As it was our first time using firebase , integrating google auth took quite a bit of time, especially configuring \"Authorized Domains\". On the backend, we had some issues with Deso. As it was our first time using it, finding our publicKey and "
      }
    ]
  },
  {
    "file_path": "./devposts/the-judgmental-calculator.html",
    "project_id": "the-judgmental-calculator",
    "title": "The Judgmental Calculator",
    "tagline": "The field of mathematics can often seem inaccessible and discouraging for beginners. We want to make it even more discouraging (a humourous take on calculators)",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/639/023/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The face of the Judgemental Calculator The face of the Judgemental Calculator The face of the Judgemental Calculator 1 2 Inspiration I am not good at math. I'm also a beginner programmer, so I lacked a lot of the knowledge and experience I needed for all the big fancy ideas I had for projects. I decided to take this hackathon as an opportunity to learn, not outdo myself, and work on a simple project with a humourous, self-deprecating twist. Is it complex? Nope. Is it original? Probably not. But I made it and I learned a lot, and overall I think I did well. What it does It's a basic online calculator that occasionally insults you, and mostly for really simple questions that people often do on calculators (e.g., any number + 1. You don't really need a calculator for that). How we built it Javascriptttttt. Challenges we ran into I couldn't figure out how to incorporate a square root function, so in the interest of time I scrapped it. I also initially had difficulty figuring out how to incorporate text into the main interface of the calculator, but I figured it out eventually. Also, my VS Code's debugger stopped working out of nowhere, and I had not the time nor patience to fix it so to repl.it we went! Accomplishments that we're proud of Nothing specifically, just the fact that I managed to finish it in time is miracle enough for me. What we learned Javascript is a lot more flexible than I thought What's next for The Judgmental Calculator More insults!! And more calculator functions. Built With css html javascript Try it out condescending-meninsky-063e9c.netlify.app GitHub Repo Submitted to Hack with Us Created by Iman Umair-Qaiser UWaterloo CE '26"
      }
    ]
  },
  {
    "file_path": "./devposts/the-world-of-wreckage-analyzing-salvaged-damaged-vehicles.html",
    "project_id": "the-world-of-wreckage-analyzing-salvaged-damaged-vehicles",
    "title": "The World of Wreckage: Analyzing Salvaged/Damaged Vehicles",
    "tagline": "The world of wreckage is a world that we know little about, very little data and information is readily available. Thus, we decided to extract and analyze data, to explore the world of wreckage.",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "csv",
      "html",
      "os",
      "python",
      "request",
      "selenium"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/703/870/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We noticed that although there is a lot of information readily available on a majority of vehicles in the market, there is a blind spot regarding salvaged vehicles, so we decided to help fill the void. What it does This project extracts and compiles data in a structured format. It allows for ease of access and ease of readability, so that way anyone could understand what the data is about. How we built it Using Python, we created a web scraper that collects price, damage, odometer reading and other information on salvaged cars from Salvage Bid that would then be placed into a .csv file. Challenges we ran into A major issue we ran into during the project is the computing resources needed to collect and implement the large data sets using a web scraping tool. Accomplishments that we're proud of We are proud of the successful implementation of a web scraper for collecting data from Salvage Bid , since we were all new to the realm of web scraping. What we learned This project gave us more insights into web scraping, and how we could compile and analyze useful data in a readable format. This data could then be implemented in various ways; furthermore, we discovered how computing resources are a major factor in how much data a web scraper can collect. What's next for The World of Wreckage: Analyzing Salvaged/Damaged Vehicles The next step would be to move the web scraper from operating and compiling the collected data on a physical host system to operating on a cloud-based system. This would raise the headroom the web scraper has on the amount of data the web scraper collects. Furthermore, we would like to implement a machine learning program to analyze the factors in the data from the web scraper such as odometer reading and the type of damage that would predict the sale of the car and allow people who flip cars to then determine the amount of potential profit they would make from the flip. Built With beautiful-soup csv html os python request selenium Try it "
      }
    ]
  },
  {
    "file_path": "./devposts/theatercrunch.html",
    "project_id": "theatercrunch",
    "title": "TheaterCrunch",
    "tagline": "The Future of Entertainment; TheaterCrunch revolutionizes the online movie experience using Web 3.0",
    "hackathon": "",
    "built_with": [
      "css3",
      "django",
      "html5",
      "moralis",
      "python",
      "react",
      "web3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/889/247/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Thumbnail Main Page Video Player Logo Thumbnail Main Page Video Player Logo 1 2 3 4 5 ☁️ Inspiration Film making students and blockbuster movie directors — what do they have in common? They both love movies, and so do we. Whether you are making the next big hit or practicing some acting with friends, TheaterCrunch will definitely help you. It is a place where all ! On top of that, we are connecting this to blockchain. As Web3 is emerging, more and more companies are turning towards it. All of our user's accounts, movies, and data is stored on the blockchain network. Each account is an ethereum key, as proof. 🚧 What It Does This application allows you to post movies, watch movies, rate movies, review movies, add movies to your watch list, recommend movies, and much more! It allows movie enthusiasts to connect with each other from all around the world. Anyone can make and enjoy movies with our app. All the accounts are ethereum addresses, meaning that they are cryptographically unhackable. 👷 How We Built It Using the moralis SDK, we connected all of our user's to the blockchain network. All the data is stored on the blockchain, and the files are stored using ReplitDB. We have a variety of services you can use to log in, such as MetaMask. On the frontend we used React and the Web 3 UI Kit to build our user interface for viewing the movies, creating the movies, and publishing the movies. 👨🏾‍💻 Challenges We Ran Into To say we ran into a few challenges is a HUGE understatement. In the backend, the file system API get causing errors. When we finally fixed that, the frontend was crashing because certain areas of the page were styled differently. All the different APIs we had to integrate was hard. Finally, communicating was an issue. Some of us were in different timezones, which was an issue. 🎉 Accomplishments That We're Proud Of We actually finished the project...yay! We used many APIs and learned about Web3 a lot. Integration of so many different things was complicat"
      }
    ]
  },
  {
    "file_path": "./devposts/the-weathering-traveller-mubndt.html",
    "project_id": "the-weathering-traveller-mubndt",
    "title": "The Weathered Traveller",
    "tagline": "A home away from home for every adventurer.",
    "hackathon": "",
    "built_with": [
      "ajax",
      "beautiful-soup",
      "css",
      "dark-sky",
      "flask",
      "google-cloud",
      "heroku",
      "html5",
      "javascript",
      "openweathermap",
      "python",
      "radar.io",
      "repl.it",
      "scrapy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Being my first hackathon, this was quite the fun experience. I worked on the front-end with Ryan."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/202/619/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Heroku Main UI About Us Dataset Heroku Main UI About Us Dataset Heroku 1 2 3 4 5 Inspiration Since most travel apps do not sort travel destinations by preferred temperature and precipitation levels, we decided that we could make a website that would fill this niche and offer people travel destinations based on their weather preferences as well. This led to the creation of The Weathered Traveller, a web application that uses climate data involving precipitation and temperature to calibrate the best travel destination. What it does The Weathered Traveller is a site that allows the user to select the ideal travel destination based on their preferences for the climate of the area. The user inputs their preferences for precipitation and temperature, and the site then searches through a database of climate data to find the closest match that best fits their request and prints out the city name. How we built it In terms of our tech stack, it was a combination of familiar languages and also explorative technologies. For the frontend, we used HTML, CSS, and JS for our landing page, and used Heroku for the backend. The backend was connected to the front end via a form, and the data from OpenWeather’s data sets were filled into a Google Sheet. It was then propagated into Heroku’s system and sorted based on temperature or rainfall data. After that, the information was relayed back to the front end using AJAX and python requests to display the final result in terms of what the best match for the user was. To get the data, we used the OpenWeatherMap API, the radar.io location API, and a web scraper with python’s beautifulsoup and scrapy. Challenges we ran into The front-end developers, all of whom were first-time hackers, encountered many challenges with creating their first working website from scratch. This included creating many widgets and the overall layout of the website from scratch. There were also some difficulties making sure that the website would display properly in m"
      }
    ]
  },
  {
    "file_path": "./devposts/therapy-buddy.html",
    "project_id": "therapy-buddy",
    "title": "Therapy Buddy",
    "tagline": "A helpful and supportive resource for your mental health",
    "hackathon": "",
    "built_with": [
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Table 131 Inspiration The inspiration for the mental health app came from the founder's own experience with mental health struggles. The founder wanted to create an app that would help others who were struggling with mental health issues, and provide them with a safe space to share their thoughts and feelings. What it does The mental health app is a platform where users can journal and track their moods.  Journaling and mood tracking can be important for mental health for a number of reasons. First, it can help people to process their thoughts and feelings. When we write down our thoughts and feelings, we are forced to confront them and to make sense of them. This can be a helpful process, as it can help us to understand our emotions and to develop coping mechanisms. Second, journaling can help people to identify patterns in their moods. If we track our moods over time, we can start to see patterns in how we feel. This can be helpful in identifying triggers for our moods, as well as in developing strategies for managing our moods. Third, journaling can be a way for people to connect with others. When we share our thoughts and feelings with others, we can feel less alone and more supported. This can be especially helpful for people who are struggling with mental health issues, as it can provide them with a sense of community and belonging. Finally, journaling can be a way for people to document their progress. When we look back on our journals, we can see how far we have come. This can be a motivating and empowering experience, as it can help us to see that we are capable of change and growth. Overall, journaling and mood tracking can be valuable tools for mental health. They can help people to process their thoughts and feelings, identify patterns in their moods, connect with others, and document their progress. If you are struggling with mental health, journaling and mood tracking may be helpful tools for you. How we built it We used React Native in order to suppor"
      }
    ]
  },
  {
    "file_path": "./devposts/the-trash-app.html",
    "project_id": "the-trash-app",
    "title": "The Trash App(Recycli)",
    "tagline": "A mobile app that allows you to scan your trashcan and calculate their California Refund Value(CRV). Then, you may take them to the nearest recycling center so you could claim your money.",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "dart",
      "django",
      "flutter",
      "python",
      "tensorflow",
      "yolo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/485/374/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration Our team’s inspiration was to make the world a greener place! Landfills are being overran with recyclable materials and it is our job to stop this! We also wanted to create a very simple app that will let people have the power at their fingertips to distinguish the differences between recycling and trash. This is our first step in creating an AI that will completely change the world! What it does An app powered by machine learning to scan your trashcan and calculate the California Refund Value(CRV) that you can claim from the nearest recycling center. How we built it Through Python and Yolo algorithms, we deployed the model on AWS through Django, then we built the front end using Flutter and Dart for the user interface. Challenges we ran into, What we learned, and Accomplishments that we're proud of. With limited time, besides all the tremendous coding challenges, technique difficulties, and limited computation resources, the hardest part is actually communicating with each other and keeping each other in the loop, through this experience, we gained a lot of experience in co-development and we learned so much from each other, which helped us grow our technical skills a lot. What's next for The Trash App What’s next for our app? As stated in our inspiration we want to create the most powerful AI to determine what is recycling and what is waste. We would like to implement features such as electric detection that will give the user the ability to take pictures of things such as TVs phones and even cars. This will then send a location and a website to where they can request someone to take their items and we as a company will dispose of those items. Built With amazon-web-services dart django flutter python tensorflow yolo Try it out GitHub Repo Submitted to HackDavis 2023 Created by I worked on the post api endpoint and integrated a modified darknet project configuration to detect recyclable materials in an image. Andrew Bustos Wendon Song A REAL eng"
      }
    ]
  },
  {
    "file_path": "./devposts/the12thplan.html",
    "project_id": "the12thplan",
    "title": "The12thPlan",
    "tagline": "The12thPlan is a website to find events in Aggieland!",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "python",
      "requests"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Aggie Hack Created by Lucian Chauvin ayalaa04 Ayala Avery Reagan",
      "Best Aggie Hack Created by Lucian Chauvin ayalaa04 Ayala Avery Reagan",
      "HowdyHack 2022WinnerBest Aggie Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/241/879/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration -Tamu calendar\n-Agenda\n-Club events\n-Academic Calendar\n-Meeting people\n-Organziation What it does This program compiles events through aggie land onto a simple map and table view. You can click on specific events to see more about them the event and also add it to your calendar with one click! You can also move around on an interactive map, clicking on certain buildings to see the events at it. How we built it It was built with HTML, CSS, JavaScript, and of course Python. We had to rip data from data sources such as calandar.tamu.edu and map data from map.tamu.edu. We then had to parse this data and make Javascript functions to connect it all. We used a map API called mapbox. Challenges we ran into Much of the data we ripped from websites had a lot of problems with it. Our solution to this was pre-processing the data in python, specifically gathering the data we wanted. Accomplishments that we're proud of This was the first time most of us worked with these programing languages and with json data so it was a great learning experience in those fields. We also learned how to get data using web requests and fetch.js. We also created a whole website in just 1 day and we are very proud of it. What we learned We learned HTML, CSS, JS, and how to work with JSON using Python. What's next for The12thPlan Make it automatically update! Built With css html javascript python requests Try it out GitHub Repo lucianchauvin.com Submitted to HowdyHack 2022 Winner Best Aggie Hack Created by Lucian Chauvin ayalaa04 Ayala Avery Reagan"
      }
    ]
  },
  {
    "file_path": "./devposts/thermostat-python-project.html",
    "project_id": "thermostat-python-project",
    "title": "Thermostat Python Project",
    "tagline": "In this project, I have used my knowledge of python to program a thermostat that detects water temperature.",
    "hackathon": "",
    "built_with": [
      "python",
      "python-package-index",
      "raspberry-pi",
      "thermostat"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Common problems: Some common problems that I encountered during the work for the project include the speaker not functioning properly, code not compiling correctly, and thermostat not detecting the temperature properly. This project has been coded using python programming on the Raspberry Pi 4 Model B. How I built it: First of all, I had connected the Raspberry Pi board to the monitor, and started coding the project. Later, I had connected a circuit that connects to the thermostat wires. After I connected the thermostat wires, I used an audio converter which was connected to a Bluetooth speaker. Later, I took two cups of water; one cup with 40 degrees Fahreneit ice water and another cup with 85 degrees hot water. I had first put the thermostat into the cold water cup. I had set the desired temperature for the water to be used as 67 degrees Fahrenheit. After I starting running the code, the display console kept showing me the updated temperature in Celsius and Fahrenheit every single second. I quickly took the thermostat and put it into the hot water cup. Challenges I ran into: While I was working on the project, I had a huge challenge connecting the wires to the thermostat circuits because the wires were thin and they had to be pushed in pretty hard and carefully in order to get connected without any lose wires. Accomplishments that I'm proud of: One accomplishment I am proud of is saving tons of water that gets drained down a sink, shower, or a tub and solving a commonly-faced problem amongst many homes in the community around me. What I learned: I have learned how to solve real-world problems and I have learned how to program high-level projects using Python. What's next for Thermostat Python Project: Now on, I will be contacting some local sponsors and companies and will be telling them about my project. I will focus on marketing this and will slowly start finding a retailer to sell these products. Built With python python-package-index raspberry-pi thermostat Tr"
      }
    ]
  },
  {
    "file_path": "./devposts/thrift-ys09e8.html",
    "project_id": "thrift-ys09e8",
    "title": "thrift",
    "tagline": "making conscious decisions while you shop",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "html",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Sustainability / Social Good Hack Created by I worked on the back-end of the Chrome extension",
      "Best Sustainability / Social Good Hack Created by I worked on the back-end of the Chrome extension",
      "JAMHacks 6WinnerBest Sustainability / Social Good Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/987/130/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "DEMO = https://youtu.be/jeM3MmDGRQ4 Inspiration Climate change is argued to be the world’s biggest problem, with strong scientific evidence that the time for climate action is now. Fast fashion is one of the biggest contributers to climate change, and we hope to encourage individuals to shop sustainably. 10% of the greenhouse gases are from fashion products. The equivalent of one garbage truck full of clothes is burned or dumped in a landfill every second \n500,000 tons of microfibers are released into the ocean each year from washing clothes — equivalent of 50 billion plastic bottles What it does Thrift is a google chrome extension helping shoppers shop sustainably with one click of a button. \nOur ultimate goal is to help browsing online shopping consumers find and buy garments second-hand that can have an influence to help stop climate change. With Thrift, we suggest second-hand items that are similar to the garment the user is browsing but are cheaper and can be upcycled. We also want to raise awareness about shopping consumer habits, checking the textile composition- making them think twice before buying. How I built it We built the back end with python and flask. The front end was built with html, css and javascript. What's next for thrift We hope to... \nadd a tracking feature to provide a history of clothing garments the user viewed\nadd technical code to web scrape material composition and visually model it on the pie chart\nuse ML to detect the colour and description of the garment through the image Built With css flask html javascript python Try it out GitHub Repo www.figma.com Submitted to JAMHacks 6 Winner Best Sustainability / Social Good Hack Created by I  worked on the back-end of the Chrome extension. I used a combination of JS and json primarily for the extension back-end, and also helped with the web-scrapping process with python. Sophie Yang I worked on our idea, coded our chrome extension using HTML and CSS, and made the presentation for our pitch. B"
      }
    ]
  },
  {
    "file_path": "./devposts/thief-nft.html",
    "project_id": "thief-nft",
    "title": "THIEF: NFT",
    "tagline": "Hey Thieves! Once a day at a random time, heist with players around the world to steal NFTs.",
    "hackathon": "",
    "built_with": [
      "c#",
      "sdk",
      "solana",
      "unity",
      "webgl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/483/988/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration 🧠 What if we combined the social thrill of BeReal and the addictiveness of playing-to-earn in Web3 games? We get THIEF: NFT—a game where players around the world log on at a random time every day to steal NFTs from a central vault. Imagine getting the notification that today's Heist is ready... and logging on to instructions from H.E.R, our adorable and hyper-intelligent bunny mascot! During your two minutes of playtime, players from all across the globe will frantically race to pull the most desirable NFTs from the vault. Play hacking minigames as fast as you can to get the rarest items! What it does 🕹️ For our hackathon submission, today's heist becomes available every time you launch the game (for demo purposes). Log in using your Phantom Wallet and get heisting! After a quick briefing from H.E.R, players are thrust into a rapid 2 minutes of gameplay, where the goal is to use the information available to you to solve puzzles and steal NFTs. Our vision for the game is a live-server experience, where players draw from the same bank—but for this demo, we have implemented it in a separate single-player experience so everyone can try it. 2 minigames are present in the hackathon submission: Guess the Security Questions and Break the Secret Code! Players use their wits and speed to \"steal\" NFTs as fast as possible. Once your 2 minutes are up, players can view what items they've collected over a lifetime of playing HEIST: NFT. In the future, we imagine that the game will have a thriving economy, where players trade rare one-of-a-kind NFTs using our own token. How we built it 🏗️ THIEF: NFT is built in Unity and C#. With the integration of the Solana framework and SDK , we're able to link Web3 wallets directly in-game and prep them for blockchain transactions. Our team hand-drew the NFT art, with graphics designed using Figma. Challenges we ran into 🥲 We used Solana-Unity-SDK Package to configure a connection to a Web3 Wallet (e.g. Phantom) but ran in"
      }
    ]
  },
  {
    "file_path": "./devposts/timetable-sweetie.html",
    "project_id": "timetable-sweetie",
    "title": "Timetable Sweetie",
    "tagline": "Our AI-powered tool helps users stay accountable, track habits, and optimize tasks with real-time voice interaction, offering personalized encouragement and a sleek, user-friendly interface.",
    "hackathon": "",
    "built_with": [
      "apis",
      "express.js",
      "html/css",
      "javascript",
      "jsx",
      "mpython",
      "node.js",
      "openai-api",
      "postgresql",
      "react",
      "vite",
      "zustand"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "General Challenge Created by Jason Shao Kaushik Tumu ⭐️ 3x Hackathon Winner | CS @ Trent University",
      "Hack the Hill IIWinnerGeneral Challenge",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/049/665/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "Extension that allows for interactive AI communication to set up calendar events. Enter urls to block during focus time Intuitive time table to see upcoming events. Extension that allows for interactive AI communication to set up calendar events. Enter urls to block during focus time Intuitive time table to see upcoming events. Extension that allows for interactive AI communication to set up calendar events. 1 2 3 4 Inspiration Our inspiration comes from the drive for self-improvement—becoming the best versions of ourselves. We asked ourselves, what’s the most efficient way to achieve this? By encouraging and reinforcing positive habits, replacing bad habits with good ones, and being able to visualize our progress, we believe people can become more self-aware and accountable. On top of that, for many of us, our mothers are our biggest supporters in life. So, we incorporated the comforting and encouraging voice of a mother to guide users along their journey. This personal touch amplifies the effectiveness of the tool, making it not just a timetable but a supportive companion for self-improvement. What it does Our project is an intelligent AI companion designed to help users stay accountable and disciplined on their journey to self-improvement. The AI listens to the user’s voice, understanding their needs and interacting in real time to provide encouragement and guidance. When a user submits a new event or task, the AI supports them throughout the process, offering motivation and ensuring they stay on track to meet their goals. The platform is equipped with a user-friendly interface, allowing users to interact in their preferred language and seamlessly manage their schedules. By intelligently analyzing user inputs, the AI optimizes daily events, finding the most productive and efficient way to complete tasks. It's more than just a scheduling assistant—it’s a personalized accountability partner that empowers users to achieve their best, both in productivity and persona"
      }
    ]
  },
  {
    "file_path": "./devposts/thr-bot.html",
    "project_id": "thr-bot",
    "title": "THR-Bot",
    "tagline": "A bot for MakerHacks.",
    "hackathon": "",
    "built_with": [
      "c++",
      "cad",
      "esp32",
      "onshape"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/252/689/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 What It Does Our bot efficiently scores points on the custom game field at MakerHacks. It effectively crosses sides during autonomous and prepares to carry 3 blocks at a time up the ramp, to the scoring area. It uses 4 individual continuous motors and two servos to have an arm for scoring. Our strategy utilized the maximum number of cubes that could be held at one time, 3 while maximizing points during the Auton period. How We Built It We used an esp32, 4 continuous TT motors, and 2 servo motors for hardware. The 4 continuous TT motors made up the drive train, while the two servos were used to maximize torque and lift the arm. We didn't have access to 3D printing earlier in the hackathon, so we innovated and built the robot from cardboard pizza boxes. We were able to 3D print an arm and use it to score points. For software, we used C++ to implement a WebSocket Wireless AP server. This ensured minimal latency when communicating with the bot during TeleOp periods. In the end, this system proved to be useful. Challenges, Accomplishments, and Things Learned This was our first hardware robotics hackathon, so we had to iterate our strategy a lot. Our 3D prints had issues the first time around, so we innovated to use a combination of cardboard and plastic. However, in this process, we learned a great deal about being resourceful and efficiently building algorithms. In the future, we hope to plan better and improve the structural integrity of the bot. Built With c++ cad esp32 onshape Try it out GitHub Repo Submitted to MakerHacks Created by Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Kosei Tsukamoto Vedant Garg"
      }
    ]
  },
  {
    "file_path": "./devposts/thrifter-dzgj0e.html",
    "project_id": "thrifter-dzgj0e",
    "title": "Thrifter",
    "tagline": "Find the clothing and fashion styles you are looking for!",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "google-cloud",
      "python",
      "tensorflow",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "prize Created by I worked on Back-end pyturtle Nathan I worked on front-end design and web scraping",
      "First place prize Created by I worked on Back-end pyturtle Nathan I worked on front-end design and",
      "hack::peelWinnerFirst place prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/922/499/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Thrifter identifies the clothes in the picture and finds the clothes as well as where to buy them Inspiration While watching T.V., I wanted to find what one of the characters in the show was wearing at the time, but couldn't find anything similar. This inspired me to create an application that can find the clothing for us. What it does This application uses Tensorflow to grab each clothing article off a person and identify it. It then matches the clothing to a catalogue of clothing we web scraped from multiple different clothing brands. How we built it We trained Tensorflow to Challenges we ran into One of our team member's computers stopped being able to connect to the Google Cloud Vision API, so we had to transfer a lot of the code to another member's computer and work on it all there. This happened 2 hours before the deadline! Accomplishments that we're proud of We are very happy that we were able to scrape all of the info about all of the clothes from multiple websites and catalogue them, then have our A.I. identify the most similar clothes to the clothes in a picture. What we learned We learnt a lot about web scraping, Google Cloud Platform, Tensorflow, and GUI design. What's next for Thrifter The next step is to create a good UI so that anyone can use it as well. Hopefully, Thrifter can become the Shazam of clothing! Built With beautiful-soup google-cloud python tensorflow tkinter Submitted to hack::peel Winner First place prize Created by I worked on Back-end pyturtle Nathan I worked on front-end design and web scraping. Curtis Li"
      }
    ]
  },
  {
    "file_path": "./devposts/tiny-office-6i9ekx.html",
    "project_id": "tiny-office-6i9ekx",
    "title": "Tiny Office",
    "tagline": "We designed a web app that consists of an isometric model utilized to customize your office. This innovation increases the synergy between teams and productivity in the company.",
    "hackathon": "",
    "built_with": [
      "flask",
      "mongodb",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by the challenging and logical nature, as well as the applicability, of the CBRE sponsor challenge. Optimization is necessary in order to create a more productive, efficient, and healthy work place, which our application aims to solve. We were eager to try our hand at tackling this problem in order to effect positive change through our project. What it does Our application allows the user to input the building floors and teams needed to be assigned to said floors. After the user inputs the data, our algorithm takes in the data and outputs the floor-team combination with the highest SNL score; our term for the combined weightings of the space-score (measures the amount of space taken), the number-score (measures the total number of teams in the building), and the like-score (measures the relationships between team pairings on each floor). In addition, our project also provides the user with saving and loading features. How we built it We built our application using ReactJS for the front end and Flask for the back end. We then hosted our application through Microsoft Azure cloud services and our domain on domain.com Challenges we ran into Since we were all first time hackers, we ran into challenges of coordination and tasks. We managed to solve this by coming together every so often and updating each other on our progress, as well as assigning tasks and figuring out next steps. After that, we had the challenge of programming the front end and back end algorithms, and connecting them together in the end. We had little experience doing this, but we are proud to say that we learned and successfully did it in the end! Accomplishments that we're proud TAMU Hackathon 2023 is the very first hackathon for all four members of our team. Despite our inexperience, we managed to thoroughly prepare ourselves with this event. We started off the hackathon by breaking down our schedule for the entire 24 hours, which included the brainstorming stage, set up"
      }
    ]
  },
  {
    "file_path": "./devposts/tindair.html",
    "project_id": "tindair",
    "title": "Tindair",
    "tagline": "Never go solo in an airport again!",
    "hackathon": "",
    "built_with": [
      "css3",
      "express.js",
      "html5",
      "javascript",
      "node.js",
      "react",
      "websockets"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/241/996/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF GIF GIF GIF GIF GIF GIF GIF GIF GIF 1 2 3 4 5 6 7 Inspiration Going through airports solo seems to be an unavoidable part of life. You walk in, go though security, and wait a few hours for your flight, trying to kill time with no one around. After all, you can't bring your friends to the airport, right? Well, if you can't bring them, make them! Tindair gives you the chance to connect to others going on the same flights as you. You can make new friends, find travel buddies, and get help travelling -- all through the power of our airport matching system! What it does After opening the page, users are directed through a short questionnaire that asks for three pieces of information -- their name, their departure airport, and their arrival airport. after answering, our system will automatically place them in a groupchat, matching them to other users that entered the same airport information. From there, it's up to the users! From meeting up at restaurants to carpooling at their arrival destination, the options are limitless -- all through the power of realtime chat. How we built it The application was built using Node.js, with the client-side being written in React. Much of the styling was written using custom CSS instead of a framework, so that we could match the custom color and design scheme we decided on. The back-end was created using Express.js, and WebSockets to allow for realtime chat. Challenges we ran into Despite how standardized React and Node.js are, it took us much longer than expected to get everything set up on all our machines. We ran into lots of setup problems related to software versions, package managers, and operating system distributions, which took us a long time to get working. Because we worked with custom styling, it took us a lot of time to adjust everything to our liking. Even though it took extra time, it was definitely worth it! Accomplishments that we're proud of Being able to create realtime chat functionality -- as well as the sy"
      }
    ]
  },
  {
    "file_path": "./devposts/tl-dw-p867k5.html",
    "project_id": "tl-dw-p867k5",
    "title": "TL;DW",
    "tagline": "An AI powered web app that turns video into text.",
    "hackathon": "",
    "built_with": [
      "assemblyapi",
      "python",
      "streamlit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack@WPI 2022WinnerHonorable Mentions",
      "Building my first text-to-speech app.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/796/952/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 ✨Inspiration✨ A lot of us would have been in a situation where we are trying to watch a video in a public space, but can’t do so because of not having headphones with us. Another downside of videos is that they are not very searchable. It takes ten minutes to figure out what’s in a ten minute video, whereas in a piece of text you could find out what interests you in a matter of seconds. I built an app that makes any YouTube video consumable in the form of text, making it concise, searchable and readable. ⚒What it does⚒ What TL;DW does is extremely simple — it is a web application that takes a video from YouTube and asynchronously transcribes it, powered by AssemblyAI. What’s really cool is that it takes just a few minutes to transcribe any length of video and thanks to Assembly AI’s Audio Intelligence, it takes any accent of English and transcribes it very accurately. 🏗How we built it🏗 I used the AssemblyAI API and Streamlit to build the web app. I was inspired by an AssemblyAI tutorial on using its asynchronous transcription feature for videos and built a tool to solve my day-to-day problems that happen due to the downsides of video content mentioned above. 🚧Challenges we ran into🚧 I had never used Streamlit before - Thanks to various resources on the internet and streamlit’s documentation, I was able to tackle multiple challenges that my lack of experience with Streamlit brought about. Me being the only teammate, I had to work around the clock to do both - frontend and backend. Being new to Assembly AI API, Assembly AI’s documentation and tutorials immensely helped me this weekend. Thus - I successfully tackled all challenges I faced this weekend and completed a fully functional hack. 🏆Accomplishments that we're proud of🏆 Building my first text-to-speech app. Successfully submitting a hack despite hacking alone and facing many challenges. 📚What we learned📚 How to use AssemblyAI’s API How to build web apps with Python using Streamlit How Audio Intellige"
      }
    ]
  },
  {
    "file_path": "./devposts/tldr-0megnj.html",
    "project_id": "tldr-0megnj",
    "title": "ThorGuide",
    "tagline": "ThorGuide: Ignite your wanderlust with AI, NFTs, and immersive experiences. Unveil hidden gems, ensure safety, and explore worryfree. Discover, navigate, and embrace the future of userfriendly travel!",
    "hackathon": "",
    "built_with": [
      "azure",
      "bootstrap",
      "css3",
      "gpt4",
      "html5",
      "imgbb",
      "javascript",
      "mapbox",
      "mediapipe",
      "mongodb",
      "node.js",
      "numpy",
      "ocr",
      "openai",
      "opensea",
      "python",
      "sklearn",
      "stablediffusion",
      "verbwire"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "s in this hackathon",
      "GryphHacks 2023WinnerBest AI Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/489/922/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Azure Cosmos DB Voice Flow Azure Container Azure Cosmos DB Voice Flow Azure Container Azure Cosmos DB 1 2 3 4 5 6 7 8 9 10 🤔 Problem Statement The challenges faced by travelers in navigating unfamiliar territories, making informed decisions, and ensuring their safety affect a significant portion of the global population. Let's explore the research and numbers that shed light on the scale of this issue, highlighting the potential impact of a comprehensive solution. According to the World Tourism Organization (UNWTO), international tourist arrivals reached a staggering 1.4 billion in 2019. This number represents a substantial percentage of the global population. Furthermore, the UNWTO predicts that international tourist arrivals will continue to grow, potentially reaching 1.8 billion by 2030. However, within this vast number of travelers, a considerable portion faces challenges in obtaining reliable information and ensuring their safety. Studies indicate that approximately 10-15% of travelers encounter safety-related incidents during their trips. These incidents can range from minor theft to more serious crimes, impacting travelers' experiences and well-being. Additionally, research suggests that a significant number of travelers struggle with trip planning and accessing accurate information about local attractions and landmarks. A study found that around 25% of travelers expressed difficulty in finding reliable and up-to-date information about their chosen destinations, resulting in suboptimal travel experiences. Furthermore, the desire for historical context and immersive experiences is prevalent among travelers. Research conducted revealed that 80% of travelers expressed a strong interest in understanding the cultural significance and history of the places they visit. However, the lack of comprehensive platforms that provide engaging historical insights limits travelers' ability to fully immerse themselves in the destinations they explore. By addressing these chall"
      }
    ]
  },
  {
    "file_path": "./devposts/token-turrets.html",
    "project_id": "token-turrets",
    "title": "Token Turrets",
    "tagline": "Play, Pay, Pulverize - on chain! ⛓️‍💥",
    "hackathon": "",
    "built_with": [
      "escrow",
      "express.js",
      "ipfs",
      "javascript",
      "mongodb",
      "nft",
      "nfts)",
      "node.js",
      "tcp",
      "three.js",
      "typescript",
      "webgl",
      "websockets",
      "xrpl",
      "xrpl-(rlusd"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "in Ledger Award Created by Ryan Ning Satyam Singh",
      "Ripple: Best in Ledger Award Created by Ryan Ning Satyam Singh",
      "Hack the North 2025WinnerRipple: Best in Ledger Award",
      "Building a secondary marketplace for NFT skins, enabling trading and rarity-driven economies.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/740/291/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Escrow Landing page Escrow Landing page Escrow 1 2 3 1st Place Ripple: Best in Ledger 🚀 Inspiration We wanted to make online competition feel real. The game is skill, tanks, and action - but the stakes are on-chain. By weaving XRPL features like RLUSD (a USD-pegged token), escrow, and tokenization directly into the match flow, we created a trustless tournament model : stake → battle → payout. No middleman, no organizer - just players competing, with XRPL guaranteeing the rewards. Live in production here! https://tokenturrets.vercel.app 💡 What it does Token Turrets is a real-time multiplayer tank battle where anyone can create a room, start a tournament pot, and let the players fight it out. Each participant stakes RLUSD to enter, the pool is locked in escrow, and when the battle ends, XRPL automatically pays the winner. On top of that, players can personalize their tanks in our skin store , where every skin purchased with RLUSD is minted as a unique NFT and stored on-chain. This turns cosmetic purchases into verifiable, tradable assets - bridging gameplay, payments, and tokenization. 🛠️ How we built it Networking & gameplay : Real-time tank arena using WebSockets, TCP protocol, and Three.js for smooth multiplayer action. Tournament flow : Any player can spin up a room → others stake RLUSD to join → our backend secures the pot in XRPL escrow → the winner is determined by in-game results → escrow automatically releases payouts. Skin store : A full in-game shop where skins are purchased with RLUSD. Each skin is minted as an NFT on XRPL, giving players unique, ownable assets tied to their tanks. Trustless by design : Because both payments and assets live on-chain, players don’t have to trust an organizer. The system itself guarantees fairness and ownership. ⚔️ Challenges we ran into Synchronizing real-time gameplay with on-chain financial flows without slowing things down. Designing escrow and NFT minting flows that feel seamless in-game. Balancing scope: building multi"
      }
    ]
  },
  {
    "file_path": "./devposts/tomato-mosaic-virus-visual-diagnosis-tmvvd.html",
    "project_id": "tomato-mosaic-virus-visual-diagnosis-tmvvd",
    "title": "Tomato Mosaic Virus Visual Diagnosis(TMVVD)",
    "tagline": "Our product is the TMVVD also known as the Tomato Mosaic Virus Visual Diagnosis, a website designed to diagnose the harmful Tobamovirus in tomato plants and increase tomato production.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "teachable-machine"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackWise 2020WinnerBest Work & Economic Growth Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/303/519/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Gilroy Farm Gilroy Farm Gilroy Farm 1 2 Inspiration Last year during a school field trip we traveled to a farm in Gilroy where we got to see many different plants, vegetables , and fruits being grown where they would then be sold to other companies where they would be sold at grocery stores. When we got to the tomato section, the entire crop was wiped out and we were informed it was because of viruses that destroyed the crops. We drew inspiration from this and set out to make an accessible cost-effective device using artificial intelligence technology that can detect the Tobamovirus and give farmers advice to stop it from destroying yields of crops and stop the virus from spreading early on. What it does The Tomato Mosaic Virus Visual Diagnosis is an accessible cost-effective device using artificial intelligence technology that can detect the Tobamovirus and give farmers advice to stop it from destroying yields of crops and stop the virus from spreading early on. How I built it We built our website first by using the Teachable Machine, and inputted images from google for each of the categories (infected with the tomato mosaic virus and not infected with the tomato mosaic virus), then inputted the code into a glitch website and added additional information with the HTML. After some trials, we finally got the machine working on our website. In the end, our result was near perfect. Challenges I ran into We ran into many challenges in the process, at the beginning when developing our Teachable machine code we struggled with it a lot trying to embed it into our html site, we realized that we needed to use a public HTML hosting website so we transferred our site on to glitch. Another challenge we faced was in the process of testing when we realized our project wasn't able to detect infected tomatoes. We edited the code and found some code online that we incorporated with our code to make our process for identifying infectious tomatoes less strict and more lenient. Accompl"
      }
    ]
  },
  {
    "file_path": "./devposts/time-chaser.html",
    "project_id": "time-chaser",
    "title": "Time Chaser",
    "tagline": "A platform that advocates for transparency and healthier work-life balance between schools and teachers.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "flask",
      "leaflet.js",
      "mui-material",
      "python",
      "react",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "New Classmate Hack Created by I contribute on front-end designing and API debugging also the User A",
      "Teacher's Hack 2WinnerNew Classmate Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/233/237/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 💡 Inspiration 💡 We believe that teachers are the pillars of our society and pave the way for the next generation to thrive and grow. Even though they play such a huge role in the development of a successful community, they are often overworked, underpaid, and treated unfairly. This led us to address the issue of exploited teachers and raise awareness of this global problem. References: https://www.rappler.com/nation/overworked-teachers-among-causes-philippines-high-learning-poverty-rate/ https://www.ei-ie.org/en/item/25366:new-global-report-points-to-overworked-underpaid-and-undervalued-teaching-profession ⚙️ What it does ⚙️ Time Chase is a QR code-based time tracking website that keeps track of your own schedule and advocates for a healthier work-life balance for teachers. We use QR codes to verify the time-ins and time-outs of our users. This is integral for us as this lets us add another layer of security to the process, promotes transparency between the school and the teacher, and makes it convenient for them to log their times. We also added a virtual map with markers with different colors that signify the average number of hours per marker with green markers being the least overworked and red markers being the most overworked academic institutions. This data helps us arrive at conclusions on which schools have the highest density of overworked teachers and can serve as a stepping stone to better equip leaders to make more inclusive decisions. 🏗️ How we built it 🏗️ We developed the application with love using the React library for the frontend, and the Flask framework for the backend. Additionally, we used CockroachDB as our database to store information such as the logs and passphrases, Psycopg2 library as an adapter to connect to it, and Twilio to send confirmation SMS. ⚫ GitHub Usage ⚫ The app consists of different components that we divided among ourselves so we used four different branches to facilitate unconflicted development on each si"
      }
    ]
  },
  {
    "file_path": "./devposts/tomravel.html",
    "project_id": "tomravel",
    "title": "Tomravel",
    "tagline": "Tomravel is designed to provide you with a ride across the globe, where you can explore the diversity of cultures and traditions that make our world so fascinating ✨",
    "hackathon": "",
    "built_with": [
      "css",
      "geoapify",
      "html",
      "javascript",
      "mapbox",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from GoDaddy Registry [APAC Only] Created by I spend my most time on building fron",
      "Hack Around the World 2WinnerBest Domain Name from GoDaddy Registry [APAC Only]",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/400/164/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "thumbnail thumbnail thumbnail 1 2 Inspiration Traveling can be a challenging experience, as individuals often face a multitude of obstacles such as limited time, unfamiliarity with their destination, and language barriers. At our organization, we strive to provide solutions to these common difficulties, ultimately resulting in a more fulfilling and enjoyable travel experience for our clients. By offering comprehensive travel assistance and guidance, we aim to help travelers overcome any obstacles that may arise and make the most out of their journey. Our ultimate goal is to ensure that every traveler has a rewarding and unforgettable travel experience. What it does Tomravel is a comprehensive website that enables users to input their desired tourist destination and displays a map of the area, along with the locations of various tourist attractions that people can visit. In addition, Tomravel also provides a detailed travel guide that can help users allocate their time more effectively and maximize the number of places they can visit. Furthermore, our website generates basic greetings in different languages, making it easier for users to communicate with locals and immerse themselves in the local culture. Challenges we ran into Limited data to work on. Coming up with a feasible idea that could be implemented within the given time frame. Completing the project in the given time frame. Accomplishments that we're proud of We are proud of finishing the project on time which seemed like a tough task as we started working on it quite late due to other commitments and were also able to add most of the features that we envisioned for the app during ideation. Moreover, we learned a lot about new web technologies and api that we could incorporate into our project to meet our unique needs. What we learned We learned about the various technologies we can use to build a website that uses multiple APIs, such as JavaScript, HTML, CSS, React,Using map gl library. We also discussed t"
      }
    ]
  },
  {
    "file_path": "./devposts/thrivetogether.html",
    "project_id": "thrivetogether",
    "title": "ThriveTogether",
    "tagline": "Collaborative and social platform for small business owners from underrepresented backgrounds.\n\nBy Casey Pei and Ryan Kabir",
    "hackathon": "",
    "built_with": [
      "express.js",
      "google-translate",
      "mongodb",
      "node.js",
      "react",
      "tailwind-css"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/488/372/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "accessability Logo Homepage groups oauth accessability Logo Homepage groups oauth accessability 1 2 3 4 5 6 💚 ThriveTogether Final Application Available at: https://thrive-together-iota.vercel.app/ Last Commit before deadline: 494597d Created for the 2023 APEC App Challenge , with the theme of  “Creating a Resilient and Sustainable Future for All.” Fifty-one percent of these vital businesses, however, require more funding than they can currently access. Credit constraints are a serious challenge for SMEs. Without reliable sources of working capital, SMEs are unable to make investments needed for growth, leading to stagnation. Given the importance of SMEs as a source of employment, barriers to accessing financing become barriers to poverty reduction and economic growth. Blended finance can help firms fill this critical gap. (Runde et al. 2021) What does this mean? It means we believe that there is a better way for small-to-medium enterprises or SMEs (particularly from underrepresented groups like those from Less Developed Countries (LDC), those that are women-owned, indigenous-owned, disabled-owned or LGBTQIA+ owned, and more) to combat their unique challenges and join the global market. How? By creating a platform where small businesses (selling similar products, of similar backgrounds, or in similar regions) can combine resources to overcome common problems that SMEs face -- such as having working capital, ability to apply for licenses, exposure, and more by working together. This also allows the communities surrounding these businesses to grow stronger without relying on outside sources of assistance. What it does Collaboration Share storefronts with other businesses to save costs on site hosting and have greater inventory. Finances Share and receive financial help in order to get necessary licenses, equipment, and more. Exposure Easily promote and get promoted by other businesses to increase business via social media! How we built it mongoDB express.js react node"
      }
    ]
  },
  {
    "file_path": "./devposts/ticketbot-w5x84s.html",
    "project_id": "ticketbot-w5x84s",
    "title": "TicketBot",
    "tagline": "Streamline IT support for content editors with AI-powered ChatGPT: Empowering faster ticket management and instant solutions.",
    "hackathon": "",
    "built_with": [
      "django",
      "openai",
      "react",
      "text-davinci-003"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/511/325/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The inspiration behind TicketBot came from observing the challenges faced by content editors in accessing timely IT support. The creators recognized the need for a more efficient and proactive solution that could assist content editors in resolving their issues before opening a support ticket. What it does TicketBot is an AI-powered chat system that acts as the first line of help for content editors. It leverages advanced natural language processing and machine learning techniques to answer questions, provide guidance, and troubleshoot common issues. By empowering content editors with instant assistance, TicketBot aims to streamline the IT support process and reduce waiting times. How we built it TicketBot was built using OpenAI model text-davince-003 to provide helpful text completions to user's prompt. The team trained the AI model on UC Davis' CMS training site to ensure accurate and relevant assistance. They also developed a user-friendly interface that enables content editors to gain helpful feedback in a visually appealing manner. Challenges we ran into During the development of TicketBot, the team encountered challenges in fine-tuning the AI model to provide precise and context-aware responses. Additionally, ensuring data privacy while web scraping a training site was also a challenge. Accomplishments that we're proud of The team takes pride in creating a functional and user-friendly AI-powered chat system that can significantly enhance the support experience for content editors. They successfully developed TicketBot to effectively address the pain points faced by content editors and IT support teams. Additionally, they achieved high accuracy and efficiency in providing proactive support, reducing the workload on IT departments. What we learned Throughout the development process, the team gained valuable insights into the complexities of IT support workflows and the specific needs of content editors. They acquired a deep understanding of natural l"
      }
    ]
  },
  {
    "file_path": "./devposts/toiletchecker.html",
    "project_id": "toiletchecker",
    "title": "ToiletChecker",
    "tagline": "So the next person could pee.",
    "hackathon": "",
    "built_with": [
      "arduino"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hardware Hack Created by Laura Tan Ching Lam Lau Yinuo Lin a student in high school or something al",
      "Best Hardware Hack Created by Laura Tan Ching Lam Lau Yinuo Lin a student in high school or somethi",
      "JAMHacks 6WinnerBest Hardware Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/987/074/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration The explicit and morbid scenes in public bathroom stalls. The pungent smell of unflushed yellow and brown excretion in toilets. The discomfort from inflation of filled up bladders. This needs to end. So, how could we find both a cost effective and efficient way to fix this? Enter ToiletChecker. What it does ToiletChecker is made of hardware that checks if one has flushed the toilet after usage, and if the answer is no , it shames them endlessly. It’s made with components that can be easily attached and installed to a bathroom stall. How we built it We have four main hardware components: button light sensor accelerometer buzzer Firstly, the button. This is attached to the lock, and it detects whether it's locked. That way, we could tell if someone is about to use the bathroom stall. Secondly, the light sensor. What this basically does is it detects whether there is a person squatting over the toilet. The light sensor would be about to receive this because the person’s body would block the place that light would touch on the lid. We specifically do this to see whether they are actually using the toilet– they may be just changing in the stall. The third piece of major hardware we used was an accelerometer to identify movement. It’s attached to the side of the flushing handle. When someone flushes the toilet, the flusher would move, and the accelerometer, which moves with the handle it's attached to, would pick this up. And finally, the buzzer. This piece of hardware is only relevant to those who don’t flush toilets. If the button of the lock is released without the accelerometer being activated, it means that the toilet is not flushed, and the buzzer will start buzzing. We used the Arduino software to program the logic of our components. Challenges we ran into This was our first time using hardware in a hackathon, and so we had to consult a lot of mentors on what to do. And when we say a lot, we mean a lot. Literally every half hour we would be "
      }
    ]
  },
  {
    "file_path": "./devposts/toronto-subway-wayfinder.html",
    "project_id": "toronto-subway-wayfinder",
    "title": "Toronto Subway Wayfinder",
    "tagline": "A program that helps commuters to find their way through the Toronto subway system.",
    "hackathon": "",
    "built_with": [
      "python",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/373/890/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "User Interface Inspiration All the members in our group commute on a daily basis and sometimes get confused on our way through the TTC. What it does This program creates which stations the user can go through the end up at their destination How we built it We built the program using Python and Tkinter package Challenges we ran into We didn't run into many challenges along the way. What we had to think most of was the implementation details. Accomplishments that we're proud of We've created a simple program accessible to anyone with a computer and is simple to use which means it relates to broader masses. What we learned We've learned much about the Tkinter package and its uses. What's next for Toronto Subway Wayfinder The following steps for Toronto Subway Wayfinder would be adding more visuals to the interface. Built With python tkinter Submitted to Hack McWiCS 2023 Created by Levent Özay Prashanth Reddy Shyamala ikraskov Kraskov"
      }
    ]
  },
  {
    "file_path": "./devposts/transcribi.html",
    "project_id": "transcribi",
    "title": "Transcribi",
    "tagline": "Get accurate transcriptions and valuable analytics with AI + GPT.",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "javascript",
      "langchain",
      "openai",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Education Hack Created by I developed the full app Arihan Varanasi Full-Stack ML Developer with a k",
      "Best Education Hack Created by I developed the full app Arihan Varanasi Full-Stack ML Developer wit",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/479/023/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home Page Analysis Page Home Page Analysis Page Home Page 1 2 3 Inspiration I was inspired to create Transcribi by the need to streamline the transcription process for researchers, professionals, and students. I wanted to develop a tool that could accurately transcribe audio and video content, making it easier to extract information and insights from large recordings. This is because I had experienced frustration looking through large videos for specific information when conducting research for projects. What it does Transcribi is an advanced transcription tool that converts audio and video files into text format. It uses cutting-edge speech recognition technology through Open AI Whisper to ensure high accuracy in transcriptions. Users can simply upload their files and receive the transcribed text, saving significant time and effort. Next, users can look through the transcript while having the ability to use real-time live subtitles when viewing the recording. Also, users can chat with GPT with the transcript of the audio as context. How we built it Transcribi was built with React for the front end, Python and Fast API for the backend + server, and Open AI, Chroma, and Langchain for using the GPT Api and for using the Open AI Whisper model. Challenges we ran into One of the main challenges we encountered was optimizing the accuracy of the transcription process and streaming it in real-time to the front end client. It was also difficult to format the transcript when sending it from the backend to the frontend. Accomplishments that we're proud of I am proud of developing a transcription tool with high accuracy, even in challenging audio conditions. The system can transcribe various languages and handle different accents effectively. Additionally, I have developed an intuitive and user-friendly interface that simplifies the transcription process for our users and allows them to easily understand and analyze content through the use of AI. What we learned I learned how t"
      }
    ]
  },
  {
    "file_path": "./devposts/touchbistro-inflation-watch.html",
    "project_id": "touchbistro-inflation-watch",
    "title": "TouchBistro Inflation Watch",
    "tagline": "Analyzing the Impact of Inflation on Restaurant Sales: Exploring the Correlation between CPI and Consumer Spending Patterns in Canada.",
    "hackathon": "",
    "built_with": [
      "dask",
      "matplotlib",
      "pandas",
      "statsmodels"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does This project provides insights into how inflation affects the restaurants. How we built it I built it with Dask so that my gaming laptop wouldn't overheat more than it already does. I additionally used the typical Pandas and Matplotlib manipulate and visualize the dataset. Challenges we ran into The first main challenge was getting into exploring the dataset, as there was so many variables and things to account for, it was incredibly daunting. This is why the best thing to do when it comes to projects with seemingly massive amount of breadth is to just started, and work your way through it, like a diagonally cut sanwich (I have not slept) . The second main challenge was actually exploring the dataset, as there were so many factors to account for, such as what should I remove? What algorithm should I use to remove the outliers? What should I keep? The last main challenge was learning times series, as I knew little about it before this project, and so I spent alot of time understanding the different techniques and why they used them. Accomplishments that I'm proud of The biggest accomplishment I was proud of was getting through an entire dataset from exploring and cleaning it to actually making insights. This is probably my first time doing it from complete scratch like this. What I learned I learned a whole lot, exploring, cleaning, and especially about time series data! What's next for TouchBistro Inflation Watch :Smiling Face with Horns: I think next, I want to try tackling classification data, as that's still a pretty big grey box for me. Built With dask matplotlib pandas statsmodels Created by https://github.com/CodeOfGordon/CxC-2025 Code_Of_Gordon Huynh she11fish she11fish"
      }
    ]
  },
  {
    "file_path": "./devposts/too-hot-to-hack.html",
    "project_id": "too-hot-to-hack",
    "title": "Too Hot to Hack",
    "tagline": "can't believe this is going on my digital footprint (pure brainrot)",
    "hackathon": "",
    "built_with": [
      "ai",
      "chatgpt",
      "figma",
      "framer",
      "github"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "brainrot jia.seed hackathon ($5,772) in prizes"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/162/983/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The Too Hot to Handle Game, specifically the iPad edition. What it does The central philosophical question that this paper seeks to interrogate is thus: What does it truly mean to exist as a reducible data point within an oppressive societal structure that demands not only compliance but also the ongoing performance of compliance in the guise of authenticity and self-determination? Through the dissection of cognitive dissonance, emotional labor, and the pervasive existential malaise that permeates both the overt and covert narrative arcs of Too Hot to Handle, this study endeavors to push the reader into an uncomfortable space of critical self-reflection. By examining how participants grapple with the dissonant tension between desire, identity, and external regulation, the paper urges the reader to reflect on their own entanglement within similar mechanisms of control that extend beyond the screen, into the very fabric of their daily lives, social media engagements, and broader societal roles. Ultimately, this paper calls for a radical re-examination of agency, identity, and selfhood in a world where we are increasingly governed by the very data we generate, and asks whether true freedom can ever be realized within a system that commodifies and surveils every aspect of human experience. How we built it Human Intuition and AI Challenges we ran into time zone difference, being too full from Thanksgiving meals, having too much personality Accomplishments that we're proud of Intuitive user experience, information architecture, collaboration, product strategy, a shipped product What we learned Product Strategy and nothing is ever too hot to handle if you put your mind to it! What's next for Too Hot to Hack Too Hot to Hack 2 (maybe) Our team has been to less than 5 hackathons. Built With ai chatgpt figma framer github Try it out brainrot.framer.website Submitted to brainrot jia.seed hackathon ($5,772) in prizes Created by User Experience, Cognitive Science,"
      }
    ]
  },
  {
    "file_path": "./devposts/trailbuster.html",
    "project_id": "trailbuster",
    "title": "TrackBuster",
    "tagline": "Keeping train tracks under control via live status monitoring, anomaly detection and stress prediction. We leverage robust statistical correlations in dataset provided to ensure guaranteed control.",
    "hackathon": "",
    "built_with": [
      "openstreetmap",
      "python",
      "r",
      "react",
      "scikit",
      "scikit-learn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "live status monitoring of train tracks",
      "stress prediction and predictive maintenance of track anomalies",
      "timeframe of 120 days (best found yet) allows high-level precision and confidence of time and place of prediction",
      "data visualization is the first step to gather knowledge about a dataset",
      "What's next for TrackBuster"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/669/883/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Post-anomaly review chart: plot GPS position and time to see where low values of RSSI (red) usually happen. Each dotted line is a recording Interface to find nearest anomaly possible given position Interface to do live monitoring (menu), review recent anomalies (menu), predict where future ones will happen and compare state of tracks Statistical analysis of data Post-anomaly review chart: plot velocity, A1-to-A2 ratio, time to see when bad RSSI (red) usually happen. Each dotted line is a recording Post-anomaly review chart: plot GPS position and time to see where low values of RSSI (red) usually happen. Each dotted line is a recording Interface to find nearest anomaly possible given position Interface to do live monitoring (menu), review recent anomalies (menu), predict where future ones will happen and compare state of tracks Statistical analysis of data Post-anomaly review chart: plot velocity, A1-to-A2 ratio, time to see when bad RSSI (red) usually happen. Each dotted line is a recording Post-anomaly review chart: plot GPS position and time to see where low values of RSSI (red) usually happen. Each dotted line is a recording 1 2 3 4 5 6 Inspiration Of utmost importance is a clean, fast, easy-to-use interface that shows reliable and robust predictions regarding future anomalies. We drew inspiration from nuclear-reactor dashboards: a powerful example of how to show many and important information clearly. Last but not least we got inspired by Ghostbusters.. What it does live status monitoring of train tracks anomaly detection (via multi poly-fit regression) stress prediction and predictive maintenance of track anomalies ensuring guaranteed control by combining and leveraging emergent statistical correlations comparison and optimization of in-place works visualizing the main results in an intuitive and user-friendly way How we built it Python React scikit-learn R GitHub Asana Challenges we ran into UI building (not enough experience in this team) accuracy of model re"
      }
    ]
  },
  {
    "file_path": "./devposts/trackease.html",
    "project_id": "trackease",
    "title": "TrackEase",
    "tagline": "An idea to help our hackathon organizers for providing shipment updates",
    "hackathon": "",
    "built_with": [
      "flask",
      "python",
      "react",
      "sql",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Future of Work Hack! Created by Kennis Joseph Aakanksha Rangdal Pratham Gupta Dev Sapariya",
      "s to ship to hackers around the world",
      "What it does The goal of this project is to create a website that enables hackers to easily track t",
      "s they have won in hackathons organized by MLH, with the aim of reducing the number of email inquiri",
      "tracking experience",
      "-tracking website",
      "Work-a-thonWinnerFuture of Work Hack!",
      "What's next for TrackEase",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/388/875/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "About us Homepage Results after query About us Homepage Results after query About us 1 2 3 4 Inspiration As we all know, our hackathon organizer, MLH, has numerous prizes to ship to hackers around the world. We also understand the volume of emails they receive from hackers inquiring about the status of their packages. To alleviate their workload and provide satisfaction to hackers, we have come up with an idea for a website that fetches details of the prizes won based on the entered email address. The user will be able to view the prize they have won and its current status, whether it is processed or shipped. This eliminates the need for hackers to email MLH about the status of their prizes. What it does The goal of this project is to create a website that enables hackers to easily track the status of the prizes they have won in hackathons organized by MLH, with the aim of reducing the number of email inquiries to MLH and providing hackers with a more efficient and satisfying prize tracking experience. By automating some of the more routine and time-consuming tasks associated with email management, our system will help free up employees' time to focus on more pressing tasks and responsibilities. How we built it We used React , a popular JavaScript library, to create the front end of the website, allowing users to input their email addresses and view the status of their prizes. For the back end, we chose Python , a versatile and widely-used programming language, to write the code that retrieves the prize data from MLH's systems. To create the API that serves the prize data to the front end, we used Flask , a lightweight web framework. Together, these technologies provided a powerful and scalable stack, enabling me to build a robust and responsive prize-tracking website. By combining these technologies, I've created a user-friendly and efficient platform for hackers to track the status of their MLH hackathon prizes. Challenges we ran into One of the biggest challenges"
      }
    ]
  },
  {
    "file_path": "./devposts/trainr-2gkv9a.html",
    "project_id": "trainr-2gkv9a",
    "title": "TrainR",
    "tagline": "The future of sports training! Custom workouts and form analysis.",
    "hackathon": "",
    "built_with": [
      "flask",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/091/744/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "GIF Our logo! Landing page Workout generation Dashboard Form check Pose recognition, up close GIF Our logo! Landing page Workout generation Dashboard Form check Pose recognition, up close GIF Our logo! 1 2 3 4 5 6 Inspiration Sport-tailored workouts work—as shown by how improvements in throwing velocity were observed alongside increases in muscular endurance and power following a sport-specific training regimen focused on the proximal segments (1). But online workout routines and training programs, especially for more specialized disciplines and activities, are oddly difficult to find and oftentimes unreliable, and not everyone can afford a personalized coach. We were inspired to fill this gap with TrainR, offering specific, professional-grade workout routines that cater to the unique demands of niche sports, ensuring everyone has access to reliable guidance and is able to achieve optimal performance. What it does TrainR is a web application that generates customized workout plans for niche sports and provides feedback on form for user-submitted videos. Users can input their sport, fitness level, workout focus, and available equipment to receive tailored training routines that suit their specific needs. Users are also given the option to submit their own research papers for the API to retrieve information from to generate additional workouts. How we built it To develop our workout generator, we leveraged LangChain for retrieval-augmented generation (RAG), enabling us to chunk and query various research articles. We applied cosine similarity to rank the relevance of searches, guiding the language model’s output. Using the GPT-4 Turbo API, we generated personalized workouts based on the retrieved information. We also trained a YOLOv8 model for pose detection in order to provide the form feedback.\nWe utilized React and HTML/CSS for the frontend. Challenges we ran into We spent about 10 hours trying to come up with an idea that was both feasible within the time period a"
      }
    ]
  },
  {
    "file_path": "./devposts/trailguide.html",
    "project_id": "trailguide",
    "title": "TrailGuide",
    "tagline": "Don't get lost",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "gcp",
      "github",
      "infobip",
      "langchain",
      "python",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of Infobip SDK, Presented by Infobip Winner Best Domain Name from GoDaddy Registry Created by I",
      "Best use of Infobip SDK, Presented by Infobip Winner Best Domain Name from GoDaddy Registry Created",
      "Hack Western 10WinnerBest use of Infobip SDK, Presented by InfobipWinnerBest Domain Name from GoDaddy Registry",
      "It's our first time using MySQL",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/683/944/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Backend Operations Logo Example SMS 1 Example SMS 2 App Maps App Notifications Backend Operations Logo Example SMS 1 Example SMS 2 App Maps App Notifications Backend Operations 1 2 3 4 5 6 Inspiration Introducing TrailGuide, an innovative service designed to enhance your hiking experience through the power of artificial intelligence. TrailGuide is AI-powered and accessible through SMS, allowing hikers to interact seamlessly with a virtual assistant throughout their journey. Imagine having a reliable companion providing real-time information on your route, delivering weather notifications, conducting periodic check-ins, and offering a plethora of useful insights for an enriching hiking adventure. Whether you're a seasoned explorer or a novice adventurer, TrailGuide is here to make your outdoor experience safer, more informed, and ultimately, more enjoyable. Say goodbye to uncertainty on the trail and let TrailGuide be your intelligent guide to a smarter and more connected hiking experience. What it does TrailGuide revolutionizes the hiking experience by offering a comprehensive set of AI-powered features accessible through SMS. That means you can access TrailGuide without an internet connection! This innovative service offers real-time information on your hiking route, keeping you informed about upcoming terrain, points of interest, and potential challenges. TrailGuide goes beyond navigation, offering dynamic weather notifications to ensure you're prepared for changing conditions. The periodic check-in feature enhances safety by prompting users to confirm their well-being during the journey. With TrailGuide, hikers can interact naturally through text messages, receiving personalized and context-aware responses, making the entire adventure more enjoyable, informed, and secure. Whether you're a solo hiker or part of a group, TrailGuide is your intelligent companion, providing a seamless and enriching hiking experience like never before. How we built it For the app, we "
      }
    ]
  },
  {
    "file_path": "./devposts/traceker.html",
    "project_id": "traceker",
    "title": "traCEker",
    "tagline": "Purging the bad hygiene habits of UW ECE & CS students one tracker at a time.",
    "hackathon": "",
    "built_with": [
      "azure",
      "figma",
      "firebase",
      "flask",
      "mongodb",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Domain Name from Domain",
      "JAMHacks 7WinnerBest Domain Name from Domain.com, Presented by MLH",
      "🌐 Best Domain Name",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/505/954/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "MongoDB storing data traCEkr Home Page Shower tracker calendar where blue is days showered and red days missed. Tracker where the user verifies their selfie to be inputted into the shower tracker. Microsoft Azure trained model MongoDB storing data traCEkr Home Page Shower tracker calendar where blue is days showered and red days missed. Tracker where the user verifies their selfie to be inputted into the shower tracker. Microsoft Azure trained model MongoDB storing data 1 2 3 4 5 6 7 💭 Inspiration Inspired by the constant complaints about the bad smell coming out of the ECE floor @ the E7 building and the DC building as a whole, we wanted to help change that. Not enough people in ECE and CS are spending time building positive hygiene habits, which is causing a ripple effect across the entirety of the Waterloo campus. To help combat this epidemic of bad body odor, we decided to create traCEker. ❓What it does TraCEker is a platform where SE/ECE/CS students (but not exclusive to) can track how often they shower and how well they are doing relative to other users with a monthly leaderboard. By seeing other people's shower ranking, traCEker uses public humiliation to incentivize users to shower consistently. Users upload a selfie of them after they shower, which is detected by a classification vision model. Once the selfie is verified as a valid submission, the user is logged as showered. Users can use the calendar view to see how often they showered throughout the days, with showered days depicted in blue. 🛠 How we built it We built traCEker using:\n-> React for the frontend website\n-> Python, Firebase, and Flask for the backend\n-> MongoDB to store all our data\n-> Trained Custom Vision using images to detect selfies with Microsoft Azure Custom Vision \n-> Figma to prototype the design 😕 Challenges we ran into We ran into challenges in connecting the front end to the back end. All three of us were working individually on our tasks (front end, backend, and Microsoft Azure),"
      }
    ]
  },
  {
    "file_path": "./devposts/travelher-p6o8kf.html",
    "project_id": "travelher-p6o8kf",
    "title": "TravelHer",
    "tagline": "TravelHer is a website built for women by women to provide you with the support you need to stay safe while travelling and have a worry-free trip!",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "replit"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/806/954/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Submit Your Story Form TravelHer Logo Main Page Our Mission Locations Page Location Subtab North America Page Canada Locations Quotes Tips Emergency Information Page Emergency Numbers Submit Your Story Form TravelHer Logo Main Page Our Mission Locations Page Location Subtab North America Page Canada Locations Quotes Tips Emergency Information Page Emergency Numbers Submit Your Story Form 1 2 3 4 5 6 7 8 9 10 11 12 13 Inspiration As young women who love to travel, we are constantly reminded of the dangers of traveling alone. This has often led to fun and carefree vacations being turned into stressful trips, filled with worry and fear of new dangers in new environments. Being from different parts of the world we realised the struggle is always the same. \nLack of helpful resources and support are the main reasons why 63%  of women think about safety while travelling. TravelHer is designed to be the resource you need when travelling! What it does? TravelHer aims to create a safe and flexible space and community for women who love to travel. We provide resources and information that can help guide women in making the safest possible travel plans and routes. Already planned a trip and need safety tips to be prepared for the worst? Our Safety Information tab is your one stop shop for self-defence tips and advice!\nPlanning on traveling to another continent? Our International Star Rating List allows you to view the overall safety of a location compared to others so you know what you're getting into.\nNot sure where to go and want some ideas? Head over to Locations for our recommendations spanning several continents! Emergency Contacts has helpline information for different countries so you can get the help you need ASAP!\nHad an unforgettable experience during your trip? Share it with us (anonymously ofcourse!) in the Share Your Story corner so women all over the world can learn from your experience and be prepared. Our goal at the end of the day is to empower women to take th"
      }
    ]
  },
  {
    "file_path": "./devposts/trashquest.html",
    "project_id": "trashquest",
    "title": "TrashQuest",
    "tagline": "A gamified litter pickup mobile app",
    "hackathon": "",
    "built_with": [
      "react",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Environment App Created by Akhil Nimmagadda",
      "Hackboro 2025WinnerBest Environment App",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "to be done at a later time Built With react react-native Submitted to Hackboro 2025 Winner Best Environment App Created by Akhil Nimmagadda"
      }
    ]
  },
  {
    "file_path": "./devposts/transparentterms.html",
    "project_id": "transparentterms",
    "title": "TransparentTerms",
    "tagline": "People accept dense TOS without reading them. TransparentTerms leverages AI to parse these legal documents and highlight ambiguous clauses, privacy pitfalls, and red flags to empower informed consent.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "react",
      "shadcn",
      "tailwind",
      "typescript",
      "vite",
      "wxt"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Coexistence with AI: UofT AI Ethics HackathonWinner1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/311/264/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Window pinning mechanism Facts in Japanese (auto detect) Facts in English Settings Page Window pinning mechanism Facts in Japanese (auto detect) Facts in English Settings Page Window pinning mechanism 1 2 3 4 Inspiration As people don't read terms of services, we wanted a quick solution to inform ourselves on what we're agreeing to when we agree to a company's TOS. What it does TransparentTerms parses through legal documents in PDF form or company's websites to get the important details of their terms of services. It offers these insights in multiple different languages that the user can choose from and also provides key Pros and Cons of the terms of service. They can also continue to prompt the AI for more explanations. How we built it We build TransparentTerms using WXT, React, TypeScript, Vite, Shadcn UI, Tailwind CSS, and the Gemini API. Challenges we ran into Getting the content from each PDF was difficult as we had to parse through each page. Accomplishments that we're proud of We managed to get a working prototype in only 5 hours. What we learned We learnt how to manage our time well in the hacking time of only 5 hours. What's next for TransparentTerms More features like: any languages custom levels of complexity in responses (someone who has the reading level of a 6th grader vs someone who's a lawyer and just wants a quick summary) Built With gemini react shadcn tailwind typescript vite wxt Try it out GitHub Repo Submitted to Coexistence with AI: UofT AI Ethics Hackathon Winner 1st Place Created by Jaden Park uoft eng '28 Sho Adachi Andy Derevyanko"
      }
    ]
  },
  {
    "file_path": "./devposts/travelclear.html",
    "project_id": "travelclear",
    "title": "TravelClear",
    "tagline": "TravelClear is a simple website that can recommend you some of the most popular tourist spots for any given city. It also provides a brief description of the city as well as the current weather.",
    "hackathon": "",
    "built_with": [
      "chatgpt",
      "css",
      "flask",
      "html",
      "openweathermapapi",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/437/852/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "tech stack travel clear home page tech stack travel clear home page tech stack 1 2 3 Inspiration 😗😍 When we heard about this weekend's theme of exploration, we all instantly thought of a tourist spot recommendation site because we understand just how tedious it is to plan out a trip to a city that you and (probably) no one else you know have visited before. What it does 🤔 After the user submits the name of the city they are currently considering planning a trip for, the python script receives this piece of information and uses various APIs to scrape the web for information about this city. If the user doesn't have any city in mind, then they could ask for a random city to be suggested (which the site gets from a preset list of 100 very popular tourist destinations). How we built it 😱 This website was developed using HTML, CSS, React, and Python with the help of flask to integrate these technologies together. This website is also powered by ChatGPT and OpenWeatherMap through their respective APIs openai and OpenWeatherMap API. Challenges we ran into 🫣 We ran into two massive roadblocks while building this project: Finding a relevant, working web scraping API, and integrating React and Python using the flask framework. We are able to discover the OpenWeatherMap API fairly quickly, but was held back for hours because there was no easily accessible and free APIs that could actually recommend tourist spots for a specific city. Eventually we settled on ChatGPT since it can do that and more which is why we later added a general description for the city. Accomplishments that we're proud of 🤫🤭 As discussed above, finding the relevant APIs proved to be a bigger challenge than expected so when we were able to solve that issue it felt like a great milestone in our project. Integrating React and Python using flask was also a quite rewarding experience since no one on the team knew all three technologies so it took quite a bit of teamwork and coordination to accomplish this part "
      }
    ]
  },
  {
    "file_path": "./devposts/traura.html",
    "project_id": "traura",
    "title": "Traura.ai",
    "tagline": "Compete against your friends to track your aura!",
    "hackathon": "",
    "built_with": [
      "auth0",
      "cohere",
      "css",
      "firebase",
      "flask",
      "python",
      "react",
      "react-speech-recognition",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Compete against your friends to track your aura!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/023/705/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What is one of the biggest motivators at hackathons? The thrill of competition. What if you could bring that same excitement into your daily life, using your speech to challenge your friends? Our app gamifies everyday conversations and interactions, letting you and your friends compete to see who projects the most positive or negative aura. What it does Captures live audio input and converts it into text using React’s speech recognition library. Analyzes the transcribed text by running it through Cohere’s semantic similarity model by encoding both input data and our dataset into vector embeddings Uses cosine similarity to compare the input with synthetic data, generated using ChatGPT, in order to evaluate whether the speech conveys a positive or negative aura based. Challenges we ran into Integrating real-time speech recognition with accurate transcription, especially when dealing with diverse speech patterns and accents. Acquiring a continuous audio input which can then be passed along for efficient transcription. Configuring Cohere’s API to work seamlessly with a large dataset and ensure fast, accurate sentiment analysis. Getting accurate data on words/actions that constitute \"positive aura\" and \"negative aura\". Accomplishments that we're proud of Cohere Embeddings for Sentiment Analysis: Integrating Cohere’s powerful semantic embeddings was another significant milestone. We used their embeddings to analyze and determine the sentiment of transcribed text, mapping speech patterns to either positive or negative aura. We’re proud of this implementation because it brought depth to the app. What's next for Traura Turning this prototype into a full-fledged web app that users can access anywhere, including the full implementation of the leaderboard functionality to foster that friendly thrill of competition. Built With auth0 cohere css firebase flask python react react-speech-recognition tailwind Try it out GitHub Repo Submitted to Hack the North 2024 Created"
      }
    ]
  },
  {
    "file_path": "./devposts/tree-analyzer.html",
    "project_id": "tree-analyzer",
    "title": "Tree Analyzer",
    "tagline": "A web app that helps logging companies visualize forestry data and cut wood sustainability",
    "hackathon": "",
    "built_with": [
      "css",
      "django",
      "html5",
      "javascript",
      "json",
      "python",
      "scss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Apply Digital Data-First Award Created by Jax Wang uwo 24' intermediate FE Michael Ng Ryan Lam UWat",
      "Hack the Earth 2021WinnerApply Digital Data-First Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/559/328/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Team members: Ryan Lam, Jax Wang, Michael Ng Inspiration We were inspired by the rate of deforestation and how quickly we are using our natural resources (wood). As a result, we wanted to help companies cut wood at a sustainable pace so we can sustainably use wood now and in the future/future generations. What it does Tree Analyzer reads a dataset and produces graphs to help users (companies) visualize forestry data for the land they own. It also provides advice on which trees to cut by checking our programmed requirements. This allows for better logging practices and preserving more natural resources. How we built it We used Django as the backend (API) and regular HTML/CSS/JS as the frontend. The JS in the front end calls our API, allowing the frontend to display new data Challenges we ran into Plotting 100s of data points on the graph (and aiming to optimize loading time) Getting our JS to connect to the backend and properly get the desired data Cleaning, formatting, sorting, and loading the data from the backend (API) Accomplishments that we're proud of Getting 4 different charts working and calling 4 different API endpoints Learning how to use JSON, APIs, and getting API requests with JS What we learned How to use JSON files How to use Chart.JS How to basically (technically) create a GET API What's next for Tree Analyzer Build a file/database uploaded Use forestry growth modeling AI recommendation tools Built With css django html5 javascript json python scss Try it out GitHub Repo Submitted to Hack the Earth 2021 Winner Apply Digital Data-First Award Created by Jax Wang uwo 24' intermediate FE Michael Ng Ryan Lam UWaterloo Physics"
      }
    ]
  },
  {
    "file_path": "./devposts/trashy.html",
    "project_id": "trashy",
    "title": "Trashy",
    "tagline": "The project that enables an exchange for virtual ownership of real-life trashcans.",
    "hackathon": "",
    "built_with": [
      "java",
      "springboot"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/304/085/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 What it does Helping people to know their surrounding trash cans, while increasing the traffic on these areas. You can trade your digital ownership of these trash cans to make the process of getting to know your clean-spots fun. This has a lot of potential for further features. How we built it The Server is built with SpringBoot and the Client with Vue.js What's next for Trashy Trashy has potential in the private sector as well. While people get to know where their nearest trash cans are located by constantly visiting them to make a selfie, a store could offer vouchers or coupons to the owner of the near trash cans, thus increasing the traffic on their area and promoting a clean surrounding. Built With java springboot Try it out GitHub Repo Submitted to hackaTUM 2022 Created by David Kratz Francisco Kusch Adrian Lieven emsilouise"
      }
    ]
  },
  {
    "file_path": "./devposts/travulator.html",
    "project_id": "travulator",
    "title": "Travulator",
    "tagline": "A virtual travel simulator seeking to educate immigrants on the experiences they will gain in their new homes!",
    "hackathon": "",
    "built_with": [
      "c#",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration A travel simulator that seeks to educate immigrants on the experiences they will have! What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Travulator Built With c# unity Try it out GitHub Repo Submitted to EurekaHACKS 2024 Created by Arihan Sharma"
      }
    ]
  },
  {
    "file_path": "./devposts/tree-planter-and-heat-shelter.html",
    "project_id": "tree-planter-and-heat-shelter",
    "title": "Tree planter and heat shelter",
    "tagline": "The goal for this project is to find the warmest areas of a city that city counsel members can use to determine",
    "hackathon": "",
    "built_with": [
      "firebase",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The inspiration for this project is the heat wave that many Californians have faced this week. What it does Our application finds the warmest areas of a city that determine where trees should be planted and where temporary heat shelters should be built. How we built it We built the web app using React JS as a front end and Firebase as a back end. Challenges we ran into The challenges we ran into were incorporating place markers on map view. We read a few forums and documentation to resolve the issue. Accomplishments that we're proud of This was some of our teammates first hackathon so getting them acquainted with the process and getting rid of the nerves was a big first step. What we learned We learned how to communicate within a team and use resting apis What's next for Untitled Built With firebase react Try it out GitHub Repo Created by I worked on creating the front end with React and updated the mapbox with weather data gathered from API calls, to represent the weather data with points on the map. Jenny Zhong CompSci student from Oregon State Barret Griffin Electrical Engineer from Cal Poly Pomona. Emphasis on Software Engineering and Control Systems. Mahika Patil Siddhartha Mahajan"
      }
    ]
  },
  {
    "file_path": "./devposts/trio-try-it-on.html",
    "project_id": "trio-try-it-on",
    "title": "Trio - Try It On",
    "tagline": "Trio makes online shopping easier by letting you virtually try on products before buying. See how it looks and fits, so you can shop confidently and avoid the frustration of returns.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "next.js",
      "node.js",
      "supabase"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/356/543/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Detail Product Home Page Before Generation After Generation Detail Product Home Page Before Generation After Generation Detail Product 1 2 3 4 5 Trio (Try It On) 🧠 Inspiration Shopping online is convenient—but how many times have you ordered something that looked great in the photo, only to try it on and… meh 😬? Our team wanted to solve that. We wanted to create a way for people to see how a product would look before they buy , without leaving their home. That’s how Trio was born—a virtual try-on experience that helps you shop smarter and more confidently. 🔧 How We Built It We combined some of the coolest tools and frameworks to bring Trio to life: 🧪 Next.js – used for building our fast and interactive frontend experience. 🔥 Supabase – handled file storage and image upload, especially for user-submitted try-on images. 🤖 Gemini API – fine-tuned for image generation. We trained it on product images to understand and simulate real-life try-on results. 🐍 Next Server Routes – used for our backend server. It handles image processing, user requests, and interacts with the Gemini model. 🧠 Custom Gemini Model – we fed it hundreds of product try-on images to fine-tune it to our use case. Before making a final try-on prediction, we preprocess and enhance images to match lighting, angles, and context. The user takes or uploads a photo, selects a product they want to try, and gets an AI-generated try-on image using our custom-tuned Gemini model. Fast, fun, and frustration-free. 😎 💡 What We Learned We dove deep into: Image preprocessing and AI-based try-on generation How to work with fine-tuned AI models Connecting a Python Flask backend to a Next.js frontend smoothly Using Supabase to manage file uploads and storage with ease Managing fast feedback loops for real-time visual updates 🚧 Challenges We Faced Image alignment : Matching the product image to the user’s body/photo took a lot of experimentation with image augmentation and pose detection. Model tuning : Getting our Gemini"
      }
    ]
  },
  {
    "file_path": "./devposts/trunked.html",
    "project_id": "trunked",
    "title": "Trunked",
    "tagline": "Gotta escape from the trunk...",
    "hackathon": "",
    "built_with": [
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/671/830/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We got inspired from the threatened escaping game when we first experienced VR. It was so impacted and we all agreed a threatening game is the best way to utilize the pros of VR. What it does \"Trunked\" is a virtual reality (VR) game that draws inspiration from the thrilling experience of escaping dangerous situations. The game is designed to immerse players in a challenging and threatening environment, providing an adrenaline-pumping escape experience. How we built it The game was built using a combination of VR technology and game development tools. We utilized platforms such as Unity or Unreal Engine for game development, integrating VR capabilities to create an immersive experience. The team likely employed 3D modeling for creating the game environment, and various scripting languages to implement gameplay mechanics. Challenges we ran into Throughout the development process, the team faced several challenges. These might include technical hurdles in implementing VR features, optimizing performance for a smooth gaming experience, or addressing unexpected issues in the game design. Overcoming these challenges required creative problem-solving and collaboration among team members. Accomplishments that we're proud of The team successfully created a captivating VR game that delivers the intended thrilling experience. This accomplishment could involve achieving realistic graphics, implementing engaging gameplay mechanics, or receiving positive feedback from playtesters. Celebrating these achievements adds to the motivation for future projects. What we learned The development of \"Trunked\" provided the team with valuable insights into VR game development, problem-solving in a collaborative environment, and understanding player psychology in the context of threatening or intense gaming experiences. These lessons can be applied to future projects to enhance development efficiency and game quality. What's next for Trunked The future of \"Trunked\" could involve fu"
      }
    ]
  },
  {
    "file_path": "./devposts/trippla.html",
    "project_id": "trippla",
    "title": "Trippla",
    "tagline": "The BEST way to Plan YOUR Wonderful Adventure!",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "html",
      "javascript",
      "visual-studio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "The BEST way to Plan YOUR Wonderful Adventure!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/603/120/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our Main Logo One of Our Questions and the Submit Design Our Main Logo One of Our Questions and the Submit Design Our Main Logo 1 2 3 Inspiration\nWe got inspired by several travel companies to make this website work. The thought of having a tool that is quick for indecisive times like trip planning is crucial as it prevents the hassle of manual searching through the web to find the best destination. This app will do it in just a few clicks! What it does\nThe website will help you efficiently pick a travel destination with APIs, HMTL, CSS, and JavaScript. Using a quiz-like approach, it will determine the best location for your next vacation spot using a series of questions. Although this is just a prototype, we still are committed to finishing this project and adding the final steps to the project to make it user-friendly. How we built it\nWe built it using JavaScript, HTML, and CSS taking advantage of bootstrap and CSS. Using this, we were able to build a travel GUI which allows you to select locations you want to go to and travel to the place directly and efficiently. Challenges we ran into\nWe ran into several challenges, but we overcame them: Different Timezones for Each Teammate Missing Teammate did not Show Up Accomplishments that we're proud of\nWe are proud that we have finished this prototype in time even though it is not fully finished. Due to our missing teammate, we were still able to overcome the challenge and go into the next steps of development as a team. What we learned\nWe learned that you can use multiple databases for you design and APIs to store data. What's next for Trippla\nWe are pleased to say that we are continuing development if everything goes well with the judges. We hope to succeed. MEMBERS:\nshibz#3953\nYeetYoshi#0001\nsrirachapapi#4091 Built With css github html javascript visual-studio Try it out GitHub Repo izaanq.github.io Submitted to Bon Voyage Hacks Created by I worked on the front end development, JavaScript, and CSS. Aidan Hoang Just a "
      }
    ]
  },
  {
    "file_path": "./devposts/twilio-12i3f4.html",
    "project_id": "twilio-12i3f4",
    "title": "Twilio",
    "tagline": "Expanding Twilio knowledge by following the INIT Twilio guide.",
    "hackathon": "",
    "built_with": [
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/026/902/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Day 5: Receiving SMS messages with our web application Day 2: Receiving a phone call with an automated message using twilio Day 3: Making an outbound call using Twilio and curl Day 4: Setting up a web application with ngrok and webhooks Day 5: Receiving SMS messages with our web application Day 2: Receiving a phone call with an automated message using twilio Day 3: Making an outbound call using Twilio and curl Day 4: Setting up a web application with ngrok and webhooks Day 5: Receiving SMS messages with our web application 1 2 3 4 About An INIT project (non-competitive) to further understand how to use Twilio. Built With twilio Submitted to Global Hack Week: INIT 2023 Created by Brayton Lordianto"
      }
    ]
  },
  {
    "file_path": "./devposts/tubilearn.html",
    "project_id": "tubilearn",
    "title": "MindfulMapper",
    "tagline": "An app to connect with health and wellness services in your local community.",
    "hackathon": "",
    "built_with": [
      "figma",
      "java",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/428/487/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Text input section of the chatbot Chatbot built with java Text input section of the chatbot Chatbot built with java Text input section of the chatbot 1 2 3 4 5 6 7 8 Inspiration 🦋 Our team recognized the need to promote healthy habits and improve overall well-being among marginalized communities in the city of Vancouver.  The inspiration for this project stems from a variety of sources, such as personal experience with health issues, concern for the health of a loved one, and a desire to make a positive impact on the community. This project focuses on providing resources, education, and support to help individuals adopt healthier lifestyles and achieve their wellness goals. What it does 🌚 Our project includes a website that allows members of a community to navigate through various services and get information that could possibly improve their wellness and fitness in society. It includes an option to call and connect with community service providers and also a chatbot that takes this communication process to the next level—ensuring that no member is left behind. How we built it 🔨 This website was built primarily by Velo and Wix. Wix is the backbone that houses this excellent work. We made use of the Figma design and pulled ideas together to develop the interface with Wix and Velo.  In building a chatbot with Java, we defined the chatbot's purpose, designed the conversation flow, and developed the chatbot's logic. Although we are yet to integrate it with a messaging platform, we have tested and refined it. We also added animations and interactions using the developer tools on the Wix platform. Challenges we ran into 🔓 Most of our teammates bailed on us at different points during the hackathon so we had to struggle to remain focused on the job as a team but with persistence and unmatched perspicacity, we were able to make it work Nevertheless. Accomplishments that we're proud of 🐐 In general, we are proud of our ability to work as a team and execute the work we set out"
      }
    ]
  },
  {
    "file_path": "./devposts/truecount.html",
    "project_id": "truecount",
    "title": "TrueCount",
    "tagline": "Voting outcomes often face backlash. That’s why trust matters. TrueCount keeps every vote secure and permanently recorded on an open ledger, ensuring every choice is counted correctly.",
    "hackathon": "",
    "built_with": [
      "hardhat",
      "rainbowkit",
      "react",
      "solidity",
      "typescript",
      "wagmi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ETHGlobal: Ethereum's Infinite Garden Created by nom nom nom Alexander Gu hackathons are fun",
      "Hack the North 2025WinnerETHGlobal: Ethereum's Infinite Garden",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/740/180/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 Inspiration One of our teammates experienced a moment in student body government where a candidate's votes were reduced by half because a moderator believed she violated a subjective rule. The issue wasn't just the penalty — it was how easily one person's judgment could undermine trust in the entire process. TrueCount was born to fix this. By moving voting on-chain, we eliminate human bias and create a system where trust is placed in code , not moderators. What It Does TrueCount: A Decentralized, Phase-Based Voting System TrueCount is a commit–reveal voting system for communities that need fairness, transparency, and verifiable results. No moderators. No tampering. Every vote is private to remove bias, later revealed and then permanently auditable on-chain. Built on Ethereum using a commit–reveal–finalize flow: 1. Poll Creation Anyone can create a poll with custom options and configurable commit/reveal durations. Smart contracts enforce deadlines and rules without a central authority. 2. Commit Phase Voters pick an option. A random 32-byte salt is generated client-side. The frontend computes a hash: solidity\nkeccak256(encodePacked(option, salt, voter, pollId)) The commitment is submitted on-chain — keeping the actual vote hidden. 3. Reveal Phase Voters resubmit their chosen option along with the salt. The contract verifies the commitment matches the reveal. Invalid reveals are automatically rejected. 4. Finalize Phase Once the reveal window closes, anyone can finalize the poll. The tallies are locked and publicly accessible forever. Key Features: 🔐 Wallet Integration - Seamless connection with RainbowKit and wagmi 📊 Customizable Polls - Flexible options with configurable time windows 🤝 Privacy-First - Votes remain hidden during the commit phase 🔍 Cryptographic Verification - Mathematical proof of vote integrity ✅ Permanent Transparency - Results locked on-chain forever 🎨 Intuitive UX - Real-time phase indicators, countdown timers, and comprehensive error han"
      }
    ]
  },
  {
    "file_path": "./devposts/tripgeniusai.html",
    "project_id": "tripgeniusai",
    "title": "TripGeniusAI",
    "tagline": "This project is an AI powered web app that provides users with AI generated itineraries for travel.",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "github",
      "json",
      "openai",
      "prisma",
      "t3",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of CockroachDB Created by Damir Romano Saathvik Chandupatla Chinat Yu My name is Chinat Yu",
      "DragonHacks 2023WinnerBest Use of CockroachDB",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/468/402/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Cockroach DB activity Landing Page Popular Trips Page AI Chatbot Cockroach DB activity Landing Page Popular Trips Page AI Chatbot Cockroach DB activity 1 2 3 4 5 TripGeniusAI This project is an AI powered web app that provides users with AI generated itineraries for travel. How does it work? TripGeniusAI is fed a location and generates custom trip plans that work around the users time and budget constraints and playlists that match the vibe of the vacation. Additionally, it takes into consideration the environmental impact of travelling and helps users understand and offset their emissions. Benefits TripGeniusAI provides its users with benefits that help with mental health, cultivate education, and make travel more accessible. Mental Health Although traveling helps reduce stress, improve mindfulness, and boosts mood, the process of planning for a trip can cause unecessary strain. TripGeniusAI takes the pressure off the travellers and allows them to enjoy the journey. Educational Traveling can provide a great number of educational opportunities, but finding the right ones can be a hassle. TripGeniusAI makes this easy by providing users with recommendations of travel spots that are educational, allowing travellers to learn through their adventures. Environmental A typical passenger vehicle emits about 4.6 metric tons of carbon dioxide per year. Traveling can add to this by adding a lot of uneccessary greenhouse emissions, making it difficult to travel green. TripGeniusAI makes it easy for users to offset their carbon emissions, making traveling more eco-friendly accessible. Our Inspiration We started by brainstorming our skill-set and identifying problems that we personally faced in work, relationships, health, and play. From that we determined that there was a need for a platform that promotes mental well-being, education, and eco-friendliness. To determine how we wanted to solve this, we interviewed over 15 students to gauge the best way to approach this problem. Fr"
      }
    ]
  },
  {
    "file_path": "./devposts/travalero-tralala.html",
    "project_id": "travalero-tralala",
    "title": "Travelero Tralala",
    "tagline": "International meetups made easy with Tinder-style, AI-powered matching.",
    "hackathon": "",
    "built_with": [
      "css",
      "http",
      "jwt",
      "lucide",
      "next.js",
      "postgresql",
      "react",
      "sqlalchemy",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Integration: Connecting with third-party booking APIs to enable direct reservations within the platform"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/405/284/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Pitch 💡 Travalero integrates Skyscanner API data, Tinder-inspired preference-based matching, and AI assistance via a custom agent to solve the complex problem of finding optimal meeting points for international friend groups . Our Flask backend processes flight availability data through custom algorithms that minimize group travel costs, while our Next.js frontend provides an intuitive interface for preference collection and real-time collaborative trip planning with embedded AI assistance. What makes our project unique? 🏆 Our project is different from the other Skyscanner Challenge submissions in many ways: Custom Qwen Agent Integration -- Our implementation integrates the Qwen large language model agent through a custom Flask endpoint ( backend/ai.py ), enabling intelligent travel recommendations. Within a trip group, each user's travel preferences, stored as JSON in our PostgreSQL database via SQLAlchemy ORM models ( backend/models.py ), are passed to the Qwen agent for context-aware responses. The agent uses this information to generate personalized recommendations, answering questions about destinations and activities while considering all group members' preferences simultaneously. For a demonstration of the standalone Qwen agent via Gradio, see this video: https://youtu.be/HtR5K8Tt8zI Advanced Qwen Algorithm -- We created a custom flight optimization engine ( gradiotest/skyscanner_api.py ) that queries the Skyscanner API with the specific date ranges and origin airports of all group members. Our algorithm ( find_top_k_full_paths function) computes a comprehensive cost matrix, identifying destinations that minimize the sum of travel costs across all participants. The system intelligently handles multi-leg journeys and self-transfer flights, significantly expanding the range of possible meeting points. Preference Collection with React-Based Tinder Interface -- Real-Time Collaborative Architecture -- Our system enables multiple users to interact simultaneousl"
      }
    ]
  },
  {
    "file_path": "./devposts/troki.html",
    "project_id": "troki",
    "title": "Troki",
    "tagline": "Digital platform for gig work in yards: Less work, More freedom.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "figma",
      "google-maps",
      "heroku",
      "mern",
      "mongodb",
      "node.js",
      "premiere-pro",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/657/509/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Login/Signup Login/Signup Login/Signup 1 2 3 What it does What teen wouldn't spend under 15 minutes shovelling their neighbour's driverway for $5? What homeowner wouldn't take that cheap & convenient offer? Enter Troki, an app-based platform connecting nearby, eager teens with neighbours in need of yard work. Short for Trochilidae – the biological family name for the fast & agile Hummingbirds – our app intends to provide a convenient and efficient way for teens or any individual to earn some very quick cash and to provide a cheap yard/driveway service for neighbours. Business Viability Convenience sells in the modern world! With our app, we hope to bring convenience to a task often viewed as boring and time-consuming. As outlined by this article , the flexibility and simplicity of providing teens a platform for yard jobs is a great opportunity for growth. Additionally, our app helps to limit the cons of a tough start-up, competition, and unexpected conditions to make it the perfect tool for teens and homeowners alike! How we built it Using a MERN stack , we divided our work based on specialties. 2 of us established a solid back-end for job listings, authentication and distance gauging with Google Maps API, 1 of us created a smooth mobile front-end which displayed a compact dashboard for all searching functions, and the last one oversaw the entire project (managing back-end, revising for clarity, etc.). In addition to using GitHub to exchange files, we also used VS Code's Live Share extension which allowed us to simultaneously code as a team. Challenges we ran into Although our respective skillsets made things efficient, integrating the two ends was our greatest challenge. Despite our collective planning through using Asana and a UML, we found that a few of our routers were not smoothly aligned to connect to the front-end. Additionally, we did not test for bugs throughout and had quite a few during the integration process. Nevertheless, we were dedicated to completin"
      }
    ]
  },
  {
    "file_path": "./devposts/twirl.html",
    "project_id": "twirl",
    "title": "Twirl (2nd Place @ UofTHacks 12)",
    "tagline": "AI Copilot for the IRL",
    "hackathon": "",
    "built_with": [
      "fastapi",
      "flask",
      "nextjs",
      "python",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "@ UofTHacks 12: https://dorahacks",
      "Best Use of Generative AI"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/227/131/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Winner @ UofTHacks 12: https://dorahacks.io/buidl/21695/ 2nd Place Overall Best Use of Generative AI Twirl: Copilot for the IRL — Turn Thoughts into Things What if you could describe something, like a chair or a cup, and have it physically created? Think Copilot, but for the IRL . Twirl, or Text-to-World IRL, is an AI agent for turning thoughts into reality via 3D printing. Inspired by the theme of Perspectives , we set out to bridge the gap between imagination and reality. Twirl empowers anyone to create real-world objects without requiring technical expertise. By reimagining how we design and build, Twirl expands perspectives on creation, making the complex world of 3D modelling accessible for all. Give any prompt, like \"rocking chair with three back supports\" and attach an image if you'd like. Twirl will extract and infer features (ex. dimensions, object spatial relationships) and create a parameterized 3D CAD model instantly. It'll allow you to continuously iterate on model generation until you have the perfect creation, making modifications with more prompts or images. You can even adjust sliders and fields that change model variables like dimensions, colour, translations, and rotations. The entire generated CAD model is parameterized, allowing full customization within the web UI. We render the 3D model live on the UI as it is created, allowing you to examine every pixel instantly. Twirl doesn't just stop at visualization. It turns perspectives into physical reality. Models can be exported for 3D printing, making it possible to create functional objects directly from ideas. During the hackathon, we tested this end-to-end pipeline by designing and printing a chair model generated entirely by Twirl, with 0 human assistance. With Twirl, we redefine the creative process, allowing everyone to see their ideas from a new perspective—one where imagination is the only limit. Technologies used: Created by: \nMartin, Marcus, William, and Jeff Built With fastapi flask next"
      }
    ]
  },
  {
    "file_path": "./devposts/ultimate-cat-chaos-dimension.html",
    "project_id": "ultimate-cat-chaos-dimension",
    "title": "Ultimate Cat Chaos Dimension",
    "tagline": "🐱✨ A purr-fectly fine cat universe that reflects one inner state of mind.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "super awesome cool prize Created by Chinat Yu My name is Chinat Yu",
      "s Winner super awesome cool prize Created by Chinat Yu My name is Chinat Yu",
      "Nosu AI Hackathon $11,300+ in prizesWinnersuper awesome cool prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/211/707/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration 🐱💡 Cats + Internal Mind => Ultimate Chaos Cat Dimension What it does 😼 It’s a dimension where cats take over, chaos reigns, and your screen might just file a restraining order. How we built it 🛠️🐾 Powered by caffeine, bad ideas, and an unhealthy number of cat memes. Also, raw HTML, CSS, and JavaScript coz who don't wanna these days? Challenges we ran into 😿 Accidentally unleashed infinite flying cats. Too much chaos. (Yes, that’s a thing.) PARTY MODE almost partied a bit too hard. Accomplishments that we're proud of 🏆🐈 Cats now rule an alternate reality. PARTY MODE doesn’t break the universe (anymore). No humans were harmed in the making of this chaos. Probably. What we learned 🧠🐾 Chaos coding is an art form. Cats make everything better. Browsers are surprisingly resilient to nonsense. What's next for Ultimate Cat Chaos Dimension 🚀🐱 Adding hats for cats. Everyone loves hats. Chaos DLC packs. Think lasers and floating toast. Taking over the multiverse, one cat at a time. Built With css html javascript Try it out cyu60.github.io GitHub Repo Submitted to Nosu AI Hackathon $11,300+ in prizes Winner super awesome cool prize Created by Chinat Yu My name is Chinat Yu. I explore how we can make learning more fun, impactful, and personal."
      }
    ]
  },
  {
    "file_path": "./devposts/turbulence-predictor.html",
    "project_id": "turbulence-predictor",
    "title": "Turbulence Predictor",
    "tagline": "This project gives passengers a peek into their upcoming plane ride, showing them the predicted zones of turbulence in addition to their intensity.",
    "hackathon": "",
    "built_with": [
      "css",
      "github",
      "html",
      "javascript",
      "leaflet.js",
      "photoshop"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/743/013/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Map View Website Front Page Map View Website Front Page Map View 1 2 3 Inspiration Having experienced unexpected turbulence, we wanted to give passengers an accurate prediction of the flying conditions and what they can expect from their upcoming flight, whether it be smooth or bumpy. What It Does The web app shows the predicted flight path in addition to zones of turbulence based on weather conditions in the area. The zones of turbulence are labeled for intensity as well, green, yellow, and red respectively. We hope that this webpage will help passengers and pilots alike to anticipate for unexpected turbulence. How We Built It We leveraged flight data and weather data to create an accurate visual prediction of how the turbulence will be on any flight. We also utilized the LeafletJS library to display our maps and routed and used HTML, CSS, and JS files to create our webpage. We also attempted to us Node.js Puppeteer to webscrape for up to date plane location and altitude. Challenges We Ran Into We all had to learn web development as the project progressed such as developing a deeper understanding of HTML. Besides the usual small bugs and fixes, the largest challenge was developing a formula to determine the amount of turbulence in a commercial airplane as there was no formula created for it yet. We also ran into the challenge of web scraping which all of us had no experience in but we still got to learn a lot despite our shortcomings to implement it into our webpage. Accomplishments That We're Proud Of Though having limited knowledge of web development, we built a working web application in less than 24 hours using many technologies for the first time. We are proud of the research we put into creating our turbulence index formula (shown in the README file on the GitHub). We came into this hackathon with 0 meterology experience or commercial flight experience so we are proud to present the formula that measures predicted turbulence using weather intensity, elevation"
      }
    ]
  },
  {
    "file_path": "./devposts/tweet-moderator.html",
    "project_id": "tweet-moderator",
    "title": "Tweet Moderator",
    "tagline": "A program that avoids the user to make tweets that promotes hate speech, discrimination, etc.",
    "hackathon": "",
    "built_with": [
      "python",
      "sight-engine",
      "tkinter",
      "tweepy",
      "twitter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Beginner Hack Created by Kalash Jain",
      "Best Beginner Hack Created by Kalash Jain",
      "CuseHacks 2022WinnerBest Beginner Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/844/328/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Comes up when you try to post something inappropriate.. The home that I made but then it just got messed up.. Comes up if you leave the entry empty.. Comes up when you try to post something inappropriate.. The home that I made but then it just got messed up.. Comes up if you leave the entry empty.. Comes up when you try to post something inappropriate.. 1 2 3 4 Inspiration Twitter has been a platform giving births to controversies, especially in my country INDIA, so that's why I came up with this idea of identifying if a user is making an inappropriate tweet. What it does It scans the tweet and lets you know whether it is a good idea to upload it on Twitter or not! How we built it I build the program using the sight_engine API, tweepy module, Twitter API. Challenges we ran into I tried to build it using Tkinter (GUI), but as this was my first time doing a project with Tkinter, it took me a lot of time and I ended up making a program with a lots of error. So, to demonstrate my idea, I made an alternate program. Accomplishments that we're proud of I'm proud of coming up with an idea that can make an impact on social media life (in a positive way) and as I was solo for this project, I'm proud that whatever I did, I did it myself :) What we learned I learned a lot about API's, Tkinter, Twitter developer tools!! What's next for Tweet Moderator I can definitely work on the GUI to make it work fine without errors and can make it a little bit more descriptive visually!! Built With python sight-engine tkinter tweepy twitter Try it out GitHub Repo Submitted to CuseHacks 2022 Winner Best Beginner Hack Created by Kalash Jain"
      }
    ]
  },
  {
    "file_path": "./devposts/undeafstand.html",
    "project_id": "undeafstand",
    "title": "UnDeafstand",
    "tagline": "A medium to reduce the communication gap between the doctors and patients who are deaf or mute!",
    "hackathon": "",
    "built_with": [
      "brain",
      "figma",
      "mediapipe",
      "python",
      "sleeping-hours",
      "tears",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/216/672/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Explanation of the AI model Logo Help doctor understand the language Talk to the deaf patient Brief description about the back-end Explanation of the AI model Logo Help doctor understand the language Talk to the deaf patient Brief description about the back-end Explanation of the AI model 1 2 3 4 5 6 Inspiration There are 300 million deaf people around the world, and it is estimated to increase by 2025 to 900 million deaf people. Meanwhile, recent international studies show the high unsatisfactory feelings of deaf people who get health services. What it does It converts the hand gesture (from deaf people) and extracts useful information to fill their information in the database, helping the doctors save time and analyze their reports efficiently. It also enable doctor to talk directly to the deaf people. How we built it We use figma to design the medium.\nWe tried to built it using Tensorflow, OpenCV and Mediapipe. Challenges we ran into We were not able to code the back-end completely but we are still pitching our idea to raise awareness! What we learned We learned about some of the machine learning algorithms and how the back-end actually works, which was very cool! This project also enhance our skill in designing UI/UX! Built With brain figma mediapipe python sleeping-hours tears tensorflow Try it out www.figma.com Submitted to ShellHacks 2022 Created by I worked as the UI/UX designer and video pitching editor Haifa Mayang Kalash Jain Amit Ramrakhyani"
      }
    ]
  },
  {
    "file_path": "./devposts/tutorhub-olsvz9.html",
    "project_id": "tutorhub-olsvz9",
    "title": "TutorHub",
    "tagline": "TutorHub provides an easy way for students and educators alike to find and post information about various subjects in a simple post and comment system.",
    "hackathon": "",
    "built_with": [
      "css",
      "css3",
      "html",
      "html5",
      "jsx",
      "next",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/607/298/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 Inspiration TutorHub was inspired by my hours of searching up articles about various topics for my physics class. I found that it was difficult to find sources on certain topics, so I decided to create TutorHub to fix this. What it does TutorHub acts as a catalyst for community-driven educational content through containing two main parts: a tutorial section and a forums section. The tutorial section is meant to post long-form informative text content, such as an article explaining how parabolas work.  The forums section is meant to be used as a place for discussion, asking questions, or making requests for more content. How we built it TutorHub is a web app that utilizes Next.js v15 with Typescript to create an organized codebase that allows for easy setup and hosting. In addition to those technologies, we used Sass for managing stylesheets and Firebase for user authentication and database. Challenges we ran into One major challenge that we ran into was our collaboration, which we were not able to do extremely efficiently because we were unable to meet up in person and had to work at different times separately, which slowed down development speed. In addition, one of our team members was unable to work for most of the time allotted due to computer issues. Accomplishments that we're proud of We are proud of being able to have a mostly functional web app running in the time we worked on it, which was about a day short of the full competition length due to timezones and school. What we learned We learned how to utilize Sass for more organized stylesheets in place of CSS as well as using Firebase's new modular SDK, which was an interesting change from previous versions that we were more familiar with. What's next for TutorHub We plan to add a system for peer review to ensure that information on our app is correct, file uploads for visual representations in tutorial posts, and LaTeX formatting for mathematics-related content. In addition, we plan to touch"
      }
    ]
  },
  {
    "file_path": "./devposts/umass-dining.html",
    "project_id": "umass-dining",
    "title": "UMass Dining+",
    "tagline": "The UMass Dining app, but better.",
    "hackathon": "",
    "built_with": [
      "go",
      "javascript",
      "machine-learning",
      "opencv",
      "python",
      "redis",
      "svelte"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Web Hack Created by I worked on a simple Go API with Redis, mux, and SockJS, connecting the API and",
      "[HACKUMASS] Best Web Hack Created by I worked on a simple Go API with Redis, mux, and SockJS, conne",
      "HackUMass XWinner[HACKUMASS] Best Web Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/293/067/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Team pic! Desktop Website Mobile Website Visualization of ML detection model Old design for the mobile version Team pic! Desktop Website Mobile Website Visualization of ML detection model Old design for the mobile version Team pic! 1 2 3 4 5 Inspiration The original UMass Dining app has a feature that tells if a dining hall is “busy,” “moderate,” or “not busy.” On paper, it’s a useful widget: students plan out their time and dodge the lines. The only caveat is that it doesn’t work!\nCountless bogus readings and avoidable crowds led us to create our project, “UMass Dining+”! Our mobile-friendly website aims to accurately show how busy each dining common is by using youtube livestreams that monitor each eatery. What it does and How we built it Our Python backend scans UMass-provided livestreams for Worcester, Berkshire, and Hampshire Dining Commons via the youtube-dl library before processing them with a computer vision machine learning model to estimate the number of people in the area. We used OpenCV in conjunction with an object detection model found on Hugging Face. The estimation of how busy the dining area is then gets sent to a Redis database. We used Redis as a feature-packed key-value store to hold our estimates of the activity levels at the dining halls over time. Go was chosen as an efficient and simple language to serve static files and respond to API requests. We used SockJS to stream the activity level data of each location to website visitors in real time, enabling the website to automatically update. We used Sveltekit Material UI to design and build our frontend webpage. Svelte’s dynamic elements allowed us to develop a streamlined UI/UX. The Svelte and SCSS formatting files for the web app were compiled and deployed using Vite. Our overall tech stack consists of Python, Redis, Go, and Svelte, and we host the website online using the free .tech domain offered by domains.com. Challenges we ran into -Inaccurate detection models -Connecting the database to"
      }
    ]
  },
  {
    "file_path": "./devposts/tyag-ai.html",
    "project_id": "tyag-ai",
    "title": "Tyāg.ai",
    "tagline": "Helping you let go of your problems, one conversation at a time",
    "hackathon": "",
    "built_with": [
      "ai",
      "bootstrap",
      "canva",
      "css3",
      "html5",
      "javascript",
      "python",
      "together.ai"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/769/321/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration With rising stress levels and increased isolation, especially among members of Generation Z, there is a growing need for adolescents to have access to a support system through which they can express their emotions without fear of judgement. What it does Tyāg.ai leverages natural language processing to match users facing similar issues together based on their inputs. When a student feels the need to share their concerns with someone else, they can write a description of what is currently bothering them.  Tyāg.ai processes this input and uses a similarity-based matching algorithm to place two users within an anonymous chatroom. Natural language processing is used to monitor the chat and ensure a safe environment. How we built it We built Tyāg.ai over the course of 36 hours, using Bootstrap for front-end development and trained and fine-tuned our NLP model using Together AI's platform. Accomplishments that we're proud of We are proud of our success in designing and developing Tyāg.ai from scratch, including implementing an accessible user interface and functional NLP properties. What we learned We learned the process of effectively planning and carrying out a software-based project aimed at addressing a societal issue. What's next for Tyāg.ai We hope to bring Tyāg.ai to a larger scale by creating new options for users to interact with each other, such as the creation of communities centered around common interests and the implementation of speech so that users can freely speak their concerns to the initial matching interface. Built With ai bootstrap canva css3 html5 javascript python together.ai Try it out 5aa0baa4-55b9-42d1-9432-1414c451a631-00-1y5tl7t66smnt.riker.replit.dev docs.google.com Submitted to TreeHacks 2024 Created by julia huang hackathon enthusiast and coder Madhuhaas Gottimukkala"
      }
    ]
  },
  {
    "file_path": "./devposts/unisight.html",
    "project_id": "unisight",
    "title": "Unisight",
    "tagline": "Improving Online Learning experience for the Better 👨‍🏫",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "gcp",
      "javascript",
      "keras",
      "pytorch",
      "react",
      "tailwind",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Google Cloud Created by Pratyay Banerjee Trying to learn how to learn ;) Private user A",
      "Kent Hack Enough 2021WinnerBest Use of Google Cloud",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/763/038/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 Inspiration 💡 E-Learning has become the new normal in this Pandemic era. Besides, for students, video conferencing tools have become the part & parcel of daily activities. But in general, this leads to feeble face-to-face traditional interaction between lecturers and students degrading the interest in online education extensively in the last few months, globally! We aim to innovate a revolutionary tool that helps teachers and students improve the online learning experience for the better. We believe that with the power of AI, this can be solved if proceeded creatively. Thus we made UniSight ! ✨ So what’s the app about? 🤔 Unisight captures the realtime expressions of the student throughout the duration of the class which will help the person on the other side of the screen understand their flow turning online learning into a fun, interesting & productive experience. We plan to use different technologies & cutting edge AI methods to extract the data & generate instant analytics. Say goodbye to boring lectures, switch to Unisight ! 🚀 Tech Stack 🏗 First and foremost, it is Crafted with 💙. \nFor the front-end, we’ve used React.js & Tailwind as CSS framework. The Authentication (OAuth) has been done by Firebase & we’re also using the Cloudstore database for storing user logs. To create this, we trained a custom sentiment analysis model which is used to analyze & predict the user emotions directly from the input video. The model used Tensorflow.js under the hood to process the data directly on the client-side & hence no data is being sent to the server which also preserves privacy . For heartbeat detection, we have taken the advantage of Mayer waves — oscillations of arterial pressure that occur in conscious subjects. Using these, we determine your heart rate by monitoring the tiny fluctuations in the color of the forehead. This is done by taking the average pixel values of the forehead region and performing a Fourier Transform to convert this signal to a su"
      }
    ]
  },
  {
    "file_path": "./devposts/unipantry.html",
    "project_id": "unipantry",
    "title": "UniPantry",
    "tagline": "A platform by students, FOR students!",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "express.js",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of CockroachDB Created by Chantal Pino Renz Vital Joshua Sintos Lib Joshua Martinito Cyril",
      "OpenHacksWinnerBest Use of CockroachDB",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/436/456/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "volunteer form Landing Page Feed volunteer form Landing Page Feed volunteer form 1 2 3 4 Inspiration One important aspect of open-source is the essence of community and that was the starting point that we hammered in on for this hackathon. Most of us are (broke) college students who live in dorms or apartments near the school we are studying at. We had to struggle with juggling horrendous transportation, braving unfamiliar places, and rent while studying for our future. One thing that kept on being a recurring problem is sustenance. Where to find affordable food? With this in mind, we wanted to create an OPEN-SOURCE application that helped fellow university students in tackling that problem. What it does UniPantry is a website that helps college students by acting as a platform, for other college students, in donating food for those who don’t have enough budget to eat. Students may opt into being How we built it The application was built with love using React and Tailwind CSS for the frontend. While, we used NodeJS and Express for the backend with CockroachDB being our go-to database option. Challenges we ran into How to work out the kinks and quirks of making sure to promote the safety and well-being of our customers as they are accepting food from, hopefully kind, strangers. We were also rusty as this is our first hackathon in such a long while and had to warm up the gears not only in development but also in time commitment and in communication. Accomplishments that we're proud of We are proud that we were able to find a very common pain point in our lives and created an application that solves it. What we learned Coming off from a hackathon hiatus, we learned what works and what doesn’t. We learned what steps we can cut out to smoothen out the development process and what strategies we can integrate to have a more effective workflow. What's next for UniPantry For UniPantry, we hope to scale the project and have different chapters in other universities as well as "
      }
    ]
  },
  {
    "file_path": "./devposts/under.html",
    "project_id": "under",
    "title": "UNDER",
    "tagline": "*Urban Navigation for Driverless and Excellent Routing*\nAn intuitive dashboard for visualizing highly optimized scheduling algorithms for a fleet of robo-taxis.",
    "hackathon": "",
    "built_with": [
      "ts"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/152/736/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Performance Boxplot II Scenario Selection Map Overview Statistics II Statistics I Performance Boxplot I Performance Boxplot II Scenario Selection Map Overview Statistics II Statistics I Performance Boxplot I Performance Boxplot II 1 2 3 4 5 6 UNDER Urban Navigation for Driverless and Excellent Routing 🚀 Inspiration Efficient vehicle scheduling is critical to improving customer satisfaction and optimizing resource utilization in urban environments. Inspired by the challenges of real-world routing in busy cities, we set out to create a tool that ensures fast and reliable vehicle scheduling using advanced computational algorithms. 🛠️ What It Does UNDER simplifies the passenger pick up and delivery to the Vehicle Routing Problem (VRP) , which is then solved using the highly optimized CP-SAT solver. Algorithm with very good results (more than 30% better than random allocation) Scalable to over 50 taxis For huge fleets, UNDER uses a still very good (over 20% improvement) greedy approximation algorithm The optimization target can be changed even during the day, to prioritise speed , energy consumption or both 🧑‍💻 How We Built It We combined cutting-edge technologies and tools to bring UNDER to life: Python : For backend logic and CP-SAT implementation. OR-Tools : To handle constraint-solving and optimization. Socket.IO : For real-time communication between the backend and frontend. React : To create an interactive and responsive user interface. OpenRouteService : For routing accurate to the street. Leaflet : To visualize maps and vehicle paths seamlessly. 🌟 Accomplishments We're Proud Of Speed and Reliability : Our approach still has very good results for huge amounts of taxis. Scalable Design : Built a flexible system capable of handling diverse routing challenges. User-Friendly Interface : Developed an intuitive interface for seamless interaction and visualization. Built With ts Try it out GitHub Repo Submitted to hackaTUM 2024 Created by Samuel Leßmann Aleksandrs Morgen"
      }
    ]
  },
  {
    "file_path": "./devposts/universe-4yectq.html",
    "project_id": "universe-4yectq",
    "title": "UniVerse",
    "tagline": "Connect with people nearby! Our chat app uses geolocation to limit conversations to specific areas. Register, stay secure, and meet like-minded individuals!",
    "hackathon": "",
    "built_with": [
      "express.js",
      "mongodb",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/392/177/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Homepage Inspiration Imagine being able to connect with people in your immediate surroundings in a meaningful way, without the need for small talk or awkward introductions. That's the idea behind a new chat application that only allows users to talk when they are within a certain area. By requiring users to register and tag their location, the app creates a sense of community and belonging that can be difficult to find in the digital age. Users can chat with others who are nearby, whether they are at a coffee shop, a concert, or a public park. This creates an opportunity for people to meet new friends, make business connections, or even find romantic partners, all while staying within their comfort zone. The app is designed to be inclusive and welcoming to all types of people. It is a safe space where users can share their thoughts, ideas, and feelings without fear of judgment or discrimination. By bringing people together based on their physical location, the app encourages face-to-face interactions and helps to combat the isolation and loneliness that many people experience in modern society. Whether you are new to a city and looking for friends, or simply want to connect with people who share your interests, this app has something to offer. By providing a platform for people to connect and communicate in real time, it has the potential to transform the way we interact with each other and create meaningful connections that last a lifetime. What it does How we built it Stack Technology Frontend React Backend Express Js Database MongoDB , GraphQL Stack Technology Frontend React Backend Express Js Database MongoDB , GraphQL Challenges we ran into We faced several challenges during the project, including connecting the front-end to the back-end of the application, designing the application, and even brainstorming the initial idea. Accomplishments that we're proud of Our accomplishments during the project include the successful design of the application and the creatio"
      }
    ]
  },
  {
    "file_path": "./devposts/uniinvest.html",
    "project_id": "uniinvest",
    "title": "Uniinvest",
    "tagline": "Getting the right financial platform/tool is difficult. You can find ones that give you tips, but don't let you invest, or only restrict you to invest. Uniinvest combines all three factors into one.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "css",
      "html",
      "javascript",
      "next.js",
      "react.js",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/194/218/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "List of Expenditures Tax Crypto Investing Crypto Lessons Accounts Articles Catalog HomePage Investment Courses Finances Articles Homepage List of Expenditures Tax Crypto Investing Crypto Lessons Accounts Articles Catalog HomePage Investment Courses Finances Articles Homepage List of Expenditures 1 2 3 4 5 6 7 8 9 10 11 12 🤩 Inspiration Over the past few years, there has been an increase of financial platforms on the web. Ranging from banking apps to investing apps, they only serve their own purpose. However, this disparity makes it harder for newcomers to join the world of finance both in the realm of investing and saving money for their future. Thus, newcomers from different countries, new grads, and more have to learn multiple platforms just to understand how to get their relevant financial information, invest, and most importantly, learn. That right there, is already 3 apps! Uniinvest aims to get rid of this chain of apps and combine all of them into one for financial ease and entering such realms with ease 🌎 ⚙️ What it does Uniinvest is a universal financial platform where users can view their balances and expenditures in different sectors (different types of investments, external spending, etc), learn about finance (topics including: crypto, stock market, Accounting, Tax, etc), and invest in either the crypto or stock market. With  Cohere's trained NLP model, users can also search in real-time any financial questions they have. This ensures that users can get all their finance cleaned up and organized with confidence. 🛠 How we built it General Platform: React.js Article Data: Cohere's NLP Model (engineered in JS) Articles Page: Next.js 🔥 Tech Challenges we ran into There were some challenges in-regards to combining react components together as one member was working with Next.js and the other was working with React Native. The head-on integration was difficult due to Next.js having a slightly different syntax when it comes to putting components on the DOM. Howe"
      }
    ]
  },
  {
    "file_path": "./devposts/up-cycle.html",
    "project_id": "up-cycle",
    "title": "Upcycle",
    "tagline": "Reduce, Reuse, Upcycle — Sustainable Fashion Revolutionized ✨",
    "hackathon": "",
    "built_with": [
      "ai",
      "docker",
      "fashion-mnist",
      "figma",
      "firebase",
      "flask",
      "gcp",
      "keras",
      "leaflet.js",
      "mongodb",
      "nextjs",
      "prisma",
      "stablediffusion",
      "tailwindcss",
      "tensorflow",
      "typescript",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1517Fund + Best Use of AI Inspiration 💡 Upcycle was inspired by the challenges faced by the global",
      "Grand Prize Created by ML x Ops Pratyay Banerjee Trying to learn how to learn ;) I handled UI/UX de",
      "Hacktech 2023WinnerGrand Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/410/749/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Hi-Fi Mockups GIF UX Flow (Hi-Level) Hi-Fi Mockups GIF UX Flow (Hi-Level) Hi-Fi Mockups 1 2 3 4 Targeted Tracks → Most Likely to Become a Business - Sponsored by 1517Fund + Best Use of AI Inspiration 💡 Upcycle was inspired by the challenges faced by the global fashion market and economy, which led to increased textile pollution and job layoffs in the tailoring and seamstress industries during the COVID pandemic. We saw an opportunity to tackle textile pollution and promote sustainability while creating new job opportunities for tailors and seamstresses. Our mission is to revolutionize the fashion industry through upcycling and machine learning, using analytics to create a more sustainable and economically stable future. By reducing waste and promoting upcycling, we aim to make a positive impact on the global economy while promoting environmental and social responsibility. As someone who deeply cares about sustainability, I believe that we must take action now to preserve our planet for future generations. We need to shift our focus towards creating a circular economy, where waste is minimized and resources are reused. This is particularly important in the fashion industry, which is responsible for a significant amount of pollution and waste. By promoting sustainable practices such as upcycling and reducing textile waste, we can not only help the environment, but also create new job opportunities and boost the global economy. It's time to rethink the way we consume and produce goods, and work towards a more sustainable future. What it does 🤔 Upcycle is a smart webapp designed to connect users with their local tailors and seamstresses to extend the lifespan of their clothes. The app's goal is to support the local tailoring industry while keeping users on-trend. Studies estimate that more than $500 billion in value is lost annually due to underutilized clothing and lack of recycling? Unfortunately, less than 50% of returned items from online shopping go back on sale, l"
      }
    ]
  },
  {
    "file_path": "./devposts/utalk.html",
    "project_id": "utalk",
    "title": "uTalk",
    "tagline": "A personalized AI therapist with the goal of trying to make uTalk",
    "hackathon": "",
    "built_with": [
      "cohere",
      "css3",
      "firebase",
      "firestore",
      "flask",
      "html",
      "openai",
      "python",
      "react",
      "react-speech-kit",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Capgemini - Best Solution to Provide Access to Existing Mental Health Resources for Students Create",
      "category -- and instead letting our project idea guide which prize category to aim for",
      "UofTHacks XWinnerCapgemini - Best Solution to Provide Access to Existing Mental Health Resources for Students",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/351/372/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Logo Logo Logo 1 2 💡 Inspiration 💡 Mental health is a growing concern in today's population, especially in 2023 as we're all adjusting back to civilization again as COVID-19 measures are largely lifted. With Cohere as one of our UofT Hacks X sponsors this weekend, we want to explore the growing application of natural language processing and artificial intelligence to help make mental health services more accessible. One of the main barriers for potential patients seeking mental health services is the negative stigma around therapy  -- in particular, admitting our weaknesses, overcoming learned helplessness, and fearing judgement from others. Patients may also find it inconvenient to seek out therapy -- either because appointment waitlists can last several months long, therapy clinics can be quite far, or appointment times may not fit the patient's schedule. By providing an online AI consultant, we can allow users to briefly experience the process of therapy to overcome their aversion in the comfort of their own homes and under complete privacy. We are hoping that after becoming comfortable with the experience, users in need will be encouraged to actively seek mental health services! ❓ What it does ❓ This app is a therapy AI that generates reactive responses to the user and remembers previous information not just from the current conversation, but also past conversations with the user. Our AI allows for real-time conversation by using speech-to-text processing technology and then uses text-to-speech technology for a fluent human-like response. At the end of each conversation, the AI therapist generates an appropriate image summarizing the sentiment of the conversation to give users a method to better remember their discussion. 🏗️ How we built it 🏗️ We used Flask to make the API endpoints in the back-end to connect with the front-end and also save information for the current user's session, such as username and past conversations, which were stored in a SQL database. "
      }
    ]
  },
  {
    "file_path": "./devposts/uptone.html",
    "project_id": "uptone",
    "title": "Uptone",
    "tagline": "Uptone is an AI-powered web extension that scans your Twitter feed for hate speech and negativity, alerting you of toxic tweets and allowing you to mute them. Focus on the upside, with Uptone.",
    "hackathon": "",
    "built_with": [
      "figma",
      "flask",
      "javascript",
      "jupyter-notebook",
      "keras",
      "nuxtjs",
      "python",
      "tensorflow",
      "webextension-polyfill",
      "windicss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Winner Most Creative Use of GitHub - MLH Created by I worked as the graphic designer, video",
      "Best Overall Winner Most Creative Use of GitHub - MLH Created by I worked as the graphic designer,",
      "MasseyHacks VIIIWinnerBest OverallWinnerMost Creative Use of GitHub - MLH",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/931/229/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "Uptone Website Uptone Website 1 2 3 4 5 6 What it does Uptone protects you from hate speech on social media by running posts through a neural network and sentiment analyzer, hiding those determined to be hateful. How we built it The browser extension was made using webextension-polyfill, in order to support all major browsers. It uses parcel to compile the extension, and web-ext for easy hot-reloading and development. The extension parses tweets on the page by hooking onto the scroll event and querying different selectors. Then, it sends the Tweets to the backend API, where predictions are returned. The backend API was made using Flask, and it consists of a POST route that serves the neural network model and sentiment analyzer. The AI model was made with Tensorflow and Keras. It is a Convolutional Neural Network that categorizes Tweet text into (0 = hate speech, 1 = offensive language, 2 = neither). Finally, the website was made using NuxtJS and WindiCSS, and designed with Figma. Challenges we ran into At the start, the accuracy of the AI model was quite low, hovering at around 70%. We were able to increase this to ~87% by tuning hyperparameters and making a custom Tweet preprocessor. In addition, we ran into a few bugs while making our browser extension, as it was the first time any of us had made one. For instance, the dialog shown when hiding a Tweet would be duplicated many times, and the \"View\" button also did not work. We were able to fix these problems after careful debugging, and testing different ideas. Accomplishments that we're proud of We are proud that we were able to accomplish so much in a short period of time. This was the first hackathon for all four of us, so we are very excited to be able to make this project and share it with the rest of the world. We are also proud that the extension and AI model work perfectly and function as intended. It was a difficult process to develop them in the short period of time given, but everything worked out in the"
      }
    ]
  },
  {
    "file_path": "./devposts/uwu-f167g2.html",
    "project_id": "uwu-f167g2",
    "title": "Hometown Tourist",
    "tagline": "Experience your hometown in a new light",
    "hackathon": "",
    "built_with": [
      "domain.com",
      "fastapi",
      "gcs",
      "mapbox",
      "mongodb",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[MLH] Best Domain Name from Domain",
      "Hack Kosice 2023Winner[MLH] Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/435/699/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Post-cleanup POI breakdown Hometown Tourist Dashboard Preview Košice. All the areal data that has been analyzed. Post-cleanup POI breakdown Hometown Tourist Dashboard Preview Košice. All the areal data that has been analyzed. Post-cleanup POI breakdown 1 2 3 4 Inspiration No matter whether you're a tourist visiting a city for the first time in your life or someone who has lived there for your whole life, every city has hidden gems and routes that might not be known even for those who live there for their whole life. To help people get to know their city even better, we developed Hometown Tourist , a web application that is meant to be the encyclopedia when it comes to discovering more about Košice. What it does Everything that Google can't!* While it's true that most of the capabilities have been made available through the sponsors who provided us with a generous amount of data, there's still quite a lot of computation and processing needed to achieve some of the most powerful suggestions and results: Calculation of optimal routes with specific themed stops and amenities that the person might have on its mind, all on the way to the destination. Evaluation of districts/boroughs based on your interests when having to move or looking for a new apartment. Pointing out the districts/boroughs based on what's missing to help business owners spot a new great location for their business. Creating the ultimate dashboard for both individual users planing their next weekend activities and governmental organs planing a greener future for their city. On top of that, the capabilities scaling directly with the amount of data provided is a plus, implying that the results will always be up-to-date, as long as the data gets updated regularly. While it makes our project very specific to Košice, it's also what makes it so unique. How we built it Since the team consisted of three people, it was very convenient to split the whole project into three separate parts: front-end with React, ba"
      }
    ]
  },
  {
    "file_path": "./devposts/vanilla-chess.html",
    "project_id": "vanilla-chess",
    "title": "vanilla-chess",
    "tagline": "it’s chess, but with explosions, surprises, and way more laughs",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/696/320/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF nuke power up in action (if you can't beat them nuke them) screenshot of screen you see when you load into the game screenshot of an ongoing match between my right and left hand GIF nuke power up in action (if you can't beat them nuke them) screenshot of screen you see when you load into the game screenshot of an ongoing match between my right and left hand GIF nuke power up in action (if you can't beat them nuke them) 1 2 3 4 🌟 Project Story ♟️ About the Project Vanilla-Chess started with a simple question: what if chess wasn’t just about memorizing moves and playing the same openings over and over? Classic chess is brilliant, but it often rewards pattern-based learning — players rely on established strategies and pre-learned tricks. While that’s impressive, it sometimes leaves little room for raw, spontaneous creativity. That’s where Vanilla-Chess with Superpowers comes in 🎉. The rules of traditional chess are still here, but with a twist: 🛡️ Shield – Protect your piece for one turn 🔄 Skip – Make your opponent lose a turn, UNO-style 💥 Nuke – Wipe out that pesky pawn These power-ups break the monotony of predictable play and throw players into real-time problem-solving mode . Suddenly, strategy isn’t just about the “best known move,” it’s about adapting to chaos, thinking creatively, and making the most of unpredictable situations. 👉 And that’s the main goal of this project: to shift players away from pattern-based thinking and towards creative, adaptive, and fun problem-solving . 💡 Inspiration The inspiration came from two places: My love for chess as a brain game 🧠. My curiosity to see how a timeless game can be reimagined with creativity and chaos . I’ve always believed coding projects should feel fun, not just functional . By combining chess with power-ups, I wanted to show how even with just vanilla HTML, CSS, and JS , you can build something both engaging and unique. 🛠️ How I Built It 🏗️ HTML – created the chessboard structure, game layout, and controls. "
      }
    ]
  },
  {
    "file_path": "./devposts/uwu-fbsrn1.html",
    "project_id": "uwu-fbsrn1",
    "title": "uwu",
    "tagline": "What if uwu, but evewywhewe",
    "hackathon": "",
    "built_with": [
      "html",
      "javascript",
      "node.js",
      "uwu"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "McHacks 11WinnerChaotic Evil",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/738/912/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Wooks wike c-cweditbwe extension uwu the news uwu DevPost uwu YouTube Wooks wike c-cweditbwe extension uwu the news uwu DevPost uwu YouTube Wooks wike c-cweditbwe extension 1 2 3 4 5 Regular Description Inspiration How can you make web browsing the worst experience possible while still being fun? We were inspired by Daniel Liu's fastest text uwuifier in the west . What if you could meme on the user without them knowing the reason why. What it does After a page is fully loaded, uwu is unleashed. It goes through every element and converts it to uwu. Images aren't safe either. The user is at the mercy of RNG and the very solid codebase. How we built it We used HTML and JavaScript to create our Chrome extension. With lots of trial and error, the right mix of commands was perfected for maximum uwu. Using uwuify , we convert all visible text into uwu. Images are from Memegen.link and randomizes for maximum unpredictability. Images are modified first because they speak a thousand words. Challenges we ran into It's really hard to modify HTML and not break everything All websites are structured different Accomplishments that we're proud of It runs relatively fast Results are funny Kept ruining documentation when forgot to turn off What we learned It is a pain to go through every single element There are more elements than you think What's next for uwu Image size manipulation Reduce queries to backend so we don't get rate limited uwuified descwiption walks away Inspiwation How c-can you make web bwowsing x3 the x3 wowst expewience possibwe whiwe stiww b-being fun!? We wewe inspiwed >w< by Daniel Liu's fastest text uwuifier in the west . What if you c-couwd meme on the x3 usew without them knyowing >w< the x3 weason w-w-why. What i-it does Aftew a page is fuwwy woaded, uwu is unweashed. cries It goes thwough evewy ewement and convewts i-it t-to uwu. Images awen't safe ;;w;; eithew. the runs away usew is at the x3 mewcy looks at you of WNG and the x3 vewy sowid c-codebase. How "
      }
    ]
  },
  {
    "file_path": "./devposts/ventout.html",
    "project_id": "ventout",
    "title": "VentOUT",
    "tagline": "A safe platform to let go of your frustrations!😮‍💨",
    "hackathon": "",
    "built_with": [
      "assembly-ai",
      "express.js",
      "figma",
      "github",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Usage of CI/CD sponsored by CircleCI We are using CircleCI for continuous integration and deploymen",
      "OVERALL HACK] 2nd Place Winner Best CI/CD Application Using CircleCI Created by Evan came up the id",
      "effort in any hackathon I attend! Involved in making several components on the frontend, implemente",
      "[BEST OVERALL HACK] 2nd Place Winner Best CI/CD Application Using CircleCI Created by Evan came up",
      "SF Hacks 2022Winner[BEST OVERALL HACK] 2nd PlaceWinnerBest CI/CD Application Using CircleCI",
      "👨🏻‍🤝‍👨🏽 Mental Health Track",
      "🎨Best UI/UX",
      "⛅ Best Use of Google Cloud",
      "🤖 Best Use of AssemblyAI",
      "🛠 Best Usage of CI/CD sponsored by CircleCI",
      "🌐 Best Domain Name from Domain.com",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/867/614/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 💡Inspiration Life can get hard sometimes. Whether in school, work, relationships, or physical health, we all face challenges that make us angry and disappointed. People often remove this frustration by cursing out loud and in the process hurt somebody else or by punching a wall, hurting themselves. Studies show that such actions, known as venting out, positively impact your mental health but negatively impact those around you. Venting out is good for you but venting out in the correct manner is even more important. We are inspired by President Abraham Lincoln’s “hot letters” written during the civil war, ones that he wrote to vent out his frustration with his colleagues and enemies but never posted. Today we have many more sophisticated tools to vent out all our anger and we made a platform to do so in an effective manner. We call this platform VentOut 🤔What it does When an individual is stressed, they often look for an outlet to release their tension, whether it be through friends, family or even just yelling out into the street. VentOUT takes this simple idea and creates a space where anyone can anonymously vocalize their feelings and see that they are not alone in their struggles. VentOUT is a chat application created to make it easier for individuals to vent and vocalize their inner thoughts. We take in a user's audio message, transcribe it to text and post it in an anonymous space.  At the same time, we provide these individuals with positive resources to understand what is making them upset and encourage them to take appropriate action. We have identified 4 main categories where people face challenges with mental health: work, school, relationship, and health. For each of these categories, we provide users with a chat room to anonymously express their frustrations and curse out loud. In order to ensure there is no toxic profanity on our application, we filter out curse words said by the user in their frustration. 🦾 How we built it Frontend: React.js, T"
      }
    ]
  },
  {
    "file_path": "./devposts/verdanda-web-app.html",
    "project_id": "verdanda-web-app",
    "title": "Verdanda - Web App",
    "tagline": "Verdanda is the solution to simplify the process by abstracting away the details and giving users specific tasks to solidify healthy financial habits and eradicate financial instability.",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "flask",
      "javascript",
      "json",
      "mysql",
      "pandas",
      "python",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked mainly in the front-end. First time using it!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/814/847/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 The Federal Reserve's 2018 Survey of Household Economics and Decision Making revealed that about 40% of Americans would struggle to come up with even $400 to pay for an unexpected bill.\nThe current COVID-19 pandemic highlights now more than ever the importance of establishing and maintaining healthy saving habits in the face of uncertainty.\nOne of the main problems when it comes to personal finance is ensuring clear and consistent tracking of savings and expenses. Our project goal is to develop a personal finance dashboard that enables customers to create and consistently sustain an emergency savings fund. Verdanda is a full-stack implementation that implements front-end, back-end, and database management to store user information and display dynamic financial goals. For the front-end, we used HTML, CSS, JavaScript, and Bootstrap as well as Bulma.io to create a cohesive color scheme, design features, and fonts that emphasize important info but also maintain concision and white-space. For the backend, we ran a local SQL server with MySQL that links user_id's to user info and financial info. These are accessed and modified by the Flask/JS program, which uses button actions to modify the database with relevant form data. Ultimately, we want to implement more data analysis for the goals, financial resources, and social features to connect successful users. Our proof-of-concept project includes features such as: A data analytics algorithm that determines the next steps after completing an emergency fund savings goal A rating system that scores users based on how consistent they are in completing their savings goals A socialization component that enables users to share their financial goals and help establish accountability Built With bootstrap flask javascript json mysql pandas python sql Try it out GitHub Repo Submitted to TAMUhack 2022 Created by I worked mainly in the front-end. First time using it! Ilse Moya Rishabh Prasad MAJ-23 Jimenez Krist"
      }
    ]
  },
  {
    "file_path": "./devposts/vaultdoor.html",
    "project_id": "vaultdoor",
    "title": "Vaultdoor",
    "tagline": "Share Safely. Encrypt Easily. Stay Secure.",
    "hackathon": "",
    "built_with": [
      "gin",
      "golang",
      "javascript",
      "repl",
      "wasm"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "TABLE 132 Inspirationtesttest What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Vaultdoor Built With gin golang javascript repl wasm Submitted to Los Altos Hacks VII Created by Gaurav Bansal Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly DevMello"
      }
    ]
  },
  {
    "file_path": "./devposts/vibeprompting.html",
    "project_id": "vibeprompting",
    "title": "VibePrompting",
    "tagline": "smarter agentic workflows.",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini",
      "googleadk",
      "next",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/501/987/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Prompt training Landing Prompt training Landing Prompt training 1 2 3 Inspiration With bigtech embracing AI agentic models in their workflow and working towards seamless integration with the infrastructure, there can be many errors during this phase. We wanted to work on this very phase of shifting and deploying AI models and also not break production while doing it. There are several cases wherein agents do not perform to their full potential due to reasons completely unrelated to the design or deployment but due to improper prompting. Even though it may seem like debugging these cases can be straightforward, our team has experienced designing near perfect workflows (of course from a human standpoint) and can still have erratic results due to semantic differences and language processing errors. That is how we thought of VibePrompting. We aim to automate the entire phase of designing agentic workflows. What it does VibePrompting is a dashboard which takes as input the AI model that the user is working on, and works on refining the workflow to help the AI model perform better. Our product has the following features: Real time AI agent refinement: On uploading the agent to the platform the user can see the workflow and input commands to customise the agent without the additional burden of overcoming precise prompting. Enabling editing different configs of the agent: Our platform allows the user to revise specific part of the field of the json config of the agent thereby giving the user more control and flexibility and mimicking the experience of working on the json itself rather than a black box intermediary which is not the best experience for devs. Version control and activity logs: We enabled version control features like branching and building off from different branches so that the dev can easily test out models made from the different branches rather than struggle with figuring the most optimised prompts which give the best results. The platform even has a log h"
      }
    ]
  },
  {
    "file_path": "./devposts/vball-trainer.html",
    "project_id": "vball-trainer",
    "title": "VBall Trainer",
    "tagline": "VBall Trainer is an app that polishes your volleyball skills to make for more exciting rallies!",
    "hackathon": "",
    "built_with": [
      "cv2",
      "mediapipe",
      "pyqt5",
      "python",
      "qtdesigner"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Created by Worked on the body tracking along with positioning of the person to detect when a volley",
      "First place Created by Worked on the body tracking along with positioning of the person to detect w",
      "hack::peel 2022WinnerFirst place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/327/851/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Main Menu VBall Trainer Main Menu VBall Trainer Main Menu 1 2 3 Inspiration All of us love playing volleyball, and setting was something that took a really long time for us to figure out. There are so many factors to take into consideration, and practising on your own doesn't cut it because things have to work seamlessly with the attacker as well. We wanted to make it easier to practice setting by provide an app that determines a good set, and finds what would make it better. What it does VBall Trainer uses object and skeleton detection to determine how \"good\" your set is—whether your form needs tweaking, if the ball is too high, or if the path of the ball is off. VBall Trainer runs a setting drill, and analyzes your form and the curve of the ball to help you improve! How we built it We used Mediapipe for object and skeleton detection, which would locate and track certain points on your body (eg. thumbs, elbows, torso, legs) as well as the ball. We trig bashed coordinates of the elbows, shoulders, and thumbs to check the setting form, and tested all kinds of gestures to make sure that we were able to properly determine proper setting form. In order to model the 3D trajectory, we took pictures of the volleyball at different distances. Then, we could use linear regression to see where a ball would be at a certain time to model a 3D trajectory. Challenges we ran into We went through some turbulence when training the model—the datasets we were using weren't the most accurate so the model wasn't as clean as we wanted it to be. Moreover, the wifi speed affected the upload time, which wasn't the most convenient given the time crunch we were in. The set detection also required a lot of 3D math that was a bit of a pain to work out. We ended up having to train the model multiple times—sometimes it got so frustrating that we wanted to change direction altogether. Another obstacle that really set us back was making a phone work as a webcam for us. The \"Continuity Camera\" that a"
      }
    ]
  },
  {
    "file_path": "./devposts/vinky.html",
    "project_id": "vinky",
    "title": "Vinky",
    "tagline": "Your personal guide for a better airport experience. \nMillions of People board Flights every day, yet most aren’t frequent flyers.\nWe want to make the airport process easy for them.",
    "hackathon": "",
    "built_with": [
      "expo.io",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/377/655/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration For many first-time flyers and flyers who are at new airports, it's often intimidating for flyers to navigate through the huge airport. There are so many terminals and gates a flyer must go through before successfully boarding the plane. Often times flyers will get lost and don't know what to do next, That's why Vinky is here to help. What it does Vinky will be your personal guide from the time you enter the airport till the time you exit at the destination. Just Scan the QR Code when you enter the Airport, Leave the rest to Vinky. Yup, that simple! Vinky will extract knowledge on your flight time, terminal, and boarding gate and guide you through each checkpoint. If you are hungry or need to use the restroom just ask Vinky. \nVinky will always be here to help. How we built it We built this using React-native Challenges we ran into There were many challenges we ran into such as integrating QRcode scan and 3d maps. When we try to integrate QR scan there were errors claiming exports were not made successful. Since this is our first time using React native the bugs were hard to debug. Our approach to using 3d maps was restricted when we found out that most 3d map services do not provide map usage for personal use.  Attempting to utilize Cockroachdb proved a challenge with various roadblocks along the way (and not enough forum answers) but it did successfully connect insecurely between two local virtual machines. GCP had issues where the libraries and frameworks weren't fully installing on their VMs. Accomplishments that we're proud of Although we did not accomplish what we imagined we are proud of ourselves for learning a new framework and trying mobile development. What we learned Our team has no experience in mobile development, this project gave us an understanding of mobile development and also exposed us to react-native. What's next for Vinky In the future, Vinky will be a fully functional app with all the features embedded. And also other cool feat"
      }
    ]
  },
  {
    "file_path": "./devposts/vaxrate.html",
    "project_id": "vaxrate",
    "title": "VaxRate",
    "tagline": "Two interactive dashboards showing global vaccination progress and COVID-19’s second-order impact on underreported communities, for achieving herd immunity and international health policymaking.",
    "hackathon": "",
    "built_with": [
      "jupyter",
      "photoshop",
      "python",
      "tableau",
      "visme"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Challenge 1 Visualization ($125 for the team) Winner Wolfram Award (Top 12 Teams, valued at $375 pe",
      "Harvard Center for Geographic Analysis - Best Challenge 1 Visualization ($125 for the team) Winner",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/614/941/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Second-order Impact Dashboard Team Logo Worldwide Vaccination Progress Dashboard Second-order Impact Dashboard Team Logo Worldwide Vaccination Progress Dashboard Second-order Impact Dashboard 1 2 3 4 Inspiration Vaccination progress and mitigating second-order impacts are both essential to achieving herd immunity and returning to normal from this pandemic. However, such data about smaller countries are often left in the dark. What it does This is why we decided to create two interactive dashboards: one showing vaccination progress for every country and another reporting findings from the C2M2 program. In our “Worldwide Vaccination Progress” report, you can hover over a region to see the % of vaccinated people in its population and select them to see more specific details like daily vaccination over time. Our other dashboard features a bubble chart of all the second-order impacts COVID-19 has had on three cities in Asia. Each bubble shows where the information is taken from, the area of impact, and a brief description of that. They are colored based on their reporting location. When you click on a particular bubble, a chart corresponding to its description will pop up. How we built it For our “Worldwide Vaccination Progress” dashboard, we first downloaded the dataset from Gabriel Preda’s “COVID-19 World Vaccination Progress” (Link: https://www.kaggle.com/gpreda/covid-world-vaccination-progress ) and Rishav Sharma’s “2021 World Population” (Link: https://www.kaggle.com/gpreda/covid-world-vaccination-progress ). We then populated them on Tableau and created a world map at the top of our dashboard. We also implemented data filtering based on the country with the world map, so when the user clicks on one area/selects multiple areas, the data about that area(s) will show up. As for our other dashboard, we first extracted the data from the 2020-2021 baseline reports from C2M2. We then organized the graphing data based on which second-order impact area it’s describing and t"
      }
    ]
  },
  {
    "file_path": "./devposts/vid2text.html",
    "project_id": "vid2text",
    "title": "Vid2Text",
    "tagline": "Easy to Access Video and Audio Transcription | Team 47",
    "hackathon": "",
    "built_with": [
      "api",
      "assemblyai",
      "css3",
      "django",
      "html5",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of the AssemblyAI API Winner All Winners - Taskade Lifetime Winner All Winners - Leading Learne",
      "Best Use of the AssemblyAI API Winner All Winners - Taskade Lifetime Winner All Winners - Leading L",
      "All Winners - HawkHacks T-Shirt Created by Abiola Farounbi Aditya Goel As a full-stack developer, I",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/930/984/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Application Page Vid2Text Logo Landing Page Application Page Vid2Text Logo Landing Page Application Page 1 2 3 4 Inspiration 💡 With the introduction of online-based learning, a lot of video tutorials are being created for students and learners to gain knowledge. As much as the idea is excellent, there was also a constraint whereby the tutorials may contain long hours of content and in some cases, it is inaccessible to users with disability. This is seen as a problem in the world today, that's why we built an innovative and creative solution Vid2Text to provide the solution to this. It is a web application that provides users with easy access to audio and video text transcription for all types of users. So either if the file is in an audio or video format it can always be converted to readable text. 🍁About Vid2Text is a web app that allows users to upload audio and video files with ease, which then generates Modified and Customized Audio and Video Transcriptions.\nSome of the features it provides are: Features Automatically transcribe audio and video files with high accuracy. Modified and Customized Audio and Video Transcriptions. Easy Keyword Search through Text Easy Keyword Search and Highlight through Text. How we built it We built our project using Django, a Python web framework that uses the MVC architecture to develop full-stack web applications. When the user uploads the video they want to transcribe,  we created a script that uploads the video onto the Django model database and after that, the video gets uploaded to the AssemblyAI server. The response of that part is the upload_url . Finally, we send a post request, with the video transcript ID and get the video transcript text as the response. We utilized the AssemblyAI to match and search the transcript text for keywords. We also created an accessible and good user experience for the client-side. Challenges we ran into In course of the hackathon, we faced some issues with limited time and integration of the "
      }
    ]
  },
  {
    "file_path": "./devposts/vibes-f093da.html",
    "project_id": "vibes-f093da",
    "title": "Vybes",
    "tagline": "We have created an intuitive system that helps you experience, travel and have more positive vibes in life.",
    "hackathon": "",
    "built_with": [
      "eeg",
      "flask",
      "grifana",
      "javascript",
      "lsl",
      "muse",
      "ppm",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/880/782/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Traveling can be an enriching and transformative experience, but it can also be daunting, especially for first-time travelers. Planning a trip often leads to anxiety, and finding the perfect travel companions can be a challenge.  Vybes was born out of the desire to create a seamless travel planning experience that not only connects you with like-minded travelers but also leverages the power of music to enhance your mood and keep you motivated throughout the journey. What it Does Vybes is a web application that uses the power of music to connect travelers and optimize their travel experience. Travelers can sign in using their Spotify account, allowing Vybes to access their music profile. This profile analysis helps identify potential travel buddies with similar musical tastes. Travelers can then input their desired travel dates and browse profiles of other users with overlapping travel plans. Vybes goes beyond simple music matching. We delve deeper to understand the user's travel motivations and desired trip experience.  This can involve anything from seeking relaxation on a beach vacation to experiencing the cultural energy of a bustling city.  By analyzing the user's music playlists, Vybes can recommend songs that align with their trip's \"vibe,\" creating a personalized soundtrack for their journey. How We Built It Vybes leverages the Spotify API to access user music profiles. To facilitate user matching, we utilize recommendation algorithms that analyze music preferences and travel plans.  For a more nuanced understanding of travel motivations, we plan to incorporate sentiment analysis techniques to interpret the emotional tone of the user's music library. The \"mood switch\" feature is where Vybes gets truly innovative.  This feature integrates with the Muse EEG headband to capture the user's real-time brainwave activity.  By analyzing these signals, Vybes can determine the user's current mood state (calm, energetic, anxious).  Here's where things get sp"
      }
    ]
  },
  {
    "file_path": "./devposts/vibe-draw.html",
    "project_id": "vibe-draw",
    "title": "Vibe Draw",
    "tagline": "turn your roughest sketches into stunning 3D worlds by vibe drawing",
    "hackathon": "",
    "built_with": [
      "celery",
      "cerebras",
      "claude",
      "fastapi",
      "gemini",
      "llama",
      "next",
      "python",
      "react",
      "three.js"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Gemini - Samsung Monitors Created by I vib3d Martin Sit CS @ UWaterloo I vib3d William",
      "GenAI Genesis 2025WinnerBest Use of Gemini - Samsung Monitors",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/331/368/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Vibe Draw Vibe Draw's UI Infinite 2D Drawing Canvas Animated 3D Models Infinite 3D World Vibe Draw Vibe Draw's UI Infinite 2D Drawing Canvas Animated 3D Models Infinite 3D World Vibe Draw 1 2 3 4 5 6 Inspiration Creativity is often constrained by technical skills or complex software. We were inspired by the idea of democratizing 3D creation, making it easy and accessible to anyone, regardless of their artistic or technical abilities. Our goal is to empower people to freely express their imagination and bring their ideas effortlessly into 3D worlds. What it does Vibe Draw is an intuitive app that transforms your simple hand-drawn sketches and rough writings into polished, colorful 3D models. Users sketch freely on an infinite 2D canvas, and the AI intelligently converts these sketches into realistic, aesthetically pleasing 3D objects. Users can then seamlessly add their creations to an infinite 3D world, building immersive scenes and environments they can export and share. How we built it We used Next.js and React for our responsive, user-friendly frontend, coupled with Three.js for rendering interactive 3D models. To convert rough sketches into detailed drawings, we used Gemini Flash 2.0 Experimental, which improved the visual quality and accuracy of user drawings. Claude Sonnet 3.7 allowed us to effectively prompt Three.js with images and text, dynamically generating accurate 3D models. Cerebras Llama 3.3 70B was used to rapidly extract individual object code from complex Three.js scenes, allowing for one-click imports in the 3D world. The backend infrastructure was developed using Python, FastAPI, and Celery to handle asynchronous tasks efficiently. Challenges we ran into One significant challenge was achieving accurate 3D interpretations from varied sketch quality. Ensuring the AI consistently understood users' intent, regardless of drawing precision, required rigorous prompt engineering and a bit of creativity. For instance, we decided to use Gemini 2.0 Flash's "
      }
    ]
  },
  {
    "file_path": "./devposts/video-montage-generator.html",
    "project_id": "video-montage-generator",
    "title": "Video Montage Generator",
    "tagline": "Creates an edited video montage based on keywords",
    "hackathon": "",
    "built_with": [
      "css",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration: We want to generate background footage for videos without editing ourselves What it does: Automatically edits a video for you based on keywords How we built it: Created a Folder of code in VSCode using Python Challenges we ran into: Getting the footage clips to combine into one .mp4 (took 11.5 hr) Accomplishments that we're proud of: Properly combining the clips together! What we learned: Python, Html/Javascript, Teamwork/Project Management What's next for Video Montage Generator: More smoothly generating videos based on lengths for multiple keywords Built With css html5 javascript python Try it out GitHub Repo Submitted to HackBU 2023 Created by Matthew Pena Hunter Tan Allen Domingo"
      }
    ]
  },
  {
    "file_path": "./devposts/vibot.html",
    "project_id": "vibot",
    "title": "ViBot",
    "tagline": "A ViBot so you can vibe with a bot :D",
    "hackathon": "",
    "built_with": [
      "api",
      "bot",
      "databases",
      "discord",
      "machine-learning",
      "nltk",
      "python",
      "servers",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "YRHacksWinnerSecond PlaceWinnerBest Use Of Any Database",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/491/418/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration The inspiration for this project originated from the Discord Rhythm bot. After playing around with various Discord Bots, we thought that it would be an interesting idea if we could create a music bot... but instead, suggested songs. To make the bot relevant to the current pandemic, we decided to make it suggest songs based off of the messages our users send, a way to combat the lack of social interaction in the pandemic. The bot is coded within python and uses the API from the Discord.py library as well as the Natural Languages ToolKit or the NLTK python library. What it Does The goal for the bot is to provide support to those that need it. Especially during the pandemic, most can’t interact with their friends due to the lockdown. This bot reads in a message with the ‘v!mood ’ command. After detecting the mood of the message, the bot then sends a corresponding song that matches the mood and produces an emotion score ranging from -1 to 1 (-1 being most sad, 1 being most happy). Our bot also stores the previous data from each user to compute your average vibe score, comparing your most recent mood with your average. For more commands, use the ‘v!help’ command! How We Built it ViBot was mainly built using python and the discord API from the python library discord.py. The backend is coded using python, while the database is scripted with SQL hosted with Microsoft Azure’s servers. To process emotions within messages, we used the built in VADER sentiment analyzer from the NLTK library in python. Challenges We Ran Into It took a long time for our team to come up with a unique yet feasible project idea. After hours of discussion, we decided on creating a discord bot. Some challenges that we ran into include finding a good platform to create our idea on. We were worried that we may not be able to finish implementing the bot in time for the deadline. ViBot was an extensive idea to finish within 24 hours within formulating it. Accomplishments that We Are "
      }
    ]
  },
  {
    "file_path": "./devposts/vibe-director.html",
    "project_id": "vibe-director",
    "title": "Stu3dio",
    "tagline": "Make a film by talking to 3D workers in the studio",
    "hackathon": "",
    "built_with": [
      "fastify",
      "nextjs",
      "react",
      "supabase"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack the North 2025: Finalists Created by we tryna make movies Emma Shi cs @uwaterloo We tryna make",
      "Hack the North 2025WinnerHack the North 2025: Finalists",
      "First, chat with an Director to brainstorm ideas, build characters, and outline scenes.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/003/741/160/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Director! Character artist inside our 3D studio Scene editing 3D map to navigate around the studio Character editing Script Writer! Time line creation before video generation Director! Character artist inside our 3D studio Scene editing 3D map to navigate around the studio Character editing Script Writer! Time line creation before video generation Director! 1 2 3 4 5 6 7 8 What it does Make an AI movie by talking to others in the 3D studio. First, chat with an Director to brainstorm ideas, build characters, and outline scenes. Secondly, collaborate with an Scriptwriter to flesh out dialogue, actions, and narrative details. Next, meet the Character Artist, where you can tweak style, clothes (ANYTHING YOU WANT) by simply scribbling on the character’s image for instant AI edits. Lastly, view a timeline of all the scenes and their frames, you could edit the scene images directly using scribbling tools and getting instant responses from our image gen AI. Finally ... generate the video ... VoiLa! Your very own AI movie is built! How we built it Projects & Nodes – Each film is a project with a tree of nodes (logline, characters, objects, scenes, final film). Editing a parent marks descendants as stale so they regenerate with fresh context. Only required context is passed when generating each node. Generation Jobs – Every AI action (LLM plot, character sheet, image, video, final stitch) is a generation, queued as a job in Redis. Workers pick jobs, call providers (LLM, image, video), and store results and artifacts. Artifacts – JSON descriptors, images, frame stills, scene clips, and the stitched film are all stored as downloadable artifacts in blob storage. Built With fastify nextjs react supabase Try it out GitHub Repo Submitted to Hack the North 2025 Winner Hack the North 2025: Finalists Created by we tryna make movies Emma Shi cs @uwaterloo We tryna make movies jeff lu we tryna make movies William Zeng we tryna make movies Martin Sit CS @ UWaterloo"
      }
    ]
  },
  {
    "file_path": "./devposts/video-summarizer-gj4uk7.html",
    "project_id": "video-summarizer-gj4uk7",
    "title": "Brevify: Video Summarizer",
    "tagline": "Don’t have time to watch the whole video?  Brevify can create a text summary of your video, so you can get the information easily and efficiently.  Learn the key information and concepts instantly!",
    "hackathon": "",
    "built_with": [
      "ai",
      "ajax",
      "assemblyai",
      "canva",
      "css3",
      "express.js",
      "html5",
      "javascript",
      "node.js",
      "replit",
      "tailwind",
      "web"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/203/647/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Data Flow Diagram Home Page User Upload Video Transcription AI-Generated Summaries and Chapters Data Flow Diagram Home Page User Upload Video Transcription AI-Generated Summaries and Chapters Data Flow Diagram 1 2 3 4 5 6 Inspiration Videos on YouTube are getting longer and longer over time - back then, youtubers get straight to the point but now they feel a need to have long intros, outros, and ad breaks, which keep the viewer from getting the information they want. In addition, as our lives are getting busier and busier in this modern, technological world, we simply don’t have the time to watch a full YouTube video for homework or for studying to understand the material. Our audience involves both student learners (K-12 and college) and adult learners. As Machine Learning enthusiasts, we wanted to find and use an AI or ML model to help solve this problem. What it does Brevify is a web app that ensures that all users, including students and adult learners alike, can always have a platform to enhance their learning by summarizing video content in a quick and convenient way.  The user can upload a video file of their choosing, and AI algorithms will then transcribe and summarize it into easily digestible sections. Brevify can be used at any time, every day. Brevity has two main functionalities: extracting the full video transcription and extracting short chapter summaries, which can be used to find specific concepts and/or retrieve the main points. After a user chooses a video of any length and format (such as .mp4) to upload to the Brevify site, their video only takes up to a minute or two to be processed and for summaries/transcriptions to be generated, making it efficient. How we built it In total, Brevify uses two main types of softwares- AI and web development . Brevify was made with a node js backend and html frontend.  In order to make the website look clean, we used Tailwind CSS for the first time in conjunction with JQuery for manipulating the DOM.  In order"
      }
    ]
  },
  {
    "file_path": "./devposts/videoninja.html",
    "project_id": "videoninja",
    "title": "VideoNinja",
    "tagline": "focus on your content, let ai take care of the rest!",
    "hackathon": "",
    "built_with": [
      "chatgpt",
      "deepgram",
      "ffmpeg",
      "git",
      "gpt-3",
      "javascript",
      "node.js",
      "openai",
      "render",
      "velo",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "HackForCreatorsWinnerBest Use of Velo by Wix",
      "Winner",
      "I worked on the frontend. It was my first time using Velo by Wix, but it was really fun and I learned a lot!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/407/820/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 ✨ Inspiration ✨ We wanted to develop something that would genuinely benefit creators by addressing their challenges and enabling them to create exceptional content with ease. We spoke to a friend who has roughly 2,000 subscribers on her YouTube channel, and she shared that she spends a significant amount of time and effort transcribing her videos, making subtitles/closed captions, creating video titles, descriptions, and hashtags, and promoting her videos on social media after making them. We wanted to help solve this problem. Thus, we created VideoNinja - a tool that simplifies the process for creators so that they can concentrate on doing what they do best - creating fantastic content. ❓What it does❓ VideoNinja is an empowering tool for creators of video content. Using the web application is a breeze: simply log in and input your video's link. In a matter of seconds, the application transcribes your video and generates closed captions, which can be uploaded as a txt file to YouTube. \nAdditionally, VideoNinja suggests catchy and compelling titles to save you the trouble of thinking them up yourself. While coming up with a description for your video and selecting effective hashtags for the YouTube algorithm can be a daunting task, VideoNinja takes the reins and recommends the best hashtags for your video to maximize its chances of going viral. 🏗️ How we built it 🏗️ Our lofty goal was to make significant progress in a short amount of time, and we had to move fast this weekend. To achieve this, we turned to Velo by Wix. Within a matter of hours, we utilized the platform's capabilities to design a stunning UI for our web app. Our innovation didn't stop there. We took advantage of Deepgram's transcription service and used it to build our own API that downloads the video from the link you provide as an MP3 file through ffmpeg. It is then transcribed using Deepgram's technology, and the result is a closed caption file that can be readily uploaded to YouTube. Anoth"
      }
    ]
  },
  {
    "file_path": "./devposts/village-volunteer.html",
    "project_id": "village-volunteer",
    "title": "Village Volunteer",
    "tagline": "We aim to help the elderly or disabled in particular to provide them a platform to find others that can help them do things from everyday chores to specific errands.",
    "hackathon": "",
    "built_with": [
      "figma",
      "storekit",
      "swift",
      "swiftui",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/188/453/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "💡 Inspiration💡 With many global cities having increasingly ageing populations, and more and more youth looking for volunteering opportunities, we’re using technology to build communities and connect volunteers to the elderly who could use their assistance. By creating a platform that’s easily accessible and builds on existing physical communities, we make volunteering and altruism easier and more effective. Please visit our put-together slides to learn more about the statistics of why this problem needs to be addressed and the inspirations behind the project. To follow our figma tutorial, follow this link with our Figma prototype . It takes around 45 seconds. ⚙️ What it does ⚙️ Elderly can post tasks and find volunteers to request their help. \nAlternatively, volunteers can find chores near them. When a volunteer matches with a chore-giver, or vice-versa, the chore-giver will receive a text notification outside of the app. \nElderly can approve volunteers to help with selected chores and can contact them directly. \nVolunteers can give Chore-givers $1 tips for volunteering to complete chores. \nSocial media discussions on each chore\nIn-progress: finding volunteers and chores on a map view 🏗️ How we built it 🏗️ Our mobile app implementation was created using SwiftUI and Swift (data was stored in Swift’s default data store). We used Twilio to implement text messages as notifications whenever a volunteer is matched with a chore. Our Figma project was created using Figma. 🚩 Challenges we ran into One of our team members had little experience with Figma, so it took some time for them to learn it and start working on the Figma prototype. Furthermore, our mobile app was not able to fully reflect the Figma prototype; however, we turned this to our advantage, making the Figma prototype mobile app a supplementary addition to the project instead of simply it’s blueprint. 🥇 Accomplishments that we're proud of We were really proud to be able to replicate in-app transactions using St"
      }
    ]
  },
  {
    "file_path": "./devposts/verisage.html",
    "project_id": "verisage",
    "title": "VeriSage",
    "tagline": "Certifying Truth in Every Byte 🧐📜",
    "hackathon": "",
    "built_with": [
      "api",
      "hedera",
      "infura",
      "love",
      "next",
      "react",
      "security",
      "shadcn",
      "tailwind",
      "web3"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Use of Hedera\" category, setting new standards for document verification systems and underscoring t",
      "Best Use of Hedera Created by Designed & Developed UI Devesh Meena Pratyay Banerjee I share memes m",
      "Web3AppsWinnerBest Use of Hedera",
      "🌟 Best Use of Hedera",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/642/203/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 🚀 Inspiration The inspiration behind VeriSage emerged from the pressing challenges and inefficiencies within the current document verification procedures. Companies and universities continually grapple with the authenticity of certificates due to the error-prone nature of manual verification. These traditional methods make it difficult to differentiate between legitimate and counterfeit documents. VeriSage is developed with the vision of revolutionizing this process, offering a solution that is not only efficient but also secure. It's driven by the belief that blockchain technology can provide a reliable, streamlined, and convenient means of verifying documents, mitigating the concerns surrounding legitimacy. 🔍 What it does VeriSage is a pioneering blockchain-based document verification system. It caters to the needs of students, educational institutions, and document verifiers. Students have the convenience of requesting certified documents from educational institutions securely. These institutions, in turn, can confidently certify and upload these documents to the blockchain, thus making them tamper-proof and easily accessible. Verifiers, such as employers or other institutions, can seamlessly authenticate documents to ensure their legitimacy. 🔧  How we built it VeriSage was meticulously crafted through a fusion of cutting-edge technologies. It incorporates API integration for enhanced functionality, employs Hedera Blockchain to provide a robust, secure, and efficient blockchain infrastructure, utilizes React for the frontend to ensure a user-friendly and responsive web interface, and leverages Infura for backend services. The system is powered by smart contract functionality, which is integral to the document certification and verification process. Moreover, stringent security measures have been meticulously implemented to guarantee the integrity and confidentiality of documents. 🌟 Best Use of Hedera VeriSage's is a testament to how Hedera Blockch"
      }
    ]
  },
  {
    "file_path": "./devposts/vino-arm04g.html",
    "project_id": "vino-arm04g",
    "title": "Vino",
    "tagline": "Meet. Play. Chat.",
    "hackathon": "",
    "built_with": [
      "express.js",
      "figma",
      "mongodb",
      "node.js",
      "react",
      "react-bootstrap",
      "socket.io"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/351/302/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Log in page Log in page 1 2 3 4 5 6 7 8 9 Inspiration Our team's mission was to make the dating experience smooth, fun and real. The dating experience has been incrementally difficult while we are all stuck in our houses because of the Corona Virus. We wanted to introduce a sense of real closeness amongst our users by introducing a trivia-based dating app. Inspired by New York Time's article, 36 questions to fall in Love. The idea is that mutual vulnerability fosters closeness. To quote the study’s authors, “One key pattern associated with the development of a close relationship among peers is sustained, escalating, reciprocal, personal self-disclosure.” Allowing oneself to be vulnerable with another person can be exceedingly difficult, so this exercise forces the issue. What it does Vino is an online trivia-based dating application. Each user anonymously paired with another user taking into factor their preferred age and gender they would like to be matched up with. Each user then is required to answer trivia questions and also answer their assumptions about other person's choices. Based on the answers by each user the algorithm decides it is a match or not. How we built it We began by using Figma to create our user flow and design our project. We built a back-end node server with Express and using MongoDB as our database, and we built the front-end with React. We used WebSockets (through Socket.io) to open connections between the client and server Challenges we ran into Some challenges we ran into include connecting the Socker.io Node.js back-end with the React.js front-end. We also had difficulties with implementing the timed transition screens using React. Accomplishments that we are proud of We are proud of our stellar design. Three of our team members had never used to React before, we managed to make a working application using React. Working and communicating virtually through the whole period of the online hackathon was one of the accomplishments we are mos"
      }
    ]
  },
  {
    "file_path": "./devposts/visionify.html",
    "project_id": "visionify",
    "title": "Visionify",
    "tagline": "A proactive real-time AI wearable that helps the visually impaired navigate safely—at a price under $100, making smart mobility finally accessible to all.",
    "hackathon": "",
    "built_with": [
      "gemini",
      "hardware",
      "langchain",
      "next.js",
      "opencv",
      "python",
      "tailwindcss",
      "tensorflow",
      "unify",
      "vapi"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "aspects of Waymo’s real-time obstacle detection with the precise location tracking features of Life",
      "InspectMind: Most Efficiency Improvements Award Created by Betool Mohsen Sapana Dhakal Prajwal Shar",
      "UC Berkeley AI Hackathon 2025WinnerInspectMind: Most Efficiency Improvements Award",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/499/096/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "3 dashboard 2 3 dashboard 2 3 1 2 3 4 Inspiration 🤔 Have you ever considered how visually impaired people navigate everyday dangers? Crossing busy roads, avoiding potholes, or noticing imminent hazards like moving vehicles can be incredibly risky. Consider these staggering statistics: Approximately 253 million people globally have a form of visual impairment; around 36 million are completely blind. [WHO Source] 40% of visually impaired individuals report frequent collisions or accidents when navigating daily. [VisionAware Source] Blind pedestrians are nearly twice as likely to be involved in accidents or injuries related to road navigation. [Journal of Visual Impairment & Blindness Source] Driven by these realities, we developed visionify. What it does + How we built it 🛠️ Visionify is an advanced wearable that combines the best aspects of Waymo’s real-time obstacle detection with the precise location tracking features of Life360, tailored specifically for the visually impaired community. At its core, Visionify provides continuous, real-time spatial awareness using advanced sensor fusion - Camera, accelerometer, Ultrasonics sensor and GPS module. A Raspberry Pi serves as our onboard computing platform, integrating sensor data from a camera, ultrasonic sensor, microphone, and ADXL345 accelerometer. We developed a three-tier intelligent safety system: Local Guardian: Instant (<50ms) detection and alert for critical dangers such as sudden obstacles, falls, or collisions, providing immediate haptic and audio feedback. VAPI AI phone calls: When it detects any unusual activity like a fall of the person through our accelerometer sensor, our voice AI agent automatically calls the emergency contacts of the person. Cloud Intelligence: Utilizing powerful cloud-based AI via REST APIs, we employ Gemini Vision and GPT-4 Turbo for detailed scene description, obstacle classification, and intelligent route guidance. Natural Interaction: Leveraging ElevenLabs VAPI for seamless and na"
      }
    ]
  },
  {
    "file_path": "./devposts/video-summarizer-z3rtwc.html",
    "project_id": "video-summarizer-z3rtwc",
    "title": "Brevify: Video Summarizer",
    "tagline": "Don’t have time to watch the whole video?  Brevify can create a text summary of your video, so you can get the information easily and efficiently.  Learn the key information and concepts instantly!",
    "hackathon": "",
    "built_with": [
      "ai",
      "ajax",
      "assemblyai",
      "canva",
      "css",
      "express.js",
      "html",
      "javascript",
      "jquery",
      "node.js",
      "replit",
      "tailwind",
      "tailwindcss",
      "web"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/203/590/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Data Flow Diagram Home Page User Upload Video Transcription Video Sections and Summary Data Flow Diagram Home Page User Upload Video Transcription Video Sections and Summary Data Flow Diagram 1 2 3 4 5 6 Inspiration Videos on YouTube are getting longer and longer over time - back then, youtubers get straight to the point but now they feel a need to have long intros, outros, and ad breaks, which keep the viewer from getting the information they want. In addition, as our lives are getting busier and busier in this modern, technological world, we simply don’t have the time to watch a full YouTube video for homework or for studying to understand the material. Our audience involves both student learners (K-12 and college) and adult learners. As Machine Learning enthusiasts, we wanted to find and use an AI or ML model to help solve this problem. What it does Brevify is a web app that ensures that all users, including students and adult learners alike, can always have a platform to enhance their learning by summarizing video content in a quick and convenient way.  The user can upload a video file of their choosing, and AI algorithms will then transcribe and summarize it into easily digestible sections. Brevify can be used at any time, every day. Brevify has 3 pages: the home page/demo page, about page, and contact page. The Home page is where the user can try out our video summarizer. The About page describes the motivation behind us creating Brevify, contains a data flow diagram, and gives instructions on how to use Brevify, which is very simple. The Contact page is there in case users have questions/suggestions and we have also included our email and social media icons in case users want to follow our updates. Brevify has two main functionalities: extracting the full video transcription and extracting short chapter summaries, which can be used to find specific concepts and/or retrieve the main points. After a user chooses a video of any length and format (such as .mp4) t"
      }
    ]
  },
  {
    "file_path": "./devposts/virality-pro.html",
    "project_id": "virality-pro",
    "title": "Virality Pro",
    "tagline": "Lower content production costs by 95% using our AI-assisted marketing system that will take care of your viral social media growth",
    "hackathon": "",
    "built_with": [
      "capcut",
      "dalle",
      "ffmpeg",
      "openai",
      "python",
      "reflex",
      "shopify"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "of the best, including Stanford CS/Math experts with Jane Street experience, founders with multiple",
      "Shoutout from Ddoski: 3rd Overall Created by DALL-E integration ffmpeg magic async magic Nils André",
      "Cal Hacks 10.0WinnerShoutout from Ddoski: 3rd Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/645/617/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Fully-Automated System In Production AI generated graphics Semi-Automed System: Dozen viral videos built for client Semi-Automed System: Dozen viral videos built for client Semi-Automated Video production Fully-Automated System In Production AI generated graphics Semi-Automed System: Dozen viral videos built for client Semi-Automed System: Dozen viral videos built for client Semi-Automated Video production Fully-Automated System In Production 1 2 3 4 5 Virality Pro: 95% reduced content production costs, 2.5x rate of going viral, 4 high ticket clients We’re already helping companies go viral on instagram & TikTok, slash the need for large ad spend, and propel unparalleled growth at a 20x lower price. The problem: growing a company is HARD and EXPENSIVE Here are the current ways companies grow reliably: Facebook ads / Google Ads : Expensive Paid Ads\nProducing ads often cost $2K - $10K+\nCustomer acquisition cost on Facebook can be as much as $100+, with clicks being as high as $10 on google ads\nSimply untenable for lower-ticket products Organic Social Media : Slow growth\nTakes a long time and can be unreliable; some brands just cannot grow\nContent production, posting, and effective social media management is expensive\nLow engagement rates even at 100K+ followers, and hard to stay consistent Solution: Going viral with Virality Pro, Complete Done-For-You Viral Marketing Brands and startups need the potential for explosive growth without needing to spend $5K+ on marketing agencies, $20K+ on ad spend, and getting a headache hiring and managing middle management. We take care of everything so that you just give us your company name and product, and we manage everything from there. The solution: viral social media content at scale . Using our AI-assisted system, we can produce content following the form of proven viral videos at scale for brands to enable consistent posting with rapid growth. Other brands: Spends $5K to produce an ad, $20K on ad spend. They have extremely th"
      }
    ]
  },
  {
    "file_path": "./devposts/visionaid-cv.html",
    "project_id": "visionaid-cv",
    "title": "VisionAid CV",
    "tagline": "Personal Agent for Daily Convenience",
    "hackathon": "",
    "built_with": [
      "css",
      "flask",
      "google-cloud",
      "groq",
      "html",
      "llama",
      "openai",
      "opencv",
      "python",
      "spotipy"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/836/908/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Personal Agent for Daily Convenience Inspiration Every year, we have witnessed how new technology has impacted senior citizens in their daily lives. As technology becomes more and more advanced, we began to realize that it is becoming much harder for senior citizens to use the technology that is put in front of them. Recognizing this pressing issue, we set out to create a project aimed at simplifying technology for users of all ages through an intuitive platform designed to streamline access to the digital world. What it does Our project is a personal agent which can do daily tasks which might be technologically complex for senior citizens. We wanted to make it as easy as possible for users to do daily tasks such as sending a text message, or an email, through a personal agent which takes voice requests, and prompts a vocal response back. The agent processes the request and sends the request to the python tools that we developed through index. Once the request is through, the agent is able to do a variety of tasks. It can recommend music, youtube videos, send texts and emails, and answer any potential questions the user has. How we built it Our project was built using python for the backend and HTML/CSS for the frontend. The code first takes a voice request and converts the speech to text. Then, the code uses artificial intelligence to interpret the user's request and determine which tool should be used to respond and support the user. Once the tool is declared, the tool completes the user request and then prompts the next request. The frontend and UI was coded entirely using HTML and CSS. Challenges we ran into The main challenge we faced when developing the program was getting the live camera to display on the website. Some other challenges we faced included some code errors, finding API's which were free of cost, and setting up the vector database. Despite these challenges, we were able to overcome our problems and develop our project. Accomplishments that we're "
      }
    ]
  },
  {
    "file_path": "./devposts/virtual-study-rooms.html",
    "project_id": "virtual-study-rooms",
    "title": "Virtual Study Rooms",
    "tagline": "This application is targeted towards students to collaborate with each other in an efficient manner",
    "hackathon": "",
    "built_with": [
      "bulma-css",
      "coil",
      "express.js",
      "firebase",
      "google",
      "html",
      "javascript",
      "node.js",
      "oauth",
      "svelte",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Web Monetization Hack Winner Most Creative Use of Twilio Created by I worked on the frontend and ba",
      "2nd Place Prize Winner Best Web Monetization Hack Winner Most Creative Use of Twilio Created by I w",
      "Winner Best Web Monetization Hack Winner Most Creative Use of Twilio Created by I worked on the fro",
      "OneHacks IIWinner2nd Place PrizeWinnerBest Web Monetization HackWinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/005/633/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Virtual Study Rooms Virtual Study Rooms Virtual Study Rooms 1 2 Inspiration 💡 From personal experience and from experience of others we saw a lot of people having trouble managing their time and collaborating efficiently with others because they did not have the tools they needed to do so, we took an inspiration from that problem to find a solution for it and came up with this to solve that problem in our own way What it does ⚙️ Virtual Study Rooms is a productivity application focused on helping the end user easily collaborate with others and have a simple application for everything they could need, pomodoro timer, lo-fi music player, to-do lists, live updating chat, twilio for SMS inviting people to use the application. It works the same on mobile as it does on your computer! How we built it ⚒️ We built it using Svelte as the framework, Node.js for backend, Express.js for our Twilio API Wrapper, Bulma CSS and HTML for frontend Challenges we ran into ❌ We had to adopt a lot of new technology, basically everything in our tech stack was new to most of us so it was a challenge, but in the end we figured everything out after hours of errors we couldn't solve and a lot of thinking. Accomplishments that we're proud of 😊 How the final website turned out, we like how the site is as functional as we originally expected it to be.\nWe are proud that we had fun in the process and we met each other and we will work together outside of this hackathon! What we learned 👨‍🔬 Learned how to use firebase, netlify (for hosting), svelte as a web framework, express.js, heroku (hosting our twilio API) and better communication skills What's next for Virtual Study Rooms ⏭️ We would like to rewrite virtual study rooms in React to meet industry standards, make the website more colorful and design it a bit better, advertise it to people and hope it is used for it's original purpose! Built With bulma-css coil express.js firebase google html javascript node.js oauth svelte twilio Try it out virtu"
      }
    ]
  },
  {
    "file_path": "./devposts/visionaid.html",
    "project_id": "visionaid",
    "title": "VisionAID",
    "tagline": "VisionAid: Enhancing mobility for Calgary's visually impaired",
    "hackathon": "",
    "built_with": [
      "calgary-open-database",
      "gemini",
      "google-cloud-speech-to-text",
      "opencv",
      "python",
      "pytorch",
      "raspberry-pi",
      "tensorflow",
      "text-to-speech",
      "web-rtc"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Tier 1 - Second Place Created by Atharva Naik Pratyay Banerjee I share memes more than I code :p //",
      "CalgaryHacks 2024WinnerTier 1 - Second Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/777/268/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF VisionAid GIF VisionAid 1 2 3 Inspiration  💡 As we navigate the vibrant city of Calgary, with its extensive transportation network including C-trains, buses, and cabs, we often take for granted the ease of moving from one locale to another. However, for individuals with disabilities, particularly those who are visually impaired, the story is quite different. Imagine, in a city as developed as ours, 69% of the signals are not accessible to disabled people. This stark number sheds light on a significant accessibility gap that exists for nearly 60,000 visually impaired residents of Calgary, making even the simple act of walking a challenge. How We Built It  ⚙️ We built VisionAID to simplify city exploration for the visually impaired by integrating three key functionalities: Navigation, Collision Detection, and Contextual Analysis. Our approach harnesses data from a head-mounted device equipped with a Raspberry Pi as the main processor, 2 ultrasonic sensors, and a camera for image capture. For navigation, we leverage Calgary's Open Data sets, including live transit routes, signals map, and crime statistics, along with Google Maps for precise directions. Collision detection is achieved through ultrasonic sensors and computer vision using OpenCV to identify nearby obstacles. To understand context, we utilize OpenAI's Vision APIs. Finally, the device converts all textual data into speech in real-time using Amazon Polly (Boto3), ensuring accessibility for users. Conceptualization and Planning 📝 The project kicked off with an intensive conceptualization phase. Our team gathered to brainstorm the needs of visually impaired users and how technology could address these needs effectively. We identified key user cases that our project should cater to, such as navigating busy streets, identifying obstacles, and understanding the immediate environment through auditory feedback. Understanding the constraints of a 24-hour development deadline, we scoped the project to ensure feas"
      }
    ]
  },
  {
    "file_path": "./devposts/visionguard-smart-vision-for-smarter-driving.html",
    "project_id": "visionguard-smart-vision-for-smarter-driving",
    "title": "VisionGuard: smart vision for smarter driving",
    "tagline": "Our AI-powered system analyzes in-car video footage to transcribe and interpret driver behavior in real time. By detecting safe/unsafe actions, we provide actionable insights to improve road safety.",
    "hackathon": "",
    "built_with": [
      "apis",
      "colab",
      "gpt",
      "python",
      "reinforcement",
      "vscode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Tesla: Excellence Prize ($2k Tesla Store Gift Card [1st], $1k Gift Card [2nd], $1k Gift Card [3rd])",
      "Autonomy Grand Prize (6-months use of a Tesla Model 3 or Y w/ Supervised FSD) Created by julia huan",
      "($2k Tesla Store Gift Card [1st], $1k Gift Card [2nd], $1k Gift Card [3rd]) Winner Autonomy Grand P",
      "(6-months use of a Tesla Model 3 or Y w/ Supervised FSD) Created by julia huang hackathon enthusias",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/269/298/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Driving in extreme conditions like icy roads and blizzards often leads to accidents due to poor visibility or slippery surfaces . Having personally experienced car accidents caused by vehicles losing control on ice, it’s clear how critical it is to ensure that drivers are cautious and aware. Similarly, my teammates from the crowded Bay Area face challenges with complex road systems and traffic , where crashes are just as frequent. This inspired us to develop VisionGuard , a system that leverages AI to analyze driver behavior and road conditions , ultimately helping drivers make safer decisions. Our goal is to build smarter driving tools that reduce accidents and save lives . What It Does VisionGuard leverages cutting-edge Vision-Language Models (VLMs) to analyze in-car video footage , transcribing and interpreting driver behavior with high precision. By detecting both safe and unsafe actions , VisionGuard generates actionable insights to encourage safer driving practices. Our system identifies critical situations such as: ✅ Distracted driving (e.g., phone use, drowsiness). ✅ Reckless maneuvers (e.g., sudden lane changes, aggressive driving). ✅ Hazardous environmental conditions (e.g., low visibility, icy roads). While we aimed for real-time inference , we found that current VLM models are too computationally expensive for low-latency performance . However, through optimizations, we significantly improved processing efficiency and benchmark accuracy , making this approach feasible for future deployment . Beyond individual drivers, VisionGuard’s insights can benefit: Insurance companies – Enhancing risk assessments and reducing fraud. Fleet managers – Monitoring driver behavior for safety compliance. Autonomous vehicle systems – Providing explainability layers for AI-driven decisions. Our AI-driven approach aims to make roads safer at scale . How We Built It Computer Vision Framework We leveraged state-of-the-art Vision-Language Models (VLMs) , including G"
      }
    ]
  },
  {
    "file_path": "./devposts/volnet-volunteer-networking-app.html",
    "project_id": "volnet-volunteer-networking-app",
    "title": "Volnet: Volunteer Networking App",
    "tagline": "Volnet is a centralized volunteer networking app similar to LinkedIn & meetups that allows non-profits and clubs to share events and volunteers and youths to find community service opportunities.",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Our duo came from strong leadership backgrounds in volunteering with Hanah Shih holding a position on the Key Club District Board and Cecilia Pham as the president of Interact Club. Through our experiences, we found it difficult to find volunteer opportunities for our combined 350+ club members. We realized that there was no specific platform that addressed this issue, which inspired us to create Volnet as a way to find these opportunities easily and allow for larger-scale volunteering projects. What it does Volnet is a centralized volunteer networking platform, allowing users to find and discover new volunteering events nearby and sign up for them. Nonprofit Organizations, charities, and clubs post these events on the Volnet app, to find volunteers for their events, which otherwise may not have enough available workers. These go on the events and explore page where volunteers can find these opportunities, save them, and attend these events. How we built it We created a prototype of the app using Figma. Challenges we ran into Although we had our winning idea, we struggled to execute our ideas since we have limited knowledge in ios and android app development as beginning hackers. However, after attending the \"Intro to Prototyping\" webinar, we learned about Figma and how to use it to showcase what our app would look like and its functionality. Since Figma was so user-friendly, we were able to create the prototype of Volnet. Accomplishments that we're proud of We are proud of creating a functional demo and prototype of Volnet and bringing it to fruition. We are also proud of the user interface and design of the app, and how our idea of Volnet has the potential to become the next social good networking platform for youths and in local communities. What we learned Throughout this weekend, we learned about all the different programs and resources that are available for beginners and ones that allow us to collaborate. We learned how to create a functional prot"
      }
    ]
  },
  {
    "file_path": "./devposts/vly-ai-the-bubble-io-killer.html",
    "project_id": "vly-ai-the-bubble-io-killer",
    "title": "vly.ai: the bubble.io killer",
    "tagline": "Generate Full-Stack SaaS Apps with just 1 click using AI.",
    "hackathon": "",
    "built_with": [
      "gpt",
      "javascript",
      "openai",
      "python",
      "reflex",
      "tailwind",
      "vly"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "use of AI Agents / AI project, best use of Reflex, most viable startup / most commercially viable s",
      "TreeHacks 2024WinnerReflex: Best Use of Reflex ($2k Cash)",
      "built by stanford, berkeley, uw cs students. majority first hackathon project (beginner hack)",
      "Tracking hours",
      "POS and inventory tracking",
      "All potential prize money will go towards funding this project and the extension.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/775/579/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Generated Database schemas Generated Hero Image designed to replicate reflex.dev the .vly programming language that uses natural english We use an AI Agent system Use of generated authentication system Support for different integrations in a growing library Generated Database schemas Generated Hero Image designed to replicate reflex.dev the .vly programming language that uses natural english We use an AI Agent system Use of generated authentication system Support for different integrations in a growing library Generated Database schemas 1 2 3 4 5 6 vly.ai: generating full-stack SaaS applications in just 1 click We generate full-stack web apps optimized for SaaS use cases (front end, back end, integrations such as stripe, email, texting, and more) completely using AI, without the need for any programming knowledge. going for: best use of AI Agents / AI project, best use of Reflex, most viable startup / most commercially viable startup (YC, pear, etc) This is a no-code system that converts our very own natural language programming framework into full-stack reflex-based code, allowing us to achieve unparallel performance from raw code without the tradeoffs of a no-code system. This means unlimited flexibility and scalability on enterprise-grade software all generated using AI. We quite literally replace the need to hire a web developer. built by stanford, berkeley, uw cs students. majority first hackathon project (beginner hack) THE PROBLEM: Building a SaaS web application is hard. If you were trying to build one, here are your options: Hiring a developer or agency: \na. $10,000-$100,000, 2-6 months\nb. Expensive to iterate, prone to miscommunication Developing an app on your own: \na. Free + Software costs, 2-12 months\nb. Requires significant amounts of personal time, not many people can do it Using a no-code tool like bubble.io:\na. Free + Software costs, 1-6 months\nb. Highly restrictive and limited, and learning curve requiring lots of time Hiring a no-code developer or"
      }
    ]
  },
  {
    "file_path": "./devposts/vocalai.html",
    "project_id": "vocalai",
    "title": "VocalAI",
    "tagline": "Improve your singing abilities anywhere, anytime",
    "hackathon": "",
    "built_with": [
      "figma",
      "javascript",
      "json",
      "mongodb",
      "python",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Game Hack Created by I worked on the front end, worked with API’s to provide access to songs and LR",
      "Best Game Hack Created by I worked on the front end, worked with API’s to provide access to songs a",
      "JAMHacks 7WinnerBest Game Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/507/975/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration Whether you're hanging out with friends, feeling bored at home, or on a long car ride -- singing is often something we find ourselves reaching to. One of the members of our team (Fiona) really enjoys singing and so we thought it would be a nice idea to look into how she can sound better so that she, and everyone else around her can better enjoy her voice. We wanted to create a tool that allows singers to practice anywhere, with real time advice. Vocal lessons are often very expensive and being able to take these lessons and sing is often viewed as a privilege. Hence, to dispel all these beliefs and help everyone like Fiona improve their singing, we've created VocalAI -- an artificial-intelligence based software that can generate you a karaoke version of any song provide you real time feedback of your singing. What it does VocalAI, our innovative platform, offers two key features that aim to enhance your singing experience. With VocalAI, you can enjoy the convenience of transforming any song into a personalized karaoke track. Whether you're practicing your favorite tunes or planning to perform them, VocalAI seamlessly creates high-quality karaoke versions that align perfectly with the original compositions. In addition to karaoke creation, VocalAI incorporates advanced speech recognition technology to ensure you're singing the right words. Our powerful speech recognition algorithms analyze your vocal delivery and compare it to the original lyrics, providing real-time feedback and guidance to ensure accurate pronunciation and word alignment. This feature helps you develop proper diction and ensures that your performance stays true to the original song. Furthermore, VocalAI includes a valuable scoring system designed to evaluate your pitch accuracy while singing. By analyzing your vocal performance, our intelligent algorithms provide constructive feedback and precise scoring based on your pitch accuracy. This feature allows you to track your progress ov"
      }
    ]
  },
  {
    "file_path": "./devposts/vow-3wngqj.html",
    "project_id": "vow-3wngqj",
    "title": "VOW- transforming multi-agent transactions",
    "tagline": "VOW is a Verified Operations Wrapper—an intelligence broker layer that acts like space police for AI agents, enforcing trust, verifying incentives, and mediating value exchanges beyond money.",
    "hackathon": "",
    "built_with": [
      "anthropic",
      "letta",
      "nextjs"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/499/958/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "VOW Visual Flow Traditional Agent Relationships VOW Agent Flow diagram Session Work Flow VOW AGENT FLOW DATA VOW Conversation Flow Broker Agent VOW agents webpage VOW Landing VOW Visual Flow Traditional Agent Relationships VOW Agent Flow diagram Session Work Flow VOW AGENT FLOW DATA VOW Conversation Flow Broker Agent VOW agents webpage VOW Landing VOW Visual Flow 1 2 3 4 5 6 7 8 9 10 💡 Inspiration Before money, humans exchanged value through barter —trading goods, services, and trust. We wondered: What does bartering look like in an agentic world? In a future full of autonomous AI agents, value shouldn't just mean dollars. It could mean data, promises, insight, or cooperation. VOW was born to explore that idea. ⚙️ What It Does VOW (Verified Operations Wrapper) is an incentive-based broker system —a kind of “space police” for AI agents. It mediates the flow of interactions between client agents (users or other AIs) and service agents (like a fitness recommender or assistant). But instead of just routing requests, it evaluates offers , checks trustworthiness , and enforces value-for-value exchanges . Think of it as a marketplace for agent interactions , where what you give (data, behavior, insight) unlocks what you get. 🛠 How We Built It We used Letta to create a multi-agent architecture with: Client Agents – who request services and offer some kind value in return Service Agents – who provide services (e.g., answers, workouts) and accept some value Broker Agents – who govern the exchange, decide if terms are fair, and track fulfillment Letta's stateful memory made it easier to simulate long-running agent interactions and implement enforcement logic like “did the user actually follow through?” 🧱 Challenges We Ran Into Letta was powerful but tricky. We hit some wild bugs—at one point, our agents entered a strange loop, the \" Doom Protocol \", where they achieved singularity and just started going off infinitely at each other. Debugging multi-agent conversations with sta"
      }
    ]
  },
  {
    "file_path": "./devposts/vmod.html",
    "project_id": "vmod",
    "title": "VMod",
    "tagline": "This small program will check for the 'bad words' in the given audio to save you from trouble!",
    "hackathon": "",
    "built_with": [
      "assembly",
      "python",
      "sightengine"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/024/524/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "What it does Helps you in moderating the audio that you gave as an input! How we built it Using the Assembly API and SightEngine API and some basic python functions! Challenges we ran into Dealing with some of the API's was hard!! It took soo much time to get ahead of just integrating the API's!! Accomplishments that we're proud of Finally made a working prototype of the program despite of the troubles with the API!! What we learned How to use different API's (Assembly API and SightEngine API) What's next for VMod A nice interface and fast running API's to work with! Built With assembly python sightengine Try it out GitHub Repo Submitted to Global Hack Week: INIT 2023 Day 1 Global Hack Week: INIT 2023 Day 5 Created by Kalash Jain"
      }
    ]
  },
  {
    "file_path": "./devposts/visualearn.html",
    "project_id": "visualearn",
    "title": "VisuaLearn",
    "tagline": "AI chat bot that makes digital literacy easy.",
    "hackathon": "",
    "built_with": [
      "electron",
      "gemini",
      "react",
      "tailwindcss",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/330/658/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Settings page Asking VisuaLearn how to perform computer tasks VisuaLearn always on top overlay feature Settings page Asking VisuaLearn how to perform computer tasks VisuaLearn always on top overlay feature Settings page 1 2 3 Problem Statement As our world grew to embrace technology, digital literacy skills have become crucial for living in our modern society. Being able to navigate research tools, financial platforms, social platforms and function effectively in a modern workplace is a must have skill. However, not all communities share this level of digital literacy. Lack of high speed internet in many communities has caused people living there to have lower tech skills. The lack of infrastructure in communities is a consequence of centuries of social division and redlining, which is further exacerbating the social and economic disadvantages in society (source). This is also a large issue for those who are older, who didn't grow up with technology and are struggling to navigate it today. As a result, there is a clear gap in the world for ways to teach people how to use technology in a way that is non-intrusive to a full-time worker. The goal of this project is to meet the need for an intuitive, accessible and simple to use tool that aids people with technology use. To be feasibly implemented, the project is scoped to be a computer program, to make it easy for us to develop and distribute. What it does VisuaLearn is a desktop application that leverages Google's Gemini AI to provide a powerful chat interface with both text and image capabilities. The application allows users to interact with Gemini using text messages, upload images for analysis, and even capture screenshots directly within the app. How we built it VisuaLearn is an Electron app with a React + Typescript + TailwindCSS frontend, built using Vite tooling. It uses Google Gemini API for the chatbot interactions. Challenges we ran into The biggest challenge was navigating unfamiliar frameworks and tools, "
      }
    ]
  },
  {
    "file_path": "./devposts/volunteer-management-system-0ik3yu.html",
    "project_id": "volunteer-management-system-0ik3yu",
    "title": "Volunteer Management System",
    "tagline": "Empower, Engage, and Evaluate: Revolutionizing Volunteerism, Your Complete Volunteer Management Solution.",
    "hackathon": "",
    "built_with": [
      "dart",
      "firebase",
      "flutter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/759/142/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Sign Up page Request for a Certificate Page Add event Manage Volunteers Page Reports Generation Page Certificate generated Volunteer Profile Page Log In page Sign Up page Request for a Certificate Page Add event Manage Volunteers Page Reports Generation Page Certificate generated Volunteer Profile Page Log In page Sign Up page 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 Project Title: Volunteer Management System (VMS) Inspiration The inspiration behind the Volunteer Management System (VMS) stemmed from witnessing the challenges organizations face in managing volunteer activities efficiently. From cumbersome manual tracking to the lack of a centralized system for volunteer engagement, the need for a streamlined solution was evident. Our goal was to create a platform that not only simplifies the management process but also enhances the volunteering experience for both organizers and volunteers. What We Learned Throughout the development of VMS, we delved deep into the world of Flutter and Dart, exploring their capabilities in creating robust and user-friendly mobile applications. We learned about handling asynchronous operations for network requests, implementing secure authentication mechanisms, and creating dynamic user interfaces that adjust to various screen sizes and orientations. Additionally, we gained insights into effective project management and collaboration techniques, ensuring that our development process was both efficient and inclusive. How We Built It VMS was built using Flutter, enabling us to deploy a cross-platform application that operates seamlessly on both iOS and Android devices. The backend infrastructure relies on Firebase for handling user authentication, data storage, and real-time updates, ensuring that information is synchronized across all users. Key features of the VMS include: Dashboard : A comprehensive overview for volunteers and admins, displaying upcoming activities, registrations, and key metrics. Event Man"
      }
    ]
  },
  {
    "file_path": "./devposts/wakeme-app.html",
    "project_id": "wakeme-app",
    "title": "WakeMe App",
    "tagline": "Make waking up fun.",
    "hackathon": "",
    "built_with": [
      "figma"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/446/535/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 Inspiration As college students, not having a sleep schedule is not unheard of. Needing to tough out through some working days due from studying until late for exams, completing projects and balancing with extracurriculars for 3-4 hours of sleep is unfortunately quite an acceptable norm, and sometimes our sheer willpower is not enough to hop out of the bed. By gamifying and socializing the process of waking up through our app, we hope to make it an exciting part of the day, rather than just a dreadful chore. Adding a little spice to the process along with your friends will hopefully help set a more energetic tone and give them the extra push of motivation to conquer the day ahead. What it does This app allows each person to join friend circles using codes. These friend circles are the basis of what allows people to choose songs for each other to wake up to.\nEach day before midnight everyone in a particular circle would be assigned a random friend in the same circle to choose a song for the next day that they will wake up to and a challenge that they would have to complete in order to stop the song when they do wake up.\nThe next morning, based on the time of the person’s alarm, the song that was chosen by another friend would play until the person completes the challenge that was set by them. This would enforce that the person is woken up by the time they do complete the challenge. They would also have an opportunity to post a picture of their morning activity within 3 hours of waking up, which will give them bonus points. Ranking of friends will be based on their scores, which is determined by how fast they complete their morning challenge and whether they do perform other optional challenges. How we built it We used Figma to create a vision for how we’d want our app to look like, and the features we’d want to include to help gamify the process of waking up. Choosing a bright color scheme was key to set the tone for motivating someone to get out of their bed. "
      }
    ]
  },
  {
    "file_path": "./devposts/vsibl.html",
    "project_id": "vsibl",
    "title": "VSiBL",
    "tagline": "A social augmented reality (AR) platform for spatial communication.",
    "hackathon": "",
    "built_with": [
      "arkit",
      "c#",
      "ios",
      "microsoft-hololens",
      "unity",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Application of Data Visualization Winner Everyday XR Created by For this project I worked on experi",
      "Best Application of Data Visualization Winner Everyday XR Created by For this project I worked on e",
      "MIT Reality Hack 2020WinnerBest Application of Data VisualizationWinnerEveryday XR",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/911/443/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 Inspiration The team formation process at this hackathon posed a challenge for us. We needed to form groups of individuals that were interested in the same topic/type of project while at the same time bringing an appropriate diversity of skills to the table. Our group found four members but got stuck when looking for a fifth to fill the \"designer/artist\" role. Amidst the chaos of the crowd, it was almost impossible to locate people with this set of skills so that we could pitch them our original idea (which was related to AR overlays for clothing). We pivoted on the spot and decided to work on this specific problem: the difficulty of live team formation at a hackathon. The more work we did to flesh out our concept, however, the more we realized the wide variety of use cases that could be addressed with similar technology. Thus, the VSiBL platform project was born. What it does Overview VSiBL makes it possible for people in the same physical space to discover and connect with one another by using AR to reveal contextual information that is anchored to the users’ personal devices. Using a multi-user spatial mesh network to establish a shared reference frame, VSiBL users join an AR session overlaying their current environment. In the session, participants can visually identify each other’s location as well as whatever information they have chosen to express about themselves. Use Cases This tool is extremely useful in situations where traditional methods of communication (such as speaking) are not viable. There are many such occasions: in the hackathon team formation example, it is difficult to be heard when yelling over a crowded room. In another scenario, a hearing-impaired individual might be attending a social mixer and wish to visually identify who else in the room can speak sign language and where those people are standing. Other people at the same social mixer may want to visually identify who is single and ready to mingle. Finally, teachers may wish to scan "
      }
    ]
  },
  {
    "file_path": "./devposts/visually-bio.html",
    "project_id": "visually-bio",
    "title": "Visually Bio",
    "tagline": "We strive to provide the necessary resources such as easy to read diagrams to aid and ease students' learning of biology concepts.",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "repl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/828/791/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Diagrams Page Home Page Diagrams Page Home Page Diagrams Page 1 2 Inspiration At Visually Bio, we strive to provide the necessary resources such as easy to read diagrams to aid and ease students' learning of biology concepts. As a biology student and visual learner myself, I hope to provide a platform to make concepts easier to understand. What it does Provides information and easy to read diagrams in biology concepts How I built it Used HTML, CSS, JavaScript to create a website showcasing bio concepts and diagrams Challenges I ran into Continuously fixing the layout of the webpage to make it consistent. Accomplishments that I'm proud of Created a functional website within 2 hours What I learned To work fast and efficiently What's next for Visually Bio To add more information, diagrams, etc. Built With css html javascript repl Try it out replit.com visuallybio.techno-jules.repl.co Created by I worked on the front end using HTML , CSS, and JavaScript for the nav bar, footer, and body of the website. julia huang hackathon enthusiast and coder"
      }
    ]
  },
  {
    "file_path": "./devposts/wastesmart-fo1vgn.html",
    "project_id": "wastesmart-fo1vgn",
    "title": "WasteSmart",
    "tagline": "Smarter waste, cleaner future :)",
    "hackathon": "",
    "built_with": [
      "css",
      "html",
      "javascript",
      "teachablemachine"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack Involving AI Winner CTF 2nd Place Scorer Winner CTF 3rd Place Scorer Created by collab Lezhi Z",
      "Best Hack Involving AI Winner CTF 2nd Place Scorer Winner CTF 3rd Place Scorer Created by collab Le",
      "MVHacks 8.0WinnerBest Hack Involving AIWinnerCTF 2nd Place ScorerWinnerCTF 3rd Place Scorer",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration The inspiration behind WasteSmart came from both the growing challenge of properly sorting waste and personal experiences of incorrectly disposing of trash. We noticed how often recyclables ended up in the wrong bins, contributing to pollution and wasted resources. This made it harder for materials to be repurposed and negatively impacted the environment. Motivated by this, we wanted to create a solution that simplifies waste sorting and encourages more effective recycling. What it does WasteSmart is an AI-based waste classification tool that uses images to identify waste items and categorize them correctly. With just a photo, WasteSmart helps users sort their waste into recycling, compost, or trash categories, making it easier to dispose of materials in the right way. How we built it We built WasteSmart using Teachable Machine for image classification. First, we trained a model using different images of waste items such as plastic bottles, food scraps, and paper. After exporting the model from Teachable Machine, we integrated it into our website. The website allows users to upload photos of waste items, which are then classified by the model and displayed with recommendations for proper disposal. Challenges we ran into One of the main challenges we faced was ensuring the accuracy of the model. Training the image classifier to recognize a wide range of waste items with varying levels of detail took a lot of time and effort. We also ran into technical challenges while integrating the model into the website and fine-tuning the user interface for a smooth experience. Additionally, handling edge cases where the model couldn't confidently classify an item proved tricky. Accomplishments that we're proud of We are proud of creating an accessible solution that helps users easily sort waste with just a photo. Our AI-based classifier works well for a variety of items and can assist in reducing contamination in recycling efforts. We are also pleased with how quickl"
      }
    ]
  },
  {
    "file_path": "./devposts/vulnerabilityai.html",
    "project_id": "vulnerabilityai",
    "title": "VulnerabilityAI",
    "tagline": "Securing systems by hand is painful. We eliminate that pain using AI.",
    "hackathon": "",
    "built_with": [
      "llamaindex",
      "nextjs",
      "node.js",
      "ollama"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Bay HacksWinnerCash",
      "Track: CyberSecurity",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/014/434/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Track: CyberSecurity Inspiration The inspiration for our project was the competition called Cyber patriots. The competition entails having to fix vulnerable systems in a limited amount of time. This is to simulate real life IT where systems in companies can be compromised and need to be patched before getting exploited. Our tool was meant to be an automated tool. What It Does Our application is an efficient way to manage remote machines and uses AI for real time scanning of the system. You can connect to a new machine using our program and the AI will run a first scan and discover vulnerabilities in the remote system.  The AI will attempt to patch the vulnerabilities using shell commands and log all of its actions into the website. You can view the actions in real time with the ability to hit the kill switch if you notice anything wrong. The scan will result in a success or a fail and every system command will show up in persistent logs saved to our back end. How We Built It We used Next.Js as the back end with PocketBase (portable Firebase alternative) as our database. For the AI model we fine tuned our own version of llama70B on cybersecurity and malware scripts. Allowing the model access to this data allowed it to know what vulnerabilities to look for and how to patch them along the way. Challenges We Ran Into We ran into challenges while implementing the AI and actually testing it. Contrary to common belief, it is actually hard coming up with a vulnerable server when creating a new computer. We had to purposefully install vulnerable system images to refine and test our AI. We were successfully able to patch these systems. Another challenge we ran into was live system logging. Originally, the company managing the computer would only see the result of the AI after it had completed or failed. This was not very useful as the manager would not be able to view what commands the AI was running. If the AI performed dangerous actions, it would be impossible to know until"
      }
    ]
  },
  {
    "file_path": "./devposts/wall-e-your-path-guide.html",
    "project_id": "wall-e-your-path-guide",
    "title": "Wall-E, your path guide",
    "tagline": "New place and scared to navigate? Airports, hospitals, you name it, we will get you anywhere indoors or outdoors.",
    "hackathon": "",
    "built_with": [
      "3d-printing",
      "android-studio",
      "intel-edison",
      "java",
      "javascript",
      "node.js",
      "project-tango",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Solving how to control motor sensors via distance/seconds unit and trigonometry calculations"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/422/245/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Assist Bot (Basic) Completed bot (Prototype) Wall-E Modeling (Inspiration) Final Model (For city mapping) Assist Bot (Basic) Completed bot (Prototype) Wall-E Modeling (Inspiration) Final Model (For city mapping) Assist Bot (Basic) 1 2 3 4 5 Inspiration Have you ever felt lost because it was your first time there? Whether it was an airport, a mall, or a grocery store, hospital. Do you face a problem traveling around a city with ease (maybe if you've just moved to that city or maybe you just are stuck in traffic?). \nIt is a general problem that one feels unfamiliar with the procedures to be followed there. Furthermore, it is hard to find particular things such as Information Desk or Restrooms. Worse case, the person may have disabilities like blindness or muteness. \nGPS navigation may help you in getting from one place to another, but it can't be specific to guide you through every single building in the entire city and sometimes can't really help people who have disabilities. \nWho can possibly be our hero? What is Wall-E Wall-E is an IoT robot that helps people who have disabilities or who are new to places in guiding them outdoors and indoors using project tango mapping. Wall-E is designed to bring out the best of the current technologies: once a person initializes the path, the robot can automatically find its path when someone requests. That is, when Wall-E asks, \"Where would you like to go?\" a person could say \"bathroom\", or \"the ford desk\" or even \"remote controller and rather than going there yourself it can help you in guiding you through all the straights and turns with you either following it by walking or sitting in it. Architecture behind Wall-E ? Our team integrated a handful of top-notch technologies, including Intel Edison (2015, quad-core, RAM 800 MHz, max 8GB memory), Google Project Tango (2014, computer vision tablet that understands positions relative to the world around it), web-services via Node.js, and motor sensors. First, the facility managers "
      }
    ]
  },
  {
    "file_path": "./devposts/waste-less-64mrqy.html",
    "project_id": "waste-less-64mrqy",
    "title": "Waste Less",
    "tagline": "Have you ever wanted to help the environment but didn't know how or where to start? You are not alone, and this is the biggest problem facing activism. We’re here to help get you started.",
    "hackathon": "",
    "built_with": [
      "css3",
      "domain.com",
      "html5",
      "microsoft-cloud",
      "twilio",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Energy Saver Hack! Winner Best Domain Name from Domain",
      "Best Use of Microsoft Cloud for Your Community Created by Caleb Hairston Kazi Tasin Aspiring Softwa",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/316/680/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Microsoft Azure Coding Js,html,css Twilio Chatbot Twilio Flowchart Microsoft Azure Microsoft Azure Coding Js,html,css Twilio Chatbot Twilio Flowchart Microsoft Azure Microsoft Azure 1 2 3 4 5 6 🌎 Inspiration After eating lunch, I had lots of trash left over. After standing by a recycling bin and trash can, I was trying to figure out what goes where. After a quick Google search, I realized I had been recycling wrong. I had been guilty of a common problem called aspirational recycling, a phenomenon where people unknowingly miss recycling because it feels like the right thing to do. We understand how this is not harmless and lowers the quality and increases sorting person-hours of each haul. ♻️ What it does We decided to make a change in two critical ways: Build an SMS chatbot to help determine the right way for consumers to dispose of trash/waste. Text what item you're unsure about, and it responds promptly. We created a website that can give advice and product recommendations to reduce waste products before you need to recycle them properly. We created a quiz to determine the level of sustainability in your life out of 100. The user can then share their score with friends. 🍀 How we built it We researched the problem and sketched an outline. Created the website on Velo by Wix and used html5/css3/ javascript to create an additional quiz website and integrate that on Wix. Build a chatbot on Twillo . Then hosted the quiz website on Microsoft Cloud . We used Domain.com to buy a domain for our website. 🤔 Challenges we ran into Unfortunately, we had never used Microsoft Cloud but could use it for free with a student account. Also, with WIX we could not create everything we wanted, for example, the quiz feature of this website. We had to develop a custom solution that would fit this solution, which was quite challenging. 🥇 Accomplishments that we're proud of We are proud that our team was able to manage our time perfectly and come up with a product on time. Also, we were abl"
      }
    ]
  },
  {
    "file_path": "./devposts/watchdog-2vwqlf.html",
    "project_id": "watchdog-2vwqlf",
    "title": "Watchdog",
    "tagline": "Help us make our schools safer.",
    "hackathon": "",
    "built_with": [
      "chroma",
      "convex",
      "deepgram",
      "express.js",
      "fetch.ai",
      "groq",
      "hyperbolic",
      "javascript",
      "next.js",
      "python",
      "tailwindcss"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Cal Hacks 11.0WinnerHyperbolic: AI Inference Application Bounty",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/090/340/datas/medium.webp",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 What inspired us to build it Guns are now the leading cause of death among American children and teens, with 1 in every 10 gun deaths occurring in individuals aged 19 or younger. School shootings, in particular, have become a tragic epidemic in the U.S., underscoring the urgent need for enhanced safety measures. Our team united with a shared vision to leverage AI technology to improve security in American schools, helping to protect children and ensure their safety. What it does Our product leverages advanced AI technology to enhance school safety by detecting potential threats in real-time. By streaming surveillance footage, our AI system can identify weapons, providing instant alerts to security personnel and administrators. In addition to visual monitoring, we integrate audio streaming to analyze changes in sentiment, such as raised voices or signs of distress. This dual approach—combining visual and auditory cues—enables rapid response to emerging threats. How we built it We partnered with incredible sponsors—Deepgram, Hyperbolic, Groq, and Fetch.AI—to develop a comprehensive security solution that uses cutting-edge AI technologies. With their support, we were able to conduct fast AI inference, deploy an emergency contact agent, and create intelligent systems capable of tracking potential threats and key variables, all to ensure the safety of our communities. For real-time data processing, we utilized Firebase and Convex to enable rapid write-back and retrieval of critical information. Additionally, we trained our weapon detection agent using Ultralytics YOLO v8 on the Roboflow platform, achieving an impressive ~90% accuracy. This high-performance detection system, combined with AI-driven analytics, provides a robust safety infrastructure capable of identifying and responding to threats in real time. Challenges we ran into Streaming a real-time AI object detection model with both low latency and high accuracy was a significant challenge. Initially,"
      }
    ]
  },
  {
    "file_path": "./devposts/watch-your-mouth.html",
    "project_id": "watch-your-mouth",
    "title": "Watch your Mouth",
    "tagline": "Before sending an impulsive tweet or\ntext, imagine if the user could text our\nautomated system powered by Twilio and\nCohere, which gives you insight into how the\nmessage may sound.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "javascript",
      "python",
      "react",
      "tailwind",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for the FutureWinnerMost Creative Use of Twilio",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/372/254/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 😶Inspiration In recent years the number of cancellations has been at an all-time high, partly due to impulsive tweeting. To help our favorite rappers, politicians, and comedians who obviously should have used a sounding board, we have created a private messaging service that can give critical insights into how you may come off with 90% or greater accuracy. 🧠What it does It was targeted at teenagers and people with mental illness, the most likely population segments to send an impulsive message(s) to prevent them from sending less than the thought-out message(s) during a stress-induced episode. Before you tweet or make a potentially risky post, text our open line to receive insights. In addition, this could be interpreted by people living with ASD (Autism Spectrum Disorder) to solve other people's messages to avoid misunderstandings and as a much-needed educational resource. 🚧How we built it First, we collect over 1100 messages through web scrapers and by hand. We then created a Python automation for sorting, dividing, and formatting as a CSV file. The information was divided into training and validation set at a 10:1 ratio. We then fed it through the Cohere NLP model. Our model passed our P value of 12.5%, thus validating our minimum standards for determining the 11 emotions + 3 Contexts. As we know, sms is more area accessible but less financial as the text still charges some people; we created a react webpage with the same functionality. 📱Challenges we ran into The Twilio service was experiencing multiple bugs preventing outgoing messages from being sent. Currently, we are running low on twillio credits. 🥇Accomplishments that we're proud of We are proud to work with an interdisciplinary team where half were first-time hackers, and the other half were non-computer science students. In addition, we put an extra amount of time into this project. 🍎What we learned We learned how to train and validate a learning model. 📝What's next for Watch your Mouth We ho"
      }
    ]
  },
  {
    "file_path": "./devposts/wall-street-wizard.html",
    "project_id": "wall-street-wizard",
    "title": "Wall Street Wizard",
    "tagline": "Educational stock market game, empowering practical skills for all.",
    "hackathon": "",
    "built_with": [
      "figma",
      "firebase",
      "flask",
      "godot"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/542/999/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Leaderboard Main Stocks Page News Page Leaderboard Main Stocks Page News Page Leaderboard 1 2 3 4 Wall Street Wizard - Rise to the Riches! Inspiration The inspiration behind Wall Street Wizard was to create an educational simulation game that simplifies the complexities of the stock market, empowering players with valuable skills for the real world. We aimed to bridge the knowledge gap and provide an enjoyable learning experience for individuals interested in finance. What it Does Wall Street Wizard is an educational simulation game designed to demystify the seemingly complexity of the stock market into simple chunks and empower the player with skills that will help them in the real world. The game immerses the player in a virtual marketplace with somewhat accurate simulations. How We Built It We used Godot for the game engine and a Flask server to host the backend. We used Firebase as our Database and Nextjs for the website. Challenges We Ran Into We could not figure out how to get HTTP requests working in Godot. This took hours of debugging and hard work to get everything figured out. Accomplishments We're Proud Of We are proud to have created an accessible game that caters to both beginners and experienced investors. The gamification approach, combining captivating gameplay with educational elements, sets Wall Street Wizard apart from traditional learning methods. What We Learned Through the development of Wall Street Wizard, we learned the importance of merging entertainment and education to enhance the learning experience. We discovered how gamification can effectively teach practical skills that are applicable in both virtual and real-world scenarios. What's Next for Wall Street Wizard In the future, we plan to expand Wall Street Wizard by adding more features, levels, and challenges. We aim to foster a stronger community of players, encouraging collaboration and competition. Additionally, we will continuously update the game with the latest financial data to "
      }
    ]
  },
  {
    "file_path": "./devposts/webchat-0avl9x.html",
    "project_id": "webchat-0avl9x",
    "title": "Jan Ken Pon",
    "tagline": "An online rock scissors paper game :)",
    "hackathon": "",
    "built_with": [
      "cohere",
      "javascript",
      "node.js",
      "socket"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/187/679/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Jan Ken Pon Jan Ken Pon Jan Ken Pon 1 2 Inspiration We were inspired by the movement of physical board games moving to virtual and web based games such as skribbl.io and looked more and more only to not find an online game version of Rock Paper Scissors What it does Jan Ken Pon lets you play rock paper scissors online with your friends while utilizing a built in chat system which is moderated by Cohere's NLP How we built it We built this using JavaScript, Node.js, Socket, and Cohere to moderate our built in chat system Challenges we ran into We were new to using socket and cohere, so we ran into trouble on how to utilize this into our application. Accomplishments that we're proud of We are proud of the new skills we have learned along the way such as Socket and Cohere\nWe are proud of us taking the 1st step to keep the game Rock Paper Scissors alive for years to come What we learned We learned how to utilize Socket, we would like to use socket in the future as it is a resourceful software that is good for many things\nCohere's advanced NLP and easy to use API allowed us to What's next for Jan Ken Pon We plan to revamp the frontend with Bootstrap and Built With cohere javascript node.js socket Try it out GitHub Repo Submitted to Snakes and Hackers 2 Created by Ayush Garg Satyam Singh"
      }
    ]
  },
  {
    "file_path": "./devposts/wenote-nu691k.html",
    "project_id": "wenote-nu691k",
    "title": "WeNote",
    "tagline": "A note taking application that converts voice notes into text and also summarizes them",
    "hackathon": "",
    "built_with": [
      "assemblyai",
      "dart",
      "flask",
      "flutter",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/702/981/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Keeping up with the curriculum and working on side ventures is difficult, which brings up the need for an application that can automate the note-taking process. What it does WeNote is a platform-independent application that uses AssemblyAI API to transcribe speech into text. WeNote allows people to take notes, just by speaking, thereby reducing the time taken to type or write them. Users can also upload an audio from their lectures and make notes out of them, without having to put in the effort. How we built it Front-end: Flutter\nBack-end: Python-Flask, AssemblyAI(API) Challenges we ran into Synchronizing the audio and directly sending it to the server, and sending a file with a POST request. The challenge with flutter web was the lack of file storage which we had to inovatively manage with the browser's session storage for storing the audio data. Another challenge was managing the different audio encodings for our cross platform application. Accomplishments that we're proud of We're proud of integrating the sound with flutter web and using that data to get the notes from it while building almost the whole application. What we learned We learned about AssemblyAI and Flutter(using sound, http requests and flutter web). What's next for WeNote We'll be connecting the in-app option to record audio and the server. Built With assemblyai dart flask flutter python Try it out GitHub Repo GitHub Repo Submitted to Hack the Valley V Created by Neel Adwani yeet Avinash Upadhyaya K R"
      }
    ]
  },
  {
    "file_path": "./devposts/website-guard.html",
    "project_id": "website-guard",
    "title": "website-guard",
    "tagline": "leaderboard to guard your website against llm-powered scrapers.",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration we want to make websites safe from scrapers What it does How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for website-guard Built With python Try it out GitHub Repo Submitted to Hacker House Hackolympics Created by Laurence Liang Innocent Munai Shefali Sastry"
      }
    ]
  },
  {
    "file_path": "./devposts/watts-up.html",
    "project_id": "watts-up",
    "title": "Watts Up",
    "tagline": "A community-driven EV platform that optimizes charging with smart scheduling, dynamic pricing, voice commands, and QR-based bookings for an efficient, and accessible experience.",
    "hackathon": "",
    "built_with": [
      "django",
      "express.js",
      "flask",
      "google-maps",
      "javascript",
      "mongodb",
      "next",
      "node.js",
      "openai",
      "openai-api",
      "python",
      "react",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Environmental Hack Winner Powering Tomorrow Created by Raymond Chan i like to build stuff Kaan Pamu",
      "Best Environmental Hack Winner Powering Tomorrow Created by Raymond Chan i like to build stuff Kaan",
      "DeltaHacks XIWinnerBest Environmental HackWinnerPowering Tomorrow",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/208/509/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Main Page Main Page - Path Login Page Create Account Page QR Code Functionality Profile Charger Provider Info Page Charger Customer Info Page Main Page - Zoomed In Main Page Main Page - Path Login Page Create Account Page QR Code Functionality Profile Charger Provider Info Page Charger Customer Info Page Main Page - Zoomed In Main Page 1 2 3 4 5 6 7 8 9 10 Inspiration The rapid rise of electric vehicles is transforming how we live in real time. However, access to charging remains an issue for EV cars, especially in residential areas. We saw communities with underutilised private chargers and overcrowded public stations, we realised that if there was a peer-to-peer sharing platform existed, it could revolutionise EV charging accessibility. Driven primarily by a passion for sustainable energy and community collaboration, our team set out to create a solution that would not only make the EV charging process as smooth as possible, but also allow users to share resources, reduce grid load, and promote renewable energy use. Our vision was to focus on driving sustainable change on a much needed issue with EV's with a community spirit. What it does Watts Up is a comprehensive community-driven EV charging network that connects EV owners with private and public charging stations all across the nation. it leverages smart scheduling, dynamic pricing features, voice detection, and AI-driven predictions to optimise charging time, reducing long wait times and enhancing user experience. Users can: Search & Book Chargers: Find closest available chargers based on your location, vehicle model and battery needs. Peer-to-Peer sharing: Rent out private EV charges to and from community members in your city. Dynamic Pricing: Benefit from adaptive pricing that reflects real-time demand and supply. Route Optimisation: Get guided directions with estimated arrival times using Google Maps API. Voice Activation: Enjoy hands-free commands to book and change your booking while keeping you away fro"
      }
    ]
  },
  {
    "file_path": "./devposts/water-diviner.html",
    "project_id": "water-diviner",
    "title": "Water Diviner",
    "tagline": "Pulls water data from the OSM database, and into an AR map in order drive action to nearby water sources",
    "hackathon": "",
    "built_with": [
      "ar",
      "esri",
      "mapbox",
      "osm",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/615/330/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "OSM Data of fountains loaded into Unity using Mapbox OSM Data of fountains loaded into Unity using Mapbox OSM Data of fountains loaded into Unity using Mapbox 1 2 Inspiration Hydration is an essential component of human life. There is no individual that is capable of escaping the need for water, and with climate change increasingly making an impact on our livelihoods our world is very aware of the need to improve the way we manage our sources of clean water. Later this year it is expected that the City of Cape Town will be forced to shut off over 100,000 taps throughout the city as the primary reservoir is close to drying up entirely. California has experienced several droughts in the past years, and these problems are only expected to get worse. Water Quest is on a mission to help citizens locate sources of reliable drinking water, assess, and improve the management of these resources through an interactive mapping experience. What it does This pulls data about water sources from the OpenStreetMap database, and imports it into an AR map in order to show the user nearby water sources How we built it We used Unity with the Mapbox v1.3 SDK, and AR Core SDK. Using the Mapbox SDK we pulled in custom datasets that we got from the OpenStreetMap database. Challenges we ran into We had two main mapping frameworks that we were looking at that created much debate and wasted time. Our team was more familiar with the Unity Game Engine with the Mapbox SDK, although the team was inclined to work on the ESRI mapping set because ESRI was one of the sponsors, and had a newly released Beta SDK. As some of our team began researching the feasibility of the ArcGIS Framework, this created uncertainty on what environment the front-end should be on, thus limiting the design team's ability to work. This led to much debate, which inevitably led the team to decide to follow the path of least resistance, which is the Unity + Mapbox combination. Accomplishments that we're proud of We were able "
      }
    ]
  },
  {
    "file_path": "./devposts/wealth-is-health.html",
    "project_id": "wealth-is-health",
    "title": "Wealth is Health",
    "tagline": "Wealth is Health is an app that utilizes AI to track how many repetitions of an exercise is completed, motivating users to exercise more.",
    "hackathon": "",
    "built_with": [
      "mediapipe",
      "opencv",
      "python",
      "tkinter"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "1st Place Winner Created by Ayush Garg Davyn Paringkoan Denis Vorobyev",
      "Blu's Hacks 2024Winner1st Place Winner",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/826/291/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Wealth is Health Wealth is Health Wealth is Health 1 2 Inspiration Research shows that people who exercise regularly have better mental health, emotional well-being, and lower rates of mental illness. But according to the CDC, just 28% of Americans are exercising enough. To address this, we created an app that utilizes AI to accurately track how many repetitions of an exercise have been completed. We also included in-game currency, motivating users to exercise daily and reach their goals. How we built it We used MediaPipe's Pose Landmark Detection model to detect different segments of the body and used a math algorithm to determine if the user completed an exercise (pushup, situp, or squat). We used Tkinter to create the UI for the program and OpenCV to easily process the live webcam video. Challenges we ran into One challenge we ran into was the math and logic required in calculating whether the user completed an exercise. This used vector addition in the third dimension with the XYZ-Coordinate system that we learned in our math classes. The vector addition allowed us to match up the users' body position with what the desired exercise form looks like, to determine if the user completed an exercise. We also had problems with integrating MediaPipe's detection into the Tkinter GUI. Accomplishments that we're proud of We're proud of implementing an AI model and completing this project on time as this was our first time participating in a hackathon for 2 of the 3 members in our group. What we learned We learned how to use OpenCV, Tkinter, and MediaPipe's AI models, and how to integrate all of these tools together. What's next for Wealth is Health In the future, we want to improve our program by implementing more exercises that can be detected and include feedback to the user on their exercise form. A cloud saving and account feature can be added to the app to make it more convenient for users. Built With mediapipe opencv python tkinter Try it out GitHub Repo Submitted t"
      }
    ]
  },
  {
    "file_path": "./devposts/weather-track.html",
    "project_id": "weather-track",
    "title": "Weather Wizard",
    "tagline": "The ultimate way to get data on local areas. Helps farmers and planters.",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "[Spire] Best Use of Spire API Created by Gaurav Bansal Sarvesh Madullapalli Full Stack Dev | Python",
      "Los Altos Hacks VIIWinner[Spire] Best Use of Spire API",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "TABLE 131 Inspiration Farmers and extreme sportists need access to various data like precipitation and sunlight. They can't access reliable data in a quick and easy way. Using our app, they can do just that. What it does Allows farmers and extreme sportists need access to various data like precipitation and sunlight. How we built it Challenges we ran into Accomplishments that we're proud of What we learned What's next for Weather Track more data Built With python Submitted to Los Altos Hacks VII Winner [Spire] Best Use of Spire API Created by Gaurav Bansal Sarvesh Madullapalli Full Stack Dev | Python, Java, NodeJS, HTML, CSS, SQL, C++ | Hackathons Weekly Rohan Fernandes A full-stack programmer who mainly works in JavaScript and Python DevMello"
      }
    ]
  },
  {
    "file_path": "./devposts/webcraft-kp3lbe.html",
    "project_id": "webcraft-kp3lbe",
    "title": "WebCraft",
    "tagline": "Imagine Google Collab, but specifically designed for web development. That's what WebCraft offers. Our AI-integrated IDE empowers new web developers to learn programming without any installations.",
    "hackathon": "",
    "built_with": [
      "autogpt",
      "docker",
      "fastapi",
      "javascript",
      "python",
      "vue"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/462/631/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration Aspiring web developers often face a steep learning curve when first starting out. Many struggle to understand the nuances of different frameworks and technologies and lack the necessary skills to build and deploy a web application from scratch. WebCraft was inspired by the need to create an intuitive, AI-assisted online Integrated Development Environment (IDE) that would make web development accessible to everyone. What it does WebCraft is a full-stack-focused version of GPT that generates and deploys code and features on a live server. Users can interact with the generated code and provide feedback and edits to improve the output. The system consists of several components, including a user interface, input preprocessing, GPT3.5/GPT4 for code generation, a live dev server, feedback loop, output post-processing, and user notifications. How we built it We built WebCraft with Vue for frontend built on top of Monaco editor and FastAPI for backend. We used GPT3.5 for code generation and AWS to host the live dev server. We integrated GitHub for cloning projects and used Docker to provide each user with a dedicated container for their work. Challenges we ran into One of the main challenges we encountered was the cost of using GPT3.5. We had to find creative ways to optimize our code and reduce costs, such as limiting the number of characters per user account. Another challenge was implementing a feedback loop that effectively collected and processed user feedback while keeping response times reasonable. Accomplishments that we're proud of We are proud of creating a powerful, AI-assisted web development tool that makes it easy for users to build and deploy web applications. What we learned Working on WebCraft taught us a great deal about AI-assisted web development, including the challenges of integrating different components into a single system and the importance of optimizing code to reduce costs. We also learned how to use Docker to provide a personalized d"
      }
    ]
  },
  {
    "file_path": "./devposts/wexhibit.html",
    "project_id": "wexhibit",
    "title": "[U25] - Wexhibit",
    "tagline": "We need such a MR tool that can: Enable remote collaboration;\nDemocratizes art through open public participation;\nReduce financial & communication costs;",
    "hackathon": "",
    "built_with": [
      "logitech",
      "openxr",
      "unity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/989/638/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "page 9 page 1 page 2 page 3 page 4 page 5 page 6 page 7 page 8 page 9 page 1 page 2 page 3 page 4 page 5 page 6 page 7 page 8 page 9 1 2 3 4 5 6 7 8 9 10 Inspiration Enable remote collaboration;\nDemocratizes art through open public participation;\nReduce financial & communication costs; What it does for remote collaboration for exhibition How we built it unity openxr, unity remote collaboration intemplement Challenges we ran into To integrate all the things together Accomplishments that we're proud of have tested and accopolished all the functions What we learned a lot especially remote collaboration What's next for Wexhibit build a full worked edition Built With logitech openxr unity Try it out drive.google.com Submitted to XR Hack - London Created by marukowanzi Zijun Wan Sowilo Xiong XR developer"
      }
    ]
  },
  {
    "file_path": "./devposts/we-cooked.html",
    "project_id": "we-cooked",
    "title": "Aisle Atlas",
    "tagline": "Sending SMS messages to complete simultaneous localization and efficient grocery shopping for maximum convenience.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "flask",
      "hardware",
      "mappedin",
      "ngroc",
      "opencv",
      "python",
      "raspberry-pi",
      "render.com",
      "svelte",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "We also used vision-based localization and object detection, as well as MappedIn with live location tracking."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/024/769/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Completed Prototype Sift Algorithm SMS Messaging Instruction Dashboard Completed Prototype Sift Algorithm SMS Messaging Instruction Dashboard 1 2 3 4 5 6 7 8 Inspiration Have you ever been frustrated looking for a grocery item, only realizing after that you passed by it multiple times? Ever wish you could receive store guidance without stepping out of your social bubble? We are introducing Aisle Atlas ! An interactive, computer vision companion residing right on top of your head. With its AI capabilities and convenience of use, our device allows anyone to become an \"employee\" of a supermarket. Through SMS messages, localization and effective mapping of grocery items, we aim to increase the efficiency and shopping experience for all. What it does Imagine needing to buy an item/items but you're in a rush to be somewhere else. Maybe someone you know is already at the supermarket and only a text message away. Using a simple SMS text, Aisle Atlas allows you to send a grocery list that is automatically received. The items are then mapped immediately for the other shopper to find the shortest algorithm to grab all the components, with detailed instructions to arrive at each \"station\". We then use localization to determine our current position within the store and the required path to each item. Once an item has been \"completed\", there is a basic fingerprint sensor attached to the side of our device. With one tap, that item is no longer at the top of the queue. You can track with live feed the positioning of the shopper and updates in real-time. How we built it Our team wanted to implement a mix of both hardware and software. We 3D-printed a headband and support compartment, housing a Raspberry Pi, camera, batteries and a touch sensor. Our original idea was to attach the device to a hard hat, but we decided in the end to go with a sponsor bucket hat. This gave us more flexibility with materials and easier mounting conditions. We interfaced both firmware and software togethe"
      }
    ]
  },
  {
    "file_path": "./devposts/where-to-1xbj6q.html",
    "project_id": "where-to-1xbj6q",
    "title": "Where to?",
    "tagline": "You're going? Where to?",
    "hackathon": "",
    "built_with": [
      "beautiful-soup",
      "bootstrap",
      "css3",
      "flask",
      "html5",
      "javascript",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "I worked on frontend and it was my first time experiencing this"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/999/953/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Our Homepage Our Homepage Our Homepage 1 2 Inspiration Whenever we try to find information about a place that we'd like to go to, it becomes a hassle scouring other websites for information about our destination. So, we came up with an idea for a one-stop-shop for all your traveling needs What it does Where To? gives the user information about their destination such as weather, estimated expenses, the exchange rate, the local time, and the ability to book flights and hotels How we built it We built it using Flask as our backend language and with lots of code in the frontend using HTML, CSS, and Bootstrap. Challenges we ran into We had a lot of issues trying to integrate APIs for our project. Also, finding the right resources to utilize was also a hassle Accomplishments that we're proud of We are very proud of the fact that although we were all beginners, we managed to create such a project in a short amount of time. What we learned APIs, Web Scraping, What's next for Where to? To provide our users with a better UI/UX design and include new features. Built With beautiful-soup bootstrap css3 flask html5 javascript python Try it out GitHub Repo Created by I worked on the backend as well as the frontend Achintya Pasricha Codes stuff I worked on the backend Aman Singh Sahni I worked on frontend and it was my first time experiencing this Onayemi Ademola"
      }
    ]
  },
  {
    "file_path": "./devposts/winterbuddy.html",
    "project_id": "winterbuddy",
    "title": "WinterBuddy",
    "tagline": "WinterBuddy is a project and team committed to providing winter-themed services, knowledge, and charity. It features Frosty the chatbot, a winter donation service, a \"Living Winter Library\" and more.",
    "hackathon": "",
    "built_with": [
      "coil",
      "css3",
      "html5",
      "javascript",
      "python",
      "twilio",
      "wix"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Web Monetization Project sponsored by Coil Created by Kazi Tasin Aspiring Software Engineer with so",
      "Hackcoming Royalty Winner Best Web Monetization Project sponsored by Coil Created by Kazi Tasin Asp",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/303/864/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 💡Inspiration This project came to fruition due to the 2022 Winter Hackcoming 2 Hackathon hosted by Major League Hacking. We wanted to create services that would help others during the winter months. 🤖What it does WinterBuddy is a collection of services. Frosty the ChatBot - Frosty will text you every morning at a time that you specify and will give you suggestions on how heavy or light to dress depending on what he reads on the weather forecasts of your local area. The Living Winter Library - The Living Winter Library is a library of information created to help our readers prosper this winter season. A new winter \"hack\" (Tip, trick, general advice, etc.) is added to an ever-growing collection of wisdom daily. The Safe Driving Program - the most dangerous season to drive. The Donation Hub - in hopes no one is left without a jacket during wintertime. ☕How we built it We created the website using Velo by Wix and used Coil for our donation and shopping web page needs. We found a weather API on OpenWeather.com that we combined with the Twilio API by calling the Sid, AUTH, and host phone numbers. After adding these to my Python script, I hosted it on EverthingPython.com. 💔Challenges we ran into We had many people come in and out of our group. People would join a little while later, saying they couldn't be part of the team anymore. This led us without a 4th group member for a while, as we could only trial-run one person at a time. This constant uncertainty led to a bit of anxiety amongst the group, yet we maintained our composure and confidence until we, fortunately, found our permanent 4th member. 🏅Accomplishments that we're proud of Since many team members are still beginners, we are very proud of our accomplishments. We created a beautiful-looking website with excellent copy, implemented high-quality features onto that website, had excellent teamwork, created a clean-cut demo and entertaining advertisement, and had developers that created c"
      }
    ]
  },
  {
    "file_path": "./devposts/whatever-lol.html",
    "project_id": "whatever-lol",
    "title": "ScribAid",
    "tagline": "Making writing more accessible, one user at a time :)",
    "hackathon": "",
    "built_with": [
      "flask",
      "gemini-api",
      "langchain",
      "node.js",
      "python",
      "react.js",
      "stable-diffusion-api"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/830/584/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "stable diffusion generated images to help prompt students in writing - topic: Global Warming main features stable diffusion generated images to help prompt students in writing - topic: Global Warming stable diffusion generated images to help prompt students in writing - topic: Global Warming main features stable diffusion generated images to help prompt students in writing - topic: Global Warming stable diffusion generated images to help prompt students in writing - topic: Global Warming 1 2 3 4 Inspiration The challenge of writing essays is a universal aspect of the student experience. \nHowever, for students with learning difficulties, this task becomes exponentially more daunting. Difficulties such as dyslexia, dysgraphia, and attention deficit hyperactivity disorder (ADHD), can severely inhibit the writing process. For instance, students with dyslexia often struggle with reading and processing langauge, which can hinder their ability to organize their thoughts and express ideas clearly. Our project, ScribAid , was inspired by the desire to bridge this gap, providing an AI-powered tool that specifically addresses the unique needs of these students. What it does The core of our project integrates Google's Gemini GenAI with proven research methods , TIDE and RAFT (as discussed in this paper ) to assist with organizing thoughts and structuring arguments, overcoming the difficult challenges of writing. Teachers can assign essay prompts and select the learning method to be used. Students then complete these assignments with the aid of visual guides and feedback provided by both software and Gemini. Concern: Will students rely too heavily on Gemini for answers, bypassing the learning process? To address this, ScribAid is designed so Gemini AI only offers feedback on essay ideas, not the essays themselves, preventing any potential misuse and ensuring the tool enhances the learning experience. How we built it The backend utilizes Google's latest language model through the"
      }
    ]
  },
  {
    "file_path": "./devposts/whatsthatstyle.html",
    "project_id": "whatsthatstyle",
    "title": "WhatsThatStyle",
    "tagline": "A webapp that helps you express your style and personality",
    "hackathon": "",
    "built_with": [
      "cockroachdb",
      "coil",
      "google-vision",
      "python",
      "react",
      "replit",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack The RunwayWinnerMost Creative Use of Twilio",
      "It was our first time working with GitHub pull requests and had to overcome hurdles of merge conflicts.",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/034/698/datas/medium.PNG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 💡 Inspiration💡 Have you ever been in a situation where your friend clicked a picture of their outfit and thought ‘I want that 👀'  and immediately saved that image in your phone for inspiration? We had that problem statement in mind when we created this app. We believe that self expression is healthy and utilizing clothes to convey who you are and what you stand for is amazing. We want this app to be a tool that helps you explore you . References: https://repeller.com/self-expression-clothing/ https://lifestylebyps.com/blogs/lifestyle/fashion-as-self-expression ⚙️ What it does ⚙️ Any images you like can be saved by giving it to the Whatsapp bot. Whether it's your friend's photo from a Whatsapp group chat or elsewhere. The bot saves your image, and you can optionally write notes about the image or not, and it will be stored in your personal WhatsThatStyle gallery. You can view your gallery on the web app, and tap on any image to get similar images and their details like where to buy them and their price. You can plan your outfits via the notes feature of the web app, where you can upload images that you want to wear and easily access these notes that include a description that you can edit any time. 🏗️ How we built it 🏗️ In a span of 48 hours, we used Python and Flask for the backend and React.js for the frontend. The designs were initially put together using Figma , were then changed during frontend's testing. For our database, we used CockroachDB , the Google Vision API and Coil . We also did full justice to all the amazing technology that MLH and their sponsors provided us with this weekend. We used CockroachDB, Coil, Twilio and GitHub. 🟣 CockroachDB 🟣 We used CockroachDB to create, delete, edit and update our resources that was populated by the Google Cloud Vision API and connected to the WhatsApp and Twilio API. 🔴 Twilio 🔴 We used ngrok to connect Twilio to our flask app. We used a flask POST request that the Twilio whatsapp bot calls whenever the user sends "
      }
    ]
  },
  {
    "file_path": "./devposts/when-there-s-a-will-there-s-a-wave.html",
    "project_id": "when-there-s-a-will-there-s-a-wave",
    "title": "One Shell of a Place",
    "tagline": "When there's a will, there's a wave! A platform that allows you to advocate for animals with a gamified experience.",
    "hackathon": "",
    "built_with": [
      "cohere",
      "css",
      "flask",
      "html",
      "pandas",
      "python",
      "scikit-learn",
      "velo"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Best Use of Microsoft Cloud for Your Community Created by Chantal Pino Lib Joshua Martinito Joshua",
      "DeepDiveHacksWinnerBest Use of Microsoft Cloud for Your Community",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/266/609/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 Inspiration Public opinion matters when it comes to advocating for causes like marine life. Animals like rhinos and orangutans get the attention they need to prevent their extinction through funding, but what about other animals without this kind of exposure? We had this thought process in mind when we created ‘One Shell of a Place’ - a gamified application that brings attention to the marine animals without the same measure of popularity. References: https://www.opendemocracy.net/en/openglobalrights-openpage/it-s-about-politics-why-public-opinion-matters-for-movement-organizing/ What it does and how we built it It’s a gamified application where the user, as a diver, bumps into marine animals and is asked to input their thoughts about that animal. We then used Cohere and Supervised Learning in Scikit-learn's Support Vector Machine (SVM) to classify and perform sentiment analysis on the user's input. The responses are labeled under the hood as ‘positive’, ‘neutral', or 'negative' and are backed up in Microsoft Cloud’s database. The data is used to advocate for the well-being of the marine animals that are usually not in the media’s spotlight and are in need of funds to help their species survive. We hope this application will bring awareness and shed light on the unnoticed creatures under the sea. Challenges we ran into This is our first time dealing with any kind of machine learning and Cohere and Scikit-learn was definitely something that we spent a considerable amount of time understanding. We had to go back to the fundamentals in order to do sentiment analysis with supervised learning successfully. Accomplishments we’re proud of We’re proud that we were able to able to utilize supervised machine learning and sentiment analysis even though we’ve never delved into that before. We’re proud we were able to create a gamified experience for a cause that we were deeply passionate about. We’re proud that we were able to continue working together and establish"
      }
    ]
  },
  {
    "file_path": "./devposts/will-i-go-viral.html",
    "project_id": "will-i-go-viral",
    "title": "Viral AI",
    "tagline": "Predict if your TikToks will go viral or not",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "docker",
      "joblib",
      "nextjs",
      "python",
      "scikitlearn"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Built an interactive dashboard for creators to track predicted factors and estimated revenue."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/285/643/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Virality Dashboard Virality Dashboard Virality Dashboard 1 2 Inspiration Our team has a combined 12,000 followers on Instagram and is constantly uploading short-form content on TikTok and Instagram. We've always struggled with figuring out what makes a viral video. So we decided to solve this problem. Our tool allows creators to see not just what allows them to go viral, but also revenue potential and how they can improve their videos. By understanding how content performs, creators can make smarter decisions and maximize their earnings. What it does \"Will I Go Viral\" gives insights into key video elements—like the number of faces, audio quality, and revenue potential—to help creators optimize their content. Using a model trained after hundreds of TikToks, we analyze likes, comments, shares, captions, and more to see what really makes a video take off. More importantly, we estimate how much revenue a creator could earn based on virality predictions. How we built it Backend: Python (Flask) handles API requests and crunches social media data. Frontend: Next.js for a sleek and easy-to-use interface. Machine Learning: We trained our own model using Python + scikit learn to predict views from virality. Infrastructure: AWS Lambda for scalable serverless functions. Containerization: Docker for streamlined deployment. Challenges we ran into Data Processing Times: Mass-downloading TikToks took a significant amount of time. View Prediction Complexity: Estimating views from engagement patterns required extensive modeling and feature engineering. Deploying on AWS: We ran into multiple Python compatibility issues that delayed the time it took to deploy the model Accomplishments that we're proud of Successfully trained and deployed a model that predicts how many views a video might get. Built an interactive dashboard for creators to track predicted factors and estimated revenue. Showed creators the revenue potential they might gain based off of their videos What we learned Engage"
      }
    ]
  },
  {
    "file_path": "./devposts/wild-west-ghost-express.html",
    "project_id": "wild-west-ghost-express",
    "title": "Wild West Ghost Express",
    "tagline": "And you thought it was just another train ride...",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "- 2nd Place Winner Best Use of Qoom Created by Anita Yip Product owner, project manager, retired ha",
      "Use of Qoom Created by Anita Yip Product owner, project manager, retired hackathon-er Gurjot Kaur S",
      "Beginner Track - 2nd Place Winner Best Use of Qoom Created by Anita Yip Product owner, project mana",
      "Sego Lily HacksWinnerBeginner Track - 2nd PlaceWinnerBest Use of Qoom",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/246/898/datas/medium.JPG",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 Inspiration We were inspired by what we could do with SLH's theme! What it does You are a sheriff taking the ghost train back home, when suddenly you surmise that wild bandits overtook the train, looking to send you careening towards a watery grave. That is, unless you can stop the train—and the bandits—in their tracks... How we built it We built our website out of HTML, JavaScript, and CSS. Challenges we ran into One of the biggest challenges was figuring out how to collaborate asynchronously on Qoom's platform. It was fine when we were coding together on one person's screen. However, when we set the project to be collaborative on Qoom's beta version, all of a sudden, no one - not even the original creator - could edit the code. It did work for <1 hour, but afterwards there would be timeouts on connectivity/reconnecting messages. We also had to come up with a cohesive story that makes sense and implement basically an entire game in the span of a relatively short hackathon/hacking period. Accomplishments that we're proud of We are so proud to have come up with a vision for this project and see our ideas come to life by implementing it ourselves! What we learned We learned a ton about: storytelling - forming a cohesive story under an atypical theme with technical features/functionality that supports the story along with music implementing interactivity using JavaScript manipulating the DOM so that we're changing components on one page and not going from one to another page Chrome's devtools for troubleshooting via the console and identifying placement of coded elements collaborating on coding together (pair programming, triple/quadruple programming) pivoting and adapting ideas - we wanted to implement an animated shooting game using HTML canvas, and that didn't quite work out as well as we would've hoped. So instead, we dug deep for how we can still simulate the shooting game we had wanted and we MADE IT WORK! What's next for Wild West Ghost Express"
      }
    ]
  },
  {
    "file_path": "./devposts/winter-ar.html",
    "project_id": "winter-ar",
    "title": "Winter-AR",
    "tagline": "An immersive winter experience using Augmented Reality",
    "hackathon": "",
    "built_with": [
      "realitykit",
      "swift",
      "swiftui",
      "xcode"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "First Overall Created by Neerraj Singh Hey, I'm a self taught 11th grader programmer interested in",
      "Hacky Winterland 2WinnerFirst Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/332/311/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Winter-AR logo Winter-AR logo Winter-AR logo 1 2 💡 Inspiration💡 All of our team members are currently located in places where it does not snow, and they will not have the opportunity to experience the Christmas Wonderland that the people who live in places where it snows get to experience. As a way to give them a similar experience from the comfort of their own home, we used Augmented Reality to give them a true experience of a Christmas Wonderland. ⚙️ What it does ⚙️ Users get to feel immersed in a really cool Christmas experience by listening to Christmas music while exploring an immersive 3D view of Christmas trees, snow, and presents. Users can also take a snapshot of themselves in the snow, and share it with the world! They can then see other people’s photos in the photo gallery and get to have a celebratory Christmas together when they usually can’t. 🏗️ How we built it 🏗️ We used Swift to build the mobile app side of things, including the AR experience, taking a snapshot, and the music. This is done using RealityKit and AVFoundation in Swift. We then connected the snapshots to a firebase storage, which is then accessible by a React app that displays all the images in a gallery. We deployed the website with Netlify and used Domain.com and displayed this website in the mobile app as a web view using Swift’s web view. This way, users can alternatively access the React website anywhere and not just in the app. Our Domain name is http://argallery.tech . 🚩 Challenges we ran into 2 of the 3 teammates were new to Swift and RealityKit, because of this development went slower than expected and we could not incorporate as many features as we wanted. We also had troubles uploading our images to our database so they could be used for our gallery website. The model we used with RealityKit did not work 100% initially so we had to modify the models for them to fit our needs. We also tried and to use Mongo Realm at first, but we decided to use Firebase instead after failing to"
      }
    ]
  },
  {
    "file_path": "./devposts/world-s-most-useful-website-qg0k3s.html",
    "project_id": "world-s-most-useful-website-qg0k3s",
    "title": "World's most useful website",
    "tagline": "A below-average front-end developer creates the most useless website with the most complicated approach possible.",
    "hackathon": "",
    "built_with": [
      "css",
      "express.js",
      "firebase",
      "html",
      "mongodb",
      "node.js",
      "react"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "to create the most useless hack, with the most maximally complicated method I could think of"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/380/645/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration I came to this hackathon with the sole purpose of learning more about front-end development. I have been avoiding learning front-end Javascript frameworks, so I promised to learn them this weekend. I found that no challenges really cared about the user interface so I decided to try my best to create the most useless hack, with the most maximally complicated method I could think of. What it does The project does absolutely nothing . I built a full-stack web application that allows users to register their emails and authenticate their login so that they may have even more access to the useless features on the website. How I built it I used React, Javascript, HTML, CSS, Node.js, Express, Firebase, and MongoDB, and hosted it locally for demoing. Challenges I ran into I knew absolutely zero about Javascript prior to this hackathon, so I spent a very long time actually learning enough to put everything together. Accomplishments that I'm proud of I learned a ton during this hackathon and I'm really proud that I was able to create something functioning with so little prior knowledge. What I learned I learned a ton about front-end development, essentially all my knowledge of javascript was learned during this weekend. What's next for World's most useful website Create something actually useful. I have a great skeleton for something that could be great, so maybe in another hackathon, I could build off of this project. Built With css express.js firebase html mongodb node.js react Try it out GitHub Repo GitHub Repo Submitted to uOttaHack 5 Created by Jackson Lippert"
      }
    ]
  },
  {
    "file_path": "./devposts/wildernez.html",
    "project_id": "wildernez",
    "title": "wildernez.",
    "tagline": "A social platform to connect with the wilderness. Engage with charitable events, animal support groups and share your knowledge to keep our animals across the globe safe and happy!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "bulma",
      "css",
      "express.js",
      "heroku",
      "html5",
      "javascript",
      "mongodb",
      "node.js",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/136/721/datas/medium.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Wildernez Wildernez Wildernez 1 2 Inspiration 💡 Our inspiration stems from our aim to provide a voice to those who we could not understand. We wanted to bridge the gap between humans and animals across the globe, to save them from the side effects from our own actions and instill a love for them in our hearts. What it does ⚙️ WIldernez at it's core is a social app aimed to provide users to directly contribute to various animal rights organizations, host or join campaigns and learn more about them by posting content on it. Communuities of various habitats act as the first filter to narrow down preferences. How we built it ⚒️ The front-end was built with a combination of Bulma and Bootsrap while the backend was done using Javascript, Nodejs and Expressjs. For the database we used MongoDB. The entire collaboration was done on VS studio Live Share with our repo hosted on GitHub. Challenges we ran into ❌ Initially we planned to work using Jekyll, however it was scrapped midway due to inconveniencess and instead shifted our direction to generate the user posts using via our database and through routing. The filter system for communities posed a slight hurdle but was eventually overcome. Accomplishments that we're proud of 🏆 We're happy to finish within the deadline after having to rewrite a large chunk halfway through the hack and brining the functionality to life without compromise. What we learned 👨‍🔬 We learnt to incorporate MongoDB and routing using ExpressJs. We also learnt to create and work with the Heroku API. What's next for Wildernez ⏭️ We plan on scaling the application in the near future to create an enormous and sustainable support system to directly oversee rescuing of animals, protection of endangered species and improving natural habitats of various places. Built With bootstrap bulma css express.js heroku html5 javascript mongodb node.js twilio Try it out twilio-api-wildhacksii.herokuapp.com GitHub Repo Submitted to WildHacks II Created by I designed the U"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-blockchain-transaction-simulation.html",
    "project_id": "wpc-blockchain-transaction-simulation",
    "title": "WPC - Blockchain Transaction Simulation",
    "tagline": "This simulates a blockchain transaction",
    "hackathon": "",
    "built_with": [
      "javascript",
      "solidity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "What we learned How to make a blockchain transaction Built With javascript solidity Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Veerrohit Veeravadivel Aarsh Mittal"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-cryptocurrency-website.html",
    "project_id": "wpc-cryptocurrency-website",
    "title": "WPC CryptoCurrency Website",
    "tagline": "We set up our domain and made a website",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired by the cryptocurrency talk today to make a website with a small but concise summary. What it does It explains crypto simply and it looks nice. How we built it We used a little bit of JavaScript but it is mostly HTML and CSS Challenges we ran into Making the website look good Accomplishments that we're proud of Making the website look good What we learned We learned about crypto currency What's next for WPC CryptoCurrency Website Updating it with more information and more sub pages. Built With css3 html5 javascript Try it out aarshmittal.co Submitted to Global Hack Week: Web3 Created by The information Jahaanshah Sheikh I'm him. Aarsh Mittal Sepandar Farhood Sohan Bhatt Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wildaware.html",
    "project_id": "wildaware",
    "title": "WildAware",
    "tagline": "An app that logs animal sightings from an IoT integrated setup and the people living near forests",
    "hackathon": "",
    "built_with": [
      "amazon-web-services",
      "dart",
      "flask",
      "flutter",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Hack for the Wild Created by Neel Adwani yeet Avinash Upadhyaya K R",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/001/678/559/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 Inspiration Each year, there are about a million car collisions with deers, which can be deadly for the wildlife and even the passengers. Not just that, annually more than 2 million animal attacks are reported in the United States alone. To solve that, we came up with WildAware. What it does WildAware is a platform-independent application that recognizes animals from images captured by an IoT-based setup and also allows its users to log animal sightings around forest regions. The users can check for animal sightings near them and take precautions accordingly. How we built it Front-end: Flutter, Dart Back-end: Python-Flask Animal Identification: AWS Rekognition Hardware: NodeMCU, External Webcam Challenges we ran into Running the flutter app locally was a challenge which we overcame with a lot of configurations. Another challenge was calling the APIs with Flutter because of the asynchronous nature of APIs. Accomplishments that we're proud of Configuring AWS rekognition to identify wild animals along with displaying them in a cross platform mobile application is an accomplishment we are proud of. What we learned We learnt flutter and AWS Rekognition over the weekend. What's next for WildAware Having a map with all the sightings and filter them based on the animal. Notifications when the user travels to a location with a recent wild animal sighting. Built With amazon-web-services dart flask flutter python Try it out GitHub Repo GitHub Repo Submitted to sunhacks WildHacks Winner Hack for the Wild Created by Neel Adwani yeet Avinash Upadhyaya K R"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-bluest-diamond-nft.html",
    "project_id": "wpc-bluest-diamond-nft",
    "title": "WPC - Bluest Diamond NFT",
    "tagline": "We made a NFT using AI",
    "hackathon": "",
    "built_with": [
      "nft"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/578/373/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Bluest Diamond We were inspired by image generating AI's to make this. Built With nft Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/winter-find.html",
    "project_id": "winter-find",
    "title": "./WinterFind",
    "tagline": "Find your way surviving the winter",
    "hackathon": "",
    "built_with": [
      "blender",
      "next.js",
      "three.js",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Dressed Hack Created by I worked on creating the environment, adding the player animations, it's mo",
      "First Overall Winner Best Dressed Hack Created by I worked on creating the environment, adding the",
      "Hackcoming 2WinnerFirst OverallWinnerBest Dressed Hack",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/306/012/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Welcome Page WinterFind world!! Welcome Page WinterFind world!! Welcome Page 1 2 3 Inspiration We got the inspiration from brainstorming and constantly thinking about games related to winter. The idea was gotten from our childhood gaming experience from playing GTA, and we wanted to create something similar, fun and also winter-related. What it does It is a game that tells the player to find a hidden Christmas gift or object in a foggy/ snowy world. How We built it We built the app using the following languages, and framework Typescript Next.js Three.js Blender Bootstrap Challenges We ran into Learning new skills to implement the project. The most challenging part was physics logic. We have to keep track of vectors according to direction and user commands. Accomplishments that we're proud of We are proud to be able to implement this game in a short time and the fact that our studies and work weren't a hindrance in implementing this game. The game helps in relieving stress and treating depression. It helps by keeping the brain busy with fun and engaging tasks. What We Learned Heard a lot about Next.js and TS (TypeScript) but implemented it the first time. GitHub branching and merge conflict, and other frameworks/tools. What's next for ./WinterFind Improvement of the game - Planning to add more hurdles and constraints in the world map to increase the difficulty. And adding multiple items at random places. Built With blender next.js three.js typescript Try it out GitHub Repo Submitted to Hackcoming 2 Winner First Overall Winner Best Dressed Hack Created by I worked on creating the environment, adding the player animations, it's model, controllers and camera Satyam Singh Kartik Patel Nothing much..! Happiness Okeke Happiness Okeke is a software developer and content creator based in the Canada. Singh Singh"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-nft-game.html",
    "project_id": "wpc-nft-game",
    "title": "WPC - NFT Game",
    "tagline": "We made a NFT game in python",
    "hackathon": "",
    "built_with": [
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Enhance the game's interface with clearer menus, informative tooltips, and charts for tracking NFT prices."
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/579/424/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The game in action What we implemented The base game and the random system What's next for WPC - NFT Game 1. Website 2. Rarity Levels: Assign rarity levels to NFTs (common, rare, legendary, etc.), affecting their value and desirability. 3. NFT Attributes: Give NFTs unique attributes or traits that can influence their value and utility in the game. 4. Player Levels: Implement a leveling system for players based on their trading success. Higher levels can unlock special abilities or opportunities. 5. Trading Challenges: Create trading challenges or missions that players can complete for rewards. These challenges can involve buying, selling, or collecting specific NFTs. 6. Auctions and Bidding: Add an auction system where players can bid on NFTs, competing with AI-controlled or other players. Allow players to list their NFTs for auction. 7. Inflation and Deflation: Simulate economic factors like inflation and deflation that affect the value of in-game currency and NFTs over time. 8. NFT History: Display a historical price chart for NFTs, allowing players to analyze trends before making trading decisions. 9. NFT Sets and Collections: Create NFT sets or collections with bonuses for owning a complete set. This encourages players to collect entire series. 10. Competitions: Organize trading competitions or tournaments where players compete to achieve the highest returns within a time frame. 11. User Interface Improvements: Enhance the game's interface with clearer menus, informative tooltips, and charts for tracking NFT prices. 12. Virtual Economy Simulation: Develop a more intricate virtual economy that responds to player actions, supply, and demand. 13. News and Updates: Provide in-game news updates and announcements that impact the game's economy, such as developer changes, market news, or NFT releases. 14. Multiplayer Interaction: Enable multiplayer interactions, such as player-to-player trading, alliances, or negotiations. 15. AI Traders: Introduce AI-controlled trader"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-hedera-dapp.html",
    "project_id": "wpc-hedera-dapp",
    "title": "WPC - Hedera DAPP",
    "tagline": "A simple Hedera DAPP that transfers digital assets",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/577/461/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Transferring of digital assets What it does Transfers digital assets How we built it Javascript and Hedera Challenges we ran into Executing main(), we had a few issues with our syntax. What we learned Use of Hedera, and how transferring digital assets works. Built With javascript Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel Sohan Bhatt"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-dapp-with-flow.html",
    "project_id": "wpc-dapp-with-flow",
    "title": "WPC Dapp With Flow",
    "tagline": "We made a DAPP with Flow",
    "hackathon": "",
    "built_with": [
      "flow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/577/390/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "It works What it does The DAPP physically transmits the transaction to the blockchain on behalf of the user. What we learned What a DAPP is and how parts of the blockchain work Built With flow Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Veerrohit Veeravadivel Sepandar Farhood Aarsh Mittal Sohan Bhatt"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-bluest-gradient-nft.html",
    "project_id": "wpc-bluest-gradient-nft",
    "title": "WPC - Bluest Gradient NFT",
    "tagline": "We made a NFT",
    "hackathon": "",
    "built_with": [
      "nft"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/577/404/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Bluest Gradient - NFT Inspiration We wanted to be really artistic, and unique, so we made a blue gradient. What it does It is blue How we built it We made it in ms paint and took a screenshot. Challenges we ran into Making a crypto wallet Accomplishments that we're proud of Making the NFTs What we learned The worth and value of NFTs and Ethereum Built With nft Submitted to Global Hack Week: Web3 Created by I made the crypto wallet Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Sohan Bhatt Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-ethereum-app.html",
    "project_id": "wpc-ethereum-app",
    "title": "WPC - Ethereum App",
    "tagline": "We made an ethereum app",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "How we built it Javascript Challenges we ran into Windows computer wasn't allowing it to run, had to run a command  in powershell, then there were a lot of errors with App.js What we learned How to use Ethereum with truffle Built With javascript Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Aarsh Mittal Sepandar Farhood Sohan Bhatt Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-storage-integration.html",
    "project_id": "wpc-storage-integration",
    "title": "WPC - Storage Integration",
    "tagline": "We made a storage integration website using IPFS",
    "hackathon": "",
    "built_with": [
      "html5",
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/578/808/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The index.html What we learned How to make a server using IPFS Built With html5 javascript Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-programmable-wallet.html",
    "project_id": "wpc-programmable-wallet",
    "title": "WPC - Programmable Wallet",
    "tagline": "We made a programmable wallet",
    "hackathon": "",
    "built_with": [
      "curl"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/577/797/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Wallet Status User Status Wallet Status User Status Wallet Status 1 2 Challenges we ran into Switching the ETH from GOERLI to SEPOLIA. What we learned How basic programmable wallets work Built With curl Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-voting-system.html",
    "project_id": "wpc-voting-system",
    "title": "WPC - Voting System",
    "tagline": "We made a voting system",
    "hackathon": "",
    "built_with": [
      "html5",
      "javascript",
      "solidity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/579/412/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "index.html What we learned How to use Ganache properly Built With html5 javascript solidity Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-token-wallet.html",
    "project_id": "wpc-token-wallet",
    "title": "WPC - Token Wallet",
    "tagline": "We made a super sick Token Wallet",
    "hackathon": "",
    "built_with": [
      "javascript",
      "solidity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "How to integrate a tracking system as a wallet"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/578/806/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Wallet Deployed What we learned How to integrate a tracking system as a wallet Built With javascript solidity Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Aarsh Mittal Veerrohit Veeravadivel"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-wallet-integration.html",
    "project_id": "wpc-wallet-integration",
    "title": "WPC - Wallet Integration",
    "tagline": "We made a wallet integration",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5",
      "javascript",
      "solidity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Challenges we ran into Fetching and reciprocating the tokens What we learned How to integrate a wallet into an app Built With css3 html5 javascript solidity Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Veerrohit Veeravadivel Aarsh Mittal"
      }
    ]
  },
  {
    "file_path": "./devposts/xchange-vi2863.html",
    "project_id": "xchange-vi2863",
    "title": "Xchange",
    "tagline": "Trading and analyzing quantitative exchanges through AI!",
    "hackathon": "",
    "built_with": [
      "bootstrap",
      "c++",
      "css",
      "html",
      "javascript",
      "matplotlib",
      "python"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/351/605/datas/medium.jpeg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration What it does By analyzing the dataset provided by a major bank, our team looked for innovative ways to display and animate the data's progression in real time, through the different states of a stock exchange.\nThis was later completed through a complete analysis of the dataset in order to determine occurrences of anomalies in the time stamps and responses. How we built it We used C++ to analyze the datasets that were provided and parse the important components into a file, later analyzed in a live Vanilla Javascript setup. What's next for Xchange The scalability of our project renders it perfect for any real-time application which would track the transactions of an exchange platform. The anomaly detection can also further be improved, and the model refined in order to suit more cases. Built With bootstrap c++ css html javascript matplotlib python Try it out GitHub Repo Submitted to ConUHacks VII Created by Aly Shariff Michael Osuji Xin Lei Lin SarinaMashreghi Mashreghi"
      }
    ]
  },
  {
    "file_path": "./devposts/write-it.html",
    "project_id": "write-it",
    "title": "HandRight",
    "tagline": "Teaching students how to handwrite using computer vision.",
    "hackathon": "",
    "built_with": [
      "css3",
      "east-deep-learning",
      "flask",
      "google-cloud-vision",
      "html5",
      "javascript",
      "opencv",
      "python",
      "sass"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MacroTech Sponsored Prize HackMann 2020 Data Day Grind Winner Best use of Google Cloud Created by I",
      "HackMann 2020 Data Day Grind Winner Best use of Google Cloud Created by I developed the EAST deep l",
      "MacroHacksWinnerMacroTech Sponsored Prize",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/139/722/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "There is a leaderboard to see how users did in comparison to others Words are displayed on the screen. Users hold up their work to have it read If users spell the word incorrectly, they lose one of their three attempts Using Google Cloud's Handwriting Detection, we find what was written Users can write the word displayed There is a leaderboard to see how users did in comparison to others Words are displayed on the screen. Users hold up their work to have it read If users spell the word incorrectly, they lose one of their three attempts Using Google Cloud's Handwriting Detection, we find what was written Users can write the word displayed There is a leaderboard to see how users did in comparison to others 1 2 3 4 5 6 7 HandRight - HackMann 2020 Project Inspiration We were inspired to create HandRight after witnessing the struggles of parents trying to teach their their kids how to handwrite words at home firsthand. COVID-19 has especially exacerbated these difficulties as teachers and educators are unable to meet with and teach young students due to the quarantine restrictions. And with parents working full-time, students find it hard to stay motivated and are not able to practice their handwriting skills. They are left alone and with no one to guide them first hand, they are sacrificing their learning. We wanted to help struggling students deal with global education crisis. What it does HandRight is a fun and captivating game that uses computer vision to help students practice their handwriting without the presence of parents or other mentors. Furthermore, HandRight offers 3 core features: Allows students to write with real writing implements such as pens and pencils Allows students to get instant feedback (the kind they can't get from their teachers during COVID-19) Gamifies the process of handwriting by assigning scores and points, and a leaderboard, motivating students to practice How We built it We used: Flask for the backend and for handling the serving of the "
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-web3j-java-library-hack.html",
    "project_id": "wpc-web3j-java-library-hack",
    "title": "WPC- Web3j Java Library Hack",
    "tagline": "We tried to make a app that used Web3j Java Library.",
    "hackathon": "",
    "built_with": [
      "javascript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "What we learned Basic blockchain operations What's next for WPC- Web3j Java Library Hack We need to add more blockchain operations, we are planning on doing this after submission, but we still think it is a valid submission currently. Built With javascript Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Sepandar Farhood Veerrohit Veeravadivel Aarsh Mittal"
      }
    ]
  },
  {
    "file_path": "./devposts/yatraveda.html",
    "project_id": "yatraveda",
    "title": "YatraVeda",
    "tagline": "The knowledge to journey",
    "hackathon": "",
    "built_with": [
      "godaddy",
      "mongodb",
      "react",
      "twilio"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/400/086/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "The Landing Page Couch Surfers The cultural Experience Share your photo Write your experience The Landing Page Couch Surfers The cultural Experience Share your photo Write your experience The Landing Page 1 2 3 4 5 6 Inspiration The theme of this hackathon is culture and heritage, and Sanskrit is the ancient language of India. In Sanskrit, 'Yatra' means 'journey' and 'Veda' means 'knowledge'. Put together, 'YatraVeda' means 'the knowledge to journey'. Our website is centered around the same idea, which is to help travelers learn more about their journey and destination. What it does Our app is designed to help travellers gain a deeper understanding of the culture of the places they visit. We collect reviews and photos from visitors and use them to continually update our content, providing accurate and up-to-date information to future travellers. In addition to reviews and photos, we also provide access to couchsurfer profiles, which allow travellers to stay with locals and observe their lifestyle firsthand. By immersing themselves in the local culture, travellers can gain a deeper appreciation for the traditions and customs of the people in the places they visit. Our app is a valuable tool for anyone who is interested in exploring new cultures and discovering the heritage of their destinations. How we built it We're proud to say that Yatraveda, our website dedicated to helping travelers explore new cultures and destinations, was built using the powerful combination of Tailwind and React. By leveraging Tailwind's utility-first approach to CSS and React's library of user interface components, we were able to create a beautiful and responsive website that's easy to navigate and interact with. Whether you're planning your next journey or just browsing for inspiration, Yatraveda has everything you need to make the most of your travels. GoDaddyRegistry- www.yatraveda.co Challenges we ran into As we were building Yatraveda using Tailwind and React, we encountered a few cha"
      }
    ]
  },
  {
    "file_path": "./devposts/xplore-a0ozng.html",
    "project_id": "xplore-a0ozng",
    "title": "Xplore",
    "tagline": "An app designed to entice people to go outside and exercise or travel to new places by providing a points based system to compete against your friends or family to see who visits the most places.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "gemini",
      "react-native"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration We were inspired to work on this project because a lot of people nowadays are more anti-social, or have difficulty finding reasons to leave home. We wanted to create an app that gives people a fun reason to be able to go out and explore the world with their friends or family, thus helping them regain their social skills as well as improving their health via the exercise that comes with it. What it does This app will tack the location of the user and keep a collection of points for them based on various landmarks or unique locations they may have visited. They can accumulate points by checking in when they reach a new landmark, providing photo verification using the phone camera to take a picture, and in return an AI generates an interesting fun fact, as well as some other useful information about where they have arrived to. After collecting a certain amounts of points users will be able to level up and compete in leaderboards. How we built it We build this app using react-native and firebase. We created the front end pages of the app using react-native to represent each of the pages the user would be able to access, and connecting it to a firebase database system to be able to store location information as well as the photos uploaded. Challenges we ran into 2 of the 3 members of our team are brand new to working with react-native and as such ran into issues early on learning how to set up the main pages. Over time those issues became less present but there were others such as errors when attempting to access the phone camera to take and store the picture, an issue that took a decent chunk of time to fix. Accomplishments that we're proud of We are proud of being able to create a functional app in react-native, particularly since most of us have little  to no experience using it and have had prior exposure that did not go as well. We are also proud of getting the camera to operate correctly. What we learned We learned a lot about how react-native operates "
      }
    ]
  },
  {
    "file_path": "./devposts/write-it-right.html",
    "project_id": "write-it-right",
    "title": "Write It Right",
    "tagline": "A machine learning algorithm integrated into a website to provide essay grades for students and teachers",
    "hackathon": "",
    "built_with": [
      "anaconda",
      "bootstrap",
      "css",
      "github",
      "html",
      "javascript",
      "jupyter-notebooks",
      "nltk",
      "pandas",
      "python",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Overall Created by diyaaggarwal Jennifer John valivetiveda@gmail",
      "Third Place Overall Created by diyaaggarwal Jennifer John valivetiveda@gmail",
      "PixelHacks IIWinnerThird Place Overall",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/000/595/847/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Screenshot of website Inspiration We've learned from our experiences at school that essay grading today is highly inefficient and subjective. With machine learning taking on a rapidly increasing number of roles in our daily lives, we decided to implement an artificial intelligence system through machine learning to automate the essay grading process. What it does Our machine learning model is built into a simple website. Students or teachers can paste in an essay into a text box, and it is run through a robust model trained on thousands of past student essays to determine a score. Currently, it is evaluated as pass or fail to allow students to determine whether they need to spend more time on their essay. We will soon expand to produce a numerical grade on a scale from 1 to 12. How we built it The core of our model is built in Python. We used the library NLTK for the natural language processing functionality to analyze the text. We trained a decision tree model on the Kaggle Hewlett Foundation essay grading dataset for classification. All Python was done in a Jupyter Notebook through Anaconda. Our website is built in HTML, CSS, and JavaScript. We will integrate the machine learning model into an API to connect it to the website. Challenges we ran into We ran into some difficulties in training our model initially, as our accuracy was far lower than we expected. Through adding additional features for analysis and experimenting with a variety of model structures, we were able to greatly improve the accuracy. Accomplishments that we're proud of We are proud to have figured out how to successfully train a robust model despite only one team member having prior experience in machine learning. What we learned We greatly expanded our knowledge of machine learning, natural language processing, and web development. What's next for Write It Right Our number one goal is to provide more precise feedback in the form of a grade from 1 to 12. We also want to improve our overall accu"
      }
    ]
  },
  {
    "file_path": "./devposts/youcourse.html",
    "project_id": "youcourse",
    "title": "Youcourse",
    "tagline": "Youcourse aims to democratize online course creation and consumption. With Youcourse, anyone can create curated and professional courses with little effort and others can view these for free.",
    "hackathon": "",
    "built_with": [
      "mongodb",
      "netlify",
      "react",
      "tailwind"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "Art of Problem Solving Winner Echo 3D Winner Leading Learners Created by Oleks G Lino Le Van",
      "Hack the Education & BeyondWinnerArt of Problem SolvingWinnerEcho 3DWinnerLeading Learners",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "(note that the app in the \"try out link\" may not load due to MongoDB free tier limits) Inspiration When I was learning React, I spent hours browsing Youtube playlists created by programming channels and watching their \"React\" tutorials. It seemed like every playlist was missing some crucial piece of knowledge and I was forced to spend more hours picking out the right videos to watch. What if I did not have to do this. What if others could make courses composed of the right Youtube videos and articles in a progression that would allow me to learn React fully. What it does Youcourse allows anyone to build courses made from Youtube videos and text blurbs which go in progression. Users are then able to watch these courses, completely for free. As you can mix and match videos, these courses have the potential to be a lot better than those made by one source. How we built it Youcourse was built with React and Tailwind for the front-end. The back-end was done with MongoDB for the database and Netlify server-less functions for the computing. Accomplishments that we're proud of The fact that the back-end is mostly server-less is a pretty cool achievement in my opinion. I think server-less is the future of cloud-computing and if needed, this app can scale to millions of users easily... though this will cost extra of course :) What we learned I learned a lot about server-less functions and MongoDB. What's next for Youcourse We want to add the ability to add not just Youtube videos, but also videos from other sources such as Vimeo. If copyright permits, we would also like to add the ability to add other resources to the course such as articles written by others, audio files, and images. Built With mongodb netlify react tailwind Try it out youcourse.netlify.app Submitted to Hack the Education & Beyond Winner Art of Problem Solving Winner Echo 3D Winner Leading Learners Created by Oleks G Lino Le Van"
      }
    ]
  },
  {
    "file_path": "./devposts/yourdish-et79ny.html",
    "project_id": "yourdish-et79ny",
    "title": "YOURDISH",
    "tagline": "Cooking home made nutritional meals can be intimidating, so it's easy to turn to processed and fast foods. The goal of YourDish is to make cooking straightforward, all to aid the heath of the users.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/194/416/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Example of included video YourDish Home Page Example of meal details Example of region home page, in this case it's Europe Example of included video YourDish Home Page Example of meal details Example of region home page, in this case it's Europe Example of included video 1 2 3 4 5 Inspiration Cooking in general is intimidating, but throwing in a whole another culture? That's another level. I wanted it to be easy for people to experience each others cultures through food, so I wanted to make a web application which helps the user do just that. That's how I came up with YourDish! What it does YourDish first presents you with a screen that displays different regions from across the world. Once you select one, it brings you to a page filled with different foods! Hover over them, and you'll see the name of the dish and where it came from. If you click on one of them, it will bring you to a page complete with an overview, step by step process of its creation, ingredient list (With checkboxes to keep track of the ingredients you have), and a video detailing the process visually with the same ingredients. How we built it The frame and structure of the website was all done in HTML and the styling was completed using CSS. Things like buttons, text and videos were all planned out using HTML, and the banners, colours, and some positioning was sorted out using CSS. Challenges we ran into The alignment of certain elements was a bit tricky to figure out since before this I didn't really understand out to effectively do it. This lead to a lot of trail and error with my CSS and HTML so that I could put everything I wanted in the place they were supposed to be. Accomplishments that we're proud of I was very happy that I was able to put everything I had come up with in my head into the website. I was invitationally worried that it was going to take longer than expect to implement everything and that I was going to have to cut it short, but that wasn't the case at all. I was able to fi"
      }
    ]
  },
  {
    "file_path": "./devposts/zenset.html",
    "project_id": "zenset",
    "title": "Zenset",
    "tagline": "Clear your mind through expressive writing and journaling and get rewarded!",
    "hackathon": "",
    "built_with": [
      "nextjs",
      "node.js",
      "verbwire"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "All Participants Winner Most Innovative Use Of Verbwire API Created by This was a solo project! Ari",
      "Skynet Hacks v2WinnerAll ParticipantsWinnerMost Innovative Use Of Verbwire API",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/511/962/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Home Page Logo Home Page Logo Home Page 1 2 3 Inspiration:\nThe inspiration for Zenset, my solo project, came from my passion for personal development and mental well-being. I wanted to create a tool that would help individuals explore their thoughts and emotions through expressive writing as well as get rewarded for doing so. What it does:\nZenset is a web-based application that provides users with a platform for expressive writing. It allows users to engage in reflective and introspective writing exercises designed to promote self-discovery, emotional release, and personal growth. The application provides prompts and guidance to help users delve deeper into their thoughts and feelings. It also allows them to clear their mind of bad thoughts through them fading away. How we built it:\nI developed Zenset using modern web technologies. The front-end of the application was built using Next JS, while the back-end was implemented using a server-side language, Node.js. I also incorporated a localstorage database to store user-generated content securely and used Verbwire for minting NFTs. Challenges we ran into:\nDuring the development process, I faced challenges in designing an intuitive user interface that would be both visually appealing and user-friendly. I also had to overcome technical hurdles in implementing the database and using verbwire for minting NFTs since I am not experienced with blockchain. Accomplishments that we're proud of:\nI'm proud to have created an application that empowers individuals to engage in expressive writing and facilitates their personal growth. I'm also proud of the seamless integration of prompts and guidance within the platform, allowing users to navigate their writing journey effectively. What we learned:\nThroughout the development of Zenset, I gained a deeper understanding of the importance of mental well-being and the therapeutic benefits of expressive writing. I also honed my technical skills in web development, database management, and"
      }
    ]
  },
  {
    "file_path": "./devposts/wpc-web3-api.html",
    "project_id": "wpc-web3-api",
    "title": "WPC - Web3 API",
    "tagline": "We used a Web3 API in this project",
    "hackathon": "",
    "built_with": [
      "javascript",
      "solidity"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/578/370/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "We have no funds :( What we learned How to integrate an API in a Web3 project. Problems we ran into: our account has no balance, and so it should throw this exact error of insufficient funds for intrinsic transaction cost when trying to deploy my NFT smart contract. Thus, it is coded to throw this exact error (We would get it to code and actually work with funds but it is too late at night). Built With javascript solidity Try it out GitHub Repo Submitted to Global Hack Week: Web3 Created by Jahaanshah Sheikh Aarsh Mittal Veerrohit Veeravadivel Sepandar Farhood"
      }
    ]
  },
  {
    "file_path": "./devposts/zemlia.html",
    "project_id": "zemlia",
    "title": "zemlia",
    "tagline": "explore. protect. preserve.",
    "hackathon": "",
    "built_with": [
      "adobe-illustrator",
      "clerk",
      "figma",
      "flask",
      "geopy",
      "mapbox",
      "nextjs",
      "numpy",
      "opencv",
      "photoshop",
      "prisma",
      "react",
      "supabase",
      "tensorflow",
      "vercel"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/274/468/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Inspiration Living nearby to one of the most beautiful places on earth - Banff National Park makes anyone realize the value of preserving wild life. People come from all over the world not even just all over Canada to appreciate the sheer beauty of the landscape, the wildlife, the terrain, and the outdoors What it does Zemlia is a platform that lets users explore, connect, learn, and protect by discovering wildlife, engaging in discussions, and accessing expert insights. Through AI-powered species recognition, interactive maps, and conservation partnerships, we empower people to track, share, and safeguard nature. How we built it Lots and lots of Redbull. We spent hours brainstorming ideas, streamlining everyones incredible suggestions, and quantifying how much we are capable of achieving in only 24 hours. We then delegated roles to one another, and began to hack. We would check in every hour or so with one another to ensure everyone was feeling supported and on track. We'd bounce around asking for votes and opinions on every new feature we implemented, every design change we suggested, and every crash we inevitably caused. Challenges we ran into git. holy goodness git. 5 people collaborating on one single thing at the same time even with an organized structure can get chaotic when on a time constraint. Accomplishments that we're proud of Training our very own AI model (appropriately named Zemli) to characterize wildlife posts from users\nIncredibly flushed out UI and UX. With appropriate color pallete, icons, animations, transitions, all taken into account.\nMajority of our starting ideas we were able to implement into our final MVP\nDesigning a wonderful pitch deck and logo, and mockups to showcase our final product What we learned the real zemlia was the friends we made along the way. Built With adobe-illustrator clerk figma flask geopy mapbox nextjs numpy opencv photoshop prisma react supabase tensorflow vercel Try it out calgary"
      }
    ]
  },
  {
    "file_path": "./devposts/yourdish.html",
    "project_id": "yourdish",
    "title": "YOURDISH",
    "tagline": "Cooking home made nutritional meals can be intimidating, so it's easy to turn to processed and fast foods. The goal of YourDish is to make cooking straightforward, all to aid the heath of the users.",
    "hackathon": "",
    "built_with": [
      "css3",
      "html5"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/002/194/077/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Europe Cuisine Home Page YourDish Logo YourDish Home page Example of Meal details Example of video included Europe Cuisine Home Page YourDish Logo YourDish Home page Example of Meal details Example of video included Europe Cuisine Home Page 1 2 3 4 5 6 Inspiration I always felt like we as a society have started moving to the path of primarily fast food and processed meals. They are quick and easy, and you don't have to waste time finding the meal you want. We all know that it's unhealthy, so I wanted to make cooking as quick and easy as I could behind a screen. That's how I came up with YourDish! What it does YourDish first presents you with a screen that displays different regions from across the world. Once you select one, it brings you to a page filled with different foods! Hover over them, and you'll see the name of the dish and where it came from. If you click on one of them, it will bring you to a page complete with an overview, step by step process of its creation, ingredient list (With checkboxes to keep track of the ingredients you have), and a video detailing the process visually with the same ingredients. How we built it The frame and structure of the website was all done in HTML and the styling was completed using CSS. Things like buttons, text and videos were all planned out using HTML, and the banners, colours, and some positioning was sorted out using CSS. Challenges we ran into The alignment of certain elements was a bit tricky to figure out since before this I didn't really understand out to effectively do it. This lead to a lot of trail and error with my CSS and HTML so that I could put everything I wanted in the place they were supposed to be. Accomplishments that we're proud of I was very happy that I was able to put everything I had come up with in my head into the website. I was invitationally worried that it was going to take longer than expect to implement everything and that I was going to have to cut it short, but that wasn't the case at al"
      }
    ]
  },
  {
    "file_path": "./devposts/zkwhistle.html",
    "project_id": "zkwhistle",
    "title": "ZkWhistle",
    "tagline": "Uncover Truth. Remain Unseen.",
    "hackathon": "",
    "built_with": [
      "e2e",
      "midnight",
      "react.js",
      "tailwind-css",
      "vite",
      "web3",
      "zk"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/003/782/893/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "1 2 3 4 5 6 7 zkWhistle Team Name: zkWhistle Inspiration 💡 In an age where accountability is paramount, whistleblowers serve as a critical check on power. However, the profound fear of retaliation (professional, financial, and personal) systematically silences those who witness misconduct. Existing platforms often rely on centralized trust, creating single points of failure that can be compromised or censored, leaving the whistleblower exposed. We were inspired by the mathematical certainty of cryptography to re-imagine this broken model. We envisioned a system where anyone could prove the validity of a claim without ever having to prove their identity. This led us to build zkWhistle: a truly anonymous, decentralized, and censorship-resistant platform that empowers anyone to speak truth to power, backed by the unbreakable security of zero-knowledge proofs on the Midnight Network. Key Challenges Addressed: The Whistleblower's Dilemma: Fear of retaliation is the primary deterrent for reporting misconduct, creating a chilling effect on transparency. The Failure of Centralized Trust: Platforms that rely on a trusted third party are vulnerable to coercion, censorship, and data breaches. The Verifiability Paradox: Anonymity is useless if the report is not credible. We needed a way to verify the submission's integrity without compromising the source. What it does 🤔 zkWhistle is a privacy-first, anonymous reporting dApp built on the Midnight blockchain that leverages a layered privacy stack to provide mathematical guarantees of anonymity and security. Objective: To allow anyone to anonymously and securely report misconduct without fear of exposure, while ensuring the integrity, authenticity, and spam-resistance of the submitted information. Users connect their Midnight Lace wallet to a clean, intuitive interface. They can then submit a report containing text and file attachments to a designated moderator by using their public key. The entire report is end-to-end encrypted i"
      }
    ]
  },
  {
    "file_path": "./devposts/your-name-is.html",
    "project_id": "your-name-is",
    "title": "Your Name Is",
    "tagline": "Your Name Is is an enhanced web app compatible with mobile devices that identify people in real-time using artificial intelligence based on facial classification.",
    "hackathon": "",
    "built_with": [
      "apis",
      "cockroach",
      "javascript",
      "python",
      "react",
      "sql"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d2dmyh35ffsxbl.cloudfront.net/assets/shared/devpost_social_icon_200_200-f56e5af715a1d95e0209bb37e899b7c18c6e7e3b933a3c1f52456a6e2ee85d09.jpg",
    "description": [
      {
        "heading": "Description",
        "content": "Inspiration In the harsh world of networking, keeping track of every new face is daunting. Do you remember the last time you were introduced to someone new, perhaps a recruiter, and immediately both initiated an engaging conversation? How optimistic did you feel leaving that conversation? Furthermore, how disappointed did you feel when you realized you could not remember their name? That’s where Your Name Is comes into play 一 this is a solution to the endless embarrassment caused by a short memory. This real-time identification system will provide all the necessary information to maintain new acquaintances and remove this setback from the What it does This web app is a mobile device-compatible application that identifies new acquaintances using artificial intelligence with a significant focus on facial classification. The user simply opens the application on their mobile device to identify a new person and points the camera-like interface toward them. With the help of facial recognition, Google Cloud and CckroachDB, the new person will be identified in relation to their Linkedin profile. The UI will then present a pop-up containing the new person’s name, interests, position, and profile image. How we built it Our backend links to an open-source A.I. facial recognition API. The frontend interface featuring a camera was created using react. These images are pulled from the frontend are analyzed using the facial recognition API. The information which associated to the recognized figure, is stored in a CockroachDB cluster which is pulled from the database in google cloud. We principally used Javascript and node.js to connect our front and backend. Challenges we ran into We faced many challenges in selecting a facial recognition API. Many existing APIs mistake two different people as highly similar, and implementation bugs were prominent because of poor API documentation. We equally faced a challenge in uploading image files in a way that can be queried, but this was res"
      }
    ]
  },
  {
    "file_path": "./devposts/yardseller.html",
    "project_id": "yardseller",
    "title": "YardSeller",
    "tagline": "YardSeller provides a platform to easily connect with others looking to sell things in your neighborhood, bringing the classic yard sale into the digital world.",
    "hackathon": "",
    "built_with": [
      "firebase",
      "firestore",
      "scss",
      "svelte",
      "sveltekit",
      "typescript"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [],
    "won": false,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_photos/002/621/311/datas/medium.png",
    "description": [
      {
        "heading": "Description",
        "content": "Listing item individual view User profile page Home (currently pretty much same as explore) Explore/search page Listing item individual view User profile page Home (currently pretty much same as explore) Explore/search page Listing item individual view 1 2 3 4 Inspiration I was inspired to make this by the large amount of old things I have, but the relative difficulty in getting rid of them due to the effort it takes to setup a yard sale. What it does YardSeller currently lists various items that people are looking to sell. How we built it I built YardSeller using SvelteKit, Typescript, and Firebase. Challenges we ran into Initially, I planned to use React Native, but to do unresolved issues, I had to migrate to using SvelteKit. In addition, some of the methods that I had planned to use were not built into Firebase SDK, so I had to improvise. Accomplishments that we're proud of Having a mostly completed app including the rewrite from one codebase to another was one of the main accomplishments. What we learned I learned how to effectively use SvelteKit and new ways of storing data in Firestore in this project. What's next for YardSeller I plan to add more search options, primarily filtering by location, and an in-app transaction system. Built With firebase firestore scss svelte sveltekit typescript Try it out GitHub Repo Submitted to ChargerHacks 2023 Created by Redger Xu"
      }
    ]
  },
  {
    "file_path": "./devposts/zentube.html",
    "project_id": "zentube",
    "title": "ZenTube",
    "tagline": "In your flow, always learning. 👼",
    "hackathon": "",
    "built_with": [
      "assemblyai-sdk",
      "docker",
      "figma",
      "firebase",
      "flask",
      "gcp",
      "huggingface",
      "javascript",
      "nginx",
      "node.js",
      "python",
      "pytorch",
      "react",
      "tailwind",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "MetroHacks 2021Winner1st Place",
      "Winner"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/749/268/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 Inspiration 💡 When was the last time you read a book? Not a required book, but one just for your personal enrichment? With more than a billion hours of Youtube Videos being streamed every day and more than 720,000 hours of content being uploaded daily , we are in the midst of a digital age where the way we learn has completely changed. Millions of daily Youtube Users are faced with an inexhaustible amount of content. Many are on YouTube for entertainment purposes, but according to a Pew Research Study, 50% of Americans use Youtube for educational purposes . This means, in the US alone, around 98.5 Million users need a way to learn more in a shorter period of time. If you want to be in control of your life, if you hate wasting time and like concise, precise, and relevant information, and if you want to optimize how you learn so you can quickly use your knowledge in the real world, zone in on ZenTube . Let's make that Happen! ✨ So what’s the app about? 🤔 ZenTube condenses the information within a YouTube Video so that you can learn, develop, and master skills more efficiently! By generating the video transcript , a concise video summary , and time-stamped key points , you don't need to watch the entire video to gain a good understanding of the subject matter. If you want to dive deeper, then you can directly ask specific questions and the application will answer the inquires based on the information inside the YouTube Video . We not only save your valuable time but also enable you to silence the noise by making the content inside videos digestible and searchable. Stay calm and Study on! 🚀 Tech Stack 🏗 First and foremost, it is Crafted with 💙.\nFor the front-end, we’ve used React.js & Tailwind as a CSS framework. The Authentication (OAuth) is done through Firebase & we also used Cloudstore database to store user logs. Using Python as the root language for creating the ML model, it was fed using a few different libraries such as Numpy , Pandas & Keras w"
      }
    ]
  },
  {
    "file_path": "./devposts/ziro.html",
    "project_id": "ziro",
    "title": "Ziro",
    "tagline": "Ensure 𝐙𝐞𝐫𝐨 𝐏𝐥𝐚𝐠𝐢𝐚𝐫𝐢𝐬𝐦 using Ziro via Decentralized Blockchain Technology 🛡️⛓️",
    "hackathon": "",
    "built_with": [
      "blockchain",
      "chakra",
      "express.js",
      "firebase",
      "ipfs",
      "javascript",
      "python",
      "react",
      "router",
      "tensorflow"
    ],
    "team_members": [],
    "team_usernames": [],
    "awards": [
      "ML/AI Hack Created by Nghi (Hailey) Ho Pratyay Banerjee Trying to learn how to learn ;) Jia Yue Wu",
      "Best ML/AI Hack Created by Nghi (Hailey) Ho Pratyay Banerjee Trying to learn how to learn ;) Jia Yu",
      "Hacktech 2022WinnerBest ML/AI Hack",
      "First and foremost, it is Crafted with 💙. The whole process can be broken into the following points :-",
      "Winner",
      "P.S. > We also won the \"1517 Grant\" prize beside the \"Best ML/AI hack\" track prize!"
    ],
    "won": true,
    "thumbnail": "https://d112y698adiu2z.cloudfront.net/photos/production/software_thumbnail_photos/001/860/711/datas/medium.gif",
    "description": [
      {
        "heading": "Description",
        "content": "GIF GIF 1 2 3 4 5 Inspiration 💡 E-Learning has become the new normal in this Pandemic era & online classes and assignments have become a part & parcel to every student. Unfortunately, this has immensely increased the rate of plagiarism in homework and assignment submissions. Enforcing academic honesty has become a nightmare for educators worldwide, and unfortunately, even at Caltech. Professors and TAs simply cannot verify the originality of each and every submitted file manually. In an online learning environment, educators are not able to supervise students as closely as it is commonly done in a physical classroom setting. It has triggered a rise in academic misconduct, with plagiarism at the forefront of this broader problem which is hindering academic integrity. Today, plagiarism is more than just about copying and pasting chunks of text from other sources. — NYTimes, 2021 We did not build a \"plagiarism checker.\" Current plagiarism detection tools infringe on intellectual property or lack file submission security. Rather, we aim to innovate a revolutionary tool that helps teachers and students improve the online learning experience by ensuring Zero Plagiarism backed by Decentralized Blockchain Technology . Thus, we built Ziro ✨ What it does 🤔 The primary goal of Ziro is to prevent active plagiarism by leveraging novel cutting edge-technologies. The whole process can be broken down into the following points :- Users (students or teachers) log in using Google's Single Sign-On (SSO). We ask for minimal identifying information, respecting privacy and safety. Teachers and students have separate user flows, tutorials, and privilege scopes. Users can see the active students enrolled in a specific class on their dashboard. Students can upload their homework/assignments in any format (including common .pdf / .jpg / .png extensions) The files are stored on a Decentralized platform via IPFS which are guided via dynamically generated smart contracts . Once the above is done"
      }
    ]
  }
]